[
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 45000,00 Euros à 55000,00 Euros",
        "company": "AVA6 ",
        "location_raw": "LIMONEST",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 2 An(s)",
        "experience": "2 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-09",
        "company_data": {
            "sector": "Conseil en systèmes et logiciels informatiques",
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1991390",
        "description": "Ton défi en tant que Data Engineer sera de répondre aux missions suivantes :     Construire      et optimiser des pipelines de données : extraction, transformation, ingestion et stockage des      données.   Assurer      la fiabilité et la performance des systèmes data : supervision,      monitoring, sauvegardes et documentation.   Automatiser      et industrialiser : mise en place de solutions CI/CD, infrastructure as      code et tests automatisés.   Gérer      les bases de données et les entrepôts data : implémentation et optimisation      (Snowflake, BigQuery, Redshift, Databricks).   Collaborer      avec les équipes Data Science et DevOps pour garantir l'intégration des modèles      et leur exploitation efficace.   Veille      technologique et amélioration continue : participation aux choix      technologiques et à l'évolution des architectures.  \n\n     \n\n  \n Issu(e) d'une formation orientée en systèmes d'information, tu disposes d'une expérience de minimum 3 ans sur un poste équivalent.   Tu maîtrises les éléments suivants :      Compétences techniques :    Maîtrise des langages : Python, SQL, Scala.    Expertise en pipelines de données et ETL : Airflow, Talend, DBT.    Expérience sur AWS, Azure et/ou GCP.    Connaissances en Spark, Hadoop, Kafka et bases de données cloud (Snowflake, BigQuery, Redshift, Databricks).    Approche DevOps & automatisation : CI/CD, Terraform, Docker, Kubernetes.   \n\n    Soft skills :    Esprit analytique et capacité à résoudre des problèmes complexes.    Expérience en méthodologies agiles.    Autonomie, rigueur et esprit d'initiative.    Capacité à travailler en équipe et à accompagner des projets clients.   \n\n   \n\n  Tu es passionné(e) par l'innovation, tu as un bon sens du service et une belle capacité d'écoute.",
        "ft_reference": "1991390",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "Snowflake",
                "BigQuery"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "CI/CD",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer confirmé(e) Services Financiers Lille (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "MARQUETTE LEZ LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1985202",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.The world is how we shape itLa division « Banque » s'est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.Description du posteAu sein d'une Data Factory, vous êtes pleinement impliqué(e) dans toutes les phases de nos projets pour le compte de grands clients, contribuant ainsi à leur succès.Vous avez l'occasion de développer vos compétences techniques et fonctionnelles de manière approfondie, tout en travaillant sur des projets exigeants et passionnants pour le compte de grands clients du secteur bancaire.C'est tentant non ? Alors embarquez pour une nouvelle aventure professionnelle !Vos missions :Rattaché(e) à la division  « Banque », vous évoluez dans un environnement challengeant et convivial, entouré(e) de passionnés dotés d'expertises dans leurs domaines.En tant que Data Engineer, vous évoluez sur des projets IT à forte valeur ajoutée et avez pour rôle la mise en place de pipelines de données fiables, sécurisés et à l'échelle pour soutenir la mise à disposition des données aux cas d'usage métier qui en ont besoin.\nVos activités principales sont les suivantes :Vous travaillez avec le client pour évaluer, concevoir, déployer, améliorer et maintenir les pipelines de données Vous vous assurez que les pipelines de données créés sont résilients, sécurisés et accessibles Vous définissez le modèle opérationnel pour monitorer et supporter les pipelines de données Vous fournissez une expertise à nos clients sur leurs données pour assurer leur optimisation et leur sécurité par rapport à leurs besoins Vous apportez un savoir en gestion de la qualité et la gouvernance de la donnée pour assurer le suivi de la conformité à la gouvernance de la donnée Vous faites de la veille technologique dans le domaine afin d'enrichir les roadmaps technologiques et fournir des solutions modernes à nos clients.QualificationsVotre profil :Diplômé(e) d'une formation supérieur en informatique type Bac + 5 (école ingénieur, université ou équivalent), vous avez déjà acquis une expérience significative en data engineer.Vous avez au moins l'une de ces compétences requises :Maîtrise des technologies de bases de données Relationnelles et NoSQLMaîtrise d'au moins un outil d'ETL/ELT (Stambia, Informatica, Datastage, etc.)Maîtrise des technologies de traitement distribué de données (Spark, Hadoop)Maîtrise d'au moins un framework de streaming de données (Kafka, RabbitMQ, etc.)Maîtrise de chaines CI/CD et de des bonnes pratiques de DataOpsMaîtrise de solution de Virutualisation de données (Denodo, Dremio, etc.)Maîtrise d'au moins un environnement cloud public ou privé (Azure, AWS, Outscale, etc.)Vous avez développé de solides compétences en matière d'autonomie, d'adaptabilité et de communication.Informations supplémentairesLes avantages à nous rejoindre :Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor que vous choisissez.Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble. Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire «Vendredi »L'opportunit¿",
        "ft_reference": "1985202",
        "skills": {
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "CLERMONT FERRAND 63",
        "location": "63",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1985084",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Atos recherche actuellement des profils :  Vous êtes à la recherche d'un défi à la hauteur de vos talents de codeur ? Rejoignez-nous en tant que Data Engineer Le poste en quelques mots : En tant que Data Engineer vous jouerez un rôle central dans la structuration, l'analyse et l'exploitation des données. Votre mission consistera à concevoir, développer et optimiser des solutions de gestion et d'analyse de données, en étroite collaboration avec nos équipes interdisciplinaires, afin de répondre efficacement aux besoins spécifiques de nos clients.¿ Ce que vous allez faire si vous nous rejoignez : La conception et le développement de pipelines de données efficaces et évolutifs.L'industrialisation et la mise en exploitation de modèles de machine learning, en assurant leur intégration fluide dans l'architecture de données existante.Mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud pour les projets stratégiques de nos clients.  Environnement technique : Outils utilisés : suite Azure, Databricks, Datafactory, Power BI, LogicapsLangages utilisés : Spark et en Python¿ ",
        "ft_reference": "1985084",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Machine Learning",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Confirmé - Dijon (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "DIJON 21",
        "location": "21",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1985046",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Capgemini recherche actuellement des profils :  En tant que Data Engineer Confirmé, vous évoluerez chez un de nos clients à Dijon dans des secteurs d'activités variées (bancaire, automobile, industrie, public...), vos responsabilités principales seront les suivantes :",
        "ft_reference": "1985046",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer - Services Financiers - Nantes (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983350",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.The world is how we shape itDescription du posteLa division « Services Financiers » de Sopra Steria se concentre sur la banque de détail, la banque privée et les services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA et Cloud. Nous accompagnons la transformation de nos clients dans les domaines des Crédits, Risques/Conformité et Moyens de Paiement.Composée d'environ 100 Data Ingénieurs, vous y rencontrerez des experts en Plateforme de Données, Data Architectes et autres spécialistes de la valorisation de la donnée.Vous serez accompagné(e) dans le développement de vos connaissances à travers divers parcours Data : ingestion, construction de datahub, transformation et valorisation de la donnée, modélisation et mise à disposition. Rejoindre la Data Factory Sopra Steria, c'est intégrer une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence, vous participezp>La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;La mise en œuvre de solutions d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;Le traitement de la donnée jusqu'à l'exposition au métier ;La mise en place de la chaine CI/CD et de sa supervision ;La veille technologique avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, RQualificationsVotre profil :Diplômé(e) d'une école d'Ingénieurs ou formation équivalente, vous avez déjà participé à un projet Data (Big Data, BI) et vous avez une expérience de minimum 3 ans sur un poste similaire.Vous accordez une importance particulière au développement de vos compétences sur plusieurs technologies. Vous souhaitez une évolution réelle de carrière à travers l'expérience projet.Vous êtes soucieux(se) de l'apport de valeur pour vos clients.Vous voulez transmettre votre savoir auprès de collaborateurs moins expérimentés.Alors, n'attendez-plus, ce poste est fait pour vous !#LI-HYBRID  #NANTESInformations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Des centaines de formations pour développer vos compétences et évoluer au sein du GroupeDes plateformes de formations en autonomie pour préparer vos certifications et accompagner votre développement personnelLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encoreli>Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements",
        "ft_reference": "1983350",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Databricks"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Nos missions :\nMichael Page recrute des cadres confirmés en CDI et CDD grâce à l'expertise de consultants répartis au sein de 17 divisions spécialisées : Achats & Logistique, Assurance, Audit, Conseil & Expertise, Banque, Commercial, Digital, Médias & Communication, Distribution & Commerce, Finance & Comptabilité, Hôtellerie & Tourisme, Immobilier & Construction, Ingénieurs, Juridique & Fiscal, Marketing, Public & Parapublic, Ressources Humaines, Santé et Systèmes d'Informat...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982885",
        "description": "Notre client, acteur de référence dans le secteur du tourisme en ligne, se distingue par son savoir-faire dans la conception et la distribution de séjours sur mesure.\nGrâce à une stratégie de croissance dynamique et des investissements dans l'innovation, l'entreprise est aujourd'hui un leader incontournable, rassemblant plus de 800 Collaborateurs.\nPour accompagner son développement et exploiter pleinement le potentiel de ses données, elle souhaite renforcer ses équipes en recrutant un Data Engineer, chargé de contribuer à des projets stratégiques et à l'optimisation de son infrastructure data.\nPoste situé en plein centre de Paris.Directement rattaché au Responsable Data de l'entreprise, vous participez à l'amélioration des enjeux de l'utilisation des données au sein de la société :\nVous aurez donc pour mission de :\nAssurer la maintenance et l'évolution des chaînes de traitement existantes (SSIS, SnowSQL, Python) tout en garantissant la qualité et la disponibilité des données,\nFinaliser la migration des anciens processus de traitement (SQL Server) vers une architecture moderne basée sur un datalake,\nCollaborer avec les équipes métiers lors d'ateliers pour recueillir les besoins, définir des solutions efficaces et pérennes,\nDévelopper de nouveaux processus de traitement pour intégrer des données supplémentaires via des approches variées (Batch, API),\nConcevoir et implémenter des règles métier afin de structurer les tables et les vues répondant précisément aux attentes exprimées,\nValider les données en collaboration avec les Product Owners et les équipes métiers pour garantir leur conformité.\nDévelopper des algorithmes avancés selon les besoins\nProcessus de recrutement :\nPremier échange avec un recruteur,\nUn échange avec le responsable Data et la Manager de l'équipe,\nEntretien sur site avec deux personnes de l'équipe.\n1 jour de télétravail,\nAvantages d'un grand Groupe,\nRéductions sur les voyages proposés par le Groupe.",
        "ft_reference": "1982885",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data & Integration Engineer H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ORLY 94",
        "location": "94",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Nos missions :\nMichael Page recrute des cadres confirmés en CDI et CDD grâce à l'expertise de consultants répartis au sein de 17 divisions spécialisées : Achats & Logistique, Assurance, Audit, Conseil & Expertise, Banque, Commercial, Digital, Médias & Communication, Distribution & Commerce, Finance & Comptabilité, Hôtellerie & Tourisme, Immobilier & Construction, Ingénieurs, Juridique & Fiscal, Marketing, Public & Parapublic, Ressources Humaines, Santé et Systèmes d'Informat...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982773",
        "description": "Notre client est un Groupe mondial qui se distingue par son approche dynamique et innovante dans le secteur du transport de passagers. En pleine expansion, il cherche à attirer des talents prêts à contribuer à leur succès. L'entreprise compte  collaborateurs et la DSI est composée de 70 collaborateurs répartis en 6 directions.\nProcessus de recrutement :\nEntretien 1 avec RH et Responsable Data (N+1) par Teams,\nEntretien 2 avec le Responsable Data dans les locaux.\nLe poste est à pourvoir en CDI en interne, directement chez le client final.  En tant que Data &amp; Integration Engineer, vous êtes rattaché au Responsable Data (N+1) et travaillez dans l'équipe Data &amp; Integration au sein de laquelle de gros enjeux et projets sont à gérer. Dans votre rôle de Data &amp; Integration Engineer, vos principales missions seront les suivantes :\nGestion des projets d'intégration : Vous serez responsable de l'intégration des systèmes en veillant à respecter des critères stricts de disponibilité, de fiabilité et de résilience. Pour ce faire, vous appliquerez des modèles d'architecture éprouvés comme par exemple « Message Broker »,\nAPI : vous mettrez en place une solution complète d'API Management, incluant la création d'un catalogue d'API,\nSupervision des flux de données : Vous prendrez en charge la recette des flux et assurerez leur suivi en production, en résolvant les incidents qui pourraient survenir,\nSupport technique sur les architectures Cloud Azure : Vous fournirez des conseils techniques sur les architectures Cloud, en collaborant étroitement avec les fournisseurs de solutions et les consultants externes,\nAmélioration continue des processus : Vous travaillerez sur l'optimisation des processus internes, notamment la localisation et la traçabilité des données, la standardisation des flux de données et la documentation associée,\nCollaboration avec les équipes internationales.\nPrime sur objectifs représentant 7,5% de la rémunération fixe brut annuelle,\n2 jours de télétravail/semaine,\nRemboursement de la carte Navigo à hauteur de 80% ou défraiement kilométrique,\nTickets restaurants,\nAvantages conséquents sur les transports,\nRTT,\nCE intéressant (300€/an).",
        "ft_reference": "1982773",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "Teams"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Senior - H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1981559",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Groupe Iliad - Free recherche actuellement des profils :  &lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Dans le cadre du d&amp;eacute;veloppement et de la structuration de l&amp;rsquo;activit&amp;eacute; Data au sein du &lt;strong&gt;p&amp;ocirc;le Audiovisuel&lt;/strong&gt; de Free, nous recherchons un(e) Data Engineer senior pour prendre une part active &amp;agrave; la collecte, l&amp;rsquo;&amp;eacute;tude et l&amp;rsquo;analyse de la &lt;strong&gt;consommation audiovisuelle des abonn&amp;eacute;s Free&lt;/strong&gt; dans le but d&amp;rsquo;am&amp;eacute;liorer le service et de personnaliser l&amp;rsquo;exp&amp;eacute;rience utilisateur.&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Vos&lt;/strong&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt; &lt;/span&gt;&lt;strong&gt;missions &lt;/strong&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;:&lt;/span&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;1&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;G&amp;eacute;rer la plateforme de &lt;/span&gt;&lt;strong&gt;r&amp;eacute;cup&amp;eacute;ration des donn&amp;eacute;es de consommation&lt;/strong&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt; provenant de l&amp;rsquo;ensemble des devices (box Internet, mobile, tablette, web, &amp;hellip;)&lt;/span&gt;&lt;/li&gt;\n&lt;ul&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;2&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Int&amp;eacute;gration de nouveaux devices ou modes de consommation&lt;/span&gt;&lt;/li&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;2&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Enrichissement des &amp;eacute;v&amp;eacute;nements&amp;nbsp;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;2&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Coordination des d&amp;eacute;ploiements avec l&amp;rsquo;&amp;eacute;quipe Infrastructure&lt;/span&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;1&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Concevoir, d&amp;eacute;velopper, mettre en production et g&amp;eacute;rer les &lt;/span&gt;&lt;strong&gt;pipelines d&amp;rsquo;ETL&lt;/strong&gt;&lt;/li&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;1&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Mettre en place des solutions de &lt;/span&gt;&lt;strong&gt;monitoring&lt;/strong&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt; et assurer la &lt;/span&gt;&lt;strong&gt;qualit&amp;eacute; des donn&amp;eacute;es&lt;/strong&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Stack Data:&amp;nbsp; Python, SQL, Clickhouse, PostgreSQL, Docker, Grafana, Sentry&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Infra Data: Self hosted sur serveur d&amp;eacute;di&amp;eacute; et/ou Cloud priv&amp;eacute;&lt;/span&gt;&lt;/p&gt;\n&lt;p&gt;&lt;strong&gt;Notre &amp;eacute;quipe Data :&lt;/strong&gt;&lt;/p&gt;\n&lt;ul&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;1&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Un Lead Data&lt;/span&gt;&lt;/li&gt;\n&lt;li style=&quot;font-weight: 400;&quot; aria-level=&quot;1&quot;&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Un(e) Data Engineer (en cours de recrutement)&lt;/span&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;p&gt;&lt;span style=&quot;font-weight: 400;&quot;&gt;Vous serez &amp;eacute;galement amen&amp;eacute;(e) &amp;agrave; &lt;strong&gt;collaborer&lt;/strong&gt; avec les&lt;strong&gt; autres &amp;eacute;quipes&lt;/strong&gt; chez OQEE by Free ( Back-End, Web, Android, iOS, &amp;hellip;), ainsi qu&amp;rsquo;avec les &lt;strong&gt;&amp;eacute;quipes Data du groupe Iliad&lt;/strong&gt; (data engineers, data scientists, data analysts).&lt;/span&gt;&lt;/p&gt;",
        "ft_reference": "1981559",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer junior f/h (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "FRANCE",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1957991",
        "description": "Safran est un groupe international de haute technologie opérant dans les domaines de l'aéronautique (propulsion, équipements et intérieurs), de l'espace et de la défense. Sa mission : contribuer durablement à un monde plus sûr, où le transport aérien devient toujours plus respectueux de l'environnement, plus confortable et plus accessible. Implanté sur tous les continents, le Groupe emploie 92 000 collaborateurs pour un chiffre d'affaires de 23,2 milliards d'euros en 2023, et occupe, seul ou en partenariat, des positions de premier plan mondial ou européen sur ses marchés. Safran s'engage dans des programmes de recherche et développement qui préservent les priorités environnementales de sa feuille de route d'innovation technologique.\n\nSafran est la 1ère entreprise du secteur aéronautique et défense du classement « World's Best Companies 2023 » du magazine TIME.\n\n\n\nSafran Electronics & Defense est une entreprise internationale de plus de 12 000 collaboratrices et collaborateurs, qui mobilisent expertises et esprit de corps pour concevoir des solutions de haute technologie dans les domaines de l'aéronautique, de la défense et du spatial. En combinant intelligence humaine et technologique, l'entreprise développe les produits et services pour aider les acteurs civils et militaires à observer, décider et guider sur terre, en mer, dans le ciel et dans l'espace. Et ainsi contribuer à un monde plus sûr.\n\n\nDescriptif missionAu sein de la direction Achats SED, dans le pôle data du département Méthodes et outils, votre mission consiste à collecter, préparer, mettre en qualité, sécuriser et faire converger les données achats SED afin de les mettre à disposition des data analysts et data scientists et accompagner la transformation data des équipes.",
        "ft_reference": "1957991",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data steward / engineer f/h (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "FRANCE",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1956482",
        "description": "Safran est un groupe international de haute technologie opérant dans les domaines de l'aéronautique (propulsion, équipements et intérieurs), de l'espace et de la défense. Sa mission : contribuer durablement à un monde plus sûr, où le transport aérien devient toujours plus respectueux de l'environnement, plus confortable et plus accessible. Implanté sur tous les continents, le Groupe emploie 92 000 collaborateurs pour un chiffre d'affaires de 23,2 milliards d'euros en 2023, et occupe, seul ou en partenariat, des positions de premier plan mondial ou européen sur ses marchés. Safran s'engage dans des programmes de recherche et développement qui préservent les priorités environnementales de sa feuille de route d'innovation technologique.\n\nSafran est la 1ère entreprise du secteur aéronautique et défense du classement « World's Best Companies 2023 » du magazine TIME.\n\n\n\nMotoriste aéronautique depuis plus de 110 ans, Safran Aircraft Engines, conçoit, développe, produit et commercialise, seul ou en coopération, des moteurs pour avions civils et militaires.\n\n\nDescriptif missionContexte\n\nLes projets d'usine 4.0 engendrent des transformations technologiques et humaines dans nos entreprises.\n\nSafran Aircraft Engines est engagé dans ces transformations et doit répondre à de nouveaux challenges et besoins.\n\n\n\nVous voulez faire partie de la transformation digitale de Safran Aircraft Engines ?\n\n\n\nVous intégrerez une équipe pluridisciplinaire dans le domaine du Manufacturing Data et de la transformation digitale avec laquelle vous travaillerez en étroite collaboration.\n\n\n\nVous serez amené à travailler sur tous les aspects de la Data dans le domaine du Manufacturing 4.0.\n\n\n\n\n\nDescription de la mission\n\nNous recherchons une personne remplissant à la fois le rôle de Data Steward et de Data Engineer passionnée pour rejoindre notre équipe dynamique. En tant que membre de notre service, vous serez intégré(e) à une équipe engagée et aurez un rôle essentiel dans le maintien en condition d'exploitation de nos systèmes, tout en participant activement à des projets de transformation et d'évolution.\n\n\n\nVous serez également amené(e) à réaliser des missions tant en interne qu'en externe, notamment chez nos fournisseurs, pour effectuer des audits de la qualité des données. Dans ce cadre, vous aurez l'opportunité de formuler des recommandations pertinentes et de concevoir des dashboards afin de visualiser et analyser les données de manière efficace.",
        "ft_reference": "1956482",
        "skills": {
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data & Integration Engineer H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 48000,00 Euros à 50000,00 Euros",
        "company": "MICHAEL PAGE ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 1 An(s)",
        "experience": "1 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": "Affrètement et organisation des transports",
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1953315",
        "description": "En tant que Data & Integration Engineer, vous êtes rattaché au Responsable Data (N+1) et travaillez dans l'équipe Data & Integration au sein de laquelle de gros enjeux et projets sont à gérer. Dans votre rôle de Data & Integration Engineer, vos principales missions seront les suivantes : \n * Gestion des projets d'intégration : Vous serez responsable de l'intégration des systèmes en veillant à respecter des critères stricts de disponibilité, de fiabilité et de résilience. Pour ce faire, vous appliquerez des modèles d'architecture éprouvés comme par exemple « Message Broker »,\n * API : vous mettrez en place une solution complète d'API Management, incluant la création d'un catalogue d'API,\n * Supervision des flux de données : Vous prendrez en charge la recette des flux et assurerez leur suivi en production, en résolvant les incidents qui pourraient survenir,\n * Support technique sur les architectures Cloud Azure : Vous fournirez des conseils techniques sur les architectures Cloud, en collaborant étroitement avec les fournisseurs de solutions et les consultants externes,\n * Amélioration continue des processus : Vous travaillerez sur l'optimisation des processus internes, notamment la localisation et la traçabilité des données, la standardisation des flux de données et la documentation associée,\n * Collaboration avec les équipes internationales.\nLe profil recherché nécessite un Diplôme Bac +5 minimum (école d'Ingénieur ou université avec cursus informatique), avec au moins 3 ans d'expérience en tant qu'Ingénieur Data, avec idéalement de la production et de l'intégration. Une excellente maîtrise de l'utilisation des API (REST, SOA) est requise.\nIl doit avoir une bonne maîtrise des services Azure : Logic Apps, API Management, Service Bus, Event Grid, Application Insights, Azure Monitoring, Azure Functions, Data Factory, Azure SQL. Il doit également avoir un bon niveau d'anglais pour échanger régulièrement avec les équipes internationales. Des compétences en langage SQL et en programmation (Python et PowerShell) seraient un réel atout.\n* Prime sur objectifs représentant 7,5% de la rémunération fixe brut annuelle,\n * 2 jours de télétravail/semaine,\n * Remboursement de la carte Navigo à hauteur de 80% ou défraiement kilométrique,\n * Tickets restaurants,\n * Avantages conséquents sur les transports,\n * RTT,\n * CE intéressant (300€/an).",
        "ft_reference": "1953315",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer/Python (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 34000,00 Euros à 60000,00 Euros",
        "company": "SOPHIA CONSEIL ",
        "location_raw": "VALBONNE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 2 An(s)",
        "experience": "2 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": "Programmation informatique",
            "company_size": "Sophia transforme depuis 2005 les idées en réalité industrielle. La culture Sophia labellisée Great Place To Work libère l'énergie et accélère l'innovation.\n\nNous sommes multi métiers, multi secteurs, et multi mode d'intervention, de l'ingénieur avec engagement de moyen, à l'équipe intégrée engagée sur le résultat, des études jusqu'à la livraison du produit, de système, ou sous-système complet.",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1953195",
        "description": "Poste :Dans le cadre de l'évolution de notre SI et dans l'environnement de la data et du décisionnel (BI), votre mission sera placé sous la responsabilité d'un chef de projet:\n\n· Développer ou faire évoluer des scripts manipulant les données\n· Automatiser les chaines de traitement et de supervision\n· Développer selon les standards de Qualité et de Performance\n· Participer à la validation du livrable en assurant les ajustements nécessaires\n· Participation aux rituels du Agile/Kamban\n· Produire la documentation logicielle nécessaire\n· Participer au maintien en condition opérationnelle des applicatifs\n· Respecter les Politiques de Sécurité du SI et RGPD\nTitulaire d'un bac + 5 et une expérience d'au moins 2 ans sur un poste de data engineer.\n\n· Maîtrise des technologies et frameworks : Python ,SQL\n· Maîtrise des outils de construction logiciel: Git, \n· Pratique des méthodologies agiles \n· Connaissance d'un outil d'orchestration de type Airflow serait un plus\n· Pratique d'ETL serait un plus\n· Expériences de gestion des performances seraient un plus\n\nQualités requises :\n· Capacité à travailler en équipe\n· Bonnes connaissances sur la mise en place de pipeline de données\n· Bonne communication écrite et orale\n· Pragmatique, force de proposition, rigueur, méthodologie\n· Intérêt pour les nouvelles technologies en général\n\nDoté d'un excellent relationnel, dynamique et curieux, vous appréciez le travail en équipe.\n\n \n\n \n\nProfil : Sophia Engineering est engagée dans la lutte contre les discriminations et la promotion de l'égalité des chances.",
        "ft_reference": "1953195",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Git"
            ],
            "Automation": [
                "Airflow",
                "Chef"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Expérimenté H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 60000,00 Euros à 65000,00 Euros",
        "company": "MICHAEL PAGE ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 1 An(s)",
        "experience": "1 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": "Commerce de détail d'habillement en magasin spécialisé",
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1951513",
        "description": "Missions : \n * Concevoir, développer et maintenir des pipelines de données robustes et évolutifs en utilisant les services et les outils GCP tels que BigQuery, Pub/Sub, Cloud Storage, Cloud Composer etc.\n * Mettre en place des processus de transformation et de contrôle des données pour garantir leur qualité et leur cohérence. Utiliser des langages de programmation tels que SQL et Python et des outils tels que DBT pour effectuer des opérations de transformation et d'enrichissement des données, d'agrégation pour alimenter les cas d'usages métier,\n * Analyser les performances des pipelines de données, identifier les dérives et proposer des améliorations pour optimiser les temps de traitement et assurer une scalabilité adéquate,\n * Rédiger la documentation technique (spécifications, documents d'exploitation.) afin d'assurer la capitalisation,\n * Mettre en place des pipelines CI/CD pour automatiser le déploiement, les tests, et la gestion des développements,\n * Travailler en étroite collaboration avec les squads big data, les équipes de l'intégrateur et de la DSI ainsi que les métiers pour comprendre leurs besoins en matière de données,\n * Contribuer au support de production, à la correction des incidents et des anomalies, implémenter les évolutions fonctionnelles et techniques pour garantir la stabilité des traitements en production.\nVous cumulez un minimum de 4 ans d'expérience, avec une expertise spécifique sur GCP sur des projets data intégrant d'importants volumes de données : \n * Solides compétences en développement et en mise en œuvre de pipelines de données sur GCP, en utilisant des services tels que Cloud Storage, BigQuery, Pub/Sub, Cloud Composer et des outils tels que DBT,\n * Maîtrise des langages de programmation tels que Python et SQL,\n * Maîtrise des pratiques DevOps, du CI/CD et de l'IaC,\n * Avoir travaillé dans le monde du retail est un réel plus.\n* Télétravail de deux jours,\n * Un poste évolutif,\n * Un environnement de travail bienveillant et agréable.",
        "ft_reference": "1951513",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer DBT F/H (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "CGI FRANCE ",
        "location_raw": "TOURS",
        "location": "37",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949651",
        "description": "Data Engineer DBT F/HDescription du poste :Big Data, Data Science, Data analyse, Data architecture,IA ... Ça n'a pas de secret pour vous?\nQue vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l'une de ces disciplines, intégrer notre communauté Data, c'est l'assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.\n\nRejoignez notre centre d'excellence en innovation à Tours et rendez unique l'expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, RPA, data, développement web et mobile, API management ou encore cybersécurité.Fonctions et responsabilités :Vous êtes passionné par le Décisionnel et la Data et avez déjà une première expérience sur l'outil DBT. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l'innovation (> 400 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d'autres outils Data que ceux de votre domaine de compétences initial.\n\nVotre rôle au sein du Centre d'Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients.\n\nVos missions sont :\n- Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place\n-Rédiger les spécifications techniques de qualité basées sur des spécifications fonctionnelles.\n- Réaliser des développements et Tests unitaires (Moyens, Complexes) en respectant les normes de développements et en assurant une qualité de code.\n- Accompagner le client sur les phases de recette en analysant les problèmes remontés et en apportant les correctifs nécessaires tout en respectant les engagements du client.\n- Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l'intégration de données avec DBT.\n- Assurer un support technique aux équipes et aux clients au quotidien.\n\nFort d'une intégration réussie, de nombreuses possibilités d'évolutions de carrière s'offriront rapidement à vous, dans l'animation de la filière technique, dans le consulting ou l'architecture autour de l'intégration de données, ou dans une fonction de Chef de Projet BI.\n\nEn rejoignant CGI, vous bénéficiez notamment d'une offre complète de formations (techniques, métiers, développement personnel,.), de flexibilité grâce à notre accord télétravail (jusqu'à 3 jours de télétravail par semaine), d'une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,.) et d'un package d'avantages intéressant (régime d'achats d'actions, participation, CSE,...).Qualités requises pour réussir dans ce rôle :- Passionné d'informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager.\n- Vous êtes également doté d'un esprit audacieux et ambitieux.\n- Vous faites preuve d'initiative et travaillez sur le long terme.\n- Vous justifiez d'une expérience professionnelle de plus de 2 ans au sein d'une entreprise de services numériques ou d'un cabinet de conseil sur la solution DBT dans le domaine de l'intégration de données et vous possédez une bonne maitrise du langage Python et SQL.\n\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l'évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d'accessibilité et de clarté, le point médian n'est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.À propos de nousFondée en 1976, CGI figure parmi les plus importantes entreprises indépendantes de services numériques et de conseil au monde.Notre connaissance fine des différents secteurs d'activité et notre expertise technologique nous permettent d'anticiper les changements du marché, de fournir des conseils pertinents et des services complets, pour accompagner nos clients dans leur transformation à travers quatre métiers : le conseil, l'intégration de systèmes, les business solutions et les services managés.Alors, qu'attendez-vous pour nous rejoindre ? Perfectionnez vos compétences. Partagez vos perspectives. Libérez votre potentiel.CGI est certifiée Great Place To WorkCette certification souligne notre volonté de « Créer un environnement où nous avons du plaisir à travailler ensemble », et notre engagement à faire de CGI un endroit",
        "ft_reference": "1949651",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Automation": [
                "Chef"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer DBT F/H (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "CGI FRANCE ",
        "location_raw": "TOULOUSE",
        "location": "31",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949340",
        "description": "Data Engineer DBT F/HDescription du poste :Big Data, Data Science, Data analyse, Data architecture,IA ... Ça n'a pas de secret pour vous?\nQue vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l'une de ces disciplines, intégrer notre communauté Data, c'est l'assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.\n\nRejoignez notre centre d'excellence en innovation à Toulouse et rendez unique l'expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, RPA, data, développement web et mobile, API management ou encore cybersécurité.Fonctions et responsabilités :Vous êtes passionné par le Décisionnel et la Data et avez déjà une première expérience sur l'outil DBT. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l'innovation (> 400 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d'autres outils Data que ceux de votre domaine de compétences initial.\n\nVotre rôle au sein du Centre d'Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients.\n\nVos missions sont :\n- Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place\n-Rédiger les spécifications techniques de qualité basées sur des spécifications fonctionnelles.\n- Réaliser des développements et Tests unitaires (Moyens, Complexes) en respectant les normes de développements et en assurant une qualité de code.\n- Accompagner le client sur les phases de recette en analysant les problèmes remontés et en apportant les correctifs nécessaires tout en respectant les engagements du client.\n- Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l'intégration de données avec DBT.\n- Assurer un support technique aux équipes et aux clients au quotidien.\n\nFort d'une intégration réussie, de nombreuses possibilités d'évolutions de carrière s'offriront rapidement à vous, dans l'animation de la filière technique, dans le consulting ou l'architecture autour de l'intégration de données, ou dans une fonction de Chef de Projet BI.\n\nEn rejoignant CGI, vous bénéficiez notamment d'une offre complète de formations (techniques, métiers, développement personnel,.), de flexibilité grâce à notre accord télétravail (jusqu'à 3 jours de télétravail par semaine), d'une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,.) et d'un package d'avantages intéressant (régime d'achats d'actions, participation, CSE,...).Qualités requises pour réussir dans ce rôle :- Passionné d'informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager.\n- Vous êtes également doté d'un esprit audacieux et ambitieux.\n- Vous faites preuve d'initiative et travaillez sur le long terme.\n- Vous justifiez d'une expérience professionnelle de plus de 2 ans au sein d'une entreprise de services numériques ou d'un cabinet de conseil sur la solution DBT dans le domaine de l'intégration de données et vous possédez une bonne maitrise du langage Python et SQL.\n\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l'évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d'accessibilité et de clarté, le point médian n'est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.Compétences :FrançaisÀ propos de nousFondée en 1976, CGI figure parmi les plus importantes entreprises indépendantes de services numériques et de conseil au monde.Notre connaissance fine des différents secteurs d'activité et notre expertise technologique nous permettent d'anticiper les changements du marché, de fournir des conseils pertinents et des services complets, pour accompagner nos clients dans leur transformation à travers quatre métiers : le conseil, l'intégration de systèmes, les business solutions et les services managés.Alors, qu'attendez-vous pour nous rejoindre ? Perfectionnez vos compétences. Partagez vos perspectives. Libérez votre potentiel.CGI est certifiée Great Place To WorkCette certification souligne notre volonté de « Créer un environnement où nous avons du plaisir à travailler ensemble », et notre engagement",
        "ft_reference": "1949340",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Automation": [
                "Chef"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer DBT F/H (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "CGI FRANCE ",
        "location_raw": "PARIS 01",
        "location": "01",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949066",
        "description": "Data Engineer DBT F/HDescription du poste :Big Data, Data Science, Data analyse, Data architecture,IA ... Ça n'a pas de secret pour vous?\nQue vous commenciez votre carrière professionnelle ou que vous soyez spécialiste de l'une de ces disciplines, intégrer notre communauté Data, c'est l'assurance de progresser, innover, partager, vous certifier et rendre service à nos clients.\n\nRejoignez notre centre d'excellence en innovation à Paris et rendez unique l'expérience digitale de nos clients en travaillant sur des sujets tels que le marketing digital, User eXperience, RPA, data, développement web et mobile, API management ou encore cybersécurité.Fonctions et responsabilités :Vous êtes passionné par le Décisionnel et la Data et avez déjà une première expérience sur l'outil DBT. Vous souhaitez diversifier vos compétences pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l'innovation (> 400 consultants Data). Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d'autres outils Data que ceux de votre domaine de compétences initial.\n\nVotre rôle au sein du Centre d'Innovation Digitale aura de très nombreuses facettes, toutes orientées vers un seul et même objectif : Contribuer à la transformation digitale et au succès de nos clients.\n\nVos missions sont :\n- Analyser, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place\n-Rédiger les spécifications techniques de qualité basées sur des spécifications fonctionnelles.\n- Réaliser des développements et Tests unitaires (Moyens, Complexes) en respectant les normes de développements et en assurant une qualité de code.\n- Accompagner le client sur les phases de recette en analysant les problèmes remontés et en apportant les correctifs nécessaires tout en respectant les engagements du client.\n- Travailler en collaboration avec les ingénieurs et autres experts afin de rechercher et fournir des réponses aux problématiques techniques autour de l'intégration de données avec DBT.\n- Assurer un support technique aux équipes et aux clients au quotidien.\n\nFort d'une intégration réussie, de nombreuses possibilités d'évolutions de carrière s'offriront rapidement à vous, dans l'animation de la filière technique, dans le consulting ou l'architecture autour de l'intégration de données, ou dans une fonction de Chef de Projet BI.\n\nEn rejoignant CGI, vous bénéficiez notamment d'une offre complète de formations (techniques, métiers, développement personnel,.), de flexibilité grâce à notre accord télétravail (jusqu'à 3 jours de télétravail par semaine), d'une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,.) et d'un package d'avantages intéressant (régime d'achats d'actions, participation, CSE,...).Qualités requises pour réussir dans ce rôle :- Passionné d'informatique décisionnelle, vous aimez le travail en équipe, apprendre, partager.\n- Vous êtes également doté d'un esprit audacieux et ambitieux.\n- Vous faites preuve d'initiative et travaillez sur le long terme.\n- Vous justifiez d'une expérience professionnelle de plus de 2 ans au sein d'une entreprise de services numériques ou d'un cabinet de conseil sur la solution DBT dans le domaine de l'intégration de données et vous possédez une bonne maitrise du langage Python et SQL.\n\nCGI est un employeur inclusif et attentif aux candidatures des personnes en situation de handicap, à l'évolution de carrières des hommes et des femmes et au bien-être de nos salariés LGBT+. Dans un souci d'accessibilité et de clarté, le point médian n'est pas utilisé dans cette annonce. Tous les termes employés se réfèrent aussi bien au genre féminin que masculin.À propos de nousFondée en 1976, CGI figure parmi les plus importantes entreprises indépendantes de services numériques et de conseil au monde.Notre connaissance fine des différents secteurs d'activité et notre expertise technologique nous permettent d'anticiper les changements du marché, de fournir des conseils pertinents et des services complets, pour accompagner nos clients dans leur transformation à travers quatre métiers : le conseil, l'intégration de systèmes, les business solutions et les services managés.Alors, qu'attendez-vous pour nous rejoindre ? Perfectionnez vos compétences. Partagez vos perspectives. Libérez votre potentiel.CGI est certifiée Great Place To WorkCette certification souligne notre volonté de « Créer un environnement où nous avons du plaisir à travailler ensemble », et notre engagement à faire de CGI un endroit",
        "ft_reference": "1949066",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "Automation": [
                "Chef"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Consultant.e Data Engineer (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "PARIS (DEPT.) 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1942055",
        "description": "groove accompagne les organisations dans leur transformation numérique et durable ∞\nNotre mission : \nNous sommes profondément convaincus que l'économie numérique évolue vers une ère où la durabilité devient une priorité absolue.\nCe nouveau paradigme est au cœur de notre culture : une opportunité de bâtir un avenir en harmonie avec les enjeux écologiques, sociétaux et économiques. Notre équipe est animée par l'ambition de créer un impact positif, en adoptant une approche collaborative, éthique et tournée vers l'avenir.\nVotre rôle :\nEn tant que Consultant.e Data Engineer, vous accompagnez nos clients dans la conception, la mise en place et l'optimisation de leurs infrastructures de données. Vous intervenez à l'interface des enjeux techniques et stratégiques pour garantir la fiabilité, la performance et la scalabilité des pipelines de données, facilitant ainsi les analyses et la prise de décisions éclairées.\nVos missions :1. Collecte et Transformation des Données\n* Concevoir et développer des pipelines de données robustes, évolutifs et adaptés aux besoins clients.\n* Automatiser l'ingestion, la transformation et la normalisation des données provenant de sources variées (bases de données, API, fichiers, etc.).\n2. Architecture et Stockage\n* Définir et mettre en place des architectures de données adaptées aux besoins métiers (Data Lake, Data Warehouse, Data Mesh).\n* Optimiser le stockage et la structuration des données pour garantir leur accessibilité, leur performance et leur évolutivité.\n3. Industrialisation et Performance\n* Déployer des solutions de traitement de données en temps réel et en batch, en assurant une gestion optimale de la performance.\n* Améliorer la qualité, l'intégrité et la gouvernance des données en appliquant les meilleures pratiques (monitoring, data lineage, gestion des métadonnées).\n4. Sécurité et Conformité\n* Garantir la sécurité et la conformité des données en appliquant les normes et réglementations en vigueur (RGPD, ISO 27001, etc.).\n* Mettre en place des contrôles et des politiques de gouvernance des accès et des usages des données pour assurer leur protection et leur conformité.\n5. Veille et Innovation\n* Réaliser une veille sur les nouvelles technologies et méthodologies en data engineering (Big Data, Cloud, ETL, streaming).\n* Proposer des solutions innovantes pour améliorer la gestion et l'exploitation des données, en fonction des évolutions technologiques et des besoins émergents des clients.\nProfil recherché :\n* Formation Bac +5 en informatique, data science ou ingénierie.\n* Expérience de 2 à 5 ans en ingénierie des données, idéalement en cabinet de conseil ou en environnement Big Data.\n* Maîtrise des outils et technologies data : SQL, Python, Spark, Airflow, Kafka, DBT.\n* Expérience sur les plateformes Cloud (AWS, Azure, GCP) et les solutions de stockage et de traitement (Snowflake, BigQuery, Redshift).\n* Connaissance des bonnes pratiques en gestion des données (ETL, ELT, CI/CD, DevOps).\n* Capacité à travailler en équipe, esprit analytique et approche orientée solution.\nPourquoi nous rejoindre ?\nChez Groove, vous ferez partie d'une équipe passionnée et engagée, prête à relever les défis de demain. Nous vous offrons un cadre de travail stimulant, basé sur l'échange, l'innovation et le développement personnel.\nLet's groove!\nType d'emploi : CDI\nStatut : Cadre\nRémunération : 45 000,00€ à 55 000,00€ par an\nAvantages :\n* Travail à domicile occasionnel\nHoraires :\n* Du lundi au vendredi\n* Travail en journée\nFormation:\n* Bac +5 (Master / MBA) (Optionnel)\nLangue:\n* Anglais (Optionnel)\nLieu du poste : Télétravail hybride (75007 Paris)",
        "ft_reference": "1942055",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "Snowflake",
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Consultant.e Data Engineer (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NORD 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1942048",
        "description": "groove accompagne les organisations dans leur transformation numérique et durable ∞\nNotre mission :Nous sommes profondément convaincus que l'économie numérique évolue vers une ère où la durabilité devient une priorité absolue.\nCe nouveau paradigme est au cœur de notre culture : une opportunité de bâtir un avenir en harmonie avec les enjeux écologiques, sociétaux et économiques. Notre équipe est animée par l'ambition de créer un impact positif, en adoptant une approche collaborative, éthique et tournée vers l'avenir.\nVotre rôle :\nEn tant que Consultant.e Data Engineer, vous accompagnez nos clients dans la conception, la mise en place et l'optimisation de leurs infrastructures de données. Vous intervenez à l'interface des enjeux techniques et stratégiques pour garantir la fiabilité, la performance et la scalabilité des pipelines de données, facilitant ainsi les analyses et la prise de décisions éclairées.\nVos missions :1. Collecte et Transformation des Données\n* Concevoir et développer des pipelines de données robustes, évolutifs et adaptés aux besoins clients.\n* Automatiser l'ingestion, la transformation et la normalisation des données provenant de sources variées (bases de données, API, fichiers, etc.).\n2. Architecture et Stockage\n* Définir et mettre en place des architectures de données adaptées aux besoins métiers (Data Lake, Data Warehouse, Data Mesh).\n* Optimiser le stockage et la structuration des données pour garantir leur accessibilité, leur performance et leur évolutivité.\n3. Industrialisation et Performance\n* Déployer des solutions de traitement de données en temps réel et en batch, en assurant une gestion optimale de la performance.\n* Améliorer la qualité, l'intégrité et la gouvernance des données en appliquant les meilleures pratiques (monitoring, data lineage, gestion des métadonnées).\n4. Sécurité et Conformité\n* Garantir la sécurité et la conformité des données en appliquant les normes et réglementations en vigueur (RGPD, ISO 27001, etc.).\n* Mettre en place des contrôles et des politiques de gouvernance des accès et des usages des données pour assurer leur protection et leur conformité.\n5. Veille et Innovation\n* Réaliser une veille sur les nouvelles technologies et méthodologies en data engineering (Big Data, Cloud, ETL, streaming).\n* Proposer des solutions innovantes pour améliorer la gestion et l'exploitation des données, en fonction des évolutions technologiques et des besoins émergents des clients.\nProfil recherché :\n* Formation Bac +5 en informatique, data science ou ingénierie.\n* Expérience de 2 à 5 ans en ingénierie des données, idéalement en cabinet de conseil ou en environnement Big Data.\n* Maîtrise des outils et technologies data : SQL, Python, Spark, Airflow, Kafka, DBT.\n* Expérience sur les plateformes Cloud (AWS, Azure, GCP) et les solutions de stockage et de traitement (Snowflake, BigQuery, Redshift).\n* Connaissance des bonnes pratiques en gestion des données (ETL, ELT, CI/CD, DevOps).\n* Capacité à travailler en équipe, esprit analytique et approche orientée solution.\nPourquoi nous rejoindre ?\nChez Groove, vous ferez partie d'une équipe passionnée et engagée, prête à relever les défis de demain. Nous vous offrons un cadre de travail stimulant, basé sur l'échange, l'innovation et le développement personnel.\nLet's groove!\nType d'emploi : CDI\nStatut : Cadre\nRémunération : 45 000,00€ à 55 000,00€ par an\nAvantages :\n* Travail à domicile occasionnel\nHoraires :\n* Du lundi au vendredi\n* Travail en journée\nFormation:\n* Bac +5 (Master / MBA) (Optionnel)\nLangue:\n* Anglais (Optionnel)\nLieu du poste : Télétravail hybride (59700 Marcq-en-Barœul)",
        "ft_reference": "1942048",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "Snowflake",
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Spark (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "FINISTÈRE 29",
        "location": "29",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939983",
        "description": "Dans le cadre de sa transformation digitale et de l?optimisation de son exploitation des données, notre client, un acteur bancaire majeur, recherche un Data Engineer Spark.\nVotre mission consistera à concevoir, développer et optimiser des pipelines de données massives en exploitant Apache Spark sur une infrastructure distribuée. Vous serez chargé(e) de garantir la robustesse, la performance et la scalabilité des traitements de données tout en assurant leur intégration fluide avec les autres composants du data lake.\nEn lien avec les équipes Data Science et IT, vous interviendrez sur l?optimisation des traitements distribués, l?industrialisation des flux et l?automatisation des processus, afin d?améliorer la qualité et la disponibilité des données en production. Vous contribuerez également à la mise en place des meilleures pratiques en matière de Big Data Engineering et de gestion des performances des architectures distribuées.\nProfil candidat:\nProfil : Expérience confirmée dans le développement avec Apache Spark et le traitement distribué des données.\nLes qualifications et compétences attendues incluent :\n? Expertise en PySpark, Scala ou Java pour la manipulation et la transformation des données.\n? Maîtrise des bases de données NoSQL (Cassandra, MongoDB) et relationnelles.\n? Expérience en optimisation de la performance et tuning de Spark.\n? Bonne connaissance des architectures Big Data et Cloud (AWS, GCP ou Azure).\n? Capacité à concevoir des pipelines de données robustes et scalables.\n? Anglais opérationnel requis.",
        "ft_reference": "1939983",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "MongoDB",
                "Cassandra"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "SoftBigDataProcessing": [
                "Cassandra"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Junior (H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939925",
        "description": "Description Mon client, leader mondial dans le domaine des moyens de paiement recherche un consultant \"Data engineer\" junior pour intervenir au sein de l'équipe BI.\nLe périmètre d'intervention est le suivant:\nRéaliser les projets BI (tout ou partie) sous la supervision du Tech lead\nAssurer du support utilisateur\nDocumenter ses réalisations et procédures support\n \nIl s'agit d'un environnement technique Microsoft cloud Azure avec une architecture orientée Big Data avec un Data Lake (Sparks) alimentant des cubes tablulaires.\nPower BI est l'outil de reporting du groupe.\nProfil candidat:\nProfil recherché \n- Azure Data Factory (obligatoire)\n- Azure Databricks (obligatoire)\n- Python/PySpark (obligatoire)\n- Sql (obligatoire)\n- Azure Analysis Services et modélisation de cubes tabulaires (obligatoire)\n- Expérience significative de Power BI\n- Expérience en DAX\n- Expérience DevOps - méthodologie CI/CD\n \nIntervention dans un environnement global avec utilisation de l'anglais au quotidien",
        "ft_reference": "1939925",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ROUEN 76",
        "location": "76",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939890",
        "description": "Concevoir et structurer des bases de données adaptées aux besoins analytiques.\nDévelopper et implémenter des DAGs en Python pour alimenter les entrepôts de données.\nParticiper à la définition et à l'optimisation des standards de développement de l?équipe Data.\nAutomatiser et renforcer les contrôles garantissant la fiabilité des données intégrées.\nRédiger la documentation fonctionnelle et technique.\nDéfinir et exécuter des plans de tests pour valider le bon fonctionnement des DAGs et assurer la cohérence des jeux de données.\nAssurer la maintenance et l?optimisation des entrepôts de données.\nContribuer à la mise en place de tableaux de bord.\nPréparer et suivre les phases d'homologation et de déploiement des solutions développées.\nFournir un support technique et fonctionnel aux équipes métiers pour l?exploitation des données et des outils analytiques.\nAméliorer les processus existants et proposer des méthodologies adaptées grâce à une veille active sur les données et les outils.\nProfil candidat:\nSolide expérience en Python, Airflow, Git et SQL.\nMaîtrise des tests automatisés appliqués aux données.\nBonne connaissance des pratiques CI/CD.\nCapacité à proposer des améliorations et à innover.\nRigueur, organisation et autonomie dans le travail.\nAptitude à l?analyse et à la synthèse.\nExcellentes compétences relationnelles et esprit d?équipe.\nSens pédagogique développé pour partager les connaissances.\nCapacité à communiquer efficacement et à rendre compte.\nBonne compréhension des architectures DATA modernes.",
        "ft_reference": "1939890",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939836",
        "description": "L'Ingénieur Data intégrera une équipe spécialisée en gestion et valorisation des données. Il/Elle sera responsable de l'acquisition et de la modélisation des données afin de fournir des résultats exploitables pour l'analytique et la data science.\nLe rôle impliquera la création de modèles de données consommables et de visualisations, tout en assurant la gestion complète du cycle de vie des données, de leur ingestion à leur traitement et préparation.\nIl/Elle travaillera en étroite collaboration avec les équipes data et métiers afin d?assurer la cohérence et la fiabilité des produits de données développés.\nTraduire les besoins métier en spécifications techniques, en collaboration avec les parties prenantes.\nEstimer, planifier, gérer et diriger les projets/tâches d'intégration des données. Coordonner les tâches et la charge de travail avec les autres ingénieurs data.\nConcevoir et développer des processus ETL/ELT et des flux de données pour fournir des résultats exploitables en analytique et data science.\nCréer des modèles de données et des visualisations intuitives et performantes.\nCollaborer avec les équipes de support pour assurer la cohérence et l?exactitude des données ainsi que la performance des flux livrés. Fournir un support de niveau 3 lorsque nécessaire.\nDéfinir et promouvoir les meilleures pratiques et principes de conception pour l'architecture Data Warehouse et Analytics.\nProfil candidat:\nDiplôme universitaire en informatique, ingénierie ou domaine équivalent.\nMinimum de quatre ans d'expérience dans des rôles similaires en ingénierie des données.\nExcellentes compétences en programmation SQL et Python.\nBonne maîtrise de Looker (y compris LookML).\nExpérience avec dbt.\nConnaissance de dbt et des outils de gestion de versions (ex. GIT).\nExpérience avec les entrepôts de données cloud, de préférence GCP ? BigQuery.\nConnaissance de la méthodologie Scrum.",
        "ft_reference": "1939836",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data analyste informatique / Analytics Engineer (Lille 3j) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939715",
        "description": "En quelques motsCherry Pick est à la recherche d'un \"Data Analyst/Analytics Engineer Confirmé\" pour un client dans le secteur du Retail\nDescriptionContexte de la mission\nL'équipe Conception Data fait partie du domaine Products Data. Son ambition est d?aider les ingénieurs de la Conception (ingénieurs produits, directeurs techniques, designers, etc.) à générer de la valeur en exploitant le potentiel des données du groupe.\nCette équipe s?est rapidement développée pour atteindre 5 personnes (Product Manager, Data Analyst, BI Engineer), avec de nombreuses opportunités à venir.\nObjectifs et livrables\nCadrer les besoins et opportunités métier en collaboration avec le Product Manager\nTravailler avec les équipes data de Decathlon (en particulier au sein de l?écosystème Core Data Product) pour identifier les données pertinentes à exploiter.\nRéaliser des explorations à l?aide de Databricks pour construire des datasets ou analyses.\nÉlaborer des premiers éléments de visualisation de données avec Tableau afin d?alimenter les discussions avec les métiers.\nLorsque cela est pertinent, collaborer avec les Analytics Engineers et BI Engineers pour les aider à construire des dashboards industrialisés à partir de tes explorations.\nElaborer des datasets en DBT\nProfil candidat:\nCompétences demandées\nCompétences / Niveau de compétence\nDatabricks / Confirmé\nAutonomie / Expert\nSQL / Expert\nDBT / Confirmé\nTableau software / Avancé \nPython / Expert\nMéthodes analytiques avancées / Confirmé",
        "ft_reference": "1939715",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER DATABRICKS/POWER BI SENIOR (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939678",
        "description": "Contexte :\nEn tant que DATA ENGINEER spécialisé en traitement de données, vous intégrerez une équipe pour concevoir, réaliser, suivre et intégrer des travaux autour de la valorisation de la donnée.\nMISSIONS\n? Étude et rédaction d?US, en particulier sur des sujets liés à la data.\n? Maîtrise des bonnes pratiques de développement (utilisation de git, lisibilité du code, tests, intégration continue).\n? Fournir une vision complète des solutions data pour le programme.\n? La maitrise de DATABRICKS est impérative\nRésultats attendus et/ou livrables\n? Documentation et spécifications des développements à réaliser. La présentation interactive avec Power BI est à privilégiée\n? Analyse de données\n? Développements DATABRICKS\n? Schéma d?architecture data en lien avec les besoins\n? Rapports d?avancement :\no Rapports hebdomadaires et mensuels sur l?état d?avancement du projet et des livrables, les points bloquants, les risques et les actions correctives. \no Indicateurs associés propres au projet.\n? Documentation technique :\no Documentation complète des solutions techniques mises en ?uvre.\nProfil candidat:\n Aptitudes et compétences\nSavoirs faire :\n? Un bon sens de l?organisation afin de participer activement à l?animation des équipes en relation avec les métiers, la MOA SI, les équipes de delivery\n? Bonne connaissance de l?architecture et services Cloud AZURE\n? Analyse de données\n? Une connaissance des outils de gestion de projet agile, idéalement de Jira\n? Un bon niveau de connaissances sur le fonctionnement des outils DATA\nAZURE est important afin de faciliter l?appropriation de l?éco système. \n? Une expérience significative sur Databricks et Power BI\n? Une bonne maitrise des outils bureautiques sera indispensable au quotidien\n(Office 365 : Powerpoint, Word, Excel, SharePoint, Outlook)\nSavoirs être :\n? Ecoute active et savoir être diplomate en temps voulu\n? Bon relationnel, tant avec les services internes qu'avec les parties prenantes externes\n? Autonomie\n? Agilité\n? Organisation et esprit de synthèse\n? Aisance dans l?expression écrite et orale\nEnvironnement technique\nUne connaissance avancée dans l?une ou plusieurs des technologies ci-dessous est recommandée pour être à même de faire le lien entre les besoins métiers et la réalisation technique.\n? SGBDR : PostgreSQL\n? ETL : Databricks\n? REPORTING : Power BI\n? USINE LOGICIELLE : GitLab, Jenkins, Artifactory, Harbor\n? SYSTEME : Windows, Linux (Ubuntu, RedHat ?), Kubernetes\n? LANGAGE : SQL, SQL LOADER, Script KSH, Java / Groovy, Javascript /\nAngular, Python\n? ORDONNANCEMENT : VTOM, Step Function\n? SUPERVISION : Datadog, Kibana, Grafana\n? OUTILS : ServiceNow, Jira, Trello\nPar ailleurs, les niveaux d?expérience minimum suivant seront exigés, une préférence sera portée au profil ayant connaissance du contexte procédure, process, organisation?) :\n? Plus de 5 ans sur le développement Databricks et Power bi",
        "ft_reference": "1939678",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939503",
        "description": "Au cours de sa mission, le consultant :\n- Participera aux rituels agiles de l'équipe,\n- Analysera les besoins des utilisateurs et proposera des solutions innovantes et en phase avec les drivers de l'entreprises,\n- Développera les solutions data (Alimentation, stockage, modélisation, restitution),\n- Validera la qualité des développements de son équipe,\n- Améliorera et optimisera le patrimoine actuel de son équipe,\n- Maintiendra les solutions existantes (Run),\n- Contribuera à la construction du nouveau socle et des services sur la plateforme Google Cloud,\nProfil candidat:\nExpertise SQL, ETL - Expert - Impératif\nCI/CD, github, Terraform, Kafka - Confirmé - Important\nPower BI, Looker - Confirmé - Important\nGoogle Cloud Platform (GCS, BigQuery) - Confirmé - Souhaitable",
        "ft_reference": "1939503",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939445",
        "description": "* Conçoit, développe, optimise et maintient une architecture de données et des pipelines qui respectent les objectifs de l'entreprise ; \n* Résout des problèmes de données afin de fournir des informations qui aident notre entreprise à atteindre ses objectifs ; \n* Crée des jeux de données pour les membres de l'équipe d'analyse afin d'améliorer leur productivité ; \n* Favorise une culture du partage, de la réutilisation, de la stabilité de la conception à l'échelle et de l'efficacité opérationnelle des données et des solutions analytiques ; \n* Contribue à l'évaluation, la mise en oeuvre et le déploiement d'outils et de processus émergents pour l'ingénierie des données analytiques afin d'améliorer notre productivité en tant qu'équipe ; \n* Élabore et met en oeuvre des plans de communication/éducation sur les capacités, les normes et les processus d'ingénierie des données analytiques ; \n* Travaille en partenariat avec des analystes business et des architectes de solutions pour développer des architectures techniques pour les projets et initiatives stratégiques de l'entreprise\nProfil candidat:\nExpertises techniques : \n* Expérience du développement de bases de données et d'une variété de technologies de bases de données relationnelles \n* Expérience des entrepôts de données \n* \nExpertise en SQL et en analyse de données maîtrise Python \n* Idéalement certifié des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) \n* Connaissance de l'intelligence artificielle, des statistiques et/ou des mathématiques appliquées \n* Expérience dans le développement de solutions sur des services et infrastructures de cloud computing dans le domaine des données et de l'analyse \n* Expérience du déploiement de Power BI \n* Expérience conceptuelle des données et de l'analyse, par exemple ETL, modélisation dimensionnelle, outils de reporting, gouvernance des données, entreposage des données, données structurées et non structurées, qualité de \ndonnées \n* Connaissance CI/CD et GitLab fortement apprécié.",
        "ft_reference": "1939445",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Statistiques",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer DWH GCP (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NOISY LE GRAND 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939418",
        "description": "DÉBUT DE MISSION : ASAP\nDURÉE : 12 mois\nLIEU : Noisy-Le-Grand ? Travail hybride\nCATÉGORIE TECHNIQUE : Systèmes (Infras, Cloud, DevOps, ...), Réseaux, Sécurité\nNous recherchons pour l?un de nos clients grands comptes un Data Engineer DWH GCP expérimenté, pour contribuer à un projet de transformation IT ambitieux.\nContexte du projet :Dans le cadre du programme de transformation IT, le département DATA mène un projet stratégique de migration du Data Warehouse France On-Premise (Oracle ? PL/SQL) vers la Google Cloud Platform (Big Query). Ce projet inclut :\nL?utilisation de Dataform, Cloud Functions, et Cloud Run.\nLa migration des données et processus existants, incluant un ETL développé en interne et certains programmes en Natural (éditeur SAG).\nVos missions principales :Participer à la migration du Data Warehouse vers Big Query sur GCP.\nDévelopper et optimiser des scripts en PL/SQL et Python pour les processus de transformation des données.\nCollaborer sur la conception et l?intégration des pipelines de données via les outils GCP.\nAnalyser et réaliser des tests unitaires, d?intégration et de non-régression.\nDocumenter les processus et assurer un transfert de compétences aux équipes.\nParticiper activement aux rituels Agiles et utiliser Jira pour la gestion des tickets.\nAnalyser les résultats des tests via des outils internes et ajuster les développements en conséquence.\nCréer et utiliser des scripts Linux KSH pour les opérations nécessaires.\nProfil recherché :Expérience : Minimum 8 ans dans un rôle similaire.\nCompétences techniques :\nLangages : PL/SQL (Confirmé), Python (Confirmé).\nBases de données : Oracle et Big Query (Confirmé).\nConnaissance des outils GCP, y compris Dataform, Cloud Functions, Cloud Run.\nFamiliarité avec des outils de Data Visualisation tels que Looker, SAP BO, ou Spotfire.\nExpérience en tests logiciels et outils de ticketing comme Jira.\nBonne connaissance des environnements Linux et scripting KSH.\nQualités personnelles :\nCapacité à travailler en équipe et dans un environnement Agile.\nSens de l?analyse et autonomie dans l?exécution des tâches.\nAdaptabilité et capacité à gérer des environnements techniques complexes.\nProfil candidat:\nProfil recherché :Expérience : Minimum 8 ans dans un rôle similaire.\nCompétences techniques :\nLangages : PL/SQL (Confirmé), Python (Confirmé).\nBases de données : Oracle et Big Query (Confirmé).\nConnaissance des outils GCP, y compris Dataform, Cloud Functions, Cloud Run.\nFamiliarité avec des outils de Data Visualisation tels que Looker, SAP BO, ou Spotfire.\nExpérience en tests logiciels et outils de ticketing comme Jira.\nBonne connaissance des environnements Linux et scripting KSH.",
        "ft_reference": "1939418",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "Big Query"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F) (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939417",
        "description": "La mission s'inscrit dans le cadre d'un projet visant à remplacer le système actuel de gestion des actifs d'entreprise (EAM), utilisé pour la maintenance des centrales nucléaires. L'ingénieur Data intervient auprès du responsable du périmètre maitrise et innovations techniques du projet, au sein d'une équipe composée d'environ 8 personnes. Il joue un rôle crucial dans l'analyse des solutions proposées par les éditeurs. Il est chargé d'analyser les solutions EAM proposées par les éditeurs et d'évaluer leur impact sur les données. Il conçoit des stratégies de migration (initiale et delta), en garantissant la qualité, la sécurité et l'intégrité des données lors de leur transition vers le nouveau système, tout en minimisant l'impact sur les processus métiers. Il assure également la mise en place des outils de reporting et de tableaux de bord pour suivre et piloter la migration en temps réel.\nObjectifs et livrables\nEvaluer l'impact des solutions EAM des éditeurs sur les données.\nGarantir la qualité, la sécurité et l'intégrité des données lors de la migration.\nRéaliser des mappings complexes pour assurer la fluidité des flux de données.\nOrchestrer la migration des données dans un environnement Cloud AWS.\nRéaliser un Proof of Concept (POC) pour aider la capacité à migrer les données sans altération.\nAutomatiser le déploiement et les contrôles : Faciliter le déploiement et assurer des contrôles rigoureux.\nMettre en place des outils de reporting pour suivre et piloter la migration en temps réel.\nMinimiser l'impact de la migration sur les opérations métiers grâce à des contrôles de qualité/quantité des processus d'intégrité à chaque étape de la migration\nProfil candidat:\nIngénieur Data Senior\nCompétences :\nAnalyse des solutions éditeurs : Évaluer les solutions proposées par les éditeurs, notamment en ce qui concerne l'impact sur les données (structure, volume, qualité), et identifier les risques et opportunités.\nConception des stratégies de migration : Définir des stratégies pour les migrations initiale et delta, garantissant une intégrité des données tout au long du processus et minimisant l'impact métier.\nMaîtrise des outils ETL : Utiliser des outils ETL performants pour réaliser des mappings complexes entre le système existant et le système cible, en assurant la fluidité et l'exactitude des flux de données.\nExpertise AWS : Exploiter les services managés AWS (DMS, Glue, SCT, etc.) pour orchestrer la migration des données dans un environnement Cloud AWS en toute sécurité.\nMise en ?uvre d'un POC : Réaliser un Proof of Concept afin de valider la capacité à migrer les données tout en tenant compte des contraintes du SI actuel et cible. Ce POC garantit que la migration se fait sans altération des données.\nAutomatisation du déploiement et des contrôles : Mettre en ?uvre des mécanismes d?automatisation pour faciliter le déploiement et des contrôles rigoureux à chaque étape du processus de migration.\nMise en place du reporting et tableaux de bord : Concevoir et mettre en place des tableaux de bord et des rapports de suivi qui permettent de piloter et superviser la qualité de la migration à chaque étape. Ces outils offrent une vision en temps réel de l'avancement, des anomalies éventuelles et de la qualité des données migrées.\nRéduction de l'impact métier : Veiller à ce que la migration ait un impact minimal sur les opérations métiers grâce à des contrôles de qualité/quantité et des processus d'intégrité à chaque étape de la migration.",
        "ft_reference": "1939417",
        "skills": {
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer - Retail H/F (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939306",
        "description": "Contexte de la mission : \nViveris pilote les chantiers de transformation métier et IT qui contribuent à la performance des entreprises du Retail.\nDans le cadre de nos priorités stratégiques DATA, nous cherchons un DATA Engineer expérimenté.\nVos missions et responsabilités :\nVous rejoignez l'équipe Supply Chain en charge des échanges de données entre le moteur de calcul de prévision de vente et de réapprovisionnement et l'ensemble des applications internes.\nActuellement l'équipe est composée de 3 ingénieurs Data, 1 Product Owner, 1 Scrum Master, 2 Business Analyst et 1 Tech Lead.\nNous recherchons un ingénieur Data pour renforcer l'équipe pour assurer le run opérationnel, optimiser l'existant et dans un avenir proche participer au déploiement de la solution dans d'autres pays.\nVos missions :\n - Traitement d'activités de support / maintenance corrective ;\n - Analyse et cadrage technique des différents besoins ou problématiques remontées par les Bus ;\n - Réalisation et maintien de la documentation technique du produit (Spécification technique, dossier d'architecture, etc...) ;\n - Réalisation des développements du produit (Modules GCP, Terraform, Python, BigQuery) ;\n - Veille et optimisation technique (architecture, fiabilisation, optimisation financière (finops)) ;\n - Appliquer les normes de qualités définies pour le groupe\nNous recherchons quelqu'un de motivé ayant déjà une expérience dans la Data.\nProfil candidat:\nProfil recherché :\n \n - De formation Bac +4/5, vous disposez d'une expérience technique de 3 ans minimum sur un poste similaire et en contexte international ;\n - Vous avez déjà travaillé en environnement GCP et vous maîtrisez les requêtes BigQuery ;\n - Vous avez des connaissances en Python et une maîtrise de SQL;\n - Vous avez une première expérience réussie en CI/CD ;\n - Vous maîtrisez l'anglais à l'écrit et à l'oral ;\n - De nature curieuse et volontaire, vous savez faire preuve de rigueur et être force de proposition.\nNos avantages :\n \n - Rémunération attractive et évolutive, mutuelle familiale à garantie haute ;\n - Tickets restaurant pris en charge à 60%, 100% titre de transport urbain remboursé ;\n - Primes d'intéressement, de participation et de cooptation ;\n - 2 jours de télétravail par semaine ;\n - Formation continue avec Linkedin Learning et nos communautés techniques.",
        "ft_reference": "1939306",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer GCP & Dbt (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939149",
        "description": "Nous recherchons pour le compte de notre client, une entreprise de premier plan reconnue pour son innovation et son excellence, un Lead Data Engineer expérimenté doté d?une expertise en environnement Google Cloud Platform (GCP). Ce rôle stratégique s?adresse à un professionnel qui saura combiner compétences techniques pointues et compréhension des enjeux métiers pour accompagner notre client dans l?exploitation et l?optimisation de ses données.\nExpertise en BigQuery\nExpérience solide avec Apache Airflow\nExpertise en Dbt\nConaissance de la CICD\nExpertise en BigQuery\nExpérience avec Apache Airflow\nUtilisation de Cloud Run\nConnaissance de Terraform\nProfil candidat:\nCompétences requises :\nComprendre et mettre en ?uvre les besoins fonctionnels\nSaisir les enjeux commerciaux de l?entreprise\nTravailler en étroite collaboration avec les Data Engineers et les autres squads métiers\nUne expérience dans le secteur du Retail serait un atout majeur\nNous recherchons un profil autonome, capable de s?adapter rapidement à de nouvelles technologies, et doté d?excellentes compétences relationnelles.",
        "ft_reference": "1939149",
        "skills": {
            "BigData": [
                "Apache Airflow"
            ],
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939058",
        "description": "Le type de mission : \n Transfert des connaissances / rédaction documentaire des pipelines data (chaine de traitement des données)\nEvolution et optimisation de la dataplatforme sur le Cloud avec mise en place de nouvelles fonctionnalités (Data Qualité, Monitoring, intégration système tiers, etc?)\nParticipe à l?évolution des bonnes pratiques d?architecture\nRédaction des spécifications et du plan de validation\nDévelopper / assembler des pipelines data (chaine de traitement des données)\nIntégrer des pipelines data (chaine de traitement des données)\nMettre en place le monitoring des pipelines data (chaine de traitement des données)\nValidation des développements et garant de la qualité des livrables\nProfil candidat:\nLes compétences requises : \nConnaissance des environnements SI et des écosystèmes de données\nCompétences et expérience avec les environnements Cloud (AWS).\nExpertise en conception d'architecture d'infrastructure/système.\nMaîtrise de la programmation et du développement de pipelines et de bases de données (Expertise Python, SPARK et SQL)\nCompétences en gestion de la donnée et en sécurité des données.\nGestion de la donnée\nSécurité liée à la gestion des données\nSensibilité aux principes d'architecture de données et connaissances en MCD",
        "ft_reference": "1939058",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (Banque) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938943",
        "description": "Profil recherché :\nVous avez une expérience significative (4 à 5 ans) en tant que Data Engineer dans des environnements complexes.\nVous êtes curieux, structuré et doté d?un bon esprit d?analyse et de synthèse.\nVous êtes bilingue en anglais et à l?aise dans un environnement international.\nVous avez un fort intérêt pour l?innovation et êtes capable de proposer des améliorations continues sur les projets.\nMission de longue durée au sein d?une équipe dynamique en pleine phase de croissance\nTélétravail partiel selon les besoins du projet.\nProfil candidat:\nConcevoir et mettre en ?uvre des solutions pour collecter, nettoyer, organiser et synthétiser de grands volumes de données, en alimentant les bases de données, datalakes et projets Big Data.\nCollaborer étroitement avec les Data Architects et Data Scientists pour industrialiser les procédés et produire des analyses opérationnelles fiables.\nParticiper à l?analyse complexe de données issues de diverses sources pour identifier des tendances et générer des insights.\nAssurer une veille technologique afin de tester et implémenter de nouvelles fonctionnalités, outils et méthodologies.\nSuperviser le traitement et la gestion des données sur des plateformes cloud, avec une transition prévue vers Microsoft Azure.",
        "ft_reference": "1938943",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Big Data & BI (Hadoop, Spark, PySpark, Scala) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938924",
        "description": "Nous recherchons un expert en Big Data avec une bonne compréhension des architectures distribuées et une maîtrise de Spark/PySpark et Hadoop. Une expérience en gestion de production et en CI/CD est un vrai plus.\nL'équipe développe et gère un DataLake (FinLake) utilisé par les équipes IT et les métiers.\nMissions\nAssurer la gestion de la production (supervision, monitoring, correction des incidents).\nRéduire la dette technique en optimisant et en modernisant les solutions existantes.\nRevoir l?architecture actuelle et proposer des améliorations.\nDévelopper des solutions data adaptées aux projets IT et métiers.\nProfil candidat:\nCompétences indispensables\nBig Data : Spark, PySpark, Scala\nSystèmes distribués : Hadoop (on-premise)\nGestion des données : Hive, Starburst\nAutomatisation & DevOps : Jenkins, Unix/Bash, Pipelines CI/CD\nOutils de suivi & gestion de projet : Jira\nBonus apprécié\nExpérience avec XLDeploy / XLRelease",
        "ft_reference": "1938924",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Bash"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Big Data",
                "CI/CD",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Spark Scala Kafka- Monitoring Datalake Finance (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée de 6 An(s)",
        "experience": "6 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938911",
        "description": "Contexte & Objectifs \nAu sein du service Gouvernance, Administration et Monitoring de la DSI Finance, la mission vise à développer et optimiser une brique applicative de monitoring des flux et traitements de données, en lien avec le programme GASPARD. L?objectif est d?assurer la qualité de service et le respect des délais de mise à disposition des données, notamment face à l?augmentation des volumes prévue en 2024-2025.\nD?une durée de 6 mois, cette mission doit finaliser les travaux en cours et garantir les performances pour les futurs déploiements. L?équipe est basée à Paris, avec des interactions quotidiennes avec les équipes GASPARD à Paris et Porto. L?anglais est donc indispensable.\nDescription & Activit és\nCollecte et mise à disposition des données pour l?entreprise.\nIndustrialisation et mise en production des traitements (tableaux de bord, intégration de modèles).\nDéveloppement et optimisation des pipelines d?ingestion (streaming & batch ).\nMise en production de modèles statistiques et traitements Spark.\nDéveloppement de scripts et jobs de traitement (mapping, normalisation, agrégation).\nDéveloppement d?API et dashboards pour la restitution des données.\nAdministration et configuration de clusters Hadoop et Spring Boot pour l?extraction et l?intégration des données via Kafka et Data Lake.\nProfil & Informations \nExpérience requise : 6 à 9 ans.\nLocalisation : paris 13.\nDébut souhaité : 03/03/2025.\nMode de travail : hybride (2 jours sur site minimum / 10 jours de télétravail max si convention).\nProfil candidat:\nExpertises spécifiques :\nNous recherchons un Data Engineer confirmé (6-9 ans d'expérience) avec une expérience significative dans un environnement Hadoop et avec une triple compétence sur les technologies Spark, Scala, Kafka.\nCompte tenu du caractère court de la mission, le prestataire devra avoir une excellente capacité à s'adapter à notre environnement technique qui repose sur :\n- un cluster Hadoop Cloudera On Premise (HDFS, Hive, Hbase, Kafka...)\n- des batchs en Spark/Scala utilisant la bibliothèque ZIO\n- des API diverses principalement développées en Java\n- une IHM développée en Java et React.js\n- des traitements ordonnancés par Control-M\nExpériences souhaitées :\n- Mise en oeuvre de traitements en Spark Scala\n- Optimisation des temps d'exécution Spark au travers de techniques avancées\n- Mise en oeuvre de producer/consumer Kafka\n- Expérience de travail dans un environnement Agile; avec outils et méthodologies associés (Confluence, Jira, Scrum, Kanban)\nCompétences techniques requises :\n- Spark / Scala : confirmé\n- Kafka : intermédiaire\n- à l'aise avec la programmation fonctionnelle\n- à l'aise avec les concepts d'API\nCompétences relationnelles :\n- Capacité à comprendre les enjeux techniques nombreux sur le projet\n- Capacité à s?organiser et travailler en autonomie et avec rigueur\n- Force de proposition adaptée au contexte client\n- Curiosité, agilité d?esprit, goût pour l?innovation\n- Esprit d?équipe et capacité à dialoguer avec les autres développeurs\n- Bonne communication orale et écrite (Français et Anglais)",
        "ft_reference": "1938911",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala"
            ],
            "DataBase": [
                "HBase"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA SCIENTIST / DATA ENGINEER Exp Banque/Assurance (CDI)PARIS (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938884",
        "description": "Vous êtes passionné(e) par le traitement du langage naturel (NLP), les modèles de langage (LLM) et les applications d?intelligence artificielle générative ? Vous souhaitez travailler sur des projets innovants intégrant les dernières avancées technologiques pour transformer les secteurs banque et assurance ? Vous avez déjà réalisé des projets DATA /IA dans ce secteur d?activité. Cette opportunité est faite pour vous !\n \nPour des missions sur Paris, Luxembourg et Londres, nous recherchons plusieurs profils DATA en CDI avec une première expérience sur des projets DATA / IA en banque ou en assurance.\nVous avez entre 2 et 7 ans d?expérience\nPoste basé à Paris\nIl s?agit d?un poste en CDI temps plein (Remote en fonction des missions)\nSalaire entre 45 000 et 85000 euros suivant expérience et qualifications plus\nBonus de performance\nBonus de publication\nAutres bonus et avantages (Mutuelle et prévoyance, tickets repas)\n \nVos missions principales :\nConception, développement et mise en production de modèles NLP avancés basés sur des architectures modernes adaptés aux besoins des secteurs banque et assurance.\nDéveloppement et personnalisation de solutions IA répondant à des problématiques métiers spécifiques (Exemple de projets réalisés, ..)\nAnalyse de documents réglementaires\nClassification et extraction d'entités dans les contrats d?assurance pour accélérer les processus de souscription et de gestion des sinistres.\nDétection de fraude via des modèles d?apprentissage supervisé et non supervisé.\nChatbots intelligents et assistants virtuels pour améliorer la relation client (gestion des demandes, simulation de prêts, etc.).\nPrédiction des risques liés aux crédits ou aux sinistres à l?aide de modèles de machine learning avancés, des risques de marché ou de liquidité.\nAutomatisation et optimisation\nTrading algorithmique\nEtc...\nDéveloppement de solutions basées sur des frameworks comme LangChain, Langgraph.. et RAG (Retrieval-Augmented Generation) pour des cas d?usage comme :\nRecherche contextuelle dans les bases documentaires.\nProduction automatisée de rapports financiers ou d?analyse de portefeuille.\nEtc..\nAutomatisation des workflows de Machine Learning via des pipelines utilisant des outils comme Kubeflow, MLflow, ou Airflow.\nCollaboration étroite avec les équipes Data Engineering et les experts métier pour garantir la qualité et la scalabilité des solutions développées.\nAnalyse des performances des modèles à l?aide de métriques dédiées (F1-score, BLEU, ROUGE, perplexité, etc.) et optimisation continue en fonction des contraintes métier et réglementaires.\n \nProfil candidat:\nProfil recherché :\nFormation :\nBac+5 ou plus (PHD, ..) (ingénierie, informatique, mathématiques appliquées, ou domaine équivalent).\nExpérience :\nMinimum 3 ans d?expérience en Data Science, avec une expertise solide en NLP, Machine Learning et Deep Learning, idéalement acquise dans les secteurs banque et assurance.\nCompétences techniques essentielles :\nLangages de programmation :\nMaîtrise de Python et des bibliothèques associées (Pandas, NumPy, scikit-learn, matplotlib, seaborn).\nMachine Learning :\nExpertise dans le prétraitement et la vectorisation de données textuelles (TF-IDF, Word2Vec, GloVe, embeddings Transformers).\nDéveloppement et optimisation de modèles adaptés aux cas d?usage spécifiques de la banque et de l?assurance (classification, clustering, régression).\nDeep Learning :\nMaîtrise des frameworks TensorFlow et PyTorch.\nExpérience avec des techniques comme le transfer learning, le fine-tuning de modèles pré-entraînés et l?apprentissage par renforcement (RLHF).\nIndustrialisation des modèles :\nConnaissance des conteneurs avec Docker et des environnements virtualisés.\nUtilisation de CI/CD pour déployer les modèles en production.\nOutils avancés :\nFamiliarité avec des solutions comme ElasticSearch et FAISS pour les recherches vectorielles.\nConnaissance des systèmes distribués pour le traitement des big data, comme Apache Spark.\nIA Agentique : Une expérience est un plus certain.\n \nQualités humaines recherchées :\nCuriosité intellectuelle et capacité à rester à la pointe des technologies émergentes en IA.\nAptitude à résoudre des problèmes complexes et à proposer des solutions innovantes adaptées aux enjeux des secteurs banque et assurance.\nSens aigu de la collaboration et de l?écoute dans un environnement Agile.",
        "ft_reference": "1938884",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "Scikit-Learn",
                "TensorFlow",
                "PyTorch"
            ],
            "DataVisualisation": [
                "Seaborn",
                "Matplotlib"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Airflow"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning",
                "Big Data",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Semarchy (F/H) (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938823",
        "description": "Vous rêvez d?un environnement où la technique, l?innovation et l?agilité se conjuguent au quotidien ?\nVous aimez travailler en mode produit et contribuer à des projets à impact ?\nNous avons une place pour vous chez CELAD ! ?\n \n \nNous poursuivons notre développement et recherchons actuellement un.e Ingénieur.e Data Semarchy pour intervenir sur un projet d?un de nos clients, dans le secteur bancaire. ??\n \n \nCe que vous allez faire ? :\nAu sein d?une organisation en mode produit, vous serez au c?ur des projets et de leur évolution :\n- Comprendre les besoins utilisateurs : Qu?ils soient clients ou collaborateurs, leur satisfaction guidera vos développements,\n- Travailler en équipe pluridisciplinaire : Développeurs, testeurs, designers UX/UI, Product Owners? Vous collaborez dans une squad de 8 à 10 personnes,\n- Adopter les meilleures pratiques : SAFE Agile, Scrum et DevOps sont au programme pour garantir des livraisons fréquentes et qualitatives,\n- Voir loin : Vous contribuerez à des produits pensés pour durer, avec une stratégie d?évolution sur le long terme.\n \n \nVos missions au quotidien :\nEn tant que Data Engineer spécialisé.e sur Semarchy, vous serez au c?ur des projets liés à la gestion et transformation des données. Vos principales responsabilités seront :\n- Concevoir, développer et maintenir des flux d'intégration de données complexes avec Semarchy.\n- Collaborer avec les équipes métiers et techniques pour comprendre les besoins et proposer des solutions adaptées.\n- Participer à la mise en ?uvre et à l?optimisation de pipelines ETL/ELT.\n- Gérer la qualité, la fiabilité et la sécurisation des données au sein des systèmes.\n- Assurer le suivi des performances et proposer des améliorations en termes de performance et de scalabilité.\n- Documenter les processus et garantir leur conformité avec les standards en vigueur.\n \nPourquoi nous rejoindre ? ?\nChez CELAD, l?humain est au c?ur de nos préoccupations :\n- Un onboarding soigné : pour bien démarrer, vous serez accompagné.e dans votre montée en compétences sur les technologies, méthodologies et outils spécifiques au projet,\n- Un suivi régulier : tous les 3 mois, nous faisons le point pour parler de votre progression et de vos attentes,\n- Des facilitateurs à vos côtés : nos coordinateurs vous épaulent au quotidien pour fluidifier vos missions,\n- Une démarche collaborative : vos retours sont intégrés dans nos Comités de Pilotage, car votre avis compte vraiment.\n \n \n? Situation géographique : Nantes (44) \nSalaire : 40-48K?\n \n? Quelques infos importantes à retenir :\n- Expérience de 3 ans minimum sur un poste similaire\n- Possibilité de télétravail (50% TT / semaine)\n- Type de contrat : CDI\n \nAvantages à la clé :\n- 15 jours de RTT (100% \"salarié\" & Rachat à 125%)\n- Participation aux bénéfices\n- Indemnité de déplacement (6? net / jour)\n- Plan Epargne Entreprise\n- Prime de vacances\n- Avance sur salaire\n- Comité Social et Economique\n \n \nSi vous êtes prêt.e à relever ce défi et à contribuer à des projets stimulants, n'hésitez pas à postuler dès maintenant ! ?\n \nProfil candidat:\nPour relever ce défi, nous recherchons un(e) collaborateur(rice) avec :\n- Une expérience confirmée de 3 ans minimum en tant que Data Engineer ou sur un poste similaire.\n- Une bonne maîtrise de Semarchy / Stambia (conception, optimisation et déploiement).\n- Une bonne connaissance des concepts ETL/ELT et des architectures Big Data.\n- Des compétences solides en SQL et bases de données relationnelles (Oracle, PostgreSQL, etc.).\n- Une connaissance des environnements Cloud (AWS, Azure, GCP) et des outils connexes serait un atout.\n- Un excellent esprit d?analyse et une capacité à résoudre des problématiques complexes.",
        "ft_reference": "1938823",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Other": [
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "POT8184-Un Data Engineer AWS sur Vélizy (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "VELIZY VILLACOUBLAY 78",
        "location": "78",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938623",
        "description": "Almatek recherche pour l'un de ses clients, un Data Engineer AWS sur Vélizy.\nExpertise requise :\nExpertise en programmation et développement de pipelines et bases de données (Python, SQL).\nGestion de la donnée.\nSécurité liée à la gestion des données.\nExpertise en services Data sur la plateforme AWS (Certifications AWS : Data Analytics, Big Data...) : S3, HDFS, RDS, Redshift, EMR, Glue.\nExpertise en solutions Big Data/Analytics : Spark, Hadoop, NoSQL.\nExpertise en technologies d?intégration de données de type ETL/EAI : Mulesoft.\nExpertise en chaîne d?automatisation MLOps et CI/CD.\nInfrastructure/system architecture design.\nConnaissance des environnements SI et des écosystèmes data associés à Safran Landing Systems.\nSensibilité aux principes de Data architecture et connaissance en MCD.\nLangue :\nAnglais obligatoire, anglais courant dans un contexte international.\nProfil candidat:\nAlmatek recherche pour l'un de ses clients, un Data Engineer AWS sur Vélizy.\nExpertise requise :\nExpertise en programmation et développement de pipelines et bases de données (Python, SQL).\nGestion de la donnée.\nSécurité liée à la gestion des données.\nExpertise en services Data sur la plateforme AWS (Certifications AWS : Data Analytics, Big Data...) : S3, HDFS, RDS, Redshift, EMR, Glue.\nExpertise en solutions Big Data/Analytics : Spark, Hadoop, NoSQL.\nExpertise en technologies d?intégration de données de type ETL/EAI : Mulesoft.\nExpertise en chaîne d?automatisation MLOps et CI/CD.\nInfrastructure/system architecture design.\nConnaissance des environnements SI et des écosystèmes data associés à Safran Landing Systems.\nSensibilité aux principes de Data architecture et connaissance en MCD.\nLangue :\nAnglais obligatoire, anglais courant dans un contexte international.",
        "ft_reference": "1938623",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Big Data",
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer H/F (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NICE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938585",
        "description": "Intégrer l?équipe Move To Cloud pour réaliser la migration dans le cloud GCP. KARMA est le système de Revenue Management du groupe\n100% migration cloud GCP\nIntégration d?une équipe de 6 personnes\nPrésence sur site (Sophia Antipolis) obligatoire 1x par semaine.\nPrésence sur site (Sophia Antipolis) obligatoire 3x par semaine pendant les 3 premiers mois (on boarding)\nCommunication, leadership, autonomie, coaching\nAnglais niveau B2 Obligatoire\nData engineering / Big Data Development Hadoop et Spark pour migration dans le cloud GCP\nProfil candidat:\nAnglais professionnel\nUne bonne connaissance de l?environnement Hadoop et une expérience certaine en développement Hadoop Dev JAVA 8/11\nHADOOP (notamment module map reduce)/SPARK\nNB : MapReduce est un paradigme de programmation qui permet une évolutivité massive sur des centaines ou des milliers de serveurs dans un cluster Hadoop \nGCP DATA module (GSC/data proc cluster/serverless/bigquery)\nUne bonne connaissance de l?environnement GCP et la réalisation d?une migration Hadoop / Spark dans GCP\nData engineering / Big Data Development Hadoop et Spark pour migration dans le cloud GCPMap Reduce et Spark Java.",
        "ft_reference": "1938585",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938530",
        "description": "Nous recherchons un(e) Data Engineer pour un démarrage ASAP, dans le cadre d?un remplacement. Ce poste est proposé en full télétravail, avec des déplacements ponctuels.\nInformations ClésExpérience : Minimum 5 ans\nSéniorité : Middle / Senior\nLangues : Bilingue anglais requis\nDescription du PosteEn tant que Data Engineer, vous serez en charge de :\nConcevoir, développer et optimiser des pipelines de données pour assurer la collecte, la transformation et le chargement des données.\nCollaborer avec des équipes multidisciplinaires pour comprendre les besoins métiers et garantir des solutions robustes et évolutives.\nMaintenir et améliorer l'écosystème de données en intégrant les meilleures pratiques en matière de qualité et de sécurité des données.\nGérer et superviser des flux de données dans des environnements complexes et distribués.\nCompétences Techniques RequisesLangages : Python, SQL\nOutils ETL : Talend\nPlateformes : Microsoft Fabric\nBases de données : Maîtrise des bases SQL et des environnements associés\nAutres compétences souhaitées : Bonne connaissance des concepts de Data Warehousing, scripting avancé et automatisation des processus.\nProfil candidat:\nSolide expérience en développement et gestion des pipelines de données (au moins 5 ans).\nBonne maîtrise des outils et technologies mentionnés ci-dessus.\nCapacité à travailler dans un environnement agile et à collaborer efficacement à distance.\nAnglais bilingue pour interagir avec des équipes internationales.\nModalitésContrat : Freelance / Indépendant\nLocalisation : Full télétravail avec déplacements ponctuels\nDémarrage : ASAP",
        "ft_reference": "1938530",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer confirmé (H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "GUYANCOURT 78",
        "location": "78",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938489",
        "description": "Le client est un acteur majeur dans le secteur de la construction.\nIl est a la recherche de 2 Data Engineers qui connaissent bien snowflake et sont en capacité de développer des procédures snowflake mais également de travailler sur des sujets de modélisations de données (DTM, DWH).\nDes connaissances en Talend sont aussi nécessaires, mais la priorité repose sur de fortes compétences en modélisation et SQL.\nLes Data Engineers vont être amenés à :\nRéaliser le cadrage technique\nCréer l?ensemble de la chaine d?ingestion de la donnée, aussi bien sur des sources tabulaires que sur du JSON provenant d?API d?IOT.\nTravailler à l?amélioration de notre processus de QOS / QOD mais également notre chaine CI/CD\nProfil candidat:\nIl est important que les profils soient en capacité d?échanger avec des équipes métiers et aient la dimension fonctionnelle de leurs travaux\nStack technique :\nGitHub\nTalend 8\nSnowflake",
        "ft_reference": "1938489",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (Python, SQL, et Scala) (h/f) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938483",
        "description": "emagine recherche pour l'un de ses Clients Grand Compte un(e) Data Engineer (Python, SQL, et Scala)\nRythme: 3 jours sur site + 2 jours de télétravail\nDurée estimée : plus de 12 mois\nLieu : Île de France, 92\nRôle :\nConception et Développement de Pipelines de Données\nGestion et Maintenance de l?Infrastructure Data\nQualité et Sécurité des Données\nSupport aux équipes Data Science et BI\nVeille Technologique et Innovation\nCollaborer avec les data scientists, les chefs de projet data et les équipes métiers pour garantir la qualité et la disponibilité des données\nProfil recherché :\nFormation : Informatique, data engineering, data science ou équivalent\nExpérience : Minimum 5 ans d'expérience en tant que Data Engineer, idéalement au sein d'une entreprise des secteurs de la construction, de l?énergie, ou de la promotion immobilière.\nCompétences techniques :\nMaîtrise des langages de programmation tels que Python, SQL, et Scala\nExpérience avec les Framework(s) de traitement de données\nConnaissance des solutions de gestion de données sur le cloud (Idéalement certification Azure)\nCompétence en modélisation de données (schémas), transport et transformation de la donnée et Data Marts\nBonne compréhension des systèmes de bases de données relationnelles et NoSQL.\nIntéressé? N?hésitez pas à me contacter au X X X X X X X\nProfil candidat:",
        "ft_reference": "1938483",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Azure Java Spark (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938412",
        "description": "? Contexte /Objectifs \nl'entité est en charge des développements liés aux applications sources, de contrôle et de valorisation des instruments, des données de marchés et des facteurs de risques.\nL'application sert à transférer les données sur le Cloud public (Azure) à des fins analytiques.\n ?Objectifs et livrables\nLes enjeux étaient nombreux :\n? Volumétrie de données\n? Performance / Multi-Threading\n? Data Quality\n? Legacy Management\n? Large éventail de technologies à maîtriser :\no Etudes techniques\no Refonte technique et refonte de l?architecture du projet\no Migration On-Premise vers Azure\no Optimisation des performances\no Amélioration du Code Quality\no Mise en place des process CI/CD\no Mise en place du monitoring\no Diverses implémentations et migrations techniques de composants déployés\ndans Azure (AirFlow, Migration Blue/Green, etc?)\nProfil candidat:\n ?Compétences attendues :\nEnvironnement Technique : Java, Kafka, Spark, Azure, PostgreSQL, Oracle, ElasticSearch, Logstash, Kibana, Docker, Kubernetes, Jenkins, Sonar, Intellij, Git, RabbitMQ, Tibco-RDV.",
        "ft_reference": "1938412",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "DataBase": [
                "Elasticsearch"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Git",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer Spark Databricks Sophia Antipolis (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NICE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938395",
        "description": "Ingénieur Data Spark Databricks Sophia Antipolis Stack Technologique :\nSpark - Doit\nDatabricks - Doit\nMicrosoft Azure\nÉchelle\nImpala\nPython ou autre langage centré sur les données\nCompétences:\nAu moins 3 ans d'activités avérées d'ingénierie de données.\nMaîtrise du développement de logiciels utilisant un framework Agile.\nExcellentes compétences en communication\nSolides capacités d?analyse et de résolution de problèmes.\nData engineer Spark Databricks Sophia Antipolis Technological Stack :\nSpark - Must\nDatabricks - Must\nMicrosoft Azure\nScala\nImpala\nPython or other data centric language\nSkills:\nAt least 3 years of proven Data engineering activities.\nProficient developing software using an Agile Framework.\nExcellent communication skills\nStrong analytical and problem-solving abilities.\nProfil candidat:\nIngénieur Data Spark Databricks Sophia Antipolis Stack Technologique :\nSpark - Doit\nDatabricks - Doit\nMicrosoft Azure\nÉchelle\nImpala\nPython ou autre langage centré sur les données\nCompétences:\nAu moins 3 ans d'activités avérées d'ingénierie de données.\nMaîtrise du développement de logiciels utilisant un framework Agile.\nExcellentes compétences en communication\nSolides capacités d?analyse et de résolution de problèmes.",
        "ft_reference": "1938395",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer AWS (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938383",
        "description": "Rejoignez un leader mondial de la transformation digitale, offrant aux collaborateurs l'opportunité de travailler sur des projets innovants intégrant des technologies de pointe.\nPoints forts de l'entreprise :Projets innovants : Travaillez avec des technologies de pointe (Big Data, Cloud).\nCulture internationale : Collaborez avec des entreprises du Fortune 500 dans des secteurs variés (finance, santé, télécoms).\nDéveloppement personnel : Formations continues, certifications (AWS), et parcours de leadership.\nÉquilibre travail-vie personnelle : Flexibilité et télétravail pour un cadre de travail équilibré.\nEngagement durable : Initiatives pour l'environnement et les communautés.\nMissions principales :Créer et gérer des entrepôts de données sur des environnements Cloud (AWS).\nDévelopper des solutions Big Data et optimiser les pipelines de données.\nCollaborer avec les équipes techniques et fonctionnelles.\nAssurer la maintenance et l'évolution des infrastructures de données.\nCompétences requises :Expérience : Minimum 4 ans en Data Engineering.\nExpertise technique : AWS, Big Data, SQL, Spark, Python.\nMéthodologies : Pratique des méthodes Agile/SCRUM.\nLangues : Anglais professionnel requis.\nBonus : Certification AWS est un plus.\nPourquoi rejoindre cette entreprise ?Innovation et leadership mondial : Participez à des projets innovants avec des technologies de pointe.\nEnvironnement inclusif : Culture diversifiée et internationale.\nOpportunités de carrière : Développement continu grâce à des formations et certifications reconnues.\nFlexibilité : Télétravail et équilibre travail-vie personnelle.\nImpact positif : Contribuez à des projets durables et socialement responsables.\nProfil candidat:",
        "ft_reference": "1938383",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (NetVibes indispensable) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "HAUTS DE SEINE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938341",
        "description": "Une expérience de minimum 2 ans dans l?utilisation de Netvibes est indispensable pour cette opportunité.\nDans le cadre de l?exploitation et du développement des applications Netvibes, le Data Engineer Netvibes est responsable de la conception, du développement, et de la maintenance des solutions data. Ce rôle requiert une expertise dans l?écosystème Netvibes (Data Perspectives, Data Queries, Data Model) et une capacité à livrer des solutions robustes, ergonomiques et en phase avec les besoins métiers.\nMissions principales :\nDéveloppement des applications Netvibes :\nÉvaluer les délais nécessaires pour les tâches à réaliser et rédiger leur description technique (ex. estimation de points de complexité, rédaction des tâches sous JIRA).\nContribuer au product backlog\nConcevoir le modèle de données, en coordination avec les Data Perspectives existantes ou à créer.\nDévelopper des solutions sur les briques data Netvibes :\nVisualisations et ergonomie des Data Perspectives.\nData Queries pour extraire les données pertinentes.\nData Model structurant les données nécessaires.\nExploration des données PLM 3DX.\nQualité et performance des développements :\nRéaliser des tests unitaires et agiles pour garantir la fiabilité des livrables.\nRespecter les engagements de performance (points de complexité) et maintenir une vélocité définie avec l?entreprise.\nExploiter efficacement l?environnement de développement fourni par l?entreprise.\nDocumentation et support :\nRédiger une documentation claire et complète des développements réalisés.\nAssister les équipes d?exploitation dans les phases de mise en production.\nPrendre en charge la correction des anomalies identifiées sur les solutions mises en ?uvre (support de niveau 2 ou 3).\nMaintenance et amélioration continue :\nMaintenir en conditions opérationnelles les cas d?usage en phase post-projet.\nParticiper à la rédaction de la Documentation d?Architecture Technique pour accompagner les évolutions d?infrastructure.\nProfil candidat:\nMaîtrise indispensable de l'outil Netvibes.\nBonne maîtrise de Data Factory Studio et Data Perspective Studio.\nBonne compréhension des flux de données dans des environnements Cloud.\nConnaissances en BI et compétences avérées dans la création de tableaux et rapports analytiques.",
        "ft_reference": "1938341",
        "skills": {
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER SEMARCHY / SAP BO F/H / NANTES (44) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938073",
        "description": "VOTRE QUOTIDIEN RESSEMBLERA A?\nVous rejoignez notre client et serez en charge de :\nComprendre l?activité et les besoins des clients, ainsi que le SI de production en collaboration avec la MOA/MOE\nModéliser le SI décisionnel \nAssurer la conception et la réalisation \nAssurer le diagnostic des dysfonctionnements rencontrés\nRéaliser les maintenances correctives et évolutives\nIntervenir sur du support de N3 sur les outils Semarchy XDI (Stambia) et SAP BO\nCréer, modélisation et alimenter un datamart via des process Semarchy (Stambia) \nCréer des rapports d?audit sur SAP BO\nAnalyser des tables VERTICA/MSSQL\nAssurer le scripting Powershell / Batch file\nApporter votre support auprès des différents métiers\nRédiger la documentation technique\nSuivre les traitements\nPiloter les projets \nEnvironnement Technique : Stambia, Semarchy XDI, SAP BO, Vertica, MSSQL, Powershell, Batch\n \nLe poste est basé à Nantes (44). Dans le cadre de vos fonctions, vous pourrez bénéficier de 1 jour de télétravail par semaine après votre période d'intégration.\nProfil candidat:\nVOUS NOUS APPORTEREZ ...\nVotre formation supérieure (Bac+5 ou Ecole d'Ingénieur) spécialisée en data\nVotre expérience de 5 ans minimum sur un poste similaire\nVotre maîtrise de Semarchy XDI (Stambia) et SAP BO \nET SURTOUT !\nVotre rigueur et votre sens des priorités\nVotre autonomie et votre capacité à proposer des solutions\nVotre esprit d'équipe et votre bonne humeur",
        "ft_reference": "1938073",
        "skills": {
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA Engineer Python, Data bricks, Azure (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938028",
        "description": "Nous recherchons un(e) Data Engineer passionné(e) et expérimenté(e) pour rejoindre une équipe innovante et participer au développement d'une plateforme de Big data. Cette plateforme vise à optimiser la gestion des risques et la performance des activités dans les domaines de la Supply Chain\nMissions :\nDéveloppement et optimisation des pipelines de données pour l?orchestration des modèles de machine learning (préparation des features, entraînement, tuning, inférence).\nCollaboration étroite avec les Quants et Data Scientists pour résoudre les problématiques liées au cycle de vie des modèles de machine learning.\nRédaction de spécifications techniques et documentation des développements.\nImplémentation de tests automatisés pour garantir la fiabilité des solutions mises en place.\nMise en production des développements et suivi de leur activité à travers des tableaux de bord.\nMaintenance, corrections et évolutions des outils existants.\nCompétences requises :\nLangages : Maîtrise avancée de Python et Spark.\nTechnologies : Expérience avec Data bricks, Azure et SQL.\nMLOps : Bonne compréhension des enjeux liés aux Feature Stores .\nMachine Learning : Expérience dans la gestion du cycle de vie des modèles ML (préparation, entraînement, tests, déploiement).\nCommunication : Maîtrise de l'anglais (écrit et oral) et capacité à s'adapter à différents interlocuteurs.\nProfil candidat:\nDe formation Bac+5 minimum au sein d'une école d'ingénieur ou d'informatique, vous avez une expérience de 7 ans minimum en tant que DATA Engineer Python, Data bricks, Azure\nData Engineer expérimenté(e) avec une forte expertise en Python et Spark.\nPassionné(e) par les technologies de machine learning et de big data.\nCapacité à collaborer efficacement avec des équipes pluridisciplinaires (Quants, Data Scientists).\nAutonomie, rigueur et esprit d'innovation dans la résolution de problèmes complexes.",
        "ft_reference": "1938028",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "ML",
                "Big Data",
                "Machine Learning"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F) (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANCY 54",
        "location": "54",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938027",
        "description": "Directement intégré à la DSI, et sous la responsabilité du responsable Data, vous serez responsable de la conception, de la construction et de la maintenance des infrastructures de données. Vous vous assurez que les données soient facilement accessibles, de haute qualité et bien organisées pour répondre aux besoins des équipes d'analyse et des data scientist. Vous serez amené à : \n- Construire et maintenir des pipelines ETL (Extract, Transform, Load)\n- Intégrer des données issues de plusieurs sources (BDD, API, fichiers, etc.)\n- Configurer et gérer les bases de données relationnelles et NoSQL\n- Mettre en place des processus pour garantir la qualité, la cohérence et l'intégrité des données\n- Automatiser les processus de nettoyage et de transformation des données\n- Travailler en étroite collaboration avec les Data Scientist et Analyst\n- Surveiller les flux de données \n- Maintenir et documenter les flux et l'infrastructure des données\nProfil candidat:\nDiplômé en informatique, ingénierie de la données ou mathématiques (niveau bac+5), vous disposez d'une expérience concrète à un poste similaire. Techniquement, vous êtes à l'aise avec l'environnement suivant : Python, Java, Scala, SGBDD (SQL, NoSQL), MySQL, PostgreSQL, MongoDB, Cassandra, outils d'ETL (NiFi, Dagster Talend, Informatica), Big Data (Hadoop, Spark, Kafka), Cloud (Azure, GCP, AWS). Vous êtes reconnu pour votre capacité à comprendre et manipuler des ensembles de données complexes ainsi que pour vos compétences en résolution de problèmes et optimisation de flux de données. Humainement, vous disposez d'excellentes compétences en communication et en travail collaboratif. \nInformations complémentaires : CDI à pourvoir rapidement à Nancy, salaire selon profil et expérience (35/45kEUR annuel brut)\nSi cette opportunité correspond à vos aspirations professionnelles alors faites-moi parvenir votre candidature. J'étudierai cette dernière et reviendrai vers vous dans les meilleurs délais pour un suivi personnalisé de votre profil !",
        "ft_reference": "1938027",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "MongoDB",
                "SQL",
                "Cassandra"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "MySQL",
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [
                "Cassandra"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "IVRY SUR SEINE 94",
        "location": "94",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937999",
        "description": "Contexte : \nNous recherchons un Data Engineer Confirmé EN PRE EMBAUCHE pour renforcer notre Data Factory.\nVous aurez la charge de concevoir, déployer et optimiser des pipelines de données tout en garantissant la qualité et la résilience des traitements.\nVous interviendrez principalement sur les technologies microsoft SSIS, SSAS, SSRS avec une ouverture recommandée sur Talend, OpenText et les solutions cloud de Google Cloud Platform (GCP).\nDescription: \n? Concevoir, développer et maintenir des workflows ETL robustes et optimisés avec SSIS, en exploitant pleinement les fonctionnalités avancées telles que la gestion des packages, l?optimisation des performances, l?orchestration des traitements complexes et l?intégration de différentes sources de données. Collaborer avec les équipes pour assurer une mise en ?uvre fluide et scalable des processus ETL.\n? Exploiter SSAS pour le développement et la gestion de cubes OLAP afin d'optimiser les analyses multidimensionnelles.\n? Utiliser SSRS pour maintenir et faire évoluer des rapports interactifs et automatisés répondant aux besoins des utilisateurs métiers.\n? Analyser les besoins métiers pour traduire leurs attentes en solutions techniques adaptées.\n? Réaliser des analyses approfondies des données pour garantir leur pertinence et répondre efficacement aux besoins identifiés.\n? Identifier et résoudre les goulots d?étranglement affectant les performances des pipelines de données.\n? Intégrer, transformer et charger les données depuis différentes sources en assurant leur qualité et leur cohérence.\n? Mettre en place et optimiser des pipelines de données sur des environnements hybrides (on-premise et cloud).\n? Assurer la résilience et le monitoring des traitements de données.\n? Collaborer avec les équipes Data Analysts, Data Scientists et autres Data Engineers pour répondre aux besoins des métiers.\n? Rédiger la documentation technique associée aux pipelines et aux traitements.\n? Participer aux phases de recette et garantir la conformité des livrables.\nProfil candidat:\nLivrables : \nDéveloppement\nCahier de recette\nDossier de recette / Mise en production\nSpécifications\nDocument d'exploitation\nFiche consigne\nCompétences\nCompétences techniques :\n? Expertise avérée sur SSIS pour le développement de processus ETL complexes.\n? Connaissance des technologies Talend, OpenText (souhaité).\n? Expérience sur Google Cloud Platform, incluant les outils BigQuery, Dataform et Cloud Composer.\n? Maîtrise avancée en SQL pour la manipulation et l?optimisation des bases de données.\n? Connaissance des concepts de Data Warehousing et des modèles en étoile et en flocon.",
        "ft_reference": "1937999",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937975",
        "description": "Nous recherchons un nouveau collaborateur pour maintenir et faire évoluer le référentiel de données historique.\nCe référentiel repose sur une base de données Oracle et contient un ensemble de traitement en PL/SQL.\nDe nombreux flux de données (fichier, message) en entrée viennent alimenter le référentiel, ces données sont ensuite consolider puis diffuser vers les clients du référentiel.\nLe référentiel est un élément centrale dans le système d'information.\nLa mission se compose de plusieurs tâches :\n1. Le suivi de la production (contrôle des flux, contrôle des traitements, ...)\n2. Traitement de ticket incidents et demandes de service\n3. Identification et gestion des problèmes\n4. Contribution pour des projets\n5. Assistance utilisateur\nUne bonne culture informatique est indispensable (flux, architecture, api, webservice)\nNous sommes une équipe Agile organisée autour de la méthodologie SCRUM.\nLa participation aux rituels d'équipe et l'esprit d'amélioration continu sont indispensables.\nUn bon sens du relationnel est également important car le référentiel de données est central dans le SI et nous sommes amenés à travailler avec différentes\néquipes et interlocuteurs (métier ou IT)\n2j de télétravail par semaine.\nSi la data n'a plus de secret pour toi et que tu souhaites découvrir le monde du RETAIL au sein d'une équipe sympa, bienveillante et dynamique, cette mission\nn'attend que toi !\nProfil candidat:\nNous sommes une équipe Agile organisée autour de la méthodologie SCRUM.\nLa participation aux rituels d'équipe et l'esprit d'amélioration continu sont indispensables.\nUn bon sens du relationnel est également important car le référentiel de données est central dans le SI et nous sommes amenés à travailler avec différentes\néquipes et interlocuteurs (métier ou IT)\n2j de télétravail par semaine.\nSi la data n'a plus de secret pour toi et que tu souhaites découvrir le monde du RETAIL au sein d'une équipe sympa, bienveillante et dynamique, cette mission\nn'attend que toi !\nCompétences techniques :\nOracle SQL - Expert - Impératif\nOracle PL/SQL - Expert - Impératif\nODI - Confirmé - Important\nShell - Confirmé - Important",
        "ft_reference": "1937975",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DBMS": [
                "Oracle SQL"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer SSIS, SSAS, SSRS Talend, GCP (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937966",
        "description": "Dans le cadre du renforcement de la Data Factory, nous recherchons un Data Engineer Confirmé pour rejoindre l'un de nos clients. En tant que Data Engineer, vous serez responsable de la conception, du déploiement et de l'optimisation des pipelines de données, en garantissant la qualité et la résilience des traitements. Vous interviendrez principalement sur les technologies Microsoft (SSIS, SSAS, SSRS), tout en étant amené à travailler avec des outils complémentaires tels que Talend, Open Text et des solutions Cloud sur Google Cloud Platform (GCP).\nConception et développement de pipelines ETL : Concevoir, développer et maintenir des workflows ETL robustes et optimisés avec SSIS, en tirant parti des fonctionnalités avancées telles que la gestion des packages, l'optimisation des performances, et l'orchestration des traitements complexes. Vous assurerez l'intégration fluide des différentes sources de données et la scalabilité des processus ETL.\nGestion de cubes OLAP avec SSAS : Exploiter SSAS pour développer et gérer des cubes OLAP afin de faciliter les analyses multidimensionnelles.\nReporting avec SSRS : Utiliser SSRS pour créer, maintenir et faire évoluer des rapports interactifs et automatisés, en fonction des besoins des utilisateurs métiers.\nAnalyse des besoins métiers : Analyser les besoins des utilisateurs métiers et proposer des solutions techniques adaptées.\nOptimisation des performances : Identifier les goulots d?étranglement dans les pipelines de données et mettre en place des solutions pour optimiser les performances.\nGestion des données : Intégrer, transformer et charger des données en garantissant leur qualité et leur cohérence.\nMise en place de pipelines hybrides : Mettre en ?uvre et optimiser des pipelines de données dans des environnements hybrides (on-premise et cloud).\nRésilience et monitoring : Assurer la résilience des traitements de données et mettre en place un monitoring efficace.\nCollaboration : Travailler en étroite collaboration avec les équipes Data Analyst, Data Scientists, et autres Data Engineer pour répondre aux besoins métiers.\nDocumentation et recette : Rédiger la documentation technique des pipelines et des traitements, et participer aux phases de recette pour garantir la conformité des livrables.\nProfil candidat:\nDe formation Bac+5 minimum au sein d'une école d'ingénieur ou d'informatique, vous avez une expérience de 2 ans minimum en tant que Data Engineer SSIS, SSAS, SSRS Talend, GCP",
        "ft_reference": "1937966",
        "skills": {
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer H/F (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937927",
        "description": "? Participer aux analyses, études d?impacts et cadrage techniques \n? Concevoir des solutions en respectant les bonnes pratiques d?architecture data et développement \n? Réaliser le développement de nouveaux data products et assurer la maintenance évolutive et corrective des data products existants \n? Rédiger la documentation technique des data products \n? Assurer un support aux testeurs \n? Reporter de ton activité à ta Squad et travailler dans une démarche d?efficacité\ncollective \nUne pratique opérationnelle de l?anglais est également nécessaire pour la rédaction de la documentation et la participation à certaines cérémonies.\nProfil candidat:\n? Langages de programmation : Python, SQL, Scripts Shell\n? Services de streaming data : Kafka\n? Services d?ingestion des données : Kafka Connect, SFTP\n? Services de stockage : GCP BigQuery, Cloud Storage, Kafka, Sharepoint\n? Processing : Scripts Python, GCP Dataflow, Data Build Tool (DBT)\n? Restitution : Looker (Dashboards, Explores de données), Fichiers de reporting (CSV, Excel)\n? Outils de collaboration et de CI/CD : GitLab, Flamingo\n? Docker, Kubernetes, Kustomize, Helm, Terraform",
        "ft_reference": "1937927",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER GCP (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937880",
        "description": "Missions principales :\n? Participer aux analyses, études d?impacts et cadrage techniques\n? Concevoir des solutions en respectant les bonnes pratiques d?architecture data et développement\n? Réaliser le développement de nouveaux data products et assurer la maintenance évolutive et corrective des data products existants\n? Rédiger la documentation technique des data products\n? Assurer un support aux testeurs\n? Reporter l?activité à la Squad et travailler dans une démarche d?efficacité collective\nLivrables principaux :\n? Rédiger les documentations techniques liés à ta solution, incluant le modèle de\ndonnées, les procédures, l?ordonnancements\n? Faire des propositions techniques\nCompétences techniques :\n? Langages de programmation : Python, SQL, Scripts Shell\n? Services de streaming data : Kafka\n? Services d?ingestion des données : Kafka Connect, SFTP\n? Services de stockage : GCP BigQuery, Cloud Storage, Kafka, Sharepoint\n? Processing : Scripts Python, Data Build Tool (DBT), GCP Dataflow\n? Restitution : Looker (Dashboards, Explores de données), Fichiers de reporting (CSV,\nExcel)\n? Outils de collaboration et de CI/CD : GitLab, Flamingo\nUtilisation de plateformes pour le développement et le déploiement : Docker,\nKubernetes, Kustomize, Helm, Terraform\n? Testing : Tests avec DBT, Tests de non-régression, collaboration avec la QA.\n? Manipulation des formats de fichiers : CSV, JSON, Avro, XML\nCompétences transverses :\n? Autonomie et rigueur\n? Curiosité, veille technologie sur le data engineering et sur l?AI / ML\n? Capacité à aborder des problèmes complexes de manière structurée\n? Aptitude à concevoir des solutions innovantes\n? Capacité d?écoute, d?analyse et de synthèse\n? Capacité à communiquer, à travailler en équipe et excellent relationnel\n? Proactivité et prise d?initiative\nProfil candidat:\nMissions principales :\n? Participer aux analyses, études d?impacts et cadrage techniques\n? Concevoir des solutions en respectant les bonnes pratiques d?architecture data et développement\n? Réaliser le développement de nouveaux data products et assurer la maintenance évolutive et corrective des data products existants\n? Rédiger la documentation technique des data products\n? Assurer un support aux testeurs\n? Reporter l?activité à la Squad et travailler dans une démarche d?efficacité collective\nLivrables principaux :\n? Rédiger les documentations techniques liés à ta solution, incluant le modèle de\ndonnées, les procédures, l?ordonnancements\n? Faire des propositions techniques\nCompétences techniques :\n? Langages de programmation : Python, SQL, Scripts Shell\n? Services de streaming data : Kafka\n? Services d?ingestion des données : Kafka Connect, SFTP\n? Services de stockage : GCP BigQuery, Cloud Storage, Kafka, Sharepoint\n? Processing : Scripts Python, Data Build Tool (DBT), GCP Dataflow\n? Restitution : Looker (Dashboards, Explores de données), Fichiers de reporting (CSV,\nExcel)\n? Outils de collaboration et de CI/CD : GitLab, Flamingo\nUtilisation de plateformes pour le développement et le déploiement : Docker,\nKubernetes, Kustomize, Helm, Terraform\n? Testing : Tests avec DBT, Tests de non-régression, collaboration avec la QA.\n? Manipulation des formats de fichiers : CSV, JSON, Avro, XML\nCompétences transverses :\n? Autonomie et rigueur\n? Curiosité, veille technologie sur le data engineering et sur l?AI / ML\n? Capacité à aborder des problèmes complexes de manière structurée\n? Aptitude à concevoir des solutions innovantes\n? Capacité d?écoute, d?analyse et de synthèse\n? Capacité à communiquer, à travailler en équipe et excellent relationnel\n? Proactivité et prise d?initiative",
        "ft_reference": "1937880",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataSerialization": [
                "XML",
                "Avro",
                "Json"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "ML",
                "CI/CD",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Initiative",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "leader informatique technique informatique Data Engineer (H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937858",
        "description": "Basée à Lille, Lyon, Nantes, Grenoble et Bruxelles, Insitoo Freelances est une société du groupe Insitoo, spécialisée dans le placement et le sourcing des Freelances IT et Métier. Depuis 2007, Insitoo Freelances a su s?imposer comme une référence en matière de freelancing par son expertise dans l?IT et ses valeurs de transparence et de proximité. Actuellement, afin de répondre aux besoins de nos clients, nous recherchons un Leader Technique Data Engineer (H/F) à Lyon, France.\nContexte :\nNous cherchons un Data Engineer expérimenté. Voici un résumé de la mission : \nProjet : Ce profil expérimenté (4 à 7 ans d?XP.) interviendra dans une équipe. Cette équipe aura pour charge d?acquérir les données de mesures ainsi que la responsabilité des acquisitions et des traitement de purge des données.\nSon rôle sera un poste de TechLead et devra superviser/ appuyer une équipe agile de 9 collaborateurs.\nLocalisation : Limonest (2 à 3 jours par semaine)\nDurée de la mission : Mission de longue durée \nLes missions attendues par le Leader Technique Data Engineer (H/F) :\nMission : \n- Relecture de codes ;\n- Réalisation d?US ;\n- Participation à des ateliers techniques transverses ;\n- Cadrage et conception ;\n- Résolution de problèmes techniques et d?incidents complexes ;\n- Réalisation de tests automatisés et de performances ;\n- Rédaction de la documentation technique ;\n- Analyse de données ;\nTechnologies : \n- SQL TERADATA\n- SPRING BOOT\n- SPRING BATCH\n- KAFKA\n- KUBERNETES\n- GITLAB\n- JENKINS\n- CUCUMBER, JMETER\n- IDATHA /GRAFANA\nProfil candidat:\n- Connaissances poussées dans les frameworks JAVA SPRING BATCH et SPRING BOOT ;\n- Aisance avec le langage SQL ;\n- Connaissance avec les outils de containérisation de microservice (Kubernetes) ;\n- Chaine CI/CD (GitLab, Jenkins, ?.) ;\n- Expérience requise d?au moins 4 ans sur un projet similaire (Data, Traitement Back) ;\n- Des connaissances et une expérience avec KAFKA serait un plus.\n- Pro-actif dans les propositions d?améliorations continues ;\n- Leadership et pédagogie ;",
        "ft_reference": "1937858",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Other": [
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Leadership"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Azure Data Factory/Synapse (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937855",
        "description": "Bonjour, \nDans le cadre de ses projets clients, Visian est à la recherche d'un Senior Data Engineer Azure Data factory : \nPrincipales responsabilités du poste :\nS'assurer que les modèles sont expliqués et compris.\nValider les développements au cours des premiers mois.\nRépondre aux questions des ingénieurs en données et assurer la liaison avec l'architecte si nécessaire.\nGarantir que tous les développements respectent les politiques de l'équipe et que les performances sont optimales.\nMettre en ?uvre ou participer à des développements complexes.\nDévelopper des normes et un kit de développement (pipelines de données, journaux, CI/CD, surveillance de la qualité des données).\nAccompagnement des profils juniors\nQualités attendues :\nCapacité à travailler en mode collaboratif au sein d'une squad pour livrer dans tous les environnements.\nAvoir une attitude orientée client.\nCapacité à collaborer avec des ressources offshore.\nSavoir communiquer entre les aspects techniques et non techniques.\nSi vous êtes actuellement à l'écoute du marché, je vous invite à m'envoyer votre candidature.\nBien à vous,\nNadia\nProfil candidat:\nData Engineer senior/ Lead data engineer. avec les compétences suivants: \nExpérience dans le mentorat d'autres ingénieurs en données et le partage des connaissances.\nExpérience avérée dans la conception, l'implémentation et la maintenance de pipelines de données ETL.\nExcellente maîtrise de SQL et des approches d'optimisation des requêtes.\nSolide connaissance et expérience avec des technologies de traitement de données distribuées comme Snowflake, Azure Synapse, Spark.\nCapacité à définir de nouvelles pratiques et à remettre en question les meilleures pratiques existantes pour le traitement et l'architecture des données.\nCapacité à conduire des initiatives technologiques de manière autonome, de l'idée à la mise en ?uvre.\nRecherche de solutions pragmatiques pour équilibrer les différentes exigences des projets de données, en construisant des systèmes robustes créant des synergies plutôt que des systèmes hérités.\nExpérience dans les environnements de production : documentation, spécifications, tests unitaires, déploiement, optimisation de code, versionnement de code.\nExpérience dans l'identification et la mise en ?uvre d'outils d'automatisation et DevOps : Azure DevOps, Terraform, Airflow, Ansible, Maven, Git, Jenkins, etc.\nExpérience avec les technologies de script comme JavaScript, Python, PowerShell.\nExpérience avec les technologies Cloud-Native, en particulier Azure.",
        "ft_reference": "1937855",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Senior- Datalake/Cloudera/Spark/ (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937840",
        "description": "Nous recherchons des Data Engineer experimentés ayant (4ans-7ans-11ans) d'expériences avec Datalake et Cloudera 7.1.9; les taches sont:\n \n- Assurer la maintenance évolutive et corrective,\n \n- Analyser, réaliser, assembler, valider techniquement et fonctionnellement et livrer des composants logiciels,\n \n- Assurer les développements spécifiques en cycle en V ou en méthode SCRUM,\n \n- Réaliser les tests unitaires et d'intégration,\n \n- Assurer le suivi de la production, Accompagner les utilisateurs,\n \n-Participer à l'étude de faisabilité en phase d'avant-projet pour identifier la solution, le chiffrage et les délais de mise en oeuvre.\n \n- Elaborer le plan projet MOE : périmètre - charges - planning - organisation, constituant l'engagement de la MOE, et le fait valider.\n \n- Rédiger le bilan du projet\n \n- Rôle de conseil, d'assistance, de formation, d'information et d'alerte auprès de l'équipe en charge du Système d'Information sur des aspects techniques très pointus,\nProfil candidat:\nLes environnements techniques :\n \n* Solvency 2, Systèmes délégataires et BI: \n \n- Stockage : Oracle 19\n \n- Informatica PowerCenter 10.5\n \n- Business Object B4.3\n \n- SAS - Angular - .Net, C#\n \n* Datalake : \n \n- Cloudera 7.1.9,\n \n- Outils Bigdata classiques : Spark/java Hive, Hue, OOZIE, ...\n \n- Git, Shell 3.2.",
        "ft_reference": "1937840",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "BigData": [
                "Spark"
            ],
            "DevTools": [
                "Git"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer EXPERT POWER BI (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "MONTREUIL 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937838",
        "description": "Contexte et Enjeu : \nData Engineering dans le domaine  DATA ANALYTICS AND MANAGEMENT PLATFORMS  au sein de la division DATA Artificial Intelligence and Innovation, intégréation au c?ur des équipes de production travaillant autour de la Data pour l?ensemble des métiers du groupe, garant de la maitrise et de la cohérence des architectures fonctionnelles et applicatives DATA délivrés à nos différents métiers.\nDans ce rôle vous serez amené à :\n?Comprehension et analyse des besoins en Dataviz Power BI sur de nombreux domaines fonctionnels afin d?y apporter des solutions adéquates et durables.\n?Promotion des nouvelles fonctionnalités ainsi que les bonnes pratiques au sein de l?ensemble de la Communauté des utilisateurs Tableau.\n?Accompagnement via des missions de coaching les nouveaux utilisateurs et conception des parcours de formation adaptés aux besoins de chacun. \n?Conception des dashboards  MVP  pour illustrer les nouvelles features de l?offre  Groupe .\nEpaulé par des Product Owners et des Offering Managers, accompagnement de chaque évolution en proposant la meilleure solution Data possible en respectant les règles d'urbanisation, les normes fonctionnelles et logicielles.\nDans l'équipe responsable des outils de Dataviz & Prep (Tableau, Cognos, Power BI, Dataiku, 50 personnes), travail dans un cadre d'agilité. Vous échangerez avec des collaborateurs du groupe du monde entier en anglais et en français.\nTravail de manière rapprochée avec le Group Data Office, les architectes groupe, les Offering Managers, Tech leads et Product Owners et serez un moteur pour la conception de solutions et de services DATA efficaces pour nos métiers (Retail, Assurance, Crédit, Leasing, fonctions?)\nLes principales missions du Data Engineer Power BI sont :\n?Une expertise  full-stack  sur la technologie Power BI afin d?accompagner les clients de l?offre  Groupe \n?Intégration et administration de la solution au Système d?information (Report Server & o365 )\n?Industrialisation et automatisation des déploiements (Power apps)\n?Expertise sur le déploiement de la solution en onprem Report Server comme en online o365\n?Expertise sur ces technos en tant que support niveau 3 sur des incidents de production, accompagnement, conseil sur l'utilisation de ces technologies et leur modélisation\n?Une prise en charge du support sur les incidents de production en interaction potentielle avec le support du fournisseur Microsoft pour le maintien en condition opérationnel de la plateforme\n?Un coaching / accompagnement des clients / prospects de l?offre  Groupe \n?Accompagnement du support des IT métiers et du maintien en condition opérationnel des applications\nProfil candidat:\nCompétences Techniques indispensables :\n-Administration du Tenant Power BI o365, Administration Report Server, Power BI Desktop, Power Query\n-Bases de données relationnelles (Oracle, SQL Server, Postgre, SSAS, SISS?)\n-Pratique de Modélisation de datamart de Reporting\nCompétences Facultatives : \n-Notions system & r éseau Windows (AD)\n-Connaissance des architecture Cloud\n-Notions sur les produits de dataviz du marché (Tableau, ?) \n-Application des méthodes Agile : Scrum et Kanban : JIRA/Confluence\n-Outillage et pratiques DEVOPS : Industrialisation de l?intégration et du déploiement de la solution : Git/Jenkins/Artifactory/Ansible\n-Capacité à scripter (PowerShell / python, ...)",
        "ft_reference": "1937838",
        "skills": {
            "ProgLanguage": [
                "Python",
                "R"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "OS": [
                "Windows"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "Automation": [
                "Ansible"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER GCP (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937813",
        "description": "Bonjour,\nPour le compte de notre client tu interviendras dans la transformation d?un projet majeur, où tu devras développer la Data Platform et l'ensemble des services Data qui seront exposés aux différentes équipes du client. Aussi, tu seras amené à développer des use cases data.\nEgalement, tu participeras à la migration du DWH Oracle vers Big Query GCP.\nDans ce sens, tes missions seront les suivantes :\nDesigner l'architecture et développer la solution\nDéfinir et développer les Data Model\nÊtre garant de la qualité du code\nEnvironnement technique :\nGCP (BigQuery, Cloud Run, Cloud Build)\nSQL et PL/SQL \nPython\nMéthodologie Agile\nProfil candidat:\nBac + 5 minimum\nExpérience de 2 ans minimum dans le domaine data et cloud GCP\nExpertise SQL\nForte expérience avec l'outil Big Query\nAnglais technique / professionnel\nRigoureux et bon communicant",
        "ft_reference": "1937813",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "Big Query",
                "BigQuery"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Expérimenté (H/F) (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937727",
        "description": "Notre client, société en pleine croissance, spécialisé dans le domaine du Big Data, recherche des Consultants Data Engineer expérimentés avec minimum 3 ans d'expérience ! Participez à cette aventure et rejoignez une formidable équipe. \nVos missions principales seront diversifiées, comprenant notamment :\n- Participation aux processus d'avant-vente : Vous contribuerez à l'élaboration des propositions techniques, mettant en avant votre expertise pour répondre aux besoins des clients.\n- Qualification technique des prestataires : Vous participerez activement à l'évaluation et à la sélection des prestataires, garantissant un partenariat de qualité.\n- Direction et coordination des projets : Vous dirigerez et coordonnerez la conception et la mise en oeuvre des projets, assurant leur réussite technique.\n- Documentation technique : Vous élaborerez, au besoin, des dossiers d'architecture, d'installation et d'exploitation, assurant une traçabilité et une compréhension optimale des solutions mises en place.\n- Participation active aux développements : Vous apporterez votre expertise en contribuant directement aux développements dans le cadre des projets.\nDe manière plus étendue, vous aurez l'opportunité de :\n- Enrichir les bonnes pratiques : Vous contribuerez à l'évolution et à l'amélioration des bonnes pratiques d'architecture et de développement dans le domaine du Big Data.\n- Veille technologique : Vous réaliserez une veille constante sur les avancées technologiques du secteur, assurant ainsi la pertinence des solutions proposées.\n- Formation technique : Vous élaborerez des supports de formation technique pour nos clients et/ou nos consultants juniors, partageant ainsi votre savoir-faire.\n- Animation du pôle technique : Vous participerez activement à l'animation du pôle technique favorisant un environnement collaboratif et innovant.\nProfil candidat:\nVous êtes détenteur d'un diplôme d'ingénieur (école ou université), et vous avez 3 ans d'expérience en tant que Data Engineer. \nEn tant que Consultant Data Engineer, nous recherchons des professionnels possédant des compétences solides et des convictions dans les domaines suivants :\n- Architectures Big Data : Kappa, Lambda, Réactive, SMACK, etc.\n- Solutions technologiques : Hadoop, SGBD NoSQL, Kafka, Spark, etc.\n- Outils de développement : Vous êtes à l'aise avec des outils tels que Hive, Pig, Python, Scala, etc.\n- Environnements d'exploitation et de supervision : Vous avez une expérience pratique avec des outils tels qu'Ambari, Oozie, Zookeeper, etc.",
        "ft_reference": "1937727",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "NoSQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "Other": [
                "Big Data"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937705",
        "description": "Dossier de spécifications / conception / Documentation technique\nMode opératoire / suivi opérationnel / traitement des incidents\nCode en fonction de la technologie (SQL, ...)\nCompétences techniques\nOracle SQL - Expert - Impératif\nOracle PL/SQL - Expert - Impératif\nODI - Confirmé - Important\nShell - Confirmé - Important\nDescription détaillée\nNous recherchons un nouveau collaborateur pour maintenir et faire évoluer le référentiel de données historique IGR.\nCe référentiel repose sur une base de données Oracle et contient un ensemble de traitement en PL/SQL.\nDe nombreux flux de données (fichier, message) en entrée viennent alimenter le référentiel, ces données sont ensuite consolider puis diffuser vers les clients du référentiel.\nLe référentiel est un élément centrale dans le système d'information.\nLa mission se compose de plusieurs tâches :\n1. Le suivi de la production (contrôle des flux, contrôle des traitements, ...)\n2. Traitement de ticket incidents et demandes de service\n3. Identification et gestion des problèmes\n4. Contribution pour des projets\n5. Assistance utilisateur\nUne bonne culture informatique est indispensable (flux, architecture, api, webservice)\nProfil candidat:\nNous sommes une équipe Agile organisée autour de la méthodologie SCRUM.\nLa participation aux rituels d'équipe et l'esprit d'amélioration continu sont indispensables.\nUn bon sens du relationnel est également important car le référentiel de données est central dans le SI et nous sommes amenés à travailler avec différentes\néquipes et interlocuteurs (métier ou IT)\n2j de télétravail par semaine.",
        "ft_reference": "1937705",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DBMS": [
                "Oracle SQL"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Snowflake / SSIS (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937610",
        "description": "? Data Engineer Passionné ? pour un beau projet technique au sein d'une entreprise innovante.\n? Contexte :\nRejoignez une entreprise innovante où vous serez au c?ur de la gestion et optimisation des pipelines de données ?, en garantissant leur qualité et leur intégrité. Vous travaillerez dans un environnement scientifique stimulant, avec un accent particulier sur les biotechnologies et des projets techniques de grande envergure.\n? Qualifications & Exp érience requises : * ? Master en informatique, data engineering ou équivalent.\n* ?? Expérience préalable :\n? Minimum 3 ans en Data Engineering.\n? Solides compétences en SQL, ETL, et gestion de données à grande échelle.\n* ? Bonus : Expertise dans les environnements scientifiques ou biotechnologiques appréciée.\n?? Compétences techniques : * Gestion des données : ? ?? Snowflake (expertise dans la gestion de données et la création de pipelines).\n? ? SSIS (Intégration des données et gestion des flux ETL).\n? ?? SQL (requêtes complexes, optimisation des performances).\n* Pipeline & Data Engineering :\n? Conception, gestion et optimisation de pipelines de données, en garantissant leur qualité et leur intégrité.\n* Cloud & DevOps :\n? ?? Expérience avec AWS (environnement full-cloud pour la gestion des données).\n? ? Familiarité avec les microservices et API RESTful.\n? Profil recherché : * ?? Langues : Niveau professionnel en anglais (indispensable pour réunions et reportings).\n* ? Compétences clés :\n? Forte capacité à résoudre des problèmes techniques complexes.\n? Esprit analytique et goût pour les challenges.\n? Capacité à collaborer efficacement avec des équipes multidisciplinaires.\n? Conditions & avantages : * Contrat : CDI avec salaire compétitif selon expérience.\n* ??? Environnement stimulant : Opportunité de travailler sur des projets innovants dans des domaines scientifiques.\n? Pourquoi les rejoindre ?\nIntégrez une structure où la technologie, l'innovation et la collaboration sont au c?ur des missions. Vous aurez l'opportunité de travailler sur des projets à forte valeur ajoutée dans un environnement flexible et moderne.\n? Intéressé ?\nEnvoyez-moi votre CV et vos disponibilités pour un échange rapide ! ?\nProfil candidat:",
        "ft_reference": "1937610",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Snowflake (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937571",
        "description": "Rejoignez une équipe dédiée à l'intelligence décisionnelle et à la valorisation des données. Votre rôle consistera à développer, optimiser et maintenir un Data Warehouse performant, au service des besoins métiers de l'entreprise. Vous serez également amené(e) à contribuer à des projets stratégiques, allant de l'intégration de nouvelles solutions technologiques à l'amélioration continue des systèmes en place.\nVos responsabilités :\nGestion des flux de données existants :\nGarantir la continuité et la fiabilité des traitements de données actuels, en utilisant des technologies telles que SSIS, SnowSQL et Python.\nMigration technologique :\nAccompagner et finaliser le passage des chaînes de traitement actuelles sous SQL Server vers une architecture modernisée basée sur Snowflake.\nInterlocuteur métier :\nCollaborer étroitement avec les équipes pour comprendre leurs besoins, proposer des solutions sur mesure et les accompagner dans leur mise en ?uvre.\nConception et développement :\nÉlaborer et mettre en place de nouveaux processus pour enrichir le Data Lake, en s'appuyant sur des méthodes variées (Batch, API).\nModélisation et organisation des données :\nStructurer les données en tables et vues selon les besoins fonctionnels et stratégiques de l'entreprise.\nValidation des données :\nParticiper aux phases de recette en coopération avec les équipes métiers pour garantir la conformité et la qualité des informations.\nProjets avancés :\nDévelopper des solutions complexes, comme la création d'un référentiel unique ou l'implémentation d'algorithmes avancés pour des usages spécifiques.\nCompétences requises :\nApproche autonome et rigoureuse : Vous savez gérer vos projets de manière indépendante et méthodique.\nExpertise SQL : Maîtrise des requêtes avancées et optimisation des performances.\nOutils d'intégration : Expérience avec des plateformes ETL comme SSIS, Talend ou autres solutions similaires, durant 5 années minimum\nCompétences en programmation : Bonne maîtrise de Python ou d'autres langages (Java, C++).\nConnaissances en architecture data : Compréhension des principes de modélisation et d'entreposage des données.\nEsprit analytique : Capacité à analyser et garantir la qualité des données.\nCommunication efficace : Savoir partager vos idées et coordonner vos actions avec des équipes variées.\nEnvironnement technique :\nVous évoluerez dans un contexte technologique riche, incluant GitLab pour la gestion des versions, Snowflake comme Data Lake, SQL Server et Python pour les développements.\nCandidatures confidentielles\n \nProfil candidat:",
        "ft_reference": "1937571",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java"
            ],
            "DataBase": [
                "SQL"
            ],
            "DBMS": [
                "SQL Server",
                "Snowflake"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER SPARK/SCALA (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937424",
        "description": "Conception et développement de pipelines de données :\nConcevoir et développer des pipelines de données robustes et évolutifs utilisant Apache Spark et d?autres outils Big Data.\nIntégrer et transformer des données en temps réel ou en batch à partir de sources variées (bases de données, APIs, fichiers plats, etc.).\nImplémenter des solutions de traitement de données massives, principalement avec Spark (Scala et Python).\nOptimisation et maintenance :\nAssurer l'optimisation des performances des pipelines de données (gestion des ressources Spark, optimisation des requêtes, réduction des latences, etc.).\nMaintenir et améliorer la fiabilité des processus de traitement de données et des infrastructures associées.\nAutomatisation des processus :\nMettre en place et gérer des workflows d?automatisation des tâches avec Apache Airflow.\nAutomatiser le déploiement et l'exécution des pipelines de données à l'aide de Jenkins.\nCollaboration avec les équipes de data science et d?infrastructure :\nCollaborer avec les data scientists pour comprendre les besoins en données et optimiser leur accès.\nTravailler étroitement avec les équipes d?infrastructure pour assurer la stabilité et la scalabilité des pipelines de données.\nVeille technologique :\nSe tenir informé des évolutions des technologies Big Data et des bonnes pratiques pour intégrer de nouvelles fonctionnalités dans les pipelines.\nLangages de programmation :\nScala et Python : Expérience confirmée dans la programmation de pipelines de données en Scala (pour Spark) et en Python.\nTechnologies Big Data :\nApache Spark : Maîtrise de Spark pour le traitement de données massives, avec une compréhension approfondie de ses API en Scala et Python.\nApache Airflow : Expérience avec la gestion et l'orchestration de workflows de données dans un environnement de production.\nOutils de CI/CD :\nJenkins : Expérience avec Jenkins pour l?automatisation des déploiements et des tests des pipelines de données.\nBases de données et gestion des données :\nConnaissances solides des bases de données relationnelles (SQL, PostgreSQL, etc.) et NoSQL (Cassandra, MongoDB, etc.).\nProfil candidat:\nConception et développement de pipelines de données :\nConcevoir et développer des pipelines de données robustes et évolutifs utilisant Apache Spark et d?autres outils Big Data.\nIntégrer et transformer des données en temps réel ou en batch à partir de sources variées (bases de données, APIs, fichiers plats, etc.).\nImplémenter des solutions de traitement de données massives, principalement avec Spark (Scala et Python).\nOptimisation et maintenance :\nAssurer l'optimisation des performances des pipelines de données (gestion des ressources Spark, optimisation des requêtes, réduction des latences, etc.).\nMaintenir et améliorer la fiabilité des processus de traitement de données et des infrastructures associées.\nAutomatisation des processus :\nMettre en place et gérer des workflows d?automatisation des tâches avec Apache Airflow.\nAutomatiser le déploiement et l'exécution des pipelines de données à l'aide de Jenkins.\nCollaboration avec les équipes de data science et d?infrastructure :\nCollaborer avec les data scientists pour comprendre les besoins en données et optimiser leur accès.\nTravailler étroitement avec les équipes d?infrastructure pour assurer la stabilité et la scalabilité des pipelines de données.\nVeille technologique :\nSe tenir informé des évolutions des technologies Big Data et des bonnes pratiques pour intégrer de nouvelles fonctionnalités dans les pipelines.\nLangages de programmation :\nScala et Python : Expérience confirmée dans la programmation de pipelines de données en Scala (pour Spark) et en Python.\nTechnologies Big Data :\nApache Spark : Maîtrise de Spark pour le traitement de données massives, avec une compréhension approfondie de ses API en Scala et Python.\nApache Airflow : Expérience avec la gestion et l'orchestration de workflows de données dans un environnement de production.\nOutils de CI/CD :\nJenkins : Expérience avec Jenkins pour l?automatisation des déploiements et des tests des pipelines de données.\nBases de données et gestion des données :\nConnaissances solides des bases de données relationnelles (SQL, PostgreSQL, etc.) et NoSQL (Cassandra, MongoDB, etc.).",
        "ft_reference": "1937424",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "MongoDB",
                "SQL",
                "Cassandra"
            ],
            "BigData": [
                "Spark",
                "Apache Airflow"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [
                "Cassandra"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Big Data",
                "CI/CD"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer senior - h/f",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "PARIS 15 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1936084",
        "description": "Description\nDans le cadre du développement et de la structuration de lactivité Data au sein du pôle Audiovisuel de Free, nous recherchons un(e) Data Engineer senior pour prendre une part active à la collecte, létude et lanalyse de la consommation audiovisuelle des abonnés Free dans le but daméliorer le service et de personnaliser lexpérience utilisateur.\nVos missions :\n- Gérer la plateforme de récupération des données de consommation provenant de lensemble des devices (box Internet, mobile, tablette, web, )\n- Intégration de nouveaux devices ou modes de consommation\n- Enrichissement des événements\n- Coordination des déploiements avec léquipe Infrastructure\n- Concevoir, développer, mettre en production et gérer les pipelines dETL\n- Mettre en place des solutions de monitoring et assurer la qualité des données\nStack Data: Python, SQL, Clickhouse, PostgreSQL, Docker, Grafana, Sentry\nInfra Data: Self hosted sur serveur dédié et/ou Cloud privé\nNotre équipe Data :\n- Un Lead Data\n- Un(e) Data Engineer (en cours de recrutement)\nVous serez également amené(e) à collaborer avec les autres équipes chez OQEE by Free ( Back-End, Web, Android, iOS, ), ainsi quavec les équipes Data du groupe Iliad (data engineers, data scientists, data analysts).\nProfil recherché\nVous justifiez dune expérience de 4-5 ans en tant que Data Engineer.\nHard-skills\n- Très solide maîtrise de Python & SQL \n- Fortes connaissances en structure dOLAP, data modeling, data streaming, \n- Maîtrise des processus de développement collaboratif (Git, Gitlab, CI, ...)\n- Bonus : expérience sur Clickhouse\nSoft-skills\n- Axé sur les résultats, ambitieux, pragmatique et agile\n- Communication maîtrisée\n- Attrait pour lopen source\n- Intérêt pour le secteur de laudiovisuel",
        "ft_reference": "1936084",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Git",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Databricks Sénior (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935387",
        "description": "Nous recherchons un Data Engineer Databricks Sénior avec une expérience minimale de 5 ans.\nLe contexte : \nMigration des traitement Apache Spark/Scala du datalake depuis une plateforme AKS/Airflow vers Azure Databricks et mise en place de nouveaux pipelines\nOrganisation et suivi des migrations des projets depuis AKS vers Databricks\nAudit du patrimoine applicatif et organisation de chantiers de refactorisation pour ame?liorer la re?silience et les performances des applications\nHomoge?ne?isation des pratiques de de?veloppement au sein du service (mise en place TU, process de code review, mise en place d?outils de code quality ...)\nSuivi et re?solution de failles de se?curite?\nElargissement de l?utilisation des services Databricks par les projets (Unity Catalog, migration parquet vers delta, workflows ...)\nMaitrise DevOps\nMaitrise de Spark / Scala / Databricks & AZURE sont indispensables\n2 ans d'expérience minimum dans le même environnement technique\nProfil candidat:\nNous recherchons un Data Engineer Databricks Sénior avec une expérience minimale de 5 ans.\nLe contexte : \nMigration des traitement Apache Spark/Scala du datalake depuis une plateforme AKS/Airflow vers Azure Databricks et mise en place de nouveaux pipelines\nOrganisation et suivi des migrations des projets depuis AKS vers Databricks\nAudit du patrimoine applicatif et organisation de chantiers de refactorisation pour ame?liorer la re?silience et les performances des applications\nHomoge?ne?isation des pratiques de de?veloppement au sein du service (mise en place TU, process de code review, mise en place d?outils de code quality ...)\nSuivi et re?solution de failles de se?curite?\nElargissement de l?utilisation des services Databricks par les projets (Unity Catalog, migration parquet vers delta, workflows ...)\nMaitrise DevOps\nMaitrise de Spark / Scala / Databricks & AZURE sont indispensables\n2 ans d'expérience minimum dans le même environnement technique",
        "ft_reference": "1935387",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Dagster/Delta lake (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935365",
        "description": "Bonjour, \nDans le cadre de ses projets clients, Visian est à la recherche d'un Data Engineer senior\nTâches : \nConception, de?veloppement et de?ploiement des pipelines de donne?es efficaces pour l?extraction, la transformation et le chargement (ETL) des donne?es,\n- Collaboration avec les e?quipes me?tier pour comprendre les besoins en matie?re de donne?es et proposer une solution adapte?e,\n- Etablissement des spe?cifications techniques a? partir des besoins,\n- Mise en place de la collecte et la mise a? disposition des donne?es,\n- Garantie de la se?curisation des pipelines de donne?es de?ploye?s,\n- Analyse et transformation des donne?es pour re?pondre aux besoins des me?tiers,\n- Industrialisation et automatisation de la transformation des donne?es suivants lesspe?cifications de?finies,\n- De?veloppement et maintien des batchs d?automatisations de traitement,\n- Suivi de la production et la maintenance,\n- De?veloppement de l?industrialisation de mode?les statistiques,\n- De?veloppement des dashboards en lien avec les attentes du me?tier,\n- Re?daction et maintien de la documentation relative aux bases de donne?es et a? leur exploitation,\n- Accompagnement des citizens developers dans leur prise en main de la plateforme data in-house.\nSi vous êtes actuellement à l'écoute du marché, je vous invite à m'envoyer votre candidature.\nBien à vous,\nNadia\nProfil candidat:\nData Engineer avec une excellente maîtrise de :\n- L' Architecture globale du data lakehouse\n- La Conceptualisation des bases de donne?es\n- La Conception des data pipelines\n- L' Exploitation des donne?es\nEt une bonne maîtrise des outils suivants: Python, Pandas, SQL, Dagster, Spark, DeltaLake, Apache Parquet",
        "ft_reference": "1935365",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935291",
        "description": "Contexte de la Mission: Nous recherchons un Data Engineer, intégrant une équipe spécialisée pour piloter des initiatives clés liées à la gestion et l'optimisation des données. Présence sur site requise trois jours par semaine pour une collaboration efficace.\nProfil Recherché:\nMaîtrise avancée en SQL et ETL avec des capacités éprouvées dans la gestion de flux de données complexes.\nExpérience dans l'implémentation de pratiques CI/CD et l'utilisation de GitHub, Terraform et Kafka.\nConnaissance pratique de Power BI et Looker, avec une familiarité dans la création de visualisations de données.\nCompétences en Google Cloud Platform, notamment GCS et BigQuery, sont hautement souhaitables.\nAptitude à communiquer clairement en anglais, tant à l'écrit qu'à l'oral.\nProfil candidat:\nCompétences Techniques:\nExpertise dans la manipulation de données, notamment avec SQL et des outils ETL.\nCapacité à gérer des projets de développement en utilisant CI/CD et des outils associés comme GitHub et Terraform.\nCompétences en visualisation de données avec Power BI et Looker pour créer des rapports et dashboards.\nExpérience avec Google Cloud Platform pour l'optimisation des solutions de données dans le cloud.",
        "ft_reference": "1935291",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "ROUEN 76",
        "location": "76",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935227",
        "description": "Poste : Data Engineer (H/F)\nLocalisation : Rouen (76)\nMode de travail : Hybride (2 jours/semaine)\nDate de démarrage : Dès que possible\nDurée de mission : 3 mois (renouvelable)\nFourchette de salaire : Entre 400?/j et 450?/j\n \nL?IT chez ARTEMYS combine la technologie et l?humain ! Nous sommes convaincus que les compétences, le savoir-être et l?épanouissement de nos Talents sont les clés de notre réussite.\n \n? Alors, vous nous rejoignez ?!\nNotre site Normand recrute dès à présent un.e Data Engineer en Freelance (6 mois renouvelable). Dans cette nouvelle étape de votre carrière, nous vous proposons d?intervenir sur de belles missions auprès d?un acteur important du secteur de l'assurance auprès duquel vous interviendrez sur les missions suivantes :\nModéliser et structurer des bases de données en fonction des besoins analytiques. \nImplémenter des DAGs en python pour alimenter les entrepôts de données. \nContribuer à la définition et l?optimisation des normes de développements de l?équipe Data \nAutomatiser et enrichir les contrôles permettant de garantir la fiabilité des données alimentées. \nRéaliser la documentation fonctionnelles. \nRéaliser la documentation technique. \nContribuer à la définition et l?exécution des plan de tests pour valider le bon fonctionnement des DAGs et assurer la cohérence et fiabilité des jeux de données. \nMaintenir les entrepôts de données. \nParticiper à la mise en place de tableaux de bord \nPréparer, suivre les phrases d'homologation et de déploiement des réalisations. \nAssurer un support technique et fonctionnel auprès des équipes métiers sur l'utilisation des données et des outils analytiques. \nOptimiser les process et proposer des méthodologies adaptées (veille sur les données, les outils).\nProfil candidat:\n? Vous épanouirez-vous sur ce poste ?\nTitulaire d?un diplôme/titre de niveau Bac+5 en informatique, vous disposez d?une expérience de 5 années sur des activités de Data Engineering.\nSi vous êtes reconnu.e pour votre rigueur, votre force de proposition et votre organisé, ce poste est parfait pour vous !",
        "ft_reference": "1935227",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer Finlake (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935108",
        "description": "Notre client, une banque française, recherche un Data Engineer FinLake (H/F) dans le cadre d'une longue mission.\nIntervenir au sein de l?IT Financement dans l'équipe Business Intelligence pour assurer le rôle de Data Engineer sur le datalake FinLake, utilisé comme data plateforme par les équipes IT et métiers.\n- Assurer la gestion de la production du datalake\n- Gérer la dette technique et proposer des améliorations\n- Revoir l'architecture actuelle et proposer des évolutions\n- Réaliser les développements liés aux projets\nProfil candidat:\nData Engineer avec une expérience confirmée dans les environnements Big Data\nExpérience en gestion de datalake et optimisation des architectures data\nCompétences techniques :\n- Spark, PySpark, Scala\n- Hadoop sur infrastructure on-premise\n- Hive, Starburst\n- Jenkins, Unix/Bash, Jira\n- Pipeline CI/CD\n- Idéalement XLDeploy/XLRelease\nTélétravail: 2 jours par semaine",
        "ft_reference": "1935108",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Bash"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Big Data",
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER SPARK / PYTHON / DATABRICKS / AZURE (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934790",
        "description": "Bonjour,\nPour le compte de notre client nous recherchons un data engineer spark / python / databricks / azure.\nAttentes:\n- Spark/Python (API dataframe, dataset, rdd) + Librairie ScalaTest\n- Expérience Azure, incluant les composants Azure : ADLS, DataBricks, Azure Data Factory, Azure), DevOps (terraform, docker, kubernetes), Azure Functions, KeyVault\n- EDI : Intellij, Visual Studio Code, Visual Studio\n- Expérience de travail avec des données de différents formats (np. Avro, Parquet, JSON, CSV/Excel, Delta)\n- Python\n- connaissance de Kafka, Impala\n- SQL\n- très bon anglais\n- soft skills : compétences en communication, autogestion, compétences ETL, travail d'équipe, partage des connaissances, qualité et objectif, bien organisé\nExemple tâches cv axa direct assurance :\nL?objectif de ce projet est de migrer d'un data warehouse on-premise vers le Azure, et reconstruire\nun datawarehouse : data ingestion, data transformation et business views.\nActivités Principales :\n? Migration d'un environnement BI (sql server, oracle) vers le cloud\n? Création de pipeline avec Azure Data Factory pour l?alimentation des tables Delta\n? Transcription des requêtes SQL existantes en code Spark Scala simplifié\n? Développement de tests unitaires avec Scala test\n? Data tests et debugging avec Azure Databricks\n? Optimisation des transformations Spark Scala\n? Développer des algorithmes génériques pour créer un lot des tables\n? Accompagner les nouveaux arrivées pendant l?intégration\n? Implémentation de workflows et pipelines CI/CD avec Azure DevOps\n? Réalisation du suivi de la production (production monitoring)\n? Participation aux workshops d?estimation des US fonctionnelles et techniques\nEnvironnement technique :\nSpark, Scala, PySpark, Azure Data Factory, Azure Blob Storage, Azure DevOps, Release, Pipeline, Board, Repos,\nAzure Databricks, Databricks Delta.\nProfil candidat:\nBac + 5 informatique\nProfil technique\nExpertise spark / python/ databricks\nBonne communication et bon relationnel\nApprécié Azure\nQualités relationnelles et aisance orale.",
        "ft_reference": "1934790",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "DataSerialization": [
                "Avro",
                "Json"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "CI/CD",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "consultant informatique Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ROUEN 76",
        "location": "76",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934752",
        "description": "Missions:\nModéliser et structurer des bases de données en fonction des besoins analytiques. \nImplémenter des DAGs en python pour alimenter les entrepôts de données. \nContribuer à la définition et l?optimisation des normes de développements de l?équipe Data \nAutomatiser et enrichir les contrôles permettant de garantir la fiabilité des données alimentées.\nRéaliser la documentation fonctionnelles.\nRéaliser la documentation technique.\nContribuer à la définition et l?exécution des plan de tests pour valider le bon fonctionnement des DAGs et assurer la cohérence et fiabilité des jeux de données. \nMaintenir les entrepôts de données.\nParticiper à la mise en place de tableaux de bord\nPréparer, suivre les phases d'homologation et de déploiement des réalisations.\nAssurer un support technique et fonctionnel auprès des équipes métiers sur l'utilisation des données et des outils analytiques. \nOptimiser les process et proposer des méthodologies adaptées (veille sur les données, les outils).\nLivrables:\nDocumentation technique\nCahiers de tests\nNote de recommandations pour améliorer l?efficacité des DAGs\nDAGs\nGuides de bonnes pratiques\nProfil candidat:\nExpérience significative sur Python /Airflow/Git/SQL\nExpérience en tests automatisés data \nConnaissance des pratiques CI/CD \nEtre force de proposition\nEtre rigoureux et organisé\nEtre autonome\nCapacité d'analyse et de synthèse\nAisance relationnelle\nGoût pour le travail en équipe\nDisposer de très bonnes qualités pédagogiques\nSavoir communiquer / rendre compte\nDe bonnes connaissances des architectures DATA récentes",
        "ft_reference": "1934752",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934623",
        "description": "Data Engineer Confirmé/Senior - Client Final (Secteur Tourisme & Voyage )\nLocalisation : Paris\nType de contrat : CDI\nRémunération : À partir de 60K?, flexible selon le profil\nContexteNotre client, un acteur majeur du secteur du tourisme et du voyage, connaît une forte croissance et mène une transformation data ambitieuse. Avec plus de 25 ans d'existence, l'entreprise évolue dans un environnement dynamique marqué par des acquisitions récentes, entraînant une diversité de systèmes et de traitements de données.\nLe pôle Data, composé d'une douzaine de personnes, accompagne les équipes métiers en consolidant leurs besoins en données, analyses et reporting. Dans le cadre de cette structuration, l'entreprise recherche un Data Engineer confirmé/senior pour renforcer son équipe.\nMissionsParticiper à la construction d'un Datalake Snowflake pour centraliser et exploiter les données\nAssurer la migration des reportings vers Power BI, avec un objectif de réduction de la dépendance à Excel\nContribuer à l'intégration et l'uniformisation des sources de données dans un environnement en pleine transformation\nImplémenter SSIS pour l'orchestration des flux de données\nTravailler en étroite collaboration avec les équipes métiers pour répondre aux besoins stratégiques et opérationnels\nProfil recherchéExpérience confirmée en tant que Data Engineer\nMaîtrise de SSIS pour l'orchestration des flux de données\nBonne connaissance de Snowflake et des architectures Datalake\nExpérience en migration de reportings vers Power BI\nCapacité à évoluer dans un environnement en forte transformation, avec des systèmes hétérogènes\nEsprit analytique, autonomie et capacité à travailler en équipe\nAvantagesEnvironnement en pleine transformation avec de nombreux défis techniques\nEntreprise en forte croissance, avec des perspectives d'évolution\nFlexibilité sur la rémunération selon le niveau d'expérience et d'expertise\nSi vous êtes à la recherche d'un projet stimulant dans un environnement dynamique, envoyez votre candidature.\nProfil candidat:",
        "ft_reference": "1934623",
        "skills": {
            "DataVisualisation": [
                "Power BI"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Hadoop (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "FINISTÈRE 29",
        "location": "29",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934567",
        "description": "Dans le cadre d?un projet stratégique au sein d?un acteur bancaire majeur, nous recherchons un Data Engineer Hadoop afin de structurer, optimiser et sécuriser la gestion des données dans un environnement Big Data.\nVous aurez pour mission d?assurer la conception, l?implémentation et l?évolution des pipelines de données, en veillant à garantir leur performance, leur scalabilité et leur robustesse. Vous travaillerez en étroite collaboration avec les équipes Data Science et IT pour optimiser les flux de données et garantir une exploitation efficace des infrastructures.\nVotre rôle inclura également l?optimisation des traitements distribués, l?automatisation des processus et l?amélioration continue des performances des systèmes basés sur Hadoop et son écosystème.\nProfil candidat:\nVous justifiez d'au moins 10 ans ans d'expérience dans la gestion de projets Big Data et l'optimisation des infrastructures Hadoop.\nLes qualités et compétences attendues incluent :\nExpérience confirmée sur Hadoop et son écosystème (HDFS, YARN, Hive, Impala, HBase, Oozie).\nCompétences avancées en ETL, ingestion et transformation de données.\nMaîtrise des langages Python, Scala ou Java pour la manipulation de données.\nConnaissance des outils de gestion de workflow et d'orchestration (par exemple : Airflow).\nCompétences en sécurisation et optimisation des clusters Hadoop.\nExpérience dans des environnements Cloud hybride.\nAnglais opérationnel requis.",
        "ft_reference": "1934567",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "HBase"
            ],
            "BigData": [
                "Hadoop"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934469",
        "description": "La mission consiste à : \n- Exposer les données utiles à l?entreprise pour les analyser et les utiliser afin d?améliorer l?expérience utilisateur et la productivité \n- Transformer des données issues du DataLake afin de les normaliser\n- Modéliser la sphère de données\n- Développer les flux\n- Exposer des données brutes et/ou agrégées au bon niveau de granularité aux différents métiers de l?entreprise\n- Travailler en lien avec des Data Scientists sur les données qu?il aura exposées\n- Mettre en place des rapports de Dataviz\n- Mission basée en métropole lilloise avec présence sur site 3j/semaine obligatoire\nCompétences demandées : \n- Formation supérieure en école d?ingénieur, école d?informatique ou Master spécialisé dans la Data Science\n- Première expérience en Data Engineering indispensable\n- GCP, BigQuery, SQL, Python, Stambia, Shell, Data Studio, Power BI, Qlikview,...\n- Excellents savoir-être : rigueur, esprit analytique et de synthèse, communication...\n- Méthode Agile\n- Anglais\nProfil candidat:\nVous êtes consultant Freelance, \nNous recherchons actuellement pour l?un de nos clients Grand Compte basé sur Lille, un(e) Data Engineer confirmé(e), pour intégrer l?équipe DATA du client et contribuer à l?optimisation de l?utilisation de la donnée sur plusieurs périmètres fonctionnels.",
        "ft_reference": "1934469",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Databricks - Power BI Sénior (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934422",
        "description": "Nous sommes à la recherche d'un Data Engineer Databricks-Power BI Sénior avec une expérience minimale de 5 ans.\nEn tant que DATA ENGINEER spécialisé en traitement de données, vous intégrerez une équipe pour concevoir, réaliser, suivre et intégrer des travaux autour de la valorisation de la donnée.\n? Étude et rédaction d?US, en particulier sur des sujets liés à la data. \n? Maîtrise des bonnes pratiques de développement (utilisation de git, lisibilité du code, tests, intégration continue). \n? Fournir une vision complète des solutions data pour le programme. \n? La maitrise de DATABRICKS est impérative\n* La présentation interactive avec Power BI est à privilégiée \n? Analyse de données \n? Développements DATABRICKS \n? Schéma d?architecture data en lien avec les besoins \n? Rapports d?avancement : \no Rapports hebdomadaires et mensuels sur l?état d?avancement du projet et des livrables, les points bloquants, les risques et les actions correctives. \no Indicateurs associés propres au projet. \n? Documentation technique : \no Documentation complète des solutions techniques mises en ?uvre.\nEnvironnement technique Une connaissance avancée dans l?une ou plusieurs des technologies ci-dessous est recommandée pour être à même de faire le lien entre les besoins métiers et la réalisation technique. \n? SGBDR : PostgreSQL \n? ETL : Databricks \n? REPORTING : Power BI \n? USINE LOGICIELLE : GitLab, Jenkins, Artifactory, Harbor \n? SYSTEME : Windows, Linux (Ubuntu, RedHat ?), Kubernetes \n? LANGAGE : SQL, SQL LOADER, Script KSH, Java / Groovy, Javascript / Angular, Python \n? ORDONNANCEMENT : VTOM, Step Function \n? SUPERVISION : Datadog, Kibana, Grafana \n? OUTILS : ServiceNow, Jira, Trello Par ailleurs, les niveaux d?expérience minimum suivant seront exigés, une préférence sera portée au profil ayant connaissance du contexte SNCF (procédure, process, organisation?) : \n? Plus de 5 ans sur le développement Databricks et Power bi\nProfil candidat:\nNous sommes à la recherche d'un Data Engineer Databricks-Power BI Sénior avec une expérience minimale de 5 ans.\nSavoirs faire : \n? Un bon sens de l?organisation afin de participer activement à l?animation des équipes en relation avec les métiers, la MOA SI, les équipes de delivery \n? Bonne connaissance de l?architecture et services Cloud AZURE \n? Analyse de données \n? Une connaissance des outils de gestion de projet agile, idéalement de Jira \n? Un bon niveau de connaissances sur le fonctionnement des outils DATA AZURE est important afin de faciliter l?appropriation de l?éco système. \n? Une expérience significative sur Databricks et Power BI \n? Une bonne maitrise des outils bureautiques sera indispensable au quotidien (Office 365 : Powerpoint, Word, Excel, SharePoint, Outlook)\nEnvironnement technique Une connaissance avancée dans l?une ou plusieurs des technologies ci-dessous est recommandée pour être à même de faire le lien entre les besoins métiers et la réalisation technique. \n? SGBDR : PostgreSQL \n? ETL : Databricks \n? REPORTING : Power BI \n? USINE LOGICIELLE : GitLab, Jenkins, Artifactory, Harbor \n? SYSTEME : Windows, Linux (Ubuntu, RedHat ?), Kubernetes \n? LANGAGE : SQL, SQL LOADER, Script KSH, Java / Groovy, Javascript / Angular, Python \n? ORDONNANCEMENT : VTOM, Step Function \n? SUPERVISION : Datadog, Kibana, Grafana \n? OUTILS : ServiceNow, Jira, Trello Par ailleurs, les niveaux d?expérience minimum suivant seront exigés, une préférence sera portée au profil ayant connaissance du contexte SNCF (procédure, process, organisation?) : \n? Plus de 5 ans sur le développement Databricks et Power bi",
        "ft_reference": "1934422",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer GCP (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1934309",
        "description": "Bonjour,\n \nJe vous envoie ce mail car dans le cadre d'une mission de longue durée pour notre client situé en à Paris, nous recherchons un Data Engineer GCP.\n \nType de profils confirmé (> 5 ans d'expérience)\nTechnologies GCP (expérience obligatoire sur ce cloud provider)\nPython (expérience obligatoire)\nBonne maîtrise BigQuery (obligatoire)\nBonne maîtrise Terraform Git (obligatoire)\n \nDans le cas où vous êtes intéressé, pourriez-vous svp envoyer votre CV au format Word en indiquant votre disponibilité ainsi qu'une fourchette de vos prétentions salariales ou de votre tarification journalière si vous êtes indépendant ?\nProfil candidat:\nType de profils confirmé (> 5 ans d'expérience)\nTechnologies GCP (expérience obligatoire sur ce cloud provider)\nPython (expérience obligatoire)\nBonne maîtrise BigQuery (obligatoire)\nBonne maîtrise Terraform Git (obligatoire)",
        "ft_reference": "1934309",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F) (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NIORT 79",
        "location": "79",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933990",
        "description": "Afin d'accompagner notre client dans l'alimentation de ses Datamarts, NORGAY recrute un Data Engineer (H/F).\nAccompagné (e) par un Chef de projet interne, vous collaborerez avec le reste de l'équipe Data, la MOA et la MOE. Vous aurez ainsi une compréhension de l'activité, des besoins et du SI de production.\nCe qui vous attend :\n- Conception et réalisation des traitements d'alimentation des datamarts;\n- Modélisation du Système d'Information Décisionnel;\n- Diagnostic des dysfonctionnements rencontrés;\n- Maintenances correctives et évolutives;\n- Support auprès des différents métiers;\n- Documentation technique et suivi des traitements.\nProfil candidat:\n- D'une formation supérieure en informatique et passionné (e) de Data, vous avez une expérience de 3 ans min en tant que Data Engineer, plus particulièrement sur de l'alimentation de Datamarts;\n- Maîtrise d'un ELT ;\n- Connaissance d'une base de données orientée Analytique (ex : VERTICA) ;\n- Appétence à manipuler de gros volumes de données ;\n- Bonne connaissance du langage SQL ;\n- Des compétences sur un outil de modélisation (ex : Power Designer) et un outil de qualification (ex : QCHP) seraient un plus.\n \nDispo : Dès que possible mais nous saurons attendre la bonne personne\nLocalisation : Niort",
        "ft_reference": "1933990",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "Automation": [
                "Chef"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Palantir (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933977",
        "description": "Pour le compte d'un client dans le secteur de l'énergie basé à la Défense, dans le cadre du développement et du déploiement du projet groupe GPC (Global Performance Cockpit) basé sur la technologie Palantir Foundry, nous recherchons un data engineer ayant des expériences significatives sur la techno dans des mises en ?uvre de pipeline et de dashboards dans la suite workshop. La mission sera pour du long terme. Le profil recherché doit être senior sur la partie data et interviendra en télétravail partiel.\nProfil candidat:\nPour le compte d'un client dans le secteur de l'énergie basé à la Défense, dans le cadre du développement et du déploiement du projet groupe GPC (Global Performance Cockpit) basé sur la technologie Palantir Foundry, nous recherchons un data engineer ayant des expériences significatives sur la techno dans des mises en ?uvre de pipeline et de dashboards dans la suite workshop. La mission sera pour du long terme. Le profil recherché doit être senior sur la partie data et interviendra en télétravail partiel.",
        "ft_reference": "1933977",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Snowflake DBT (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933898",
        "description": "Loc : Lyon ou Bordeaux (Full TT avec des déplacements ponctuels sur site) \nAnglais courant demandé \nExigences techniques :\nDiplôme universitaire ou équivalent en informatique, ingénierie ou domaine pertinent.\nExpérience approfondie avec des solutions modernes d'entrepôts de données et d'intégration : Snowflake, DBT, Informatica\nMaîtrise des services Cloud : AWS, Azure ou GCP.\nConnaissance des outils d'orchestration : Airflow.\nCompétence en langages de script (Python) et écriture de SQL modulaire.\nExpérience approfondie en SQL et technologies/concepts de bases de données relationnelles.\nUtilisation des outils de gestion de projet et de documentation : JIRA, Confluence.\nMaîtrise des pipelines CI/CD avec Github Actions.\nSecteur pharmaceutique\nProfil candidat:\nLoc : Lyon ou Bordeaux (Full TT avec des déplacements ponctuels sur site) \nAnglais courant demandé \nExigences techniques :\nDiplôme universitaire ou équivalent en informatique, ingénierie ou domaine pertinent.\nExpérience approfondie avec des solutions modernes d'entrepôts de données et d'intégration : Snowflake, DBT, Informatica\nMaîtrise des services Cloud : AWS, Azure ou GCP.\nConnaissance des outils d'orchestration : Airflow.\nCompétence en langages de script (Python) et écriture de SQL modulaire.\nExpérience approfondie en SQL et technologies/concepts de bases de données relationnelles.\nUtilisation des outils de gestion de projet et de documentation : JIRA, Confluence.\nMaîtrise des pipelines CI/CD avec Github Actions.\nSecteur pharmaceutique",
        "ft_reference": "1933898",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer/ ingénieur informatique de données (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933881",
        "description": "Développer et maintenir nos pipelines de données :\nConcevoir, mettre en ?uvre et optimiser des pipelines de données évolutifs qui gèrent à la fois les flux de données par lots et en temps réel.\nPiloter les changements dans nos processus de développement :\nAméliorer et faire évoluer en permanence nos flux de travail et processus de développement pour augmenter l'efficacité, l'évolutivité et la fiabilité.\nDévelopper et pérenniser notre architecture de données :\nContribuer à la conception et à l'amélioration d'une architecture de données robuste et évolutive hébergée dans le cloud AWS.\nIngénierie et maintenance de l'infrastructure de données :\nCréer, configurer et maintenir l'infrastructure de données sous-jacente qui prend en charge l'ingestion, le stockage et le traitement des données. Optimiser l'utilisation des ressources cloud pour garantir la rentabilité, les performances et la sécurité.\nProfil candidat:\nMembre de l'équipe Data Engineering, définissant la manière dont les données sont exploitées dans les services commerciaux et produits.\nConcentrez-vous à la fois sur les objectifs d'analyse et d'embellissement des données.\nÉlément clé du département Data Science.\nTravaillez avec une architecture de données mature hébergée dans le cloud AWS.\nGérez les ensembles de données par lots et en temps réel.\nGérez les pipelines de données à l'aide du framework Spark avec Scala et Java.",
        "ft_reference": "1933881",
        "skills": {
            "ProgLanguage": [
                "Java",
                "Scala"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Spark Scala Python confirmé (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933803",
        "description": "Dans le cadre du développement de solutions analytiques et du traitement de données à grande échelle pour l'un de nos clients, nous recherchons un Data Engineer confirmé avec une expertise sur les technologies Spark, Scala et Python, ainsi qu'une solide compréhension du secteur de la finance.\nMissions :\nConcevoir, développer et maintenir des pipelines de données à grande échelle en utilisant Spark, Scala et Python.\nTravailler sur des systèmes de traitement de données complexes dans un environnement Big Data.\nParticiper à l?intégration et l'optimisation des flux de données dans des environnements distribués.\nCollaborer avec les équipes produit et business pour comprendre les besoins et les traduire en solutions techniques adaptées.\nAssurer la qualité et la fiabilité des données avec des tests et des contrôles appropriés.\nApporter une expertise technique pour résoudre des problématiques complexes et proposer des améliorations.\nMettre en place des solutions de traitement en temps réel avec Apache Spark et optimiser les performances des systèmes.\nTravailler avec des outils de gestion de données et des bases de données NoSQL et SQL.\nParticiper à des projets d'analyse de données financières et à des reporting pour les équipes business.\nProfil candidat:\nDe formation Bac+5 minimum au sein d'une école d'ingénieur ou d'informatique, vous avez une expérience de 3 ans minimum en tant que Data Engineer Spark Scala Python confirmé",
        "ft_reference": "1933803",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "Other": [
                "Big Data"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer - Spatial (H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "TOULOUSE 31",
        "location": "31",
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933789",
        "description": "Nous recherchons pour notre client un Data Engineer (H/F) :\nPrestation pure Freelance ou Portage salarial (CDI.c) ; \n(Longue) Durée : 6 à 12 mois minimum ;\nDémarrage : Février 2025 ;\nLocalisation : Toulouse Est (31) ;\nTélétravail : Possible à 80% ;\nSecteur : Spatial.\n \nMission :\nDévelopper et maintenir des pipelines de données scalables sur AWS.\nUtiliser des outils Python pour le traitement et l'analyse de grandes quantités de données (Pandas, TensorFlow, PyTorch, etc.).\nTravailler avec des données géospatiales et des outils GIS (zarr, QGis).\nCollaborer avec les équipes pour intégrer et transformer les données.\nPossibilité d?implémenter des solutions de Machine Learning/MLOps.\nEnvironnement technique : AWS, Python, DevOps, GIS/SIG.\nProfil candidat:\nProfil recherché : Confirmé / Senior\nVous avez au moins 5 ans d?expériences professionnelles en qualité de Data Engineer.\nVous avez une expertise autour de Python.\nVous avez une bonne expérience dans la manipulation de gros volumes de données.\nVous avez une bonne expérience dans le traitement de données géospatiales.\nVous avez de l?expérience avec l?environnement Cloud AWS.\nVous avez idéalement une approche DevOps et/ou MLOps.",
        "ft_reference": "1933789",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "MachineLearning": [
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "Other": [
                "Machine Learning",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer AI (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ROSNY SOUS BOIS 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933752",
        "description": "Chez Big APPS, le Data Engineer a pour responsabilité de :\n- Concevoir, développer et maintenir les plateformes de données de nos clients, en garantissant l?intégrité, la disponibilité et la sécurité des données.\n- Implémenter des pipelines de traitement de données, du stockage à l?ingestion, en passant par la transformation et l?analyse en temps réel.\n- Participer à la création et au déploiement de solutions d?IA, telles que les modèles de machine learning et les systèmes de recommandation.\n- Collaborer avec les équipes Data Science pour intégrer les modèles prédictifs dans les environnements de production.\n- Exploiter les services Cloud (Azure, AWS, GCP) pour le développement de solutions de données et d?IA.\n- Contribuer à la culture DevOps de l?entreprise en automatisant les processus de déploiement et en intégrant des pratiques CI/CD.\nProfil candidat:\nPour réussir en tant que Data Engineer chez Big APPS, il serait utile d?avoir :\n- Une expérience ou des connaissances dans les langages de programmation et les outils utilisés dans les plateformes Data (Python, Spark, Scala, Kafka, Java?).\n- Une appétence pour les sujets IA, avec une curiosité pour les modèles de machine learning et les techniques de data science.\n- Une expérience avec les services Cloud (Azure, AWS, GCP), et idéalement des certifications techniques dans ces domaines.\n- Une connaissance des technologies d'orchestration de données (Airflow, Prefect) et des bases de données (SQL, NoSQL).\n- Une sensibilité pour les bonnes pratiques DevOps, avec des notions en automatisation et intégration continue.\n- Des certifications techniques dans les domaines Data et Cloud (ex. : Azure Data Engineer, AWS Certified Big Data, Google Cloud Professional Data Engineer, DBT, Snowflake et Databricks) sont fortement appréciées.",
        "ft_reference": "1933752",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD",
                "Cloud",
                "DevOps",
                "Big Data"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer Sénior (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933719",
        "description": "Nous sommes à la recherche d'un data engineer sénior pour une mission longue durée pour un client de grand compte dans le secteur de la grande distribution. \nContexte et missions :\nConception et optimisation de pipelines de données sur GCP (BigQuery, Cloud Functions).\nModélisation des données et optimisation des requêtes SQL.\nMise en place de solutions de monitoring et maintenance des pipelines.\nEncadrement d'une petite équipe et collaboration avec les équipes métiers.\nCompétences requises :\nMaîtrise de GCP, SQL, Python.\nConnaissances Kafka, Airflow/Composer.\nSens de la qualité des données et de la sécurité.\nPlus de 5 ans d'expérience autant que data engineer \nConnaissance Data Studio, Looker\nProfil candidat:\nOn cherche un profil sénior maitrisant parfaitement : \nMaîtrise de GCP, SQL, Python.\nIoT\nConnaissances Kafka, Airflow/Composer.\nSens de la qualité des données et de la sécurité.\nPlus de 5 ans d'expérience autant que data engineer \nConnaissance Data Studio, Looker\nUne expérience en retail \nMobilité à Lille ( Important !!)\nCertification GCP est un grand plus",
        "ft_reference": "1933719",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer GCP (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933653",
        "description": "Je recherche en ce moment un Data Engineer pour accompagner un de mes client sur différents projets autour de GCP\nMissions\nConception et développement :\nConcevoir et développer des pipelines de données robustes et évolutifs sur GCP, en utilisant principalement BigQuery et Cloud Functions.\nModéliser les données, optimiser les requêtes SQL et les schémas pour améliorer les performances.\nMettre en place des solutions de monitoring et d'alerting pour assurer la disponibilité des traitements.\nMaintenance et évolution :\nAssurer la maintenance et l'évolution des pipelines existants.\nIdentifier et résoudre les problèmes techniques.\nMettre en ?uvre de nouvelles fonctionnalités et améliorer les performances.\nCollaboration :\nTravailler en étroite collaboration avec les équipes métiers pour comprendre leurs besoins et leur fournir des solutions adaptées.\nParticiper aux choix techniques et à l'amélioration continue des processus.\nProfil candidat:\nProfil recherché\nCompétences techniques indispensables :\nMaîtrise approfondie de GCP (BigQuery, Cloud Functions, Cloud Storage, Dataflow, etc.).\nSolides connaissances en SQL et Python.\nConnaissances Kafka, Debezium .\nExpérience avec les outils d'orchestration de workflows (Kestra, Airflow/Composer).\nConnaissance des bonnes pratiques en matière de qualité de données et de sécurité.\nQualités personnelles :\nRigoureux(se), organisé(e) et méthodique.\nBon(ne) communicant(e) et capable de travailler en équipe.\nAutonome et proactif(ve).\nCurieux(se) des nouvelles technologies et des évolutions du marché.\nExpérience :\nAu moins cinq années d'expérience en tant que Data Engineer.\nExpérience significative dans la mise en ?uvre de projets de données sur GCP.",
        "ft_reference": "1933653",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer Finlake (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "CHARENTON LE PONT 94",
        "location": "94",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933638",
        "description": "Contexte / Objectifs : \nLa mission va se dérouler au sein de l'IT Financement dans l'équipe Business intelligence qui aujourd'hui développe et gère un datalake (FinLake).\n Ce datalake est utilisé comme une data plateforme pour les équipes IT et métiers. \nL'objectif de la mission est d'assurer le rôle de Data Engineer du Finlake :\n- Gestion de la production\n- Gestion de la dette technique\n- Revoir l'architecture actuelle et proposer des évolutions \n- Développements liés aux projets\nDescription : \n? Mettre en place la collecte et la mise à disposition des données au sein de l?entreprise \n? Industrialiser et mettre en production des traitements sur les données (par exemple : mise à disposition de tableaux de bords, intégration de modèles statistiques) en lien avec les équipes métiers et les équipes qui les analysent \nActivités et tâches : \n? Acheminement de la donnée \n? Mise à disposition de la donnée aux équipes utilisatrices \n? Mise en production de modèles statistiques \n? Suivi de projet de développement \n? Développement job spark \n? Traitement et ingestion de plusieurs formats des données \n? Développement des scripts \n? Développement et Implémentation des collectes de données, des jobs de traitement et Mapping de données \n? Développement des moyens de restitution via génération de fichier et ou API & Dashboarding \n? Collecter toutes les données et les fournir aux clients en tant qu'API ou fichiers \n? Développer de pipelines d'ingestion à partir de différentes sources (streaming et batch) ainsi que des spark jobs le prétraitement des données et calcul des indicateurs de performance (KPI) \n? Développer des API génériques d?ingestion et de traitement de données dans un environnement HDP \n? Participer à la conception, mise en place et administration de solutions Big Data \n? Participation à l?installation, administration et configuration des Hadoop clusters. Mise en place en Spring Boot des services d'extraction de data du système legacy (tera data), la data sera par la suite envoyée au data lake via des topics Kafka \n? Normalisation et agrégation des données afin de produire les rapports sous forme de Business View\nProfil candidat:\nExpertises spécifiques :\n- Spark\n- PySpark\n- Scala\n- Hadoop sur infra on premise \n- Hive\n- Starburst\n- Jenkins\n- Unix/Bash\n- Jira\n- Pipeline CI/CD\nIdéalement XLDeploy/XLRelease",
        "ft_reference": "1933638",
        "skills": {
            "ProgLanguage": [
                "Scala",
                "Bash"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DevTools": [
                "Jenkins"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Statistiques",
                "Big Data",
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "DATA ENGINEER -VANNES - (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "VANNES 56",
        "location": "56",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933597",
        "description": "En tant que Data Engineer, votre mission principale sera de produire des solutions techniques robustes et performantes pour exploiter au mieux les données du client. Cependant, votre rôle ne se limitera pas à l?aspect technique : vous serez également un partenaire stratégique des métiers, capable d?identifier leurs besoins, de comprendre leurs enjeux et de proposer des solutions techniques adaptées.\nVos responsabilités :\nConcevoir, développer et maintenir des pipelines de données performants et évolutifs\nParticiper à la définition de l'architecture Data\nDévelopper les solutions de collecte et de stockage des données\nMettre en place les tests unitaires et automatisés\nGarantir la qualité, la sécurité et l?intégrité des données tout au long de leur cycle de vie.\nImplémenter des solutions qui optimisent la gestion des données pour les équipes métier.\nCollaborer étroitement avec les équipes métier pour comprendre leurs objectifs stratégiques.\nFaciliter la communication entre les équipes techniques et les non-techniciens\nVous serez à la croisée des chemins entre technique et métier, jouant un rôle clé pour transformer les données en un véritable levier de décision. Votre capacité à allier expertise technique et vision stratégique fera de vous un acteur indispensable pour relever les défis de l?entreprise.\nProfil candidat:\nProfil recherché :\nExpertise en architecture de données, Spark, Kafka,Java, Stack, Hadoop, Cloudera etc...\nForte appétence pour le dialogue avec les métiers et la résolution de problemes\nCapacité à vulgariser des concepts techniques pour les metiers\nGarantir le bon fonctionnement du produit en production et assurer le suivi/ l'assistance / La gestion des incidents\nEsprit créatif et orienté solutions, avec un excellent sens de l?écoute.",
        "ft_reference": "1933597",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Senior AWS Glue (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933589",
        "description": "Nous recherchons un Data Engineer Senior AWS Glue \nExpertise GLUE impérative. \nData Engineer Senior AWS, maitrisant très bien les CI/CD avec AWS GLUE.\nDémarrage : asap\nMust have:\nExpérience : 6+ ans minimum.\nUne expérience dans l'utilisation des git hub actions avec des multibranches avec utilisation de triggers, de if conditions, de workflow, de jobs. \nAvoir déjà utilisé les technologies suivantes sur AWS : EC2, S3, LAMBDA, STEP FUNCTIONS, CLOUDWATCH\n- Déploiement de nouveau job d'ingestion pour des data products en pyspark\n- contrôle des schémas, des nombres de workers\n- Optimisation de l'ingestion des data products existants en jouant sur la persistance des données de dans l'ingestion \n- Contrôle des partitions\n--\nNous recherchons un Data Engineer Senior AWS\nData Engineer Senior AWS, maitrisant très bien les CI/CD avec AWS GLUE.\nDémarrage : asap\nMust have:\nExpérience : 6+ ans minimum.\nUne expérience dans l'utilisation des git hub actions avec des multibranches avec utilisation de triggers, de if conditions, de workflow, de jobs. \nAvoir déjà utilisé les technologies suivantes sur AWS : EC2, S3, LAMBDA, STEP FUNCTIONS, CLOUDWATCH\nET en priorité profils qui ont une expérience GLUE. \nProfil candidat:\nData Engineer Senior AWS Glue\nExpertise GLUE impérative. \nData Engineer Senior AWS, maitrisant très bien les CI/CD avec AWS GLUE.\nMust have:\nExpérience : 6+ ans minimum.\nUne expérience dans l'utilisation des git hub actions avec des multibranches avec utilisation de triggers, de if conditions, de workflow, de jobs. \nAvoir déjà utilisé les technologies suivantes sur AWS : EC2, S3, LAMBDA, STEP FUNCTIONS, CLOUDWATCH\nET en priorité profils qui ont une expérience GLUE.",
        "ft_reference": "1933589",
        "skills": {
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer DWH GCP H/F (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NOISY LE GRAND 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933584",
        "description": "Nous recherchons pour l?un de nos clients grands compte un \"Data Engineer DWH GCP H/F\". \nContexte du projet :\nDans le cadre du programme de transformation IT, le département DATA mène un projet d?envergure pour migrer le DataWareHouse France On-Premise (Oracle ? PL/SQL), accompagné d?un ETL développé en interne, avec parfois des programmes en langage Natural (éditeur SAG) vers la Google Cloud Plateforme : Big Query en utilisant Dataform, Cloud functions, Cloud Run.\n \nProfil\nVous justifiez d?une expérience professionnelle similaire minimum de 8 ans, et maîtrisez les environnements suivants :\nExpérience confirmée des langages PL/SQL et Python requise\nMaîtrise des systèmes de bases de données Oracle et Big Query\nConnaissance souhaitée des outils de Data Visualisation de type Looker/SAP BO ou Spotfire\nRéalisation de projets similaires en méthodologie Agile impérative\nConnaissance de l?outil de ticketing Jira\nRéalisation de Tests (Unitaires, d?Intégration et de non régression)\nAnalyse des résultats des tests via un outil interne\nConnaissance Linux, via des scripts KSH\nTravail en équipe\nAdaptation facile\nProfil candidat:\nVous justifiez d?une expérience professionnelle similaire minimum de 8 ans, et maîtrisez les environnements suivants :\nExpérience confirmée des langages PL/SQL et Python requise\nMaîtrise des systèmes de bases de données Oracle et Big Query\nConnaissance souhaitée des outils de Data Visualisation de type Looker/SAP BO ou Spotfire\nRéalisation de projets similaires en méthodologie Agile impérative\nConnaissance de l?outil de ticketing Jira\nRéalisation de Tests (Unitaires, d?Intégration et de non régression)\nAnalyse des résultats des tests via un outil interne\nConnaissance Linux, via des scripts KSH\nTravail en équipe\nAdaptation facile",
        "ft_reference": "1933584",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "OS": [
                "Linux"
            ],
            "DBMS": [
                "Big Query"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Azure(H/F) (IT) / Freelance",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933553",
        "description": "Contexte\nDans le cadre du programme transformation du SI, votre role consistera à intégrer l'équipe Projets en charge de l'intégration des données de l'entreprise au sein de la plateforme Data sous le Cloud Azure afin de couvrir les besoins Big Data et BI de nos métiers.\nLa personne sera intégrée dans l'équipe projet qui fonctionne dans une organisation en mode Agile.\nDescription de la mission\nNous recherchons un Data Engineer Sénior avec une forte expertise sur Azure, Databricks, Spark, Scala.\nDéveloppement et l?implémentation de solutions Big Data Analytics\nAnalyse du besoin, étude d'impacts et conception de la solution technique\nConception et modélisation des données au niveau d'un Data Lake (format Parquet, Delta table, ?)\nConstruction des pipelines de données pour collecter, transformer et traiter des données dans le Data Lake\nDéveloppements de notebooks (ex : Databricks) de traitements avancés des données\nCloud Datawarehousing (tuning, optimisation de traitements et requêtes SQL)\nRédaction de documentation technique (Dossier d'Analyse Technique, release delivery note, ?.)\nRevue de code\nRéalisation de tests unitaires\nMaintenance corrective et évolutive\nLivraison dans un environnement Devops, CI/CD et outils associés\nProfil candidat:\nCompétences techniques requises\nExpérience Data\nAzure\nExpérience architecture Lakehouse\nDatabricks\nSpark\nScala\nMaitrise de CI/CD, Azure DevOps\nConnaissance des outils Agile (JIRA) et ayant travaillé dans un environnement agile",
        "ft_reference": "1933553",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Splunk (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "MONTREUIL 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933478",
        "description": "Dans le cadre des missions de l'équipe Log Analytics, le bénéficiaire souhaite une prestation d?accompagnement technique de RUN sur la technologie Splunk (OPS + Data Engineering + notions Data Analyse), avec potentiellement des notions sur Elasticsearch et Dynatrace également.\nLes missions sont : \n- Intégration dans une équipe d'experts techniques pour maintenir en conditions opérationnelles des plateformes de données d'observabilité très ambitieuses\n- Participation aux évolutions des plateformes, des services rendus, améliorer la fiabilité et les performances des clusters mis en place, de la gestion des agents et de l'automatisation des actions\n- Accompagnement des clients dans leurs usages, les guider dans les meilleurs usages des produits\n- Force de proposition pour automatiser, industrialiser et rendre plus efficientes nos implémentations et nos interactions clients\nProfil candidat:\nDans le cadre des missions de l'équipe Log Analytics, le bénéficiaire souhaite une prestation d?accompagnement technique de RUN sur la technologie Splunk (OPS + Data Engineering + notions Data Analyse), avec potentiellement des notions sur Elasticsearch et Dynatrace également.\nLes missions sont : \n- Intégration dans une équipe d'experts techniques pour maintenir en conditions opérationnelles des plateformes de données d'observabilité très ambitieuses\n- Participation aux évolutions des plateformes, des services rendus, améliorer la fiabilité et les performances des clusters mis en place, de la gestion des agents et de l'automatisation des actions\n- Accompagnement des clients dans leurs usages, les guider dans les meilleurs usages des produits\n- Force de proposition pour automatiser, industrialiser et rendre plus efficientes nos implémentations et nos interactions clients",
        "ft_reference": "1933478",
        "skills": {
            "DataBase": [
                "Elasticsearch"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer Snowflake (F/H) (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "BORDEAUX 33",
        "location": "33",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933414",
        "description": "? CDI (40-45K?) - ? 2 jours de télétravail / semaine - ? Bordeaux - ? Expérience de 4 ans minimum\n \nEnvie de rejoindre un projet stimulant dans un environnement technique innovant ?\nVous êtes passionné(e) par le traitement, l?optimisation et l?analyse des données ?\nRejoignez CELAD en tant que Data Engineer pour travailler sur des projets ambitieux où Snowflake, AWS et Airflow sont au c?ur des enjeux ! ?\n \nVoici un aperçu de vos missions\nEn tant que Data Engineer, vous serez un maillon clé de l?équipe Data et contribuerez à la transformation des données en solutions fiables, sécurisées et scalables. Vous serez amené(e) à :\n- Concevoir, développer et maintenir des pipelines de données robustes pour collecter, transformer et charger les données (ETL/ELT).\n- Mettre en ?uvre des architectures Data sur Snowflake dans un environnement AWS.\n- Assurer l?orchestration des workflows via Apache Airflow et le développement avec DBT (Data Build Tool).\n- Optimiser les performances des traitements et garantir la qualité et la disponibilité des données.\n- Collaborer étroitement avec les équipes Data Analyst, Data Scientist et les métiers pour comprendre les besoins et y répondre efficacement.\n- Mettre en place des bonnes pratiques en matière de sécurité, monitoring et documentation des pipelines de données.\n \nVotre environnement technique ?\n- Technologies obligatoires :\nData Warehouse : Snowflake\nCloud : AWS (S3, Lambda, Glue)\nOrchestration : Apache Airflow\nTransformation : DBT\no Outils & M éthodologies : Git, CI/CD, Terraform, Méthodes Agile.\nDes connaissances en Spark ou Kafka seraient un atout.\nProfil candidat:\nVotre profil :\n- Expérience : Vous justifiez de 4 ans minimum en tant que Data Engineer avec une expertise prouvée sur Snowflake et AWS.\n- Maîtrise des pipelines de données complexes.\n- Expertise en modélisation de données et optimisation des performances.\n- Expérience avec des outils d'orchestration de workflow (Airflow) et de transformation (DBT).\n \nPourquoi choisir CELAD ?\nChez CELAD, l?humain est au c?ur de nos préoccupations :\nUn onboarding personnalisé pour bien démarrer votre mission.\nUn suivi régulier : un point trimestriel pour accompagner votre progression.\nUne équipe à votre écoute : nos coordinateurs sont là pour fluidifier votre quotidien.\nUne véritable démarche collaborative : vos idées et retours sont pris en compte.\n \n? Lieu : Bordeaux (33)\n \nAvantages à la clé :\n- 15 jours de RTT (100% \"salarié\" & Rachat à 125%)\n- Participation aux bénéfices\n- Indemnité de déplacement (6? net / jour OU 50% du titre de transport)\n- Plan Epargne Entreprise\n- Prime de vacances\n- Avance sur salaire\n- Comité Social et Economique\n \n? Rémunération : 40-45k? CDI / 400?/jour\n \nSi vous êtes prêt.e à relever ce défi et à contribuer à des projets stimulants, n'hésitez pas à postuler dès maintenant ! ?",
        "ft_reference": "1933414",
        "skills": {
            "BigData": [
                "Spark",
                "Apache Airflow"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933407",
        "description": "Le group Sapiens est à la recherche pour l'un de ses client d'un(e) Data Engineer. \nConception et Développement de Pipelines de DonnéesConcevoir, développer et maintenir des pipelines de données robustes pour collecter, transformer et charger les données (ETL/ELT).\nAutomatiser les flux de données pour garantir leur disponibilité en temps\nGestion et Maintenance de l'Infrastructure de DonnéesInstaller et configurer des bases de données (SQL, NoSQL) ou des entrepôts de données.\nMettre en place des environnements de stockage adaptés (cloud, on-prem\nAssurer la scalabilité et l'optimisation des performances\nNettoyage et Transformation des DonnéesNettoyer, normaliser et enrichir les données brutes pour l\nSurveillance et Résolution des ProblèmesIdentifier les goulots d'étranglement et optimiser les processus de traitement.\nGestion des Big Data et Environnements CloudManipuler de gros volumes de données et optimiser leur traitement\nGérer des environnements cloud (AWS, Azure, Google Cloud) pour des solutions\nProfil candidat:\nExpérience significative de 2ans / Expérience souhaité sur la partie RSE / Green \nData : SQL ? ETL Talend \nXLR et XLD\nSQL server / Sybase\nData Visualisation : Power BI, Excel, Power design\nDéveloppement : Javascript ? Shell UNIX ? Python\nOracle/EXADATA\nELT Semarchy\nOrdonnanceur VTOM ou control M\nConfluence et Jira",
        "ft_reference": "1933407",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "consultant informatique (H-F) Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933406",
        "description": "Nous recherchons un Data Engineer confirmé pour intégrer un projet stratégique pour l' un de nos clients.\nVos principales missions incluront :\n? Codage et testage des composants logiciels.\n? Formalisation des cas d?usages.\n? Conception et mise en ?uvre des flux d?intégration de données.\n? Optimisation de la performance et la qualité logicielle.\n? Apport du support technique.\n? Bonne maitrise de l?écosystème Data / Java / SQL / Cloud.\n? Notions dans d?autres langages de programmation (Python, Scala) et connaître le fonctionnement des bases de données (SQL, NoSQL).\nProfil candidat:\nCompétences techniques requises :\nMaîtrise de la programmation orientée objet (POO), notamment avec Java.\nExpertise des frameworks Java courants et des bases de données relationnelles (SQL, NoSQL).\nExpérience avec les outils DevOps (CICD, Git, Jenkins).\nConnaissance approfondie de Spark (local ou Cloud) et d?Airflow.\nNotions en Python et Scala appréciées.\nUtilisation des outils de développement comme IntelliJ IDEA.\nQualités comportementales :\nRésolution de problèmes complexes.\nEsprit d?équipe et autonomie.\nCuriosité, adaptabilité et organisation.\nBonne capacité de communication, vulgarisation d?idées techniques auprès de divers publics.",
        "ft_reference": "1933406",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer - Candidats BASÉS à LYON UNIQUEMENT (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933368",
        "description": "Nous recherchons un Data Engineer Sénior pour une mission longue (+6 mois) en régie, dans le secteur de l'énergie. Vous serez intégré(e) à une équipe technique où vous aurez pour rôle principal de concevoir, développer et optimiser des pipelines de données complexes. Vous interviendrez sur des projets stratégiques, avec des enjeux business critiques, nécessitant une manipulation experte des outils ETL et une maîtrise approfondie d?Amazon Web Services (AWS).\nVos missions incluront :\nLa collecte, la transformation et l?intégration des données en respectant les bonnes pratiques.\nLa mise en ?uvre d?architectures performantes pour le traitement et la gestion des données.\nL?automatisation des workflows ETL pour des volumes importants de données.\nLa collaboration étroite avec des équipes transverses (BI, Data Science, Développement).\nL?analyse et la résolution des problématiques liées à la qualité des données.\nProfil candidat:\nExpérience confirmée (Sénior) en Data Engineering.\nExcellente maîtrise des ETL Tools et expertise sur Amazon Web Services (AWS).\nCapacité à résoudre des problèmes complexes et à travailler dans un environnement agile.\nBonnes compétences en communication et en collaboration d'équipe.",
        "ft_reference": "1933368",
        "skills": {
            "CloudComputing": [
                "AWS"
            ],
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (Spark / Hadoop) (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933355",
        "description": "* Compétences techniques requises :\no Solide maitrise de Java\no Forte maitrise de Spark\no Très bonne connaissance de l?écosystème Hadoop (Hive, Hdfs, Yarn, Hbase, ?)\no Maîtrise des bases de données relationnelles et NoSQL\no Expérience dans l?optimisation performances des traitements Batch Spark\no Expérience avec les outils CI/CD (Git, Jenkins, Kubernetes, ?)\n \n* Compétences techniques souhaitables (nice to have) :\no Maitrise des systèmes streaming et de gestion de flux (Spark Streaming, Kafka)\no Connaissance du produit MapR\no Connaissance Oozie - AirFlow\no Expérience en modélisation des données pour les systèmes analytiques et transactionnels\no Connaissance des bonnes pratiques de gouvernance des données et de la gestion du cycle de vie des données\n \n \nSoft Skills :\n? Capacité de lead, encadrement, accompagnement, pédagogie\n? Capacité d?analyse technique et fonctionnelle, de vulgarisation des aspects techniques\n? Bonne connaissance des pratiques Agiles / SAFe, utilisation de JIRA\n? Connaissance des métiers de l?assurance (Assurance vie / Prévoyance)\n? Connaissance de la data (qualité, mapping & transformations ?)\nProfil candidat:\n* Compétences techniques requises :\no Solide maitrise de Java\no Forte maitrise de Spark\no Très bonne connaissance de l?écosystème Hadoop (Hive, Hdfs, Yarn, Hbase, ?)\no Maîtrise des bases de données relationnelles et NoSQL\no Expérience dans l?optimisation performances des traitements Batch Spark\no Expérience avec les outils CI/CD (Git, Jenkins, Kubernetes, ?)\n \n* Compétences techniques souhaitables (nice to have) :\no Maitrise des systèmes streaming et de gestion de flux (Spark Streaming, Kafka)\no Connaissance du produit MapR\no Connaissance Oozie - AirFlow\no Expérience en modélisation des données pour les systèmes analytiques et transactionnels\no Connaissance des bonnes pratiques de gouvernance des données et de la gestion du cycle de vie des données\n \n \nSoft Skills :\n? Capacité de lead, encadrement, accompagnement, pédagogie\n? Capacité d?analyse technique et fonctionnelle, de vulgarisation des aspects techniques\n? Bonne connaissance des pratiques Agiles / SAFe, utilisation de JIRA\n? Connaissance des métiers de l?assurance (Assurance vie / Prévoyance)\n? Connaissance de la data (qualité, mapping & transformations ?)",
        "ft_reference": "1933355",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "DataBase": [
                "NoSQL",
                "HBase"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Airflow",
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes"
            ],
            "Collaboration": [
                "JIRA"
            ],
            "Other": [
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "POT8224-Un Data Engineer Snowflake AWS sur le 92 (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933351",
        "description": "Almatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nProfil candidat:\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92\nAlmatek recherche pour l'un de ses clients, un Expert Snowflake Aws sur le 92",
        "ft_reference": "1933351",
        "skills": {
            "CloudComputing": [
                "AWS"
            ],
            "DBMS": [
                "Snowflake"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer - Développement Python/SQL orienté Data (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933245",
        "description": "?Objectifs et livrables\nL'équipe Data Warehouse est en charge d'un datawarehouse global (US, EU and APAC) et transverse (Multi-Asset Class) dans un environnement technico-fonctionnelle en finance de marché. \nCette équipe est en charge:\n- d'assurer la transparence au sein des marchés mondiaux en stockant, collectant et centralisant les données pre-trade de trading.\n- de mettre en oeuvre une stratégie complète de gestion des données à l'échelle mondiale.\n- de produire de multiples reporting pour différents besoins internes, notamment réglementaires.\n La mission se concentre autour du développement et maintien d'un outil de détection d'abus de marché développé en interne à l'aide du langage de programmation Python.\n?Caractéristiques de la mission:\n - Analyser et comprendre des spécifications fonctionelles sur différents modèles d'abus de marché (Périmètre Equity & Fixed Income).\n- Participer à la phase de préparation des données via la construction de datamarts en SQL et PL/SQL sur une base de données relationnelle Oracle.\n- Participer au développement de nouveaux modèles statistiques de détection d'anomalies. Implémentation d'algorithmes en Python à l'aide de modules tels que Pandas et Numpy.\n- Tester et améliorer les algorithmes implémentés en terme d'efficacité et de performance (Unit & Integration testing, Profiling et optimisation en Python).\n- Présenter les résultats d'analyses sous une forme visuelle parlante, via des outils de visualisation (APEX).\n- Environnement de développement DevOps (Git, Ansible, Linux).\n- Environnement anglophone.\nProfil candidat:\n?Compétences attendues :\nPython : +++\nSQL: ++\nData: +\nDe formation école d'ingénieur ou ayant un niveau équivalent à un Master 2, nous recherchons quelqu'un de curieux, dynamique, et force de proposition.",
        "ft_reference": "1933245",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataAnalytics": [
                "NumPy",
                "Pandas"
            ],
            "DevTools": [
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "Automation": [
                "Ansible"
            ],
            "Other": [
                "Statistiques",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer / GCP (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933164",
        "description": "Nous recherchons un Data Engineer pour rejoindre une équipe dynamique dans le secteur bancaire et participer à la mise en ?uvre et à l?optimisation des chaînes de traitement des données. L?objectif principal est de récupérer, traiter et mettre à disposition des données enrichies, tout en exploitant la puissance d?un Data Lake.\nVos principales missions :\nMettre en ?uvre les chaînes de traitement des données : ingestion, validation, croisement et intégration dans le Data Lake.\nDévelopper dans le respect des règles d?architecture définies.\nDocumenter les user stories avec le Product Owner.\nProduire des scripts de déploiement et prioriser les corrections d?anomalies.\nAutomatiser les tests fonctionnels et participer à la chaîne de delivery continue.\nAssister les équipes d?exploitation et collaborer en mode Scrum/Kanban.\nCompétences techniques indispensables :\nPlateforme et environnement GCP (Google Cloud Platform).\nEnvironnement GKE (Google Kubernetes Engine).\nStockage : HDFS / GCS.\nTraitement : Maîtrise de Spark, Kafka, Scala.\nPlanification : Airflow / Composer.\nDWH : SQL, BigQuery, BigTable.\nDelivery : Git, Ansible, Docker, Terraform, Jenkins / Cloud Build.\nMéthodologies : Scrum, Kanban, Git.\nAspects humains recherchés :\nCapacité à travailler en équipe, en mode Agile (Scrum/Kanban).\nExcellentes compétences relationnelles et communicationnelles.\nCuriosité et sensibilité aux évolutions technologiques.\nProfil candidat:\nExpérience : Minimum 5 ans en tant que Data Engineer dans un contexte similaire.\nExpertise technique :\nSolide maîtrise de l?écosystème GCP (GKE, BigQuery, BigTable).\nCompétences confirmées en Spark, Kafka, Scala, et Airflow.\nExpérience avec les outils d?intégration et de déploiement continu : Terraform, Jenkins, Docker.\nSoft skills :\nExcellente capacité à travailler en équipe (Scrum/Kanban).\nSens du détail et rigueur dans la documentation et le développement.\nCuriosité pour les nouvelles technologies et capacité d?adaptation.",
        "ft_reference": "1933164",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "DevTools": [
                "Jenkins",
                "Git",
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow",
                "Ansible",
                "Kubernetes"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (H/F) (IT)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933038",
        "description": "Vos missions ? \nEn tant qu'Ingénieur Data, vous serez responsable de la conception, du développement et de la maintenance de solutions data au service des différents métiers de l'entreprise .\nAux côtés d'experts métiers, et d'un Leader Technique, vous devrez développer des traitements robustes, monitorés et résilients dans un écosystème Cloud avec des technologies d'industrialisation à l'état de l'art.\nVos traitements répondront à des besoins autour de problématiques complexes dans les domaines d'activité de l'entreprise (Réseau & syst ème IOT, évolutions possibles sur comptage de l'eau, gestion des déchets, etc ?)\nLa stack Technique :\n- MongoDB, PostgreSQL, Power BI\n- Python, Scala, R\n- Docker, Jenkins\n- Gitlab/Github\n- Grafana\nProfil candidat:\nAlors ? Prêt à devenir Amiltonien ? \nN'hésitez pas à postuler si vous vous reconnaissez : \nDiplômé bac+5 (école d'ingénieur ou master), vous avez 5 ans d'expériences sur des sujets Data, Python, SQL.\nVous aimez découvrir de nouveaux contextes fonctionnels et comprendre les objectifs des applications que vous développez.\nA l'aise dans une organisation agile, vous faites preuve de rigueur et appliquez les standards de qualité Amiltone durant toute la durée des développements.\nOutre vos compétences techniques, nous nous intéressons également à votre potentiel et votre motivation.\nNos postes sont ouverts aux personnes en situation de handicap.",
        "ft_reference": "1933038",
        "skills": {
            "ProgLanguage": [
                "R",
                "Python",
                "Scala"
            ],
            "DataBase": [
                "MongoDB",
                "SQL"
            ],
            "DataAnalytics": [
                "R"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "DevTools": [
                "Jenkins",
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "consultant informatique (H-F) Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933006",
        "description": "Nous recherchons un Data Engineer confirmé pour intégrer un projet stratégique pour l' un de nos clients.\nVos principales missions incluront :\n? Codage et testage des composants logiciels.\n? Formalisation des cas d?usages.\n? Conception et mise en ?uvre des flux d?intégration de données.\n? Optimisation de la performance et la qualité logicielle.\n? Apport du support technique.\n? Bonne maitrise de l?écosystème Data / Java / SQL / Cloud.\n? Notions dans d?autres langages de programmation (Python, Scala) et connaître le fonctionnement des bases de données (SQL, NoSQL).\nProfil candidat:\nCompétences techniques requises :\nMaîtrise de la programmation orientée objet (POO), notamment avec Java.\nExpertise des frameworks Java courants et des bases de données relationnelles (SQL, NoSQL).\nExpérience avec les outils DevOps (CICD, Git, Jenkins).\nConnaissance approfondie de Spark (local ou Cloud) et d?Airflow.\nNotions en Python et Scala appréciées.\nUtilisation des outils de développement comme IntelliJ IDEA.\nQualités comportementales :\nRésolution de problèmes complexes.\nEsprit d?équipe et autonomie.\nCuriosité, adaptabilité et organisation.\nBonne capacité de communication, vulgarisation d?idées techniques auprès de divers publics.",
        "ft_reference": "1933006",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer / MLOps AWS (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932974",
        "description": "Le Data Engineer est garant de l?accès qualitatif aux sources de données. Il s?assure de la maîtrise de la donnée et est garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d?en faciliter l?exploitation par les équipes (Data Analysts et Data Scientists).\nLe Data Engineer contribue également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur, en collaboration avec le Chief Data Officer.\nSon périmètre d?intervention est axé sur les systèmes applicatifs autour de la gestion de la donnée et du traitement, et sur les plateformes Big Data, IoT? Il assure la supervision et l?intégration des données de diverse nature qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le datalake (il recette de la donnée, supprime les doublons, ?).\nProfil candidat:\n? Forte sur la Data (5 ans).\n? Une expertise sur les services AWS (Cloud formation, Lambda, EMR, S3, EC2, Step Function, les services autour de l?IA).\n? Plus particulièrement sur SageMaker (Porteur de la pratique MLOPS, de l?administration, de la gouvernance et des développements).\n? Une maîtrise des outils : Snowflake, Azure DevOps (maîtrise de la méthodologie DevOps, MLOPS, LLMOPS) et des langages de programmation : Python et PySpark.\n? Des compétences sur les outils ETL/ELT seraient un plus.",
        "ft_reference": "1932974",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "CloudComputing": [
                "AWS",
                "Azure"
            ],
            "DBMS": [
                "Snowflake"
            ],
            "Other": [
                "Big Data",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data engineer Réseau - Rentabilité (IT) (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "CHARENTON LE PONT 94",
        "location": "94",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932966",
        "description": "Contexte / Objectifs : \nRécupérer les données issues de sources externes\n? Utiliser la puissance du Datalake\n? Produire et mettre à disposition automatiquement des agrégats journaliers, hebdomadaires et mensuels.\nMise en ?uvre de la chaîne :\n o d?ingestion de données, \n o de validation de données, \n o de croisement de données, \n o de déversement dans le datalake des données enrichies\n? Développer dans le respect des règles d?architecture définies\n? Développer et documenter les user stories avec l?assistance du Product Owner.\n? Produire les scripts de déploiement \n? Prioriser les corrections des anomalies\n? Assister les équipes d?exploitation\n? Participer à la mise en ?uvre de la chaîne de delivery continue\n? Automatiser les tests fonctionnels\n \nDescription : \n? Mettre en place la collecte et la mise à disposition des données au sein de l?entreprise \n? Industrialiser et mettre en production des traitements sur les données (par exemple : mise à disposition de tableaux de bords, intégration de modèles statistiques) en lien avec les équipes métiers et les équipes qui les analysent \nActivités et tâches : \n? Acheminement de la donnée \n? Mise à disposition de la donnée aux équipes utilisatrices \n? Mise en production de modèles statistiques \n? Suivi de projet de développement \n? Développement job spark \n? Traitement et ingestion de plusieurs formats des données \n? Développement des scripts \n? Développement et Implémentation des collectes de données, des jobs de traitement et Mapping de données \n? Développement des moyens de restitution via génération de fichier et ou API & Dashboarding \n? Collecter toutes les données et les fournir aux clients en tant qu'API ou fichiers \n? Développer de pipelines d'ingestion à partir de différentes sources (streaming et batch) ainsi que des spark jobs le prétraitement des données et calcul des indicateurs de performance (KPI) \n? Développer des API génériques d?ingestion et de traitement de données dans un environnement HDP \n? Participer à la conception, mise en place et administration de solutions Big Data \n? Participation à l?installation, administration et configuration des Hadoop clusters. Mise en place en Spring Boot des services d'extraction de data du système legacy (tera data), la data sera par la suite envoyée au data lake via des topics Kafka \n? Normalisation et agrégation des données afin de produire les rapports sous forme de Business View\nSéniorité : Entre 3 et 6 ans\nCharenton-Le-Pont - Site Liberté 2 \nDate de début souhaitée : 03/02/2025\nProfil candidat:\nAspects Humains :\n? Grande capacité à travailler dans une équipe, en mode Scrum / Kanban.\n? Bonnes compétences relationnelles et grand sens de la communication (capacité à entrer dans le détail).\n? Sensible et informé des évolutions technologiques sur les piles logicielles pratiquées.\nExpertises spécifiques :\nConnaissances techniques : \n ? Plateforme et environnement GCP (indispensable)\n ? Environnement GKE\n ? Stockage : HDFS / GCS\n ? Traitement: Maitrise de l?écosystème Spark / Kafka / Scala\n ? Planification : Airflow / Composer\n ? Méthodologies : Scrum, Kanban, Git\n ? DWH : SQL, BigQuery, BigTable\n ? Delivery : Git, Ansible, Docker, Terraform, Jenkins / Cloud Build",
        "ft_reference": "1932966",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DevTools": [
                "Jenkins",
                "Git",
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow",
                "Ansible"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Statistiques",
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer GCP (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932874",
        "description": "Nous recherchons un Data Engineer confirmé GCP pour intervenir sur des projets stratégiques liés à la gestion et au traitement des données massives en temps réel dans un environnement Cloud moderne.\nVos missions :\nMettre en ?uvre des chaînes complètes de traitement des données : ingestion, validation, croisement et enrichissement des données.\nAutomatiser la production et la mise à disposition d?agrégats journaliers, hebdomadaires et mensuels.\nCollaborer avec l?équipe Agile pour développer et documenter des user stories en lien avec le Product Owner.\nConcevoir des scripts de déploiement et prioriser les corrections d?anomalies.\nAutomatiser les tests fonctionnels et participer à la mise en place de chaînes de livraison continue.\nProfil candidat:\nes indispensables :\nMaîtrise des environnements GCP (Google Cloud Platform), notamment GKE, HDFS/GCS.\nExcellente connaissance de Spark, Kafka et Scala pour le traitement de données.\nConnaissance des outils de planification comme Airflow ou Composer.\nSolides compétences en SQL, BigQuery et BigTable pour travailler sur des DWH (Data Warehouses).\nExpérience avec les outils de delivery comme Git, Docker, Terraform, Jenkins ou Cloud Build.\nMéthodologies Agile (Scrum, Kanban) et outils associés (Git).",
        "ft_reference": "1932874",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "Google Cloud Platform",
                "GCP"
            ],
            "DevTools": [
                "Jenkins",
                "Git",
                "Docker"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Airflow"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932851",
        "description": "Présentiel obligatoire 3 jours sur site par semaine\nLe livrable est-Compétences techniques\nExpertise SQL, ETL - Expert - Impératif\nCI/CD, github, Terraform, Kafka - Confirmé - Important\nPower BI, Looker - Confirmé - Important\nGoogle Cloud Platform (GCS, BigQuery) - Confirmé - Souhaitable\nConnaissances linguistiques: Anglais Lu, écrit (Impératif)\nDescription détaillée\nAu cours de sa mission, le consultant :\n- Participera aux rituels agiles de l'équipe,\n- Analysera les besoins des utilisateurs et proposera des solutions innovantes et en phase avec les drivers de l'entreprises,\n- Développera les solutions data (Alimentation, stockage, modélisation, restitution),\n- Validera la qualité des développements de son équipe,\n- Améliorera et optimisera le patrimoine actuel de son équipe,\n- Maintiendra les solutions existantes (Run),\n- Contribuera à la construction du nouveau socle et des services sur la plateforme Google Cloud,\n- Accompagnera et acculturera les métiers sur les bonnes pratiques de l'exploitation de la Data\nProfil candidat:\nSA MISSION :\nIl est garant de l'accès qualitatif aux sources de données.\nIl s'assure de la maîtrise de la donnée et est garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists).\nIl contribue également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur, en collaboration avec le Chief Data Officer.\nSon périmètre d'intervention est axé sur les systèmes applicatifs autour de la gestion de la donnée et du traitement, et sur les plateformes Big Data, IoT,\nIl assure la supervision et l'intégration des données de diverse nature qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le Data Lake (il recette de la donnée, supprime les doublons, ).",
        "ft_reference": "1932851",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "InfrastructureAsCode": [
                "Terraform"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Engineer (IT) / Freelance (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932384",
        "description": "Il est garant de l'accès qualitatif aux sources de données.\nIl s'assure de la maîtrise de la donnée et est garant de la qualité de son utilisation (référencement, normalisation, et qualification) afin d'en faciliter l'exploitation par les équipes (Data Analysts et Data Scientists).\nIl contribue également à la définition de la politique de la donnée et à la structuration de son cycle de vie dans le respect des réglementations en vigueur, en collaboration avec le Chief Data Officer.\nSon périmètre d'intervention est axé sur les systèmes applicatifs autour de la gestion de la donnée et du traitement, et sur les plateformes Big Data, IoT,\nIl assure la supervision et l'intégration des données de diverse nature qui proviennent de ces sources multiples et vérifie la qualité des données qui entrent dans le Data Lake (il recette de la donnée, supprime les doublons, ).\nSON ACTIVITE :\nQUALIFICATION ET GESTION DES DONNÉES :\n- Capte les données (structurées et non structurées) produites dans les différentes applications ou à l'extérieur de l'entité\n- Intègre les éléments\n- Structure la donnée (sémantique, etc.)\n- Cartographie les éléments à disposition\n- Nettoie la donnée (élimination des doublons, )\n- Valide la donnée\n- Éventuellement, il crée le référentiel de données\nSES LIVRABLES :\n- Data Lake approprié et partagé et son dimensionnement\n- Cartographie des données\n- Les éléments permettant de garantir la qualité de la donnée\nProfil candidat:\nCompétences techniques :\nKafka - Confirmé - Impératif\nBig Query - Confirmé - Impératif\nPowerBi - Confirmé - Impératif\nCompétences linguistiques :\nAnglais Professionnel (Impératif)",
        "ft_reference": "1932384",
        "skills": {
            "DBMS": [
                "Big Query"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Lead Data Engineer H/F",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 50000,00 Euros à 55000,00 Euros",
        "company": "HARRY HOPE ",
        "location_raw": "MARSEILLE 01",
        "location": "01",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": "Activités des agences de placement de main-d'œuvre",
            "company_size": "Lead Data Engineer (H/F) - CDI - Marseille - 50/55KEUR -Autonomie - Implication - Entreprise challengeante\n\nHarry Hope, cabinet de recrutement accompagne candidats et entreprises dans leurs recherches des meilleures opportunités en France et à l'international. Afin de mieux répondre à vos enjeux, tous nos consultants sont spécialisés par secteur d'activité et zone géographique.",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1928466",
        "description": "POSTE : Lead Data Engineer H/F\nDESCRIPTION : Harry Hope recherche, pour son client, entreprise spécialisée dans l'immobilier, leader national dans son secteur, un Lead Data Engineer (H/F) en CDI.\n\nRattaché au Directeur des Systèmes d'Informations et de la Transformation Numérique, vous jouerez un rôle crucial dans le département IT en tant que Lead Data Engineer (H/F).\n\nVos missions sont articulées autour d'un grand axe : construire et mettre à disposition le socle technologique nécessaire au fonctionnement des flux inter-applicatifs et aux outils de BI de l'entreprise\n\nVos missions :\n\n- Mettre en place l'architecture technique nécessaire à l'exploitation des données et en assurer le MCO\n- Concevoir et construire l'architecture technique\n- FinOps Cloud Azure\n- Administrer et maintenir la plateforme technique en place\n- Concevoir, développer et optimiser les flux de données entrants/sortants\n- Actualiser la documentation technique\n- Construire et faire évoluer les modèles de données de l'entreprise\n- Concevoir les modèles de données du Data Warehouse\n- Optimiser les modèles de données\n- Prendre en charge le ticketing du périmètre\n- Participer au pilotage du domaine Data du Pôle SI\n- Participer à la conception du portefeuille projet\n- Mettre en oeuvre le planning d'exploitation et de tableau de bord de pilotage du périmètre\n- Réaliser une veille technologique\nnon renseigné\nPROFIL : Le profil qu'on cherche :\n- 5 ans d'expérience dans les métiers de la Data ayant eu un rôle d'Architecte Data ainsi/ou celui de Data Engineer.\n- Connaissance des systèmes de données Data (datawarehouse, datalake)\n- Modélisation de données\n- Modélisation des flux d'alimentation Datawarehouse + inter-applicatifs (contrat d'interface)\n- Développement sur l'ETL/ELT Azure Data Factory\n- Connaissance des pratiques DEVOPS pour l'automatisation et le déploiement\n- Connaissance d'outils de reporting (PowerBI, Qlik, SAP BI)\n- Connaissance des bases de données Azure SQL et Oracle\n- Maîtrise du SQL : optimisation des requêtes et des performances des bases de données (T-SQL, PL-SQL)\n- Expérience dans les services cloud, idéalement Azure, pour le stockage et le traitement des données\n- Gestion et pilotage de projet (charge, budget, planning)\n- Communication en interne et avec les fournisseurs\n- Connaissance des principes de gouvernance des données, de sécurité et de conformité\n- Veille technologique : capacité à rester à jour sur les dernières tendances et technologies en matière de données\n\nCe qu'on vous propose :\n- Rejoindre une équipe dynamique\n- Participer à l'amélioration du service financier\n- Être autonome\n\nLe processus de recrutement :\n\n1ere phase : entretien de validation avec le cabinet Harry Hope\n2ème phase : entretien avec le Directeur des Systèmes d'Informations et de la Transformation Numérique\n3ème phase : entretien avec le Directeur des Systèmes d'Informations et de la Transformation Numérique et le Président de l'entreprise",
        "ft_reference": "1928466",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Tableau"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "IT Operations Engineer H/F",
        "job": "sysops",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Nos missions :\nMichael Page recrute des cadres confirmés en CDI et CDD grâce à l'expertise de consultants répartis au sein de 17 divisions spécialisées : Achats & Logistique, Assurance, Audit, Conseil & Expertise, Banque, Commercial, Digital, Médias & Communication, Distribution & Commerce, Finance & Comptabilité, Hôtellerie & Tourisme, Immobilier & Construction, Ingénieurs, Juridique & Fiscal, Marketing, Public & Parapublic, Ressources Humaines, Santé et Systèmes d'Informat...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1986269",
        "description": "Notre client est un Groupe international du secteur du BTP qui compte aujourd'hui plus de  collaborateurs. Avec un département technologique en croissance, il cherche à renforcer son équipe avec un Ingénieur en Opérations Informatique. La DSI se compose de plus de 200 personnes, réparties dans différents pays. En tant qu'Ingénieur en Opérations Informatique, l'objectif principal est d'améliorer l'efficacité opérationnelle, de réduire les coûts et d'assurer une disponibilité et une résilience élevées des systèmes. Vous jouerez également un rôle-clé dans la préparation aux incidents, garantissant que l'organisation dispose des bonnes directives opérationnelles pour maintenir sa continuité en cas de perturbation. Vous promouvrez les meilleures pratiques et mettrez en oeuvre des améliorations dans les environnements Azure, Microsoft 365 (M365), Dynamics 365 (D365), diverses plateformes SaaS et des infrastructures hybrides sur site. Vous aurez les responsabilités suivantes :\nDocumentation technique : Créer et maintenir des guides, diagrammes et runbooks,\nOptimisation : Améliorer l'efficacité, réduire les coûts et promouvoir les bonnes pratiques (Azure, M365, D365),\nRésilience : Élaborer des plans de reprise après sinistre et assurer la continuité des systèmes,\nSupport stratégique : Alignement avec les objectifs IT et accompagnement des équipes.\n Les avantages à ce poste sont :\nPoste en full-remote,\nUn salaire fixe et variable,\nTicket restaurant,\nUn comité d'entreprise très actif,\nChèques vacances,\nWeek-end festif chaque année,\nConvention du BTP (prime de congés de 30%),\nRTT.",
        "ft_reference": "1986269",
        "skills": {
            "CloudComputing": [
                "Azure"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 48000,00 Euros à 50000,00 Euros",
        "company": null,
        "location_raw": "ORLY 94",
        "location": "94",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Notre client est un Groupe mondial qui se distingue par son approche dynamique et innovante dans le secteur du transport de passagers. En pleine expansion, il cherche à attirer des talents prêts à contribuer à leur succès. L'entreprise compte 3000 collaborateurs et la DSI est composée de 70 collaborateurs répartis en 6 directions.\nProcessus de recrutement :***Entretien 1 avec RH et Responsable Data (N+1) par Teams,\n* Entretien 2 avec le Responsable Data dans les locaux.\n~@...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1973438",
        "description": "Description du poste :\nEn tant que Data & Integration Engineer, vous êtes rattaché au Responsable Data (N+1) et travaillez dans l'équipe Data & Integration au sein de laquelle de gros enjeux et projets sont à gérer. Dans votre rôle de Data & Integration Engineer, vos principales missions seront les suivantes :***Gestion des projets d'intégration : Vous serez responsable de l'intégration des systèmes en veillant à respecter des critères stricts de disponibilité, de fiabilité et de résilience. Pour ce faire, vous appliquerez des modèles d'architecture éprouvés comme par exemple « Message Broker »,\n* API : vous mettrez en place une solution complète d'API Management, incluant la création d'un catalogue d'API,\n* Supervision des flux de données : Vous prendrez en charge la recette des flux et assurerez leur suivi en production, en résolvant les incidents qui pourraient survenir,\n* Support technique sur les architectures Cloud Azure : Vous fournirez des conseils techniques sur les architectures Cloud, en collaborant étroitement avec les fournisseurs de solutions et les consultants externes,\n* Amélioration continue des processus : Vous travaillerez sur l'optimisation des processus internes, notamment la localisation et la traçabilité des données, la standardisation des flux de données et la documentation associée,\n* Collaboration avec les équipes internationales.\n* Prime sur objectifs représentant 7,5% de la rémunération fixe brut annuelle,\n* 2 jours de télétravail/semaine,\n* Remboursement de la carte Navigo à hauteur de 80% ou défraiement kilométrique,\n* Tickets restaurants,\n* Avantages conséquents sur les transports,\n* RTT,\n* CE intéressant (300€/an).\nDescription du profil :\nLe profil recherché nécessite un Diplôme Bac +5 minimum (école d'Ingénieur ou université avec cursus informatique), avec au moins 3 ans d'expérience en tant qu'Ingénieur Data, avec idéalement de la production et de l'intégration. Une excellente maîtrise de l'utilisation des API (REST, SOA) est requise.\nIl doit avoir une bonne maîtrise des services Azure : Logic Apps, API Management, Service Bus, Event Grid, Application Insights, Azure Monitoring, Azure Functions, Data Factory, Azure SQL. Il doit également avoir un bon niveau d'anglais pour échanger régulièrement avec les équipes internationales. Des compétences en langage SQL et en programmation (Python et PowerShell) seraient un réel atout.",
        "ft_reference": "1973438",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "PARIS (DEPT.) 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée de 6 An(s)",
        "experience": "6 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1964882",
        "description": "Description du poste :\nEn tant qu'organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises & organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l'un de nos forums.\nL'entreprise Groupe Iliad - Free recherche actuellement des profils :\nDans le cadre du développement et de la structuration de l'activité Data au sein du pôle Audiovisuel de Free, nous recherchons un(e) Data Engineer senior pour prendre une part active à la collecte, l'étude et l'analyse de la consommation audiovisuelle des abonnés Free dans le but d'améliorer le service et de personnaliser l'expérience utilisateur.\nVos missions :***Gérer la plateforme de récupération des données de consommation provenant de l'ensemble des devices (box Internet, mobile, tablette, web, .)\n  - Intégration de nouveaux devices ou modes de consommation\n  - Enrichissement des événements***- Coordination des déploiements avec l'équipe Infrastructure\n* Concevoir, développer, mettre en production et gérer les pipelines d'ETL\n* Mettre en place des solutions de monitoring et assurer la qualité des données\nStack Data:  Python, SQL, Clickhouse, PostgreSQL, Docker, Grafana, Sentry\nInfra Data: Self hosted sur serveur dédié et/ou Cloud privé\nNotre équipe Data :***Un Lead Data\n* Un(e) Data Engineer (en cours de recrutement)\nVous serez également amené(e) à collaborer avec les autres équipes chez OQEE by Free ( Back-End, Web, Android, iOS, .), ainsi qu'avec les équipes Data du groupe Iliad (data engineers, data scientists, data analysts).",
        "ft_reference": "1964882",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Le Groupe PIMENT et ses marques spécialisées OPTIMA et KUBIC vous accompagnent tout au long de votre évolution professionnelle, en vous proposant des contrats en intérim, CDD, CDI, assistance technique, freelance dans de nombreux secteurs d'activité.\nNous apportons une vision et des méthodes de recrutement centrées sur les qualités humaines.\nPour cela, nous proposons à nos clients des solutions de recrutement sur-mesure.\nNotre mission : trouver l'entreprise qui corres...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1961905",
        "description": "Description du poste :\nNotre client recherche son futur(e) Data Engineer au sein de ses équipes.\nL' IA Factory développe des solutions permettant d'améliorer le traitement des interactions écrites des clients. Nous sommes à la recherche d'un développeur Python et DevOps passionné pour rejoindre notre équipe dynamique et participer à la mise en place de solutions d'intelligence artificielle et de machine learning.\nMissions:\nEn tant que Développeur Python et DevOps, vos principales missions seront :\n1. Mise en place de la chaîne CI/CD :\n2. Conception et déploiement des pipelines CI/CD sur GitLab CI pour automatiser le déploiement des modèles de machine learning.\n3. Mise en place les stage de validation et de la qualité du code et les bonnes pratiques.\n4. Développement :\n5. Des applications et des scripts en Python pour faciliter l'automatisation des processus liés à MLOps.\n6. 3. Gestion des Conteneurs et d'environnement :\n7. Utilisation Docker pour containeriser les applications\n8. Gérence des environnements virtuels et les dépendances avec Conda pour garantir la reproductibilité des environnements de développement et de production\n9. Collaboration et Documentation\n10. Travail en étroite collaboration avec les équipes de data science pour garantir l'alignement des objectifs et des processus.\n11. Rédaction de la documentation technique claire et complète pour assurer la pérennité des solutions mises en place.\n12. 5Intégration des Outils :\n13. MLflow pour le suivi des expériences, la gestion des modèles et la mise en production.\n14. Mise en œuvre Airflow pour orchestrer les workflows de data pipelines et les processus de machine learning.\nDescription du profil :\nHard skills:***Excellente maîtrise de Python et des bibliothèques comme Poetry, FastApi, etc..\n* Expérience significative avec les outils DevOps, en particulier GitLab CI, Docker, Airflow et MLflow.\n* Bonne compréhension des environnements Conda et de la gestion des dépendances.\n* Connaissance approfondie des bonnes pratiques de développement et des Design Pattern\n* Maîtrise de la conception et du développement d'APIs RESTful.\nles + (Optionnel)***Conception asynchrone\n* Connaissance Domaine Cloud\n* Connaissance du Métier Data / Big Data\n* Connaissance Domaine DataScience\n* Connaissance Domaine Cybersecurité\nSoft skills :***Autonomie\n* Motivation\n* Organisation\n* Humilité\n* Négociation\n* Curiosité\n* Partage\n* Sens du service\n* Pragmatique / Réaliste\n* Mindset\n* Envie de développer en Python\n* Sensibilisé à la Qualité de code",
        "ft_reference": "1961905",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Airflow"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning",
                "CI/CD",
                "Cloud",
                "DevOps",
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "PARIS 09 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Lancé en 2021, Team.is est une start-up de recrutement spécialisée dans la chasse et le recrutement de profils IT, Digital, Ingénierie & Supply Chain.\nTeam.is c'est avant tout une entreprise à taille humaine animée par la passion du recrutement !\nTeam.is possède l'expertise et l'énergie pour s'attaquer à n'importe quel défi. Mais nous ne sommes pas des robots du recrutement. Nous sommes des consultants qui vivent et respirent ce que nous faisons ! Nous sommes déterminés...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1960390",
        "description": "Description du poste :\nEn postulant à cette offre, vous aurez l'opportunité de rejoindre un groupement d'experts en Data Engineering, animé par une mission : \"Master The Data Engineering Landscape\".\nLe Data Engineering est devenu un véritable défi pour les entreprises : un domaine complexe, évolutif et marqué par des pratiques encore disparates.\nDans cette optique, ils recherchent un·e Data Engineer expérimenté·e pour intervenir chez leurs clients et contribuer au développement de Modeo.\nEn tant que Senior Data Engineer H/F, vous travaillerez sur l'ensemble des outils de la Modern Data Stack, sur une grande variété de projets comprenant la mise en place de Data Platforms, le développement d'applications data avancées et la mise en place de stratégie DataOps. Au cours de ces projets, vous serez régulièrement amené·e à travailler avec des équipes métier et à présenter et vulgariser votre travail à des décisionnaires.\nEn plus de cela, vous serez en charge de piloter des missions et de manager des équipes.\nVos missions, si vous les acceptez :***Mettre en place des infrastructures de données pour des clients ou des projets de Modeo, en collaboration avec d'autres membres de l'équipe\n* Développer et optimiser les flux de données depuis l'extraction de données brutes jusqu'à leur activation\n* Déployer des solutions data chez nos clients\n* Travailler avec des équipes métier pour comprendre et définir leurs besoins puis leur mettre à disposition des solutions adaptées\n* Mettre en place les bonnes pratiques de DataOps au sein des entreprises\n* Encadrer des projets internes et accompagner nos Data Engineers dans leur montée en compétences\n* Gérer des projets Data, de leur planification à leur livraison\nDescription du profil :\nEt vous !***Diplômé·e d'école d'ingénieur\n* Minimum 3 ans d'expérience en Data Engineering\n* Une ou plusieurs expériences majeures en tant que Data Engineer sur des projets de construction de Data Platform et de pipelines ETL/ELT\n* Très bonne compréhension du fonctionnement des bases de données et des cycles de gestion de la donnée ainsi qu'une maîtrise de SQL\n* Excellentes compétences en Software Engineering et Python\n* Connaissances d'un des écosystèmes cloud AWS, GCP ou Azure\n* Des connaissances en DevOps : CI/CD, IaC.\n* Volonté d'apprendre et de s'investir pour l'entreprise\n* Capacité à expliquer et vulgariser des concepts techniques à tout type de profil\n* Intérêt pour le travail en équipe et le management de profils Data juniors",
        "ft_reference": "1960390",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Migration Lead SAP Paris (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-09",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1989986",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Capgemini recherche actuellement des profils :         En tant que Data Migration Lead, vous serez responsable de la définition de la stratégie de migration des données et de la coordination des activités liées au pilotage de la donnée de bout en bout, incluant le nettoyage, l'extraction, la transformation et le chargement dans le système cible.. Responsabilités principales :  Définir la stratégie de migration : Identification et collecte des objets à reprendre, choix des méthodes de reprise des encours, master data, outils de migration, gestion du planning et des dry runs. Piloter la phase de conception : Animer la phase de conception générale et détaillée en collaboration avec les équipes migration, tout en participant aux comités projets pour partager l'avancement. Mettre en œuvre la stratégie de migration : Assurer l'implication des acteurs internes (consultants Capgemini) et externes (représentants clients) dans la migration. Gestion des cycles de migration : Superviser les équipes de migration tout au long des cycles de migration, de l'environnement de test à la mise en production. Communication avec les parties prenantes : Tenir informé le client et le management des difficultés rencontrées et proposer des plans d'action. Développer la confiance avec les parties prenantes : Cultiver des relations de confiance avec les clients, les partenaires SAP et les équipes internes.",
        "ft_reference": "1989986",
        "skills": {
            "EnSoftSkils": [
                "Communication",
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Chef de Projet Data H/F",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "GRASSE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Nos missions :\nMichael Page recrute des cadres confirmés en CDI et CDD grâce à l'expertise de consultants répartis au sein de 17 divisions spécialisées : Achats & Logistique, Assurance, Audit, Conseil & Expertise, Banque, Commercial, Digital, Médias & Communication, Distribution & Commerce, Finance & Comptabilité, Hôtellerie & Tourisme, Immobilier & Construction, Ingénieurs, Juridique & Fiscal, Marketing, Public & Parapublic, Ressources Humaines, Santé et Systèmes d'Informat...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1986845",
        "description": "Michael Page Technology se consacre exclusivement à la recherche de profils IT pour des postes en CDI, Freelance ou Management de Transition.\nNotre client évolue dans un environnement dynamique où créativité et innovation sont au coeur de son savoir-faire. Spécialisé dans la création d'arômes, de parfums et d'ingrédients, il accompagne de grandes marques en développant des solutions sensorielles uniques. Dans ce cadre, il recherche un Chef de Projet Data pour renforcer ses équipes et accompagner sa transformation digitale.Vous rejoignez un acteur majeur du secteur des arômes et des parfums afin de les accompagner comme Chef de Projet Data. À ce titre, vous êtes notamment impliqué sur les sujets suivants :\nContribuer à la conception, à l'architecture et à l'intégration de la solution d'intégration choisie,\nConcevoir et superviser le déploiement de notre CRM en ce qui concerne son intégration,\nDéfinir et organiser le plan de migration de notre ESB actuel (SAP PO) vers la nouvelle plateforme d'intégration,\nMettre en place des processus et bonnes pratiques en matière d'intégration et de migration de données,\nCoordonner les équipes techniques, y compris les intégrateurs externes, ainsi que les parties prenantes métier tout au long des différentes étapes du projet (analyse, mise en oeuvre, tests),\nGarantir la conformité avec les régulations sur la protection des données et la sécurité, en collaboration avec le DPO.\n  Vous bénéficierez de :\n2 jours de télétravail par semaine,\nRTT,\nPrime de participation\nMutuelle\nStatut cadre,\nRestaurant d'entreprise,\nAugmentation collective.\nDe plus, la politique de notre client s'engage à promouvoir des relations humaines respectueuses, plaçant le bien-être et le respect d'autrui au coeur de leur culture d'entreprise.",
        "ft_reference": "1986845",
        "skills": {
            "Automation": [
                "Chef"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Lead Tech Big Data H/F",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Nos missions :\nMichael Page recrute des cadres confirmés en CDI et CDD grâce à l'expertise de consultants répartis au sein de 17 divisions spécialisées : Achats & Logistique, Assurance, Audit, Conseil & Expertise, Banque, Commercial, Digital, Médias & Communication, Distribution & Commerce, Finance & Comptabilité, Hôtellerie & Tourisme, Immobilier & Construction, Ingénieurs, Juridique & Fiscal, Marketing, Public & Parapublic, Ressources Humaines, Santé et Systèmes d'Informat...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1986662",
        "description": "Notre client, une entreprise reconnue comme un acteur incontournable dans son secteur d'activité, se distingue par son expertise et son engagement à fournir des solutions innovantes et de qualité.En tant que Lead Tech Data, vous serez responsable de l'évolution des environnements Data &amp; IA au sein de l'entreprise. Vous travaillerez en étroite collaboration avec les équipes techniques pour concevoir, développer et maintenir des solutions industrielles alignées avec les besoins des clients.\nVos principales missions seront les suivantes :\nAssurer le rôle de référent technique pour les environnements Data &amp; IA,\nConcevoir et déployer des solutions pour la gestion des données et l'intégration des modèles d'IA,\nGarantir le respect des bonnes pratiques de développement et encourager leur adoption au sein de l'équipe.\nDéployer des cas d'usage IA et participer à la création de POC,\nAccompagner la mise en œuvre et le déploiement des solutions développées,\nContribuer à l'animation de la communauté technique et à la veille technologique pour les clients,\nSoutenir l'équipe Data &amp; IA Engineers pour garantir la qualité des projets,\nPromouvoir des solutions standardisées pour nos clients.\nPoste évolutif.",
        "ft_reference": "1986662",
        "skills": {
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Consultant Data Expérimenté - Industrie et Services - Lille (H/F)",
        "job": "consultant data",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "MARQUETTE LEZ LILLE 59",
        "location": "59",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1984822",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.The world is how we shape itDescription du posteVous intégrerez le Pôle Data, travaillant pour plusieurs clients Retail, acteurs majeurs de la Région.Dans ce cadre, vous participerez à des projets data de la conception des solutions à l'accompagnement des équipes de mise en œuvre. Vous serez en forte proximité avec nos clients et saurez vous appuyer sur les experts du Groupe pour proposer les meilleures solutions. Votre rôle et vos missions :Vous serez amené à travailler dans des contextes technologiques variés et novateurs.Dans un contexte où l'équipe et nos clients sont principalement localisés dans la région, vous pourriez être amenés à vous déplacer ponctuellement dans les différentes agences du groupe dans le cadre de projets communs ou d'évènements.Ateliers d'identification des besoins avec nos clients.Participation au cadrage des sujetsConception de solutions de bout en boutAccompagnement des équipes de mise en oeuvreParticipation aux réflexions d'améliorations continues du Pôle data (en termes de développements, outils, bonnes pratiques, processusli>Environnement technique : Talend, PowerBI, Looker, python, JAVA, GitLab, hebergement CloudQualificationsVotre profil : Vous êtes rigoureux(euse), méthodique et possédez un fort esprit d'équipe et d'initiative.Votre aisance relationnelle, vos capacités d'expression écrite et orale ainsi que votre esprit d'analyse et de synthèse seront des atouts indispensables pour réaliser cette mission.De formation Bac+5 (ingénieur ou universitaire ou équivalent), expérience de minimum 5 ans dans la data.Vous avez une vraie volonté de continuer à vous former.La maîtrise de la langue anglaise est appréciée mais pas rédhibitoire.Informations supplémentairesCe que nous vous proposons :Un accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressants : des titres restaurants, accès aux subventions des activités sociales &amp; culturelles.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria AcademyLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi »De nombreuses opportunités en CDI peuvent vous attendre à l'issue de votre stage.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements",
        "ft_reference": "1984822",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Consultant / Architecte DATA & AI - MICROSOFT (H/F)",
        "job": "data architect",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "69 69",
        "location": "69",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983804",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,1 milliards d'euros.\nThe world is how we shape it Description du posteVotre futur environnement de travailRattaché au Pôle France de Sopra Steria vous rejoindrez le Cloud Center of Excellence Microsoft. Ce CCoE Microsoft concentre les référents et profils clefs dédiés aux activités Microsoft. Ce Centre adresse l'ensemble des enjeux de l'éditeur autour de la déclinaison de son offre de valeur : Consulting Microsoft, Apps &amp; DevOps, Modern Work, Infra &amp; Cyber, Data &amp; AI, Business Solutions. Il a pour vocation d'accompagner les clients dans leurs activités Microsoft et développer les opportunités business pour les BUs.Partagez l'ambition et les enjeux du CCoE Microsoft avec Pascal LEBOUC, Ali BOUHADDOU et ses équipes.Votre rôle et missionsIntervenir sur des missions à forte valeur ajoutée pour nos clients autour de la donnée et de l'intelligence artificielle avec les produits et services MicrosoftDéployer l'ensemble de la valeur des plateformes Data et IA Microsoft chez nos clients et dans les offres du pôle FranceAccompagner le développement des savoirs faire et compétences Data-AI Microsoft du Pôle FranceParticiper à la communauté des experts Data-AI Microsoft Ce que nous vous proposonsRejoindre une équipe 100% orientée sur les technologies MicrosoftIntervenir sur des projets à forte valeur ajoutée et visibilité en proximité avec les équipes MicrosoftParticiper à l'animation d'une vision Microsoft des compétences du Pôle FranceDévelopper vos savoirs faire et vos compétences dans une entreprise qui favorise l'entreprenariat.Qualifications  Vous êtes diplômé(e) d'une école d'Ingénieurs ou d'une université, avec une majeure en informatique.Vous disposez d'au moins 5 ans en tant qu'architecte de solutions dans des environnements complexes et variés autour des technologies Data-AI dans le Cloud Microsoft AzureVous avez une parfaite maitrise d'une ou plusieurs technologies Microsoft parmi les suivantes : Microsoft Azure Synapse, Fabric, PowerBI, Purview, Azure ML, Azure AI Services.Les Certifications Microsoft sur ces domaines sont un atout majeur. Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encoreli>Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements",
        "ft_reference": "1983804",
        "skills": {
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "ML",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Leader Technique DATA - Informatica IDMC - DCoE France (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "13 13",
        "location": "13",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983450",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteLe Data Center of Excellence Sopra Steria (DCoE), entité transverse du pôle France, est au cœur de l'accompagnement et de la transformation Data / IA de nos clients. Convaincu que la Data est le moteur d'un socle industriel évolutif et durable construit pour répondre aux enjeux business nous travaillons sur toute la chaine afin d'apporter de la valeur à nos clients sur tous les niveaux (métier, IT, CxO.) en lien avec nos équipes conseils et delivery.Le DCOE regroupe les expertises technologiques et méthodologiques sur toute la chaine de valeur Data : de la stratégie de transformation, à la mise en place d'usage d'IA au quotidien, en passant par la gouvernance et les architectures Data Cloud et on premise. Environnement de travail En tant que Lead tech Data - Compétences Informatica vous intégrerez notre centre d'excellence Data, afin d'intervenir auprès de divers clients dans des secteurs d'activités variés (Banque, Assurance, Secteur Public, Télécom, Média, Jeux, Industrie et Services) sur l'ensemble du territoire Français. Nous intervenons en appui des équipes delivery, lors de la phase de prospection, d'avant-vente et de réalisation des projets.Vous travaillerez en priorité sur les sujets d'architecture Data, tout en intégrant les concepts de data gouvernance, data catalogue, gestion de référentiel, qualité de donnée et d'industrialisation d'IA.Nous travaillons en partenariat avec les éditeurs phares du marché, ainsi qu'avec les hyperscalers. Vos missionsElaboration d'architectures optimisées intégrant la Data plateforme IDMCConception et mise en place des ingestions de données sur IDMCMise en œuvre des transformations et de la valorisation des données sur IDMCParticipation à des ateliers clients de conception et de conseilCadrage/AVV :Comprendre un RFPElaboration d'une réponse technique (architecture fonctionnelle, technique et logicielle)Soutenir face à un auditoire technico/fonctionnelCapacité d'analyse pour identifier les besoins du client afin de :Proposer des solutions techniques adaptéesEviter la redondance si des outils existent déjàChallenger les idées du client pour l'emmener vers les bonnes pratiques « Data Management »Suite à votre prise de poste, vous serez amené(e) à réaliser de l'encadrement d'équipe de développement et participer au delivery de la solution.QualificationsProfil recherchéDe formation Bac+5 (ingénieur grandes écoles ou universités), vous justifiez d'une expérience d'au moins trois ans sur un poste Lead tech Data avec de solides compétences sur Informatica.Vous avez une appétence pour le data management au sens large et une capacité d'adaptation permettant de passer d'un projet à un autre. Dans un contexte d'amélioration continue, le perfectionnement passent par la formation / certification ; vous serez challengé dans votre parcours par le passage de certification.Le passage de compétences / connaissances aux équipes est un élément clés dont vous devrez être moteur.Connaissances techniques poussées sur la partie Cloud Data Intégration d'Informatica de la plateforme IDMCConnaissances complémentaires sur le reste de la plateforme IDMC est un vrai plus : API management, MDM, Data Quality.Connaissance de la partie on-prem Informatica via Power CenterLa certification « Cloud Data Integration (CDI) Modernization » est un réel plusConnaissance de briques techniques globale du SI sont un vrai plus : Datalake, datawharehouse, MDM, autres outils d'intermédiation (ETL, ESB, API managementli>Connaissance de méthodologie et d'outil autour du Devops en contexte DataVous avez une sensibilité particulière sur des sujets Data plus larges (qualité des donnée, référentiels, gouvernance, processus métier) ? Cela sera un véritable atout p",
        "ft_reference": "1983450",
        "skills": {
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Consultant DATA transverse DCoE - France (H/F)",
        "job": "consultant data",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "13 13",
        "location": "13",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983343",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,1 milliards d'euros.\nThe world is how we shape it Description du posteLe Data Center of Excellence Sopra Steria (DCoE), entité transverse du pôle France, est au cœur de l'accompagnement et de la transformation Data / IA de nos clients. Convaincu que la Data est le moteur d'un socle industriel évolutif et durable, construit pour répondre aux enjeux buisness, nous travaillons sur toute la chaine afin d'apporter de la valeur à nos clients sur tous les niveaux (métier, IT, CxO.) en lien avec nos équipes conseils et delivery.Le DCOE regroupe les expertises technologiques et méthodologiques sur toute la chaine de valeur Data : de la stratégie de transformation, à la mise en place d'usage d'IA au quotidien, en passant par la gouvernance et les architectures Data Cloud et on premise. Environnement de travail En tant que Consultant Data vous intégrerez notre centre d'excellence Data, ce qui vous permettra d'intervenir auprès de divers clients dans des secteurs d'activités variés (Banque, Assurance, Secteur Public, Télécom, Média, Jeux, Industrie et Services) sur l'ensemble du territoire Français. Nous intervenons en appuis des équipes delivery, lors de la phase de prospection, d'avant-vente et de réalisation des projets.Vous travaillerez en priorité sur les sujets de gouvernance de la data (Référentiel, qualité, catalogue,.) tout en intégrant les concepts d'architecture data, d'Analytics &amp; d'industrialisation IA .Nous travaillons en partenariat avec les éditeurs phares du marché, ainsi qu'avec les hyperscaler. Vos missionsCadrer et mettre en œuvre la gouvernance des donnéesOptimiser l'organisation, les méthodes et les processus DataParticiper à l'audit de l'existant Data (usages, données, capacités)Expertise sur des activités de qualités des donnéesExpertise sur des activités de référentiels de données, implémentation d'outil de type MDMDéployer une démarche de « cataloguing » des données via outil de data catalogue (éditeur ou non)Connaissance du marché et des éditeurs leader sur les activités Data GouvernanceParticipation à des ateliers clients de conception et de conseilCadrage/AVV, comprendre un RFP, construire une réponse adaptée afin de la soutenir face à un auditoire métier et/ou ITContribuer au rayonnement de nos activités à travers des recrutements et des évènementsParticiper à l'évolution de nos offres Data  Suite à votre prise de poste, vous serez potentiellement amené(e) à réaliser de l'encadrement d'équipe et/ou intervenir sur le delivery de solution (à titre d'expertise).QualificationsDe formation Bac+5 (ingénieur grandes écoles ou universités), vous justifiez d'une expérience d'au moins trois ans sur un poste d'Architecte Data vous ayant permis d'acquérir de solides compétences.Vous avez une sensibilité particulière sur des sujets Data plus larges (qualité des donnée, référentiels, gouvernance, processus métier) ? Cela sera un véritable atout pour vous adaptez aux différents projets desquels vous serez en charge.A l'aise avec la prise de parole en public cela vous permettra de présenter et animer des ateliers et réunions autour de solutions d'architecture.Pour finir, vous disposez d'un anglais de niveau B2 nécessaire pour adresser nos clients à l'étrangers.Tous nos postes sont ouverts aux personnes en situation de handicap. https://www.soprasteria.fr/nous connaitre/nos engagementsEmployeur inclusif et engagé, Sopra Steria œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantag",
        "ft_reference": "1983343",
        "skills": {
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "CDI - Architecte technique Big Data - SBS - Annecy (H/F)",
        "job": "data architect",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ANNECY 74",
        "location": "74",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983159",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Banking Software est le partenaire technologique de référence de plus de  institutions financières dans le monde.La richesse de notre offre, la puissance de notre engagement et notre passion pour l'innovation nous permettent d'accompagner nos\nclients au quotidien dans leurs projets d'avenir, mais également de contribuer à rendre la finance accessible au plus grand nombre.\nNos clients bénéficient chaque jour de la puissance de nos technologies et softwares, ainsi que de l'expertise de nos  collaborateurs.\nNous les accompagnons dans plus de 80 pays dans le monde.Sopra Banking Software est une filiale du groupe Sopra Steria, leader européen du conseil, des services numériques et de l'édition de\nlogiciels. Fort de  collaborateurs, ce dernier affiche un chiffre d'affaires  de €5.1 Milliards d'euros.Pour plus d'information, retrouvez-nous sur LinkedIn, Twitter &amp; Instagram ou visitez www.soprabanking.comDescription du posteAu sein d'un pôle R&amp;D annécien de plus de 100 personnes, vous integrez une équipe internationale de 50 personnes basées entre Annecy (France) et Noida (Inde) en charge de la conception et du développement du tout nouveau progiciel de reporting réglementaire PURE. Ces développements s'inscrivent dans le cadre d'initiatives du groupe autour du technologies Big Data et Intelligence artificielle.PURE (Pioneering the Unified Reporting Experience) est la nouvelle solution Cloud Native / Big Data / Analytics de reporting réglementaire de Sopra Banking Software. Elle est basée sur la plateforme orientée DevOps développée par SBS. Elle expose de nombreux services qui permettent d'optimiser les activités de reporting de notre très large portefeuille de banques clientes. PURE est opéré en SaaS sur AWS par nos équipes.En tant que membre de la Core Team responsable de définir les orientations fonctionnelles et techniques de la solution PURE, vous définirez l'architecture de la couche commune de l'acquisition de données de la solution PURE dans un contexte Cloud agnostic.Vous collaborez dans ce cadre avec les architectes techniques et fonctionnels sitiés à Annecy et à Noida, ainsi qu'avec les architectes d'autres composants de Sopra Banking Software travaillant sur les mêmes problématiques.Vos missions sont les suivantes :\n- Comprendre les besoins fonctionnels à servir et les challenger avec les équipes responsables de l'Offre. Le but est d'acquérir des volumes importants de données, effectuer la mise en qualité, les explorer et restituer des indicateurs, le tout autour de nos cas métiers.\n- Proposer des solutions d'architecture et la stack technique orientée data permettant de mettre en oeuvre les besoins fonctionnels\n- Prendre en compte les besoins d'industrialisation du déploiement de la solution dans un environnement multi-tenant\n- Implémenter des maquettes permettant de valider les architectures proposées\n- Prendre en compte les problématiques liées à la volumétrie et aux besoins de scalabilité horizontale\n- Superviser les développements de la solution réalisés par les équipes agiles\n- Participer aux initiatives autour de la data menées par Sopra Banking Software et le groupe Sopra SteriaStack technique : Apache Spark / MongoDB / ClickHouse / Metabase / Cloud / Kubernetes / Java / GitLab\nEnvironnement : Environnement développement OpenSource, équipes de développement Agile, toutes les communications se font en anglais QualificationsDe formation ingénieur en IT, vous avez 10 ans d'expérience en technologies autour de la data, et avez déjà dirigé des travaux de design ou d'architecture dans un contexte Big Data.\nVous avez également un intérêt pour le fonctionnel Bancaire.Vous avez une très bonne connaissance des architectures Big Data ainsi que du domaine du Data Lake.\nVous avez une bonne compréhension des problématiques associées aux plateformes cloud et bases de données.\nUne expérience devOps / Architecture conteneurs (Docker, Kubernetes) est requise.Vous pouvez vous exprimer quotidiennement en anglais, à l'oral comme à l'écrit.Tous nos postes sont accessibles aux personnes en situation de handicap.Informations complémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant",
        "ft_reference": "1983159",
        "skills": {
            "ProgLanguage": [
                "R",
                "Java"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "DataAnalytics": [
                "R"
            ],
            "BigData": [
                "Spark"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Docker"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "Big Data",
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Leader Technique DATA - Informatica IDMC - DCoE France (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982709",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteLe Data Center of Excellence Sopra Steria (DCoE), entité transverse du pôle France, est au cœur de l'accompagnement et de la transformation Data / IA de nos clients. Convaincu que la Data est le moteur d'un socle industriel évolutif et durable construit pour répondre aux enjeux business nous travaillons sur toute la chaine afin d'apporter de la valeur à nos clients sur tous les niveaux (métier, IT, CxO.) en lien avec nos équipes conseils et delivery.Le DCOE regroupe les expertises technologiques et méthodologiques sur toute la chaine de valeur Data : de la stratégie de transformation, à la mise en place d'usage d'IA au quotidien, en passant par la gouvernance et les architectures Data Cloud et on premise. Environnement de travail En tant que Lead tech Data - Compétences Informatica vous intégrerez notre centre d'excellence Data, afin d'intervenir auprès de divers clients dans des secteurs d'activités variés (Banque, Assurance, Secteur Public, Télécom, Média, Jeux, Industrie et Services) sur l'ensemble du territoire Français. Nous intervenons en appui des équipes delivery, lors de la phase de prospection, d'avant-vente et de réalisation des projets.Vous travaillerez en priorité sur les sujets d'architecture Data, tout en intégrant les concepts de data gouvernance, data catalogue, gestion de référentiel, qualité de donnée et d'industrialisation d'IA.Nous travaillons en partenariat avec les éditeurs phares du marché, ainsi qu'avec les hyperscalers. Vos missionsElaboration d'architectures optimisées intégrant la Data plateforme IDMCConception et mise en place des ingestions de données sur IDMCMise en œuvre des transformations et de la valorisation des données sur IDMCParticipation à des ateliers clients de conception et de conseilCadrage/AVV :Comprendre un RFPElaboration d'une réponse technique (architecture fonctionnelle, technique et logicielle)Soutenir face à un auditoire technico/fonctionnelCapacité d'analyse pour identifier les besoins du client afin de :Proposer des solutions techniques adaptéesEviter la redondance si des outils existent déjàChallenger les idées du client pour l'emmener vers les bonnes pratiques « Data Management »Suite à votre prise de poste, vous serez amené(e) à réaliser de l'encadrement d'équipe de développement et participer au delivery de la solution.QualificationsProfil recherchéDe formation Bac+5 (ingénieur grandes écoles ou universités), vous justifiez d'une expérience d'au moins trois ans sur un poste Lead tech Data avec de solides compétences sur Informatica.Vous avez une appétence pour le data management au sens large et une capacité d'adaptation permettant de passer d'un projet à un autre. Dans un contexte d'amélioration continue, le perfectionnement passent par la formation / certification ; vous serez challengé dans votre parcours par le passage de certification.Le passage de compétences / connaissances aux équipes est un élément clés dont vous devrez être moteur.Connaissances techniques poussées sur la partie Cloud Data Intégration d'Informatica de la plateforme IDMCConnaissances complémentaires sur le reste de la plateforme IDMC est un vrai plus : API management, MDM, Data Quality.Connaissance de la partie on-prem Informatica via Power CenterLa certification « Cloud Data Integration (CDI) Modernization » est un réel plusConnaissance de briques techniques globale du SI sont un vrai plus : Datalake, datawharehouse, MDM, autres outils d'intermédiation (ETL, ESB, API managementli>Connaissance de méthodologie et d'outil autour du Devops en contexte DataVous avez une sensibilité particulière sur des sujets Data plus larges (qualité des donnée, référentiels, gouvernance, processus métier) ? Cela sera un véritable atout p",
        "ft_reference": "1982709",
        "skills": {
            "Other": [
                "Cloud",
                "DevOps"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur Data Confirmé - Services Financiers - Bordeaux (H/F)",
        "job": "data engineer",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "BORDEAUX 33",
        "location": "33",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1980694",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative. Sopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif.En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itLa division « Services financiers » s'est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.Description du posteVotre futur environnement de travail :Intégré(e) au sein de l'une de nos agences à Bordeaux, vous rejoignez une équipe Data et prenez une part active aux projets délivrés pour le compte d'un grand client.Votre rôle et vos missions :Vous intégrez l'équipe d'Intégration de la Donnée, équipe responsable de la gestion des données, garantissant qu'elles sont collectées, préparées et intégrées de manière fiable pour alimenter les analyses et les applications de l'équipe Big Data. Vous jouez un rôle clé dans la transformation des données brutes en informations exploitables.Collecte de DonnéesExtraction, Transformation et Chargement (ETL)Intégration des Données Structurées et Non StructuréesGestion des Flux de Données en ContinuSécurité des DonnéesGestion des Métadonnées Performance et ÉvolutivitéCollaboration avec les Autres ÉquipesPlanification et AutomatisationMaintenance et SurveillanceEnvironnement technologique : Plateformes : Cloudera Data Platform et Openshift / KubernetesIngestion : Kafka, Camel, BenthosOrchestration : Airflow/ArgoStockage données brutes : Ceph/MinIO, Parquet, Avro, IcebergStockage données structurées : PostgreSQL, MongoDB, Oracle DatabaseTraitements : Spark, Pyspark, Scala, JavaExploration : Trino/Dremio, Jupyter, Hive/Beeline, DataikuCI/CD : Gitlab, HarborDatavisualisation : Superset, DigDash, IHM AngularQualificationsVotre profil : Vous êtes diplômé(e) d'une école d'Ingénieur ou Master 2 Informatique, ou formation équivalente. Vous avez au moins 4 ans d'expérience dans la data.Vous êtes curieux(se), logique et vous appréciez le travail collaboratif. Vous êtes passionné(e) par les enjeux induits par la transformation digitale en cours et à venir et vous voulez en être un acteur / une actrice.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encoreli>Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C'est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements",
        "ft_reference": "1980694",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "BigData": [
                "Spark"
            ],
            "DataSerialization": [
                "Avro"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "Automation": [
                "Airflow"
            ],
            "Containers": [
                "OpenShift"
            ],
            "Other": [
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Tech Lead Big Data(F/H)  - MASSY (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": "FRANCE",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "-",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1978487",
        "description": " Le saviez-vous ? \n \nCréateur de l'hypermarché, Carrefour reste fidèle à ses racines tout en se réinventant pour permettre à chacun de mieux manger : plus sain, plus local, plus responsable. Leader mondial de la distribution, nous sommes engagés pour la diversité, la RSE et la transformation digitale, tout en créant un environnement de travail inclusif et stimulant.\n \nNos atouts pour y parvenir ? \nUn réseau multi format, multi métiers avec des collaborateurs passionnés, qui s'engagent, pour réussir la transition alimentaire pour tous.\n \nBienvenue chez nous ! La Direction  Plateforme Data recrute un(e) :\nTech Lead Big Data(F/H) \nContexte et présentation de la direction :\nLa direction de la Plateforme Data, au sein de la Direction des Systèmes d'Information, définit, construit, et supporte l'ensemble des infrastructures Data France et Groupe. \nLa Plateforme Data a pour mission la construction d'un socle de données mutualisées d'Entreprise. Les équipes de la Direction travaillent conjointement à une plateforme unique pour collecter, structurer, stocker et diffuser les données du Système d'Information Carrefour. \nUn socle Data Centric est mis en œuvre pour permettre des usages opérationnels, décisionnels et analytiques. Dans ce contexte, nous vous proposons l'opportunité unique de prendre la responsabilité de Tech Lead BigData. \n \n? Missions :\nAu sein de la Plateforme Data, vous intégrez une équipe de développement Big Data au sein de l'une de nos équipes Produits (Finance/RH, Référentiels Produit et Fournisseur et Offre Vendable, Stocks et ATP, Flux Marchandises, Offre Commandable, Référentiel client et animation commerciale, Événements client), et serez en lien direct avec l'équipe Core.\nVous animez une équipe de 4 à 6 collaborateurs, internes ou externes. \nPassionné(e), polyvalent(e), expert(e) et expérimenté(e), le/la Tech Lead a pour responsabilité de diffuser le savoir-faire et concrétiser les projets sur son périmètre de responsabilité avec un brin de challenge, une volonté d'apprendre et un sens de la communication. \n \nLe/la Tech Lead incarne des compétences en architecture applicative et en développement. Vos missions consistentp>\n- Animer et gérer le flux de travail de l'équipe \n- Accompagner et former les équipes de développeurs sur la qualité logicielle en inculquant les pratiques de TDD/DDD, les revues de code et le pair programming. \n- Garantir l'application des bonnes pratiques de développements via l'approche , et respecter l'approche du software craftsmanship pour améliorer la qualité du code et la performance de nos solutions et notre architecture technique \n- Participer au processus de recrutement de nouveaux développeurs pour la plateforme - Gérer l'intégration des nouveaux arrivants dans l'équipe \n- Accompagner le Product Owner de l'équipe, en lien avec l'architecte de la plateforme, pour définir l'architecture des nouveaux projets \n- Superviser et assurer les activités de delivery et accompagner les équipes dans la résolution des problèmes \n- Participer aux choix des solutions techniques \n- Réaliser des veilles technologiques et être force de proposition pour évoluer et améliorer la plateforme\n- Contribuer fortement à une communauté d'experts et développer les compétences des équipes \n ",
        "ft_reference": "1978487",
        "skills": {
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 45000,00 Euros à 55000,00 Euros",
        "company": null,
        "location_raw": "PARIS 09 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Lancé en 2021, Team.is est une start-up de recrutement spécialisée dans la chasse et le recrutement de profils IT, Digital, Ingénierie & Supply Chain.\nTeam.is c'est avant tout une entreprise à taille humaine animée par la passion du recrutement !\nTeam.is possède l'expertise et l'énergie pour s'attaquer à n'importe quel défi. Mais nous ne sommes pas des robots du recrutement. Nous sommes des consultants qui vivent et respirent ce que nous faisons ! Nous sommes déterminés...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1966161",
        "description": "Description du poste :\nEn postulant à cette offre, vous aurez l'opportunité de rejoindre le premier groupe français de cliniques vétérinaires, est présent dans toute la France avec prés de 200 établissements. Créé en 2016, le groupe souhaite moderniser le métier et mettre la qualité des soins et la satisfaction client au cœur de son projet.\nLe projet d'entreprise se caractérise par son hyper croissance et une culture de type start-up axée sur le collectif, la cohésion, et l'engagement.\nVos missions si vous les acceptez :***Conçoit, développe, optimise et maintient une architecture de données et des pipelines qui respectent les objectifs de l'entreprise ;\n* Résout des problèmes de données afin de fournir des informations qui aident l'entreprise à atteindre ses objectifs ;\n* Crée des jeux de données pour les membres de l'équipe d'analyse afin d'améliorer leur productivité ;\n* Favorise une culture du partage, de la réutilisation, de la stabilité de la conception à l'échelle et de l'efficacité opérationnelle des données et des solutions analytiques ;\n* Contribue à l'évaluation, la mise en œuvre et le déploiement d'outils et de processus émergents pour l'ingénierie des données analytiques afin d'améliorer leur productivité en tant qu'équipe ;\n* Élabore et met en œuvre des plans de communication/éducation sur les capacités, les normes et les processus d'ingénierie des données analytiques ;\n* Travaille en partenariat avec des analystes business et des architectes de solutions pour développer des architectures techniques pour les projets et initiatives stratégiques de l'entreprise.\nDescription du profil :\nEt vous ?***Expérience du développement de bases de données et d'une variété de technologies de bases de données relationnelles ;\n* Expérience des entrepôts de données ;\n* Expertise en SQL et en analyse de données ; maîtrise Python ;\n* Idéalement certifié des technologies BI du Cloud Azure (Synapse, Azure Data Factory, PurView) ;\n* Connaissance de l'intelligence artificielle, des statistiques et/ou des mathématiques appliquées ;\n* Expérience dans le développement de solutions sur des services et infrastructures de cloud computing dans le domaine des données et de l'analyse ;\n* Expérience du déploiement de Power BI ;\n* Expérience conceptuelle des données et de l'analyse, par exemple ETL, modélisation dimensionnelle, outils de reporting, gouvernance des données, entreposage des données, données structurées et non structurées, qualité de données ;\n* Connaissance CI/CD et GitLab fortement apprécié.",
        "ft_reference": "1966161",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "Other": [
                "CI/CD",
                "Statistiques",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "VALBONNE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons p...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1965040",
        "description": "Description du poste :\nLieu : Sophia Antipolis, FranceConstruisons ensemble un avenir de confiance\nThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d'activité : Défense & Sécurité, Aéronautique & Spatial, et Cyber & Digital. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l'environnement et plus inclusif. Le Groupe investit près de 4 milliards d'euros par an en Recherche & Développement, notamment dans des domaines clés de l'innovation tels que l'IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.\nNos engagements, vos avantages\n* Une réussite portée par notre excellence technologique, votre expérience et notre ambition partagée***Un package de rémunération attractif***Un développement des compétences en continu : parcours de formation, académies et communautés internes***Un environnement inclusif, bienveillant et respectant l'équilibre des collaborateurs***Un engagement sociétal et environnemental reconnu\nVotre quotidien\nLa mission de la Direction d'Ingénierie Data & Artificial Intelligence est de fournir et opérer une capacité et des services d'intégration des systèmes data et IA clés en main pour gérer, valoriser et sécuriser la donnée sur tout son cycle de vie.\nNos savoirs faires :***Data Science, Intelligence Artificielle, IA Générative, Algorithmie, Expertise Imagerie ;\n* Data Engineering, DevOps, MLOps.\nNos domaines d'activité :***Développement d'applications pour la collecte et la valorisation des données de nos clients\n* Optimisation des flux de données, big data, streaming de données, création de bases de données\n* Applications métiers : détection de fraudes, maintenance prédictive pour l'industrie, IA générative, .\nNos partenaires :***Recherche : INRIA, CNRS, INSERM, 3IA. ;\n* Externes : MistralAI, NVIDIA, Elastic, MongoDB.\nEn collaboration avec les membres de notre Département Data & AI :***Vous contribuerez au développement et à la scalabilité de nos plateformes au travers d'activités d'automatisation, de création de services managés et d'API.\n* Vous accompagnerez nos clients dans leurs projets de valorisation de données en proposant des solutions techniques et fonctionnelles, évaluées, choisies et opportunes.\n* Vous participerez à l'intégration des plateformes techniques sécurisées développées par Thales, faisant appel aux meilleurs technologies actuelles (Kubernetes, Pometheus, Grafana .)\nLes principales activités que vous réaliserez sont les suivantes :***Mise en place de pipelines de traitement de données\n* Utilisation de l'état de l'art des technologies actuelles dédiées à ces activités : Kafka / Spark / Spark Streaming / Flink / Storm\n* Développement sur des stacks Hadoop (HDFS / Hive / Pig / HBase / Oozie)\n* Utilisation de tous les types de stockage actuels :\n  - SQL : Oracle, SQLServer, PostgreSQL\n  - NoSQL : Cassandra / MongoDB / HBase\n  - Objet : S3 / MinIO\nVotre Profil\nDe formation Bac +5 (école d'ingénieur ou équivalent), vous possédez de bonnes connaissances dans le domaine de la data (Data Engineering, Big data, DevOps, Stockage&BD), et en ingénierie logicielle globalement.\nUne connaissance cloud serait un réel atout, qu'il soit public (AWS, GCP, AZURE) ou privé., et une certification dans ce domaine serait un vrai plus.\nVous possédez une expérience réussie d'au moins 3 ans en développement logiciel orienté data, sur des projets à forte volumétrie de données impliquant l'utilisation de Gitlab, de chaines CI/CD, et de scripting (Java, Scala, Spark, Python).\nVous maitrisez l'utilisation d'outils tels que Docker et Kubernetes, Kafka.\nVous êtes à l'aise en Anglais.\nVous êtes curieux et rigoureux et savez travailler dans une environnement agile (Scrum, SAFe)\nVous aimez travailler en équipe au quotidien, pour vous le succès n'est que collectif.\nLe mot de l'équipe\nDans le département Data & Intelligence Artificielle, nous nous intégrons pleinement dans la quatrième révolution industrielle portée par l'essor de l'IA et du big data. Nous déclinons ces avancées technologiques aux domaines critiques (Défense, aéronautique, santé, industrie) qui sont l'ADN du groupe THALES, afin de proposer à nos clients des IA de confiance et des pipelines de traitement de données sécurisés.\nNous recherchons des collaborateurs enthousiastes et désireux de s'impliquer sur des projets data avec un fort niveau de challenge et d'exigence, mais aussi en capacité de suivre l'évolution des nouvelles technologies dans ce domaine en pleine mutation. Le partage est primordial pour que chacun développe ses compétences.\nThales reconnait tous les talents, la diversité est notre",
        "ft_reference": "1965040",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "MongoDB",
                "HBase",
                "Cassandra",
                "NoSQL",
                "SQL"
            ],
            "BigData": [
                "Hadoop",
                "Spark",
                "Flink"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "DevTools": [
                "Docker"
            ],
            "DBMS": [
                "PostgreSQL"
            ],
            "SoftBigDataProcessing": [
                "HBase",
                "Cassandra"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes",
                "Docker"
            ],
            "Other": [
                "CI/CD",
                "Big Data",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "VALBONNE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Expérience exigée de 6 An(s)",
        "experience": "6 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons p...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1965009",
        "description": "Description du poste :\nLieu : Sophia Antipolis, FranceConstruisons ensemble un avenir de confiance\nThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d'activité : Défense & Sécurité, Aéronautique & Spatial, et Cyber & Digital. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l'environnement et plus inclusif. Le Groupe investit près de 4 milliards d'euros par an en Recherche & Développement, notamment dans des domaines clés de l'innovation tels que l'IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.\nNos engagements, vos avantages\n* Une réussite portée par notre excellence technologique, votre expérience et notre ambition partagée***Un package de rémunération attractif***Un développement des compétences en continu : parcours de formation, académies et communautés internes***Un environnement inclusif, bienveillant et respectant l'équilibre des collaborateurs***Un engagement sociétal et environnemental reconnu\nVotre quotidien\nLa mission de la Direction d'Ingénierie Data & Artificial Intelligence est de fournir et opérer une capacité et des services d'intégration des systèmes data et IA clés en main pour gérer, valoriser et sécuriser la donnée sur tout son cycle de vie.\nNos savoirs faires :***Data Science, Intelligence Artificielle, Algorithmie, Expertise Imagerie ;\n* Data Engineering, DevOps, MLOps.\nNos domaines d'activité :***Applications métiers : détection de fraudes, maintenance prédictive pour l'industrie, IA générative, IA pour la santé.\n* Développement d'applications pour la collecte et la valorisation des données de nos clients\n* Optimisation des flux de données, big data, streaming de données, création de bases de données\nNos partenaires :***Recherche : INRIA, CNRS, INSERM, 3IA. ;\n* Externes : NVIDIA, Elastic, MongoDB.\nAfin de renforcer nos équipes sur notre site de Sophia Antipolis nous sommes à la recherche d'un Ingénieur Data Scientist Senior (F/H).\nVos missions, en collaboration avec les membres de l'équipe de la DI DAI :***Assurer la veille technologique pour suivre les évolutions dans tous les domaines de l'IA (Machine Learning, Deep Learning, IA générative).\n* Participer aux actions d'avant-vente à destination de nos clients (présentation de nos offres, qualification des besoins)\n* Prendre un rôle de lead technique sur certains projets afin d'accompagner nos clients dans leurs projets de valorisation de données en proposant des solutions techniques innovantes et pertinentes.\n* Sélectionner, concevoir, implémenter et valider des solutions data science dans des domaines variés (Industrie, Spatial, Défense, Santé).\n* Participer aux réflexions sur la gestion du cycle de vie des algorithmes et des données en production.\n* Contribuer à l'intégration et au déploiement en production des solutions développées (conteneurisation, services managés, APIs).\n* Communiquer et partager votre savoir-faire en interne Thales comme en externe au travers de publications, conférences et webinars.\nVotre Profil\nDe formation Bac +5 minimum, vous possédez une grande maitrise des outils et concepts liés à la data et à l'intelligence artificielle (écosystème technique et littérature scientifique, maitrise du fonctionnement et de l'entrainement des algorithmes IA) et possédez de bonnes connaissances en ingénierie logicielle ;\nVous avez de l'expérience sur une plateforme Cloud (Azure/AWS/GCP) ;\nVous êtes familier avec certains outils data tels que DataIku, MLFlow, DVC, Kibana, SageMaker ;\nVous maitrisez des langages de développement logiciel (Python, Spark, Scala, Java, C/C++ .) ;\nTensorflow, Keras, PyTorch, ScikitLearn ou Pandas, . n'ont pas de secrets pour vous ;\nVous connaissez les principaux frameworks d'IA générative (Langchain, Ollama, etc) et en maitrisez certains.\nVous maitrisez l'Anglais ;\nVous souhaitez mettre en application vos compétences pour la résolution de problèmes complexes dans des domaines métiers variés ;\nVous aimez transmettre vos savoirs faires et accompagner les utilisateurs dans la prise en main de vos solutions innovantes ;\nVous aimez travailler en équipe au quotidien et vous savez interagir en mode « Agile ». Pour vous le succès n'est que collectif ;\nVous avez plus de 6 ans d'expérience sur un poste équivalent.\nLe mot de l'équipe\nDans le département Data & Intelligence Artificielle, nous nous intégrons pleinement dans la quatrième révolution industrielle portée par l'essor de l'IA et du big data. Nous déclinons ces avancées technologiques aux domaines critiques (Défense, aéronautique, santé, industrie) qui sont l'ADN du groupe THALES, afin de proposer à nos cl",
        "ft_reference": "1965009",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java",
                "Scala"
            ],
            "DataBase": [
                "MongoDB"
            ],
            "DataAnalytics": [
                "Pandas"
            ],
            "BigData": [
                "Spark"
            ],
            "MachineLearning": [
                "Keras",
                "PyTorch",
                "TensorFlow"
            ],
            "CloudComputing": [
                "AWS",
                "GCP",
                "Azure"
            ],
            "Other": [
                "Machine Learning",
                "Big Data",
                "Cloud",
                "DevOps"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data Manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "MONTREUIL SUR EPTE 95",
        "location": "95",
        "remote": null,
        "experience_raw": "Expérience exigée de 6 An(s)",
        "experience": "6 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "BNP Paribas (BNPP) est une banque commerciale française présente dans 63 pays.\nLe groupe est issu de la fusion en avril 2000 entre la Banque nationale de Paris, banque née en 1965 de la fusion de l'ancienne banque nationale de crédit et du comptoir national d'escompte de Paris, et de la banque Paribas, établissement né au cours du xixe siècle.\nAvec 184 000 employés en avril 2023, la banque est organisée selon trois grands domaines d'activités : services bancaires pour par...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1963889",
        "description": "Description du poste :\nAu quotidien, ça donne quoi ?\nVous rejoindrez les équipes Corporate& Institutional Banking IT et Operations (CIB ITO) et plus précisément le département IAAS (Infrastructure As AService)\nCIB ITO Production est àla recherche d'un manager pour gérer l'équipe Backup. Votre mission est lasuivante :***La gestion de l'équipe en termesd'organisation et de priorités\n* La productivité de l'équipe avec la mise en place de KPIs pertinents\n* Le maintien en condition opérationneldes infrastructures Backup\n* La définition et l'implémentation desstandards technologiques\n* Le pilotage de la relation client avec une culture orientée service\n* La gestion du budget avec pour objectifl'optimisation des coûts\n* Le pilotage des projets dans le respectdes délais\n* La gestion des audits régulateurs etinspection générales\n* Le respect des process de sécuritéinhérents à BNP\n* L'alignement entre les différentes régions dans la gestion du support\nVous gérez une équipe de 5 personnes.\nVous serez installé dans nos locaux situésà Montreuil\nCe poste est soumis à des astreintesnuit, week-ends et jour fériés.\nCe poste est ouvert à un rythme detravail hybride avec du télétravail jusqu'à 50% du temps de travail.\nEt après ?\nBNP Paribas, c'est plus de 300 métierset une vaste offre de formation pour vous permettre de monter en compétences etd'évoluer tout au long de votre parcours professionnel.\nNotre filière IT compte plus de 14 000collaborateurs dans le monde, c'est autant d'opportunités d'évolution !Imaginez la diversité des missions possibles, dans tous les métiers del'informatique, dans toutes les activités de la banque, partout dans lemonde. En IT les passerelles sontmultiples.\nLes avantages à nous rejoindre\nUn package rémunération et des avantages :\n- Un fixe annuel brut et un variable individuel et/oucollectif (défini en fonction de votre performance et de celle de votreéquipe).\n- Plan épargne entreprise/retraite, intéressement etparticipation, couverture santé et prévoyance, activités sociales etculturelles via le comité d'entreprise, .\n- De la flexibilité avec un rythme de detravail hybride : jusqu'à 2,5 jours detélétravail par semaine à définir avec votre manager.\nRejoignez un Groupe engagé et prenezpart à notre grand projet de transformation vers la construction d'un mondeplus durable. Découvrez nosengagements pour notre clientèle et la société.\nEngagez-vous à nos côtés sur votre tempsprofessionnel, à travers notre programme OneMillionHoursToHelp.\nÊtes-vous notre prochain IT Manager data backup H/F ?\nDe formation Ingénieur ou équivalant, Vous avez 10 années d'expériences minimum sur desactivités de sauvegarde et de restauration des données idéalement dans undomaine bancaire. Vous avez une expérience en management d'équipe.\nUne expérience sur un ou plusieurs logiciels suivants:***Logiciel VeritasNet backup\n* CommvaultSoftwate backup\n* TSM IBM software\nVos compétences d'adaptation, àcollaborer, en conduite du changement seront autant d'atouts nécessaires pourréussir sur le poste.\nVotre capacité à décider et votreorientation client sont nécessaires.\nVotre niveau d'anglais et de françaisest opérationnel.\nLesétapes du recrutement\nSi votre CV est retenu par notre équipede recrutement, vous passerez des tests en ligne, puis un à trois entretiens aumaximum avec des RH et/ou manager opérationnel.\nCes étapes peuvent varier légèrement en fonction despostes.\nSi vous êtes dans une situation de handicap et souhaitez un échangefacilité, vous pouvez envoyer votre CV et lettre de motivation à***.\nDans unmonde qui change, la diversité, l'équité et l'inclusion sont des valeurs cléspour le bien-être et la performance des équipes. Chez BNP Paribas, noussouhaitons accueillir et retenir tous les talents sans distinction : c'estainsi que nous construirons, ensemble, la finance de demain, innovante, responsableet durable\nEnfin,nous attachons une importance particulière à ce que nos futurs collaborateurset collaboratrices agissent au quotidien avec responsabilité éthique etprofessionnelle. À tout moment pendant le processus de recrutement, lesinformations figurant sur votre CV, vos données d'identification et vosantécédents pourront être vérifiés.",
        "ft_reference": "1963889",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "VELIZY VILLACOUBLAY 78",
        "location": "78",
        "remote": null,
        "experience_raw": "Expérience exigée de 3 An(s)",
        "experience": "3 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Chez Thales, nous sommes fiers de travailler ensemble pour imaginer des solutions innovantes qui contribuent à construire un avenir plus sûr, plus vert et plus inclusif. Un avenir de confiance. Mais ces technologies ne viennent pas de nulle part. L'intelligence humaine est le moteur derrière la technologie qui fait la renommée de Thales. Les projets que nous conduisons sont complexes et nos clients exigeants. Pour répondre aux besoins actuels et futurs de nos clients, nous maîtrisons p...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1960759",
        "description": "Description du poste :\nLieu : Vélizy-Villacoublay, FranceConstruisons ensemble un avenir de confiance\nThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d'activité : Défense & Sécurité, Aéronautique & Spatial, et Cyber & Digital. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l'environnement et plus inclusif. Le Groupe investit près de 4 milliards d'euros par an en Recherche & Développement, notamment dans des domaines clés de l'innovation tels que l'IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.\nNos engagements, vos avantages\n* Une réussite portée par notre excellence technologique, votre expérience et notre ambition partagée***Un package de rémunération attractif***Un développement des compétences en continu : parcours de formation, académies et communautés internes***Un environnement inclusif, bienveillant et respectant l'équilibre des collaborateurs***Un engagement sociétal et environnemental reconnu\nVotre quotidienRejoignez-nous sur le campus Vélizy qui héberge une grande diversité d'activités Thales, aéro, défense, civile,... A l'ouest de Paris, ce site offre un environnement de travail équipé des dernières innovations technologiques et propose des services permettant de concilier vie professionnelle et personnelle.\nEn tant que spécialiste en data visualisation, vous serez responsable de la création et de la présentation de visualisations de données qui permettront à nos clients de prendre des décisions éclairées basées sur l'analyse des données.\nVous collaborerez avec différentes équipes pour comprendre leurs besoins en matière de données et traduire ces besoins en visualisations claires et impactantes.\nAnalyse des Besoins :***Collaborer avec les équipes interfonctionnelles pour comprendre leurs exigences et objectifs en matière de données.***Identifier les sources de données pertinentes et les méthodes d'analyse nécessaires.\nCréation de Visualisations :***Développer des tableaux de bord interactifs et des rapports visuels à l'aide d'outils de visualisation de données tels que Tableau, Power BI, ou D3.js.***Concevoir des graphiques, des infographies et d'autres formes de visualisation qui facilitent l'interprétation des données et la prise de décision.\nValidation et Maintien des Données :***Assurer l'exactitude et la fiabilité des données utilisées pour les visualisations.***Mettre à jour et maintenir les visualisations en fonction des évolutions des données et des besoins des utilisateurs.\nFormation et Support :***Former les utilisateurs à l'interprétation des visualisations et à l'utilisation des tableaux de bord créés.***Fournir un support technique et des conseils pour l'utilisation optimale des outils de visualisation.\nVeille Technologique :***Rester informé des nouvelles tendances et techniques en matière de data visualisation.***Proposer des améliorations et des innovations dans les méthodes de visualisation utilisées dans l'entreprise.\nVotre profil\nDiplômé d'un Bac+5, vous bénéficiez d'une solide expérience dans un rôle similaire\nVous maitrisez les outils de visualisation de données (Tableau, Power BI, D3.js, etc.).\nVous avez de solides compétences en analyse de données et en statistiques.\nVous avez des connaissances en SQL ou dans d'autres langages de requête de données.\nVous avez d'excellentes compétences en communication pour expliquer des concepts complexes aux non-spécialistes.\nVous bénéficiez d'un esprit d'équipe et d'une capacité à travailler de manière autonome.\nAlors ce poste est fait pour vous !\nThales reconnait tous les talents, la diversité est notre meilleur atout. Postulez et rejoignez nous !",
        "ft_reference": "1960759",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI",
                "Tableau"
            ],
            "Other": [
                "Statistiques",
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": "CHERRY PICK ",
        "location_raw": "LE MANS",
        "location": "72",
        "remote": null,
        "experience_raw": "Expérience exigée de 10 An(s)",
        "experience": "10 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949953",
        "description": "Dans le cadre de la fusion et de l?harmonisation des Active Directory (AD) de trois marques de notre client, nous recherchons un Directeur de Programme expérimenté pour piloter cette transformation stratégique.\nMissions :1. Définition et pilotage de la stratégie de fusion des AD\nÉtablir la roadmap globale du programme de fusion et harmonisation des AD.\nDéfinir les principes d?architecture et de gouvernance de l?AD cible.\nAssurer la cohérence entre les différents environnements Active Directory existants.\n2. Supervision de la migration et harmonisation des infrastructures\nPlanifier et piloter la migration des utilisateurs, groupes, GPO et services associés.\nS?assurer de la mise en place des bonnes pratiques de sécurité et de conformité.\nGarantir la compatibilité des systèmes et applications après la migration.\n3. Gestion des risques et accompagnement du changement\nIdentifier les risques liés à la fusion des AD et définir les plans d?atténuation.\nMettre en place une stratégie de gestion des impacts métier.\nAssurer la communication et la conduite du changement auprès des équipes et utilisateurs.\n4. Coordination des équipes techniques et des parties prenantes\nAnimer et superviser les équipes techniques internes et externes.\nAssurer la synchronisation entre les équipes IT, la DSI et les métiers.\nSuivre l?avancement des travaux et résoudre les points de blocage.\n5. Définition d?un catalogue de services Active Directory\nRecenser les services AD existants et définir un modèle cible.\nStandardiser et documenter les services pour une meilleure gestion future.\nAssurer l?optimisation et l?automatisation des services AD.\n6. Gestion du programme et suivi des objectifs stratégiques\nMettre en place les outils de suivi et de reporting du programme.\nAssurer le respect des délais, budgets et engagements du projet.\nRendre compte à la direction et aux comités de pilotage.\n2 jours sur site par semaine au Mans.",
        "ft_reference": "1949953",
        "skills": {
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data analyst (H/F)",
        "job": "data analyst",
        "contract_type": "Profession",
        "salary": null,
        "company": "NEXORIS ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949609",
        "description": "Notre client recherche un Senior Data Analyst - Alteryx (H/F) dans le cadre d'une longue mission.\nPilotage du projet réglementaire Valuation Data Set, visant à produire des extractions de données de gestion à destination du régulateur (SRB), avec un impact transverse sur les établissements du Groupe BPCE.\n- Assurer la gestion du projet en lien avec les équipes Finance, Risque et IT\n- Définir les besoins métiers et les traduire en spécifications fonctionnelles\n- Piloter l?implémentation des workflows Alteryx pour les extractions de données\n- Coordonner les interactions entre les établissements du Groupe et leur SIR\n- Suivre les impacts sur les processus opérationnels et les échanges de données\n- Travailler en étroite collaboration avec la DSI et les équipes Résilience Financière\nLivrables\n- Spécifications fonctionnelles détaillées\n- Workflows Alteryx optimisés et documentés\n- Reporting sur l?avancement du projet et suivi des impacts",
        "ft_reference": "1949609",
        "skills": {
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": "ALLEGIS GROUP ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949590",
        "description": "Teksystems recherche pour l'un de ses clients un(e) Procurement data control officer (H/F)\nLes tâches :\n \nêtre le référent fonctionnel et technique concernant la gestion des données d?achat et la procédure de préparation et migration de ces données (classification Achat, typologie fournisseur, fournisseurs, contrats, eCatalogues...):\n \n- Prendre connaissance des règles de gestion actuelles (Oracle Business Suite) et participer aux ateliers qui définiront la cible (pour les données utilisées par les Achats et celles utilisées pour la comptabilisation).\n- Devenir le référent sur ce sujet auprès des ?Local Data Stewart?.\n- Préparer les données (nettoyage, compléments) et la migration des données du siège (nommé ?eQ?).\n- Etre responsable de la cohérence des données sur l?ensemble du Groupe de manière à permettre la consolidation des dépenses et la mutualisation des actions:\no Gestion de la hiérarchie des fournisseurs et des liens client-fournisseur\no Contrôle qualité concernant les fournisseurs multi-BUs\no Gestion des e-catalogues\n- Avoir la charge de tâches d?administration orientées métier (formulaire de création fournisseur, grille d?appel d?offre, formulaires de demande,...)\n- Intervenir dans le processus d?on-boarding initial des fournisseurs\n- Répondre aux besoins de reporting Groupe (ex: taux de respect de la compliance / politiques Groupe (CSE,..))\n- Participer à l?élaboration des jeux de test et aux tests\n- Analyser les erreurs liées aux interfaces fournisseur (aspects fonctionnels)\n- Back-up de l?administrateur Groupe (périmètre à définir / certifications à obtenir)",
        "ft_reference": "1949590",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data analyst (H/F)",
        "job": "data analyst",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 10000,00 Euros à 52000,00 Euros",
        "company": "PROXIAD ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 2 An(s)",
        "experience": "2 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949532",
        "description": "Au sein du Département Marketing et Veille stratégique du groupes, l?équipe Digital and Payments met de la science dans l?art des pratiques business, dans un contexte où il est nécessaire de s?adapter à des outils DATA en constante évolution, apprendre des best in class et saisir les opportunités data en terme d?innovation.\nLe Data Analyst interviendra principalement sur l?accompagnement des phases d?avant-vente et sur l?implémentation d?analyses à destination de sociétés, clientes. \nLa ressource recherchée pourra le cas échéant intervenir sur la partie Observatoires, pour mettre à disposition des visions enrichies du marché, des tendances pour aider la prise de décisions et favoriser les initiatives sur les axes stratégiques majeurs, grâce à une meilleure autonomie dans la consommation de data.\nDescription : \n? Mettre en ?uvre des outils informatiques, des techniques et des méthodes statistiques pour permettre d?organiser, synthétiser et traduire efficacement des données \n? Fournir un appui analytique à la conduite d?exploration et à l?analyse complexe de données \n? Créer des algorithmes de recherche de données qui permettent d'explorer les données utiles \n? Procéder aussi à l'industrialisation du procédé pour les données les plus intéressantes. Et organiser, synthétise et traduit les informations pour faciliter la prise de décision. \n? Gérer les opérations et l'administration, la modélisation et l'architecture des gisements de données. Et s'assurer que les bases de données existantes fonctionnent bien et en cohérence \n? Donner un sens aux données à l?aide de ses connaissances analytiques (SQL, analytics/BI, statistiques basiques) \n? Travailler en collaboration avec le management pour résoudre des questions business en se focalisant sur l?analyse du passé",
        "ft_reference": "1949532",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "Other": [
                "Statistiques"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": "HEXATEAM ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949462",
        "description": "Principales missions\n- Maîtrise des outils Databricks (création de jobs, cluster, notebook) et pouvoir\nrequêter efficacement avec SQL\n- Maintien en condition opérationnelle de la plateforme en production (analyse et\ncorrection d?incidents, de defects)\n- Développement des jobs d'ingestion et transformation data Python avec Spark sur\nde gros volumes de données\n- Fournir une vision long terme, tant opérationnelle qu?en terme de stratégie de\nplateforme data\n- Accompagner et promouvoir les bonnes pratiques\n- Participer aux ateliers de conception techniques et fonctionnels\n- Rédaction et actualisation de la documentation technique\nCompétences techniques recherchées dans l?ordre de priorité :\n- MUST\no Python\no Spark\no SQL\n- SHOULD\no Databricks\no AWS (S3, Glue, AirFlow, Cloudwatch, Lambda, IAM)\n- COULD\no Big DATA\n- WOULD\no GIT\nMéthodologies :\n- CI/CD avec Gitlab\n- JIRA / Confluence\n- Scrum",
        "ft_reference": "1949462",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "Big Data",
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": "ALLEGIS GROUP ",
        "location_raw": "ISSY LES MOULINEAUX",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 2 An(s)",
        "experience": "2 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949287",
        "description": "Bonjour,\n \nJe recherche pour mon client grand compte basé à Issy-les-Moulineaux (92), un Responsable Réseaux expérimenté pour gérer et optimiser notre infrastructure réseau.\n \nVous serez en charge de la maintenance, de la sécurité et de l'évolution des réseaux de l'entreprise.\n \nS'agissant du poste :\nAssurer la disponibilité et la performance des réseaux.\nGérer les équipements réseau (routeurs, switches, firewalls).\nSuperviser les projets d'extension et de mise à jour du réseau.\nMettre en place et maintenir les politiques de sécurité réseau.\nDiagnostiquer et résoudre les incidents réseau.\nCollaborer avec les équipes techniques pour répondre aux besoins en connectivité.\nCompétences :\nCoordination \nExpérience en gestion de réseaux.\nMaîtrise des technologies réseau (TCP/IP, VPN, VLAN, etc.).\nCompétences en sécurité réseau.\nCapacité à travailler en équipe et à gérer des projets.\nAnglais fluent indispensable !\n \nSi le poste vous intéresse, n'hésitez pas à me partager votre CV.\n \nNatàlia - TEKsystems",
        "ft_reference": "1949287",
        "skills": {
            "NetworkSecurty": [
                "VPN"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 50000,00 Euros à 65000,00 Euros",
        "company": "CITECH ",
        "location_raw": "MONTPELLIER",
        "location": "34",
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949144",
        "description": "CITECH recrute ! ?\n? Rejoignez-nous et intégrez un environnement Big Data à la pointe de la technologie !\nVous êtes passionné(e) par les environnements Big Data et souhaitez relever des défis en gestion courante applicative au sein d?une équipe dynamique et engagée ? Nous avons le poste d?Ingénieur Data (H/F) pour vous ! ? \n? Votre mission est pour un client du secteur banque et assurance qui dispose de 3000 caisses locales sur l?ensemble du territoire ainsi que de 8000 conseillers. Le projet est pour l?une de ces caisses. ?\nAu sein de la Direction des Systèmes d?Information, vous rejoignez l?équipe Gestion Courante Décisionnelle et jouerez un rôle clé dans le maintien et l?évolution des applications décisionnelles du groupe.\n?? Vous aurez les missions principales suivantes : ??\n? Suivi et exploitation des traitements quotidiens en Spark/Scala\n? Analyse et correction des incidents fonctionnels\n? Reprise et qualité des données en lien avec l?équipe Datalake\n? Rédaction et mise à jour de la documentation\n? Livraison en production des corrections et suivi des mises en production\n? Collaboration avec les chefs de projet pour assurer une amélioration continue",
        "ft_reference": "1949144",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "BigData": [
                "Spark"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data analyst (H/F)",
        "job": "data analyst",
        "contract_type": "CDD",
        "salary": null,
        "company": "GRLCI ",
        "location_raw": "BOULOGNE BILLANCOURT",
        "location": "92",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1949096",
        "description": "Dans le cadre d'un nouveau projet, nous recherchons un stagiaire pour intégrer l'équipe en place et réaliser les missions suivantes :\nObjectifs du Stage\nExplorer et organiser des données numériques.\nAnalyser les variations des données en fonction des différents critères.\nIdentifier des tendances et schémas récurrents dans les données pour identifier des insights opérationnels.\n Votre formation académique en mathématiques appliquées vous permettra de développer des modélisations et des analyses pertinentes",
        "ft_reference": "1949096",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": "Salaire brut : Annuel de 42000,00 Euros à 45000,00 Euros",
        "company": "LÙKLA ",
        "location_raw": "MONTAUBAN",
        "location": "82",
        "remote": null,
        "experience_raw": "Expérience exigée de 2 An(s)",
        "experience": "2 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1948949",
        "description": "Au sein d?un organisme de la protection sociale, vous intervenez sur un projet de migration de données. Vous êtes chargés de rédiger le plan de bascule en faisant preuve autonomie (y compris dans le contexte actuel de travail à distance), et en étant capable d?animer un sujet avec les parties prenantes. \nVos missions : \n Rédaction du plan de bascule :\nIdentifier et structurer les items clés\nPartager une vision commune du séquencement des opérations\nAnticiper les risques et définir des mesures de mitigation\nPréparer un plan de retour arrière en cas de besoin\nIdentifier et coordonner les jalons de la bascule\nSuivi et pilotage du plan :\nAssurer la revue et l?amélioration continue du plan\nPiloter l?exécution de la bascule\nMettre en place des KPI pour mesurer l?efficacité et la progression\nCoordonner avec les Business Owners (BO) et Product Managers (PM)\nAnimer des ateliers et réunions avec les parties prenantes\n La prestation se déroule à Montauban, avec une présence requise 2 jours par semaine sur site et 3 jours en télétravail.",
        "ft_reference": "1948949",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Data manager (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": "HEXATEAM ",
        "location_raw": "FRANCE",
        "location": null,
        "remote": null,
        "experience_raw": "Expérience exigée de 5 An(s)",
        "experience": "5 an(s)",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1948933",
        "description": "Principales missions\n- Maîtrise des outils Databricks (création de jobs, cluster, notebook) et pouvoir\nrequêter efficacement avec SQL\n- Maintien en condition opérationnelle de la plateforme en production (analyse et\ncorrection d?incidents, de defects)\n- Développement des jobs d'ingestion et transformation data Python avec Spark sur\nde gros volumes de données\n- Fournir une vision long terme, tant opérationnelle qu?en terme de stratégie de\nplateforme data\n- Accompagner et promouvoir les bonnes pratiques\n- Participer aux ateliers de conception techniques et fonctionnels\n- Rédaction et actualisation de la documentation technique\nCompétences techniques recherchées dans l?ordre de priorité :\n- MUST\no Python\no Spark\no SQL\n- SHOULD\no Databricks\no AWS (S3, Glue, AirFlow, Cloudwatch, Lambda, IAM)\n- COULD\no Big DATA\n- WOULD\no GIT\nMéthodologies :\n- CI/CD avec Gitlab\n- JIRA / Confluence\n- Scrum",
        "ft_reference": "1948933",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Spark",
                "Databricks"
            ],
            "CloudComputing": [
                "AWS"
            ],
            "DevTools": [
                "Git"
            ],
            "Automation": [
                "Airflow"
            ],
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "Other": [
                "Big Data",
                "CI/CD"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "architecte informatique Data / IA (habilité) (IT) (H/F)",
        "job": "data architect",
        "contract_type": "CDI",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1940842",
        "description": "Chez Exiptel, ESN spécialisée en infrastructures et en sécurité, nous recherchons un Architecte IT pour l?un de nos clients.\nDans cette mission, vous serez en charge de :\nDéfinir l'architecture globale de la plateforme data hub et des modules IA associés\nConcevoir et coordonner la réalisation technique de la plateforme data hub et des modules IA\nApporter une expertise et une analyse sous l'angle de la cybersécurité tout au long du projet\nParticiper à toutes les étapes clés du projet (définition des besoins, spécifications, développement, tests, déploiement)\nAssurer l'intégration et l'interopérabilité des différents composants de la plateforme\nDéfinir les standards, les outils et les bonnes pratiques pour la gestion des données et le développement des modules IA\nAccompagner et former les équipes techniques du ministère\nProfil candidat:\nFormation supérieure en informatique, data science ou ingénierie\nExpérience confirmée (5-10 ans) en tant qu'architecte data et/ou IA\nExpertise approfondie en architecture de systèmes d'information, en gestion et traitement des données, ainsi qu'en développement d'applications IA\nSolides compétences en cybersécurité et en garantie de la conformité réglementaire\nMaîtrise des technologies et des outils du data management et de l'IA (stockage, traitement, modélisation, déploiement, etc.)\nSens de l'innovation, de l'analyse et de la résolution de problèmes\nCapacités de coordination et de gestion de projet\nExcellent relationnel et capacité à travailler en mode collaboratif\nÊtre habilité (nationalité française)",
        "ft_reference": "1940842",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Expert Data Center (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "MONTREUIL 93",
        "location": "93",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939981",
        "description": "Missions principales :\nConcevoir, implémenter et maintenir les architectures Data Center et L2DCI.\nAssurer l'implémentation, l'exploitation et la migration sur des environnements critiques mutualisés.\nDiagnostiquer et résoudre des incidents techniques sur des infrastructures complexes.\nAutomatiser et optimiser les opérations réseau en utilisant des outils DevNet (Python, Netmiko).\nVeiller à l'application des processus stricts en matière de documentation, gestion des incidents et gestion des changements.\nAssurer un support technique de haut niveau et garantir la disponibilité des infrastructures.\nProfil candidat:\nCompétences requises :\nExcellente maîtrise des architectures Data Center et L2DCI.\nExpertise en implémentation, migration et exploitation d?environnements critiques.\nSolide capacité d?analyse et de résolution d?incidents sur des infrastructures complexes.\nCompétences en développement et automatisation réseau (Python, Netmiko).\nAdaptabilité aux processus stricts (documentation, gestion des incidents, gestion des changements).\nGestion efficace du stress et réactivité face aux situations critiques.\nProfil recherché :\nExpérience significative en Data Center exigée.\nNiveau de compétences équivalent à CCIE (certification non obligatoire).\nEsprit analytique, rigueur et capacité à travailler en équipe.\nSens des responsabilités et engagement dans la fiabilité des infrastructures.",
        "ft_reference": "1939981",
        "skills": {
            "ProgLanguage": [
                "Python"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Expert Big Data (IT) (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NIORT 79",
        "location": "79",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939909",
        "description": "SI LA GESTION DES DONNEES EST TON DADA, TU PEUX GAGNER LA COURSE EN LISANT CETTE ANNONCE ?\nCe que tu recherches :\n Evoluer au sein d?une équipe dynamique\n Participer à des projets innovants d?envergure\n Relever des défis\n Donner un nouveau souffle à ta carrière\nAlors nous avons la mission idéale pour toi.\nAu sein d?acteurs majeurs du secteur Bancaire, tu participeras des projets d?envergure sur des évolutions majeures à mettre en ?uvre dans le SI du client :\n Analyse des besoins, tu feras\n Spécifications techniques, tu rédigeras\n L?architecture et/ou socle technique, tu définiras\n Bonnes pratiques, tu instaureras\n De nouvelles fonctionnalités, tu développeras\n Zéro bug, tu laisseras\n Ton équipe, tu accompagneras\n Aux instances de pilotage, tu participeras\nProfil candidat:\nQui tu es :\n Diplômé(e) de la formation qui va bien\n Surdoué(e) ou dôté(e) d?une expérience de 5 ans minimum\n Expert(e) de la Stack technique Hadoop Big Data\n Habile avec les Frameworks et Outils : Scala, Spark, Hive, HBASE\nAu-delà des compétences techniques, tu es :\n Dynamique : tu n?aimes pas rester les deux pieds dans le même sabot\n Autonome : un guide du Routard te suffira\n Esprit de synthèse : tu sais aller à l?essentiel\n Capacité d?adaptation : tu es un vrai caméléon\n Sens de la communication : les mots n?ont pas de secret pour toi\n Force de proposition : tu es l?Aladdin de l?informatique\n Esprit d?équipe : un pour tous et tous pour un !",
        "ft_reference": "1939909",
        "skills": {
            "ProgLanguage": [
                "Scala"
            ],
            "DataBase": [
                "HBase"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Expert Data & IA sénior (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1939137",
        "description": "Nous sommes à la recherche d'un expert Data & IA sénior (10 ans d'XP minimum) maitrisant des écosystèmes, des solutions et des patterns Data & IA .\nAyant à minima 1 expérience réussi en Lean Portfolio Management et une réelle expertise technique de gestion et priorisation de portefeuille de projets Data (Usage & capabilities / 5 ans au minimum)\nMaitrise des techniques de conduite du changement dans un contexte Data & IA (5 ans minimum)\nMaitrise des outils de gestion du projet et des outils collaboratifs : Jira, Confluence, Excel, PowerBI, Miro\nExpe?rience minimum d?au moins 2 re?alisations et conduites de programme d?envergure et de de?ploiement de me?thode, a? l?e?chelle d?un grand groupe\nExpe?rience dans la conception et le de?ploiement d?au moins un plan de conduite de changement a? l?e?chelle d?un grand groupe\nExpe?rience confirme?e dans la gestion transversale de dossiers strate?giques\nRapport de l?e?tat des pratiques internes Data,\nDossier de synthe?se des propositions de recommandations court/moyen terme, enrichies par un\nbenchmark externe dans les environnements Data\nStructure du portefeuille des projets Data enrichi des donne?es ne?cessaires au suivi ?haut\nniveau  et re?gles de mise a? jour et de maintien en qualite?\nDiagnostic des pratiques internes Data,\nBenchmark externe dans les environnements Data & IA (3 a? 4 organisations, dont au moins 1\nfaisant re?fe?rence)\nDossier de recommandations court/moyen terme et conditions de mise en ?uvre\nBilan d?un test sur un pe?rime?tre a? de?terminer\nMe?tadonne?es du portefeuille permettant le suivi haut niveau et description des modalite?s\nope?rationnelles de suivi\nPlan culture Data de?cline? par entite? : roadmap des formations a? concevoir et a? de?ployer, vision\nconsolide?e du de?ploiement,\nRe?fe?rentiels des KPI de suivi de la transformation\nUn rapport de fin de mission contenant, entre autres : la de?marche ge?ne?rale, les livrables\nre?alise?s, les points souleve?s et non traite?s\nProfil candidat:\nNous sommes à la recherche d'un expert Data & IA sénior (10 ans d'XP minimum) maitrisant des écosystèmes, des solutions et des patterns Data & IA .\nAyant à minima 1 expérience réussi en Lean Portfolio Management et une réelle expertise technique de gestion et priorisation de portefeuille de projets Data (Usage & capabilities / 5 ans au minimum)\nMaitrise des techniques de conduite du changement dans un contexte Data & IA (5 ans minimum)\nMaitrise des outils de gestion du projet et des outils collaboratifs : Jira, Confluence, Excel, PowerBI, Miro\nExpe?rience minimum d?au moins 2 re?alisations et conduites de programme d?envergure et de de?ploiement de me?thode, a? l?e?chelle d?un grand groupe\nExpe?rience dans la conception et le de?ploiement d?au moins un plan de conduite de changement a? l?e?chelle d?un grand groupe\nExpe?rience confirme?e dans la gestion transversale de dossiers strate?giques\nImportance de l'autonomie, rigueur & relationnel \nElle suppose aussi de s?organiser, d?anticiper, de prioriser et de respecter les de?lais, mais aussi d?avoir une capacite? d?analyse, de propositions, de conseils en faisant preuve d?initiative tout en ayant la faculte? a? identifier les difficulte?s pour remonter les bonnes alertes.",
        "ft_reference": "1939137",
        "skills": {
            "Collaboration": [
                "JIRA",
                "Confluence"
            ],
            "EnSoftSkils": [
                "Initiative"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "architecte informatique Azure Data (IT) / Freelance (H/F)",
        "job": "data architect",
        "contract_type": "Profession",
        "salary": null,
        "company": "ILE-DE-FRANCE",
        "location_raw": "ILE-DE-FRANCE",
        "location": "ILE-DE-FRANCE",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938875",
        "description": "Bonjour, \nJe recherche un Architect Azure Data pour la mise en place de la plateforme Azure Data from Scratch.\n \nMon client souhaite mettre en place la plateforme Azure Data avec un DataLake et du traitement via Synapse.\nÉgalement, les données seront récupéré via Dynamics F& O .\n \nLe consultant doit donc avoir mis en place une plateforme from scratch ainsi que d'avoir de l'expérience avec une BDD Dynamics.\n \nEnvironnement technique :\nAzure Data\nAzure DataLake\nSynapse\nDynamics F& O \n \n \nJe suis disponible pour discuter avec vous et échanger sur cette proposition,\nVuillerme François.\nProfil candidat:\nJe recherche un Architect Azure Data pour la mise en place de la plateforme Azure Data from Scratch.\n \nMon client souhaite mettre en place la plateforme Azure Data avec un DataLake et du traitement via Synapse.\nÉgalement, les données seront récupéré via Dynamics F& O .\n \nLe consultant doit donc avoir mis en place une plateforme from scratch ainsi que d'avoir de l'expérience avec une BDD Dynamics.\n \nEnvironnement technique :\nAzure Data\nAzure DataLake\nSynapse\nDynamics F& O \n \n \nJe suis disponible pour discuter avec vous et échanger sur cette proposition,\nVuillerme François.",
        "ft_reference": "1938875",
        "skills": {
            "CloudComputing": [
                "Azure"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Développeur C++/Data 3D (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938829",
        "description": "Compétences requises Profil orienté infra, expérimenté dans le domaine des SI, de l?exploitation informatique mais aussi et surtout en architecture informatique et technologies associées. Connaissance d?outils de modélisation, technologies réseaux, Cloud, Big Data (capacité à produire du code robuste et optimal afin de traiter des Péta Octets de données de manière extrêmement fiable.). Langage de programmation : développement bas niveau : C, maitrise des directives préprocesseur ainsi que des compétences en C++, javascript et python pour dialoguer avec les autres entités. Docker et Airflow Mathématique : un fort niveau en mathématique analytique et en optimisation sous contrainte Bon relationnel et fort sens du client. Autonome et à l?aise dans le rôle de facilitateur, doté d?une bonne capacité d?analyse et de rédaction. Compétences souhaitées Connaissances en Data Science (Machine learning, Deep learning) Idéalement  double casquette  infra/data science. \nEnvironnement technique : Windows, Linux (CentOS)\nProfil candidat:\nCompétences requises Profil orienté infra, expérimenté dans le domaine des SI, de l?exploitation informatique mais aussi et surtout en architecture informatique et technologies associées. Connaissance d?outils de modélisation, technologies réseaux, Cloud, Big Data (capacité à produire du code robuste et optimal afin de traiter des Péta Octets de données de manière extrêmement fiable.). Langage de programmation : développement bas niveau : C, maitrise des directives préprocesseur ainsi que des compétences en C++, javascript et python pour dialoguer avec les autres entités. Docker et Airflow Mathématique : un fort niveau en mathématique analytique et en optimisation sous contrainte Bon relationnel et fort sens du client. Autonome et à l?aise dans le rôle de facilitateur, doté d?une bonne capacité d?analyse et de rédaction. Compétences souhaitées Connaissances en Data Science (Machine learning, Deep learning) Idéalement  double casquette  infra/data science. \nEnvironnement technique : Windows, Linux (CentOS)",
        "ft_reference": "1938829",
        "skills": {
            "ProgLanguage": [
                "Python"
            ],
            "DevTools": [
                "Docker"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "Automation": [
                "Airflow"
            ],
            "Containers": [
                "Docker"
            ],
            "Other": [
                "Machine Learning",
                "Big Data",
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Expert Data BI (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "YVELINES 78",
        "location": "78",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938421",
        "description": "Le client recherche un spécialiste Microsoft on-premises spécialisé dans les technologies SQL Server, SSAS et Power BI Report Server.\nAttention : Le client recherche un profil orienté administration et non développement.\nLa mission vise à assurer la continuité des services critiques, l?amélioration des performances et la sécurité de la plate-forme tout en préparant son évolution vers une infrastructure haute disponibilité avec Always On, ainsi que l?accompagnement technique aux équipes utilisant la plateforme.\nObjectif principal de la mission :\nGarantir la continuité des services critiques, améliorer les performances et renforcer la sécurité de la plateforme tout en préparant son évolution vers une infrastructure haute disponibilité avec Always On. La mission inclut également un accompagnement technique pour les équipes utilisant la plateforme.\nObjectifs détaillés :\nMaintien en condition opérationnelle (MCO) de la plateforme :\nSuperviser et administrer les environnements SQL Server, SSAS, et Power BI Report Server aux niveaux 2 et 3.\nGérer les incidents et effectuer les corrections nécessaires pour garantir une disponibilité optimale.\nAppliquer les mises à jour logicielles (patches, hotfixes, etc.) pour assurer sécurité et stabilité.\nAmélioration des performances et de la sécurité :\nIdentifier et résoudre les goulots d?étranglement afin d?optimiser les performances des bases de données, cubes SSAS, et rapports Power BI.\nImplémenter les meilleures pratiques de sécurité, incluant la gestion des accès, l?audit, et la protection des données sensibles.\nDesign et évolution de la plateforme :\nParticiper à la conception et à l?implémentation d?une architecture haute disponibilité.\nMettre en place une solution Always On pour SQL Server afin de renforcer la résilience et la tolérance aux pannes.\nIntégrer la plateforme avec Google Cloud Platform et le Lakehouse Thales.\nPréparer l?infrastructure à l?intégration de nouvelles fonctionnalités ou services en fonction des besoins métiers.\nPortée de la mission :\nLe spécialiste interviendra sur les environnements on-premises existants, incluant :\nSQL Server : Administration des bases de données relationnelles et gestion de leur intégration avec les services applicatifs.\nSQL Server Analysis Services (SSAS) : Conception, optimisation, et maintenance des cubes OLAP et modèles tabulaires.\nPower BI Report Server : Administration, optimisation des rapports et support technique pour les utilisateurs finaux.\nLes environnements concernés incluent des serveurs critiques exploités par les équipes métiers pour des applications analytiques.\nProfil candidat:\nCompétences requises :\n? Expertise avancée sur SQL Server (administration, optimisation, haute disponibilité).\n? Maîtrise des solutions Always On (groupes de disponibilité, bascule, réplication).\n? Connaissances approfondies en SSAS (OLAP et tabulaire) et Power BI Report Server.\n? Solide compréhension des bonnes pratiques en sécurité des bases de données.\n? Capacité à documenter et à communiquer efficacement.\nNF OBLIGATOIRE\nAnglais courant",
        "ft_reference": "1938421",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "Google Cloud Platform"
            ],
            "DBMS": [
                "SQL Server"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager informatique (IT) / Freelance (H/F)",
        "job": "data manager",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1938260",
        "description": "Consultant Data Manager Freelance\nBonjour,\nJe suis à la recherche d'un consultant \"Data Manager\" pour un client parisien. \nIl jouera un rôle clé dans la gestion et optimisation de la qualité des données de l'entreprise.\n? Maitrise d'outils de gestion de bases de données : SQL, Databricks\n? Bonne compréhension des modèles de données\n? Modélisation UML, BPMN\nMission de 6 mois renouvelable. \nDémarrage ASAP. \nMerci par avance,\nConsultant Data Manager Freelance\nBonjour,\nJe suis à la recherche d'un consultant \"Data Manager\" pour un client parisien. \nIl jouera un rôle clé dans la gestion et optimisation de la qualité des données de l'entreprise.\n? Maitrise d'outils de gestion de bases de données : SQL, Databricks\n? Bonne compréhension des modèles de données\n? Modélisation UML, BPMN\nMission de 6 mois renouvelable. \nDémarrage ASAP. \nMerci par avance,\nProfil candidat:\nConsultant Data Manager Freelance\nBonjour,\nJe suis à la recherche d'un consultant \"Data Manager\" pour un client parisien. \nIl jouera un rôle clé dans la gestion et optimisation de la qualité des données de l'entreprise.\n? Maitrise d'outils de gestion de bases de données : SQL, Databricks\n? Bonne compréhension des modèles de données\n? Modélisation UML, BPMN\nMission de 6 mois renouvelable. \nDémarrage ASAP. \nMerci par avance,",
        "ft_reference": "1938260",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "BigData": [
                "Databricks"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data manager informatique (H/F) (IT)",
        "job": "data manager",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "LES ANDELYS 27",
        "location": "27",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1937848",
        "description": "Vos Missions :\nSous la responsabilité du Responsable Administratif et Financier (RAF) et en collaboration directe avec les différents services, vous serez au coeur de projets visant à structurer, exploiter et valoriser les données de l'entreprise. Vos principales responsabilités incluent :\n1. Gestion des données :\nCréation et maintenance des données dans l'ERP (JDE - formation possible).\nGarantie de la qualité, de la cohérence et de la mise à jour des données.\nOptimisation des référentiels de données.\n2. Contrôle de gestion et reporting :\nAnalyse et extraction des données pour répondre aux enjeux stratégiques.\nConception de tableaux de bord et reporting à l'aide de Power BI.\nDéfinition et suivi des KPI stratégiques.\nVous jouerez également un rôle de coordination avec le groupe et participerez à des projets stratégiques tels que :\nLa digitalisation des processus encore basés sur Excel.\nL'intégration des données provenant de machines récentes GPAO dans l'ERP.\nL'amélioration de la gestion des données de pricing.\nProfil candidat:\nVotre Profil :\nFormation et expérience :\nBac+5 en gestion de données, contrôle de gestion, finance ou équivalent.\nExpérience en gestion de données ou en reporting (débutant accepté, une première expérience est un atout).\nCompétences techniques :\nMaîtrise de Power BI (indispensable).\nFamiliarité avec un ERP.\nExcellentes capacités analytiques et maîtrise d'outils digitaux.\nCompétences linguistiques :\nAnglais courant ou bilingue (interactions régulières avec le groupe en Italie).\nQualités personnelles :\nEsprit d'analyse, rigueur et autonomie.\nCapacité à interagir avec divers interlocuteurs internes et internationaux.\nConditions et Avantages :\nRémunération : Entre 35 000 EUR et 47 000 EUR, selon profil et expérience.\nRejoignez une entreprise dynamique où vous pourrez pleinement exprimer votre expertise en gestion de données et contribuer à des projets ambitieux et structurants !\nPostulez dès maintenant pour relever ce défi passionnant !",
        "ft_reference": "1937848",
        "skills": {
            "DataVisualisation": [
                "Power BI"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Expert Big Data - Technologies Cloudera / Hadoop / Spark / JEE (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "LE MANS 72",
        "location": "72",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1935276",
        "description": "Expertise développement / outillage / intégration sur des technologies Open Source en environnement Big Data Hadoop (Cloudera).\nConnaissance de la solution Talend. Maîtrise des solutions de conteneurisation (openshift).\nCapacité à assurer l'évolution des socle Data et leur enrichissement en fonction de la roadmap stratégique définie.\n? Aide au diagnostic et à la résolution de problèmes\n? Analyse et réalisation d?outils d?aide au développement et à l'exploitation\n- Maintenance et évolution des solutions ETL Light (Socle Générique) et de l'offre Micro-Services\nLes compétences techniques requises :\n- Expérience significative(> 5 ans) sur les technologies de la Data\n- Expertise sur les technologies et API Java / JEE\nProfil candidat:\nLa société devra fournir les prestations suivantes :\nL'équipe Socles Data se renforce d'un profil expert pour intervenir sur 2 projets stratégiques :\n- finaliser la migration Cloudera / Talend du DataHub historique\n- enrichir l'offre de service de son socle générique, et produire des accélérateurs pour mieux l'exploiter\nCompétences technologiques requises :\n- Développement : Full Stack JEE, SQL\n- Outillage : Eclipse, SubVersion, Jenkins\n- Environnement : Linux Red Hat, PostGre, ELK, Open Source Apache, OpenShift / Kubernetes\n- Technologies et langages Big Data: Cloudera, Java, Python, Json, GIT, SVN, Shell, Hadoop, Hive, Hbase, Solr, Hue, Kafka, Spark, Talend ...\nLes compétences fonctionnelles requises : \n? Animation, diffusion de connaissances\n? Rédaction et administration des documentations relatives au développement\n? Communication sur les normes de développement, les guides d?architecture, les bonnes pratiques\n? Contrôles et revues de code\n? Assurance de l?exploitabilité des systèmes sur les différents environnements\n? Aide au diagnostic et à la résolution de problèmes\n? Analyse et réalisation d?outils d?aide au développement et à l'exploitation\n- Maintenance et évolution des solutions ETL Light (Socle Générique) et de l'offre Micro-Services\nLes compétences techniques requises :\n- Expérience significative(> 5 ans) sur les technologies de la Data\n- Expertise sur les technologies et API Java / JEE",
        "ft_reference": "1935276",
        "skills": {
            "ProgLanguage": [
                "Python",
                "Java"
            ],
            "DataBase": [
                "SQL",
                "HBase"
            ],
            "BigData": [
                "Hadoop",
                "Spark"
            ],
            "DataSerialization": [
                "Json"
            ],
            "DevTools": [
                "Jenkins",
                "Git"
            ],
            "OS": [
                "Linux"
            ],
            "SoftBigDataProcessing": [
                "HBase"
            ],
            "Automation": [
                "Kubernetes"
            ],
            "Containers": [
                "Kubernetes",
                "OpenShift"
            ],
            "Other": [
                "Big Data"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Data lead workday specialist (IT) / Freelance (H/F)",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "75 75",
        "location": "75",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1933792",
        "description": "Vos missions :\nGestion des données et migration :\nParticipez aux ateliers de data conversion avec l'intégrateur Workday (Mercer).\nDéfinissez la stratégie de migration des données en collaboration avec le Chef de Projet client et l'intégrateur.\nPilotage des étapes du Data Load :\nOrganisez les collectes de données RH nécessaires pour les environnements Workday.\nCoordonnez les contributeurs locaux pour respecter les délais de collecte.\nAssurez la qualité des données collectées et leur consolidation au format attendu par Workday.\nValidez la migration des données avec le soutien des contributeurs fonctionnels et locaux.\nSupport et déploiement :\nContribuez à la construction du plan de déploiement et suivez les activités de data conversion pendant la phase de go-live de Workday.\nDéfinissez, avec le support du Chef de Projet, la stratégie de data catch-up post-go-live.\nParticipez aux comités de pilotage et préparez les indicateurs de suivi de la migration.\nGestion des risques :\nEscaladez au Chef de Projet les problèmes liés aux données pouvant impacter la date de go-live de Workday.\nProfil candidat:\nCompétences requises :\nExpérience en pilotage de phases de data migration dans des projets d'implémentation de SIRH (Workday HCM, SAP SuccessFactors, Oracle HCM) en contexte international.\nCompétence en coordination d'équipes multiculturelles.\nCapacité à travailler en mode distanciel et présentiel.\nCompétences avancées sur Excel (indispensable).\nConnaissance de Power BI appréciée.\nMaîtrise du français et de l'anglais.\nPourquoi nous rejoindre ?\nTravaillez pour un client leader dans le secteur pharmaceutique.\nUn environnement de travail stimulant et international.\nL'opportunité de participer à des projets de grande envergure.\nDes équipes multiculturelles et collaboratives.\nUne localisation idéale au c?ur de Paris (Nation).\nPrêt à relever le défi ?\nEnvoyez-nous votre candidature dès aujourd'hui et faites partie de notre aventure passionnante !",
        "ft_reference": "1933792",
        "skills": {
            "DataVisualisation": [
                "Power BI"
            ],
            "Automation": [
                "Chef"
            ],
            "EnSoftSkils": [
                "Collaboration"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Chef de Projet Data - Bi H/F",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": "SOLOCAL GROUP ",
        "location_raw": "BORDEAUX",
        "location": "33",
        "remote": null,
        "experience_raw": "Expérience exigée",
        "experience": "expérience exigée",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": "Activités des sièges sociaux",
            "company_size": "1er acteur français du marketing digital, Solocal est le premier partenaire de toutes les entreprises locales, que ce soit des ETI, TPE, PME, mais aussi des grandes enseignes à réseaux ou des collectivités. Sa mission : dynamiser la vie locale.\n\nChaque jour, Solocal conseille 253 000 entreprises clientes présentes partout en France et les accompagne pour booster leur activité. Solocal travaille à révéler le potentiel de toutes les entreprises en les connectant à leurs cli...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1932264",
        "description": "POSTE : Chef de Projet Data - Bi H/F\nDESCRIPTION : Présentation de la Direction :\nLa Direction des Contenus a pour mission de conduire la politique des données du groupe Solocal et notamment l'acquisition des contenus permettant d'assurer l'exhaustivité, la richesse et la pertinence des annuaires et services d'information édités par le groupe sous les marques PagesJaunes, ou Ooreka notamment, ainsi que celles de la base de prospection commerciale utilisée par ses forces de vente.\nLa Direction du Contenu travaille au quotidien à 3 missions majeures :\n- Rechercher l'exhaustivité des professionnels\n- Enrichir ces professionnels d'un maximum de contenus les plus riches et uniques\n- Veiller à la qualité des données présentes en base\n\nLa Direction épaule les évolutions des produits du groupe Solocal.  Elle s'assure, pour cela, de délivrer le bon service et de la bonne cohérence entre les contenus en base et les nécessités produits.\nLa Direction cherche également constamment à améliorer l'exposition de ses contenus vers nos médias et partenaires.\nAfin de remplir ces objectifs prioritaires, la Direction du Contenu recherche donc aujourd'hui un.e Chef.fe de Projet BI pour rejoindre une équipe de 8 personnes composée de profils techniques et fonctionnels.\n\nLes missions :\nEn qualité de Chef.fe de projet BI, vous aurez la responsabilité de différents projets visant à toujours cibler l'exhaustivité et l'excellence des données de notre base de professionnels.\n\nVous prendrez en charge les projets : du cahier des charges à la recette. Vous vous assurerez que les solutions délivrées sont en accord avec les besoins exprimés et priorisés. Vous interviendrez sur l'ensemble des étapes nécessaire à la bonne réalisation d'un projet :\n- Écoute des besoins clients\n- Cadrage du projet\n- Rédaction des spécifications fonctionnelles\n- Lotissement des actions\n- Étude des livrables et recette\nVous aurez également un rôle central en constituant, organisant et animant l'équipe projet tout en veillant à respecter les délais et budgets attendus.\n\nDe manière opérationnel il s'agira de :\n- Mener des actions qualités sur le gisement de données\n- Participer à l'intégration de contenus dans nos bases dans le respect des process en place\n- Porter les évolutions de process nécessaire\n- Étudier les cas et remontées des anomalies\n- Épauler les autres activités de la Direction (équipe d'intégration de données, prestations offshore, outils, etc.)\n- Échanger avec d'autres Chefs et Responsables de Projet en interne ou en transverse\n- Réaliser des traitements de données ou reporting (GCP Data Studio, Micro Strategy)\nPROFIL : Nous recherchons une personne disposant d'une première expérience aboutie d'un ou deux ans sur des projets data ou décisionnel, avec une capacité à gérer plusieurs projets en même temps.\nLes projets sont de nature variée mais impliquent plusieurs notions et outils techniques, pour cela un profil IT est donc nécessaire pour ce poste.\nCompétences techniques requises :\n· ETL : Talend (maîtrise)\n· BDD & SGBD : Oracle, GCP BigQuery\n· Expertise en langage SQL\n· BI : QlikView, Power BI, Google Cloud (Data Studio), MicroStrategy\n· Maîtrise des outils bureautiques, spécifiquement Excel, Des connaissances en VBA sont un plus\n· Outil Internet et les technologies Web (HTML)\n· Connaissances en programmation (JAVA)\n· Suivi d'anomalies : KATS, Mantis\nSavoir être :\n· Une capacité à coordonner et réaliser plusieurs sujets en même temps\n· Pédagogue et bon communicant : épauler la Direction sur l'ensemble de ses besoins\n· Respect des procédures, délais et règles\n· Curiosité et passion pour les nouvelles technologies.\n· Esprit d'équipe marqué\n· Esprit de synthèse et d'analyse\n· Esprit orienté client\n· Anglais parlé\n· Etre force de proposition pour automatiser, formaliser, actualiser et simplifier les tâches\n#LI-ML1",
        "ft_reference": "1932264",
        "skills": {
            "ProgLanguage": [
                "Java"
            ],
            "DataBase": [
                "SQL"
            ],
            "DataVisualisation": [
                "Power BI"
            ],
            "CloudComputing": [
                "GCP"
            ],
            "DBMS": [
                "BigQuery"
            ],
            "Automation": [
                "Chef"
            ],
            "Other": [
                "Cloud"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Responsable de Secteur GMS H/F",
        "job": "Other",
        "contract_type": "Profession",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-09",
        "company_data": {
            "sector": null,
            "company_size": "Qui sommes-nous ?\nPage Personnel est une filiale de PageGroup, reconnu comme le leader du recrutement et de l'intérim spécialisés dans de nombreux pays grâce à ses 4 marques : Page Executive, Michael Page, Page Personnel et Page Outsourcing.\nCréé en 1976 à Londres, le Groupe compte aujourd'hui 140 bureaux dans 36 pays et rassemble plus de 7 000 collaborateurs. \nNos missions :\nPage Personnel intervient sur le recrutement (CDD, CDI) et l'intérim de cadres 1er nive...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1989478",
        "description": "Notre client reconnu au niveau national et parmi les leaders internationaux des produits d'hygiène, d'entretien et pharmaceutiques en grande distribution. Nous recrutons un Responsable de Secteur GMS - HealthCare, pose à Paris Ouest (Nanterre, Argenteuil, Versailles, Houilles, Bezons, Cergy Pontoise...) et plus précisement sur le 92 et le 78. en charge d'un portefeuille de marques pharmaceutiques, fortes et novatrices.\nResponsable de l'ensemble du portefeuille de marques, vous serez en charge de l'ensemble des produits pharmaceutiques.\nRattaché au Chef des Ventes Régional, vos missions en tant que Responsable de Secteur GMS - HealthCare, poste à Paris Ouest (Nanterre, Argenteuil, Versailles, Houilles, Bezons, Cergy Pontoise...) et plus précisement sur le 92 et le 78 sont :\nVous organiser votre tournée terrain en toute autonomie,\nVous diffusez et optimisez la gamme, le linéaire, le prix et la politique d'animation et de promotion,\nVous optimisez les nombreux moyens mis à votre disposition pour assurer le développement de nos marques en hyper et supermarchés,\nVous assurez un vrai rôle de conseil et d'expertise auprès de votre portefeuille client, avec lesquels vous bâtissez une relation de partenariat,\nVous êtes l'ambassadeur de nos marques.\nRejoignez un Groupe international pour boostez votre carrière. Rémunération Fixe : K€ Fixe + Variable en moyenne de 12K€ annuels bruts + voiture de fonction 5P + forfait repasjour) + indemnité bureau (30€/ mois).",
        "ft_reference": "1989478",
        "skills": {
            "Automation": [
                "Chef"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Manager DBA / Base de données - DSI - Annecy (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ANNECY 74",
        "location": "74",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982837",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous managez une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions :En phase avec les priorités du groupe et les technologies émergentes, vous piloterez l'évolution des infrastructures, des normes et des standards en organisant et respectant les plannings. Vous êtes responsable d'un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.En tant que leader d'équipe, vous assurez le suivi quotidien des collaborateurs :Définir et assurer le suivi des missions et des objectifs de chacun d'entre eux,Prendre la responsabilité de l'exploitation du parc de bases de données du groupe ainsi que des différents projets dans le respect des priorités et des objectifs de l'année,Développer les activités de l'équipe sur les environnements Cloud,Être force de proposition pour faire évoluer l'organisation et progresser les membres de l'équipe,Contribuer à la préparation de la roadmap et de l'exercice budgétaire.Vous êtes aussi amené(e) à intervenir sur les activités suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »Ce que nous vous offrons :Être au cœur de la gestion des infrastructures d'un groupe de  personnes, Intégrer une équipe dynamique, en forte proximité avec les autres équipes de la DSI et les utilisateurs, Réaliser des défis quotidiens au sein d'un environnement technologique riche et varié, Construire votre projet professionnel en fonction de vos motivations et vos aptitudes.  QualificationsVous justifiez d'une expérience en mangement d'équipe d'au moins 3 ans. Vous avez de bonnes compétences relationnelles et savez faire preuve de leadership et de rigueur.Ayant au moins 8 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL S",
        "ft_reference": "1982837",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Manager DBA / Base de données - DSI - Nantes (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982700",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous managez une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions :En phase avec les priorités du groupe et les technologies émergentes, vous piloterez l'évolution des infrastructures, des normes et des standards en organisant et respectant les plannings. Vous êtes responsable d'un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.En tant que leader d'équipe, vous assurez le suivi quotidien des collaborateurs :Définir et assurer le suivi des missions et des objectifs de chacun d'entre eux,Prendre la responsabilité de l'exploitation du parc de bases de données du groupe ainsi que des différents projets dans le respect des priorités et des objectifs de l'année,Développer les activités de l'équipe sur les environnements Cloud,Être force de proposition pour faire évoluer l'organisation et progresser les membres de l'équipe,Contribuer à la préparation de la roadmap et de l'exercice budgétaire.Vous êtes aussi amené(e) à intervenir sur les activités suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »Ce que nous vous offrons :Être au cœur de la gestion des infrastructures d'un groupe de  personnes, Intégrer une équipe dynamique, en forte proximité avec les autres équipes de la DSI et les utilisateurs, Réaliser des défis quotidiens au sein d'un environnement technologique riche et varié, Construire votre projet professionnel en fonction de vos motivations et vos aptitudes.  QualificationsVous justifiez d'une expérience en mangement d'équipe d'au moins 3 ans. Vous avez de bonnes compétences relationnelles et savez faire preuve de leadership et de rigueur.Ayant au moins 8 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL S",
        "ft_reference": "1982700",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication",
                "Leadership"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Responsable de secteur GSB H/F",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "APT 84",
        "location": "84",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Créé en 2002, Menway couvre l'ensemble des prestations RH pour permettre aux entreprises une gestion optimale de leurs effectifs et accompagner efficacement chaque candidat/salarié dans les différentes étapes de sa vie professionnelle.Acteur majeur de l'emploi en France, Menway Emploi est un trait d'union efficace et dynamique entre tous ceux qui recherchent un travail ou de nouveaux talents.",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1979578",
        "description": "Votre mission principale est d'assurer le suivi des points de vente de votre portefeuille, pour la majorité, des grandes surfaces de Bricolage. En effet, vous veillez à ce que les contrats qui ont été conclus par la direction commerciale soient appliqués en magasin en contrôlant lors de votre passage la présence du référencement national en linéaire. Vous apportez à votre interlocuteur les conseils techniques nécessaires à la bonne mise en avant de vos produits. Vous participez aux opérations de promotion et d'animation : salons professionnels et journées techniques. Vous Rapportez toutes études sur l'état du marché, l'activité de la concurrence et les souhaits de la clientèle. Vous informez la direction commerciale de toutes les anomalies de conception et de fabrication rencontrées. Vous participez par votre connaissance du terrain à l'élaboration des outils et des actions de marketing. Vous rendez compte de votre activité dans un rapport hebdomadaire transmis à la direction commerciale, planning de visites et compte rendu via le CRM uniquement.",
        "ft_reference": "1979578",
        "skills": {}
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur base de données H/F",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "BORDEAUX 33",
        "location": "33",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983422",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Inetum recherche actuellement des profils :  Description de la mission :\nNotre agence Inetum de Bordeaux souhaite consolider ses équipes afin de pouvoir répondre à notre forte croissance. A ce titre, nous sommes à la recherche d'un ingénieur base de données PostgreSQL et SQL Server.\nVos missions seront les suivantes :\n Etudier et concevoir des architectures de bases de données\n Comprendre le besoin utilisateur (fonctionnel ou technique)\n Prendre en compte les contraintes métiers et techniques\n Traduire ce besoin en réponse technique fiable, robuste et évolutive\n Assurer le support technique des N2 et N3 auprès des utilisateurs\n Assurer une veille technologique, suivre les évolutions de version, tester et valider les logiciels, définir les normes et standards\nLes compétences demandées sont :\n Maîtrise de SQL et PostgreSQL\n Bonne expérience d'investigation d'incident dans un environnement de production\n Optimisation des requêtes existantes et de la stratégie d'indexation\n Maitrise de l'anglais\nLes compétences suivantes seraient un plus : MongoDB et Azure Cosmos DB\n \nPOURQUOI NOUS REJOINDRE ? \nInetum c'est :\n Un accord de télétravail pour plus de flexibilité\n Une trajectoire de carrière personnalisée et adaptée à vos souhaits d'évolution grâce à une implantation à l'international (26 pays, 7 Fablab), des formations ciblées et des projets couvrant l'ensemble de la chaîne de valeur IT (+25 filières métiers)\n Intégrer un collectif d'experts partageant des valeurs de solidarité et d'excellence\n Une culture de la proximité au sein de nos 45 agences en France\n Une carte ticket restaurant\n Un CSE proposant divers avantages (billetterie, tarifs négociés pour vos vacances, chèques loisirs...)\n \nProfil :\nVous avez la volonté de travailler dans une agence à taille humaine composée de 50 collaborateurs, et vous souhaitez apporter votre dynamisme et votre proactivité à une équipe : rejoignez-nous !\nNous recherchons des personnes souhaitant partager leurs expériences, leurs idées et surtout aspirant à participer au développement de notre agence bordelaise.\nVous disposez d'une expérience similaire en tant qu'ingénieur base de données et votre relationnel ainsi que votre esprit d'équipe sont la clé de votre réussite.\nSi vous vous retrouvez dans cette brève description, n'hésitez plus, et rejoignez-nous !",
        "ft_reference": "1983422",
        "skills": {
            "DataBase": [
                "MongoDB",
                "SQL"
            ],
            "CloudComputing": [
                "Azure"
            ],
            "DBMS": [
                "SQL Server",
                "PostgreSQL"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur(e) DBA / Base de données expérimenté(e) - DSI - Nantes (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTES 44",
        "location": "44",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1983324",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous êtes intégré(e) à une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions : En phase avec les priorités du groupe et les technologies émergentes, vous participez à l'évolution des infrastructures, des normes et des standards. Vous travaillez sur un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.Vous apporterez également votre expertise sur la gestion des données dans le cloud. Ainsi, vous effectuez les missions suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N2 et N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »QualificationsAyant au moins 5 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL Server, MySQL et PostgreSQL étant un plus), vous possédez de solides compétences en automatisation multi-plateformes (scripting PowerShell et Linux).Diplômé(e) d'un bac+5 et issu(e) d'une formation en Ecole d'Ingénieurs ou d'un équivalent Universitaire, vous avez des compétences et des connaissances sur les environnements de bases de données dans le Cloud.Autonome, pragmatique et rigoureux(se), vous savez être force de proposition et prendre des initiatives. Vous disposez de bonnes compétences relationnelles et appréciez travailler dans un environnement multiculturel (France, Inde, UKp>Vous maîtrisez l'anglais à l'oral comme à l'écrit pour répondre aux enjeux du poste.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelle",
        "ft_reference": "1983324",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL",
                "PostgreSQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur(e) DBA / Base de données expérimenté(e) - DSI - Nice (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NICE 06",
        "location": "06",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982687",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous êtes intégré(e) à une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions : En phase avec les priorités du groupe et les technologies émergentes, vous participez à l'évolution des infrastructures, des normes et des standards. Vous travaillez sur un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.Vous apporterez également votre expertise sur la gestion des données dans le cloud. Ainsi, vous effectuez les missions suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N2 et N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »QualificationsAyant au moins 5 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL Server, MySQL et PostgreSQL étant un plus), vous possédez de solides compétences en automatisation multi-plateformes (scripting PowerShell et Linux).Diplômé(e) d'un bac+5 et issu(e) d'une formation en Ecole d'Ingénieurs ou d'un équivalent Universitaire, vous avez des compétences et des connaissances sur les environnements de bases de données dans le Cloud.Autonome, pragmatique et rigoureux(se), vous savez être force de proposition et prendre des initiatives. Vous disposez de bonnes compétences relationnelles et appréciez travailler dans un environnement multiculturel (France, Inde, UKp>Vous maîtrisez l'anglais à l'oral comme à l'écrit pour répondre aux enjeux du poste.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelle",
        "ft_reference": "1982687",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL",
                "PostgreSQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur(e) DBA / Base de données expérimenté(e) - DSI - Annecy (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "ANNECY 74",
        "location": "74",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982678",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous êtes intégré(e) à une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions : En phase avec les priorités du groupe et les technologies émergentes, vous participez à l'évolution des infrastructures, des normes et des standards. Vous travaillez sur un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.Vous apporterez également votre expertise sur la gestion des données dans le cloud. Ainsi, vous effectuez les missions suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N2 et N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »QualificationsAyant au moins 5 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL Server, MySQL et PostgreSQL étant un plus), vous possédez de solides compétences en automatisation multi-plateformes (scripting PowerShell et Linux).Diplômé(e) d'un bac+5 et issu(e) d'une formation en Ecole d'Ingénieurs ou d'un équivalent Universitaire, vous avez des compétences et des connaissances sur les environnements de bases de données dans le Cloud.Autonome, pragmatique et rigoureux(se), vous savez être force de proposition et prendre des initiatives. Vous disposez de bonnes compétences relationnelles et appréciez travailler dans un environnement multiculturel (France, Inde, UKp>Vous maîtrisez l'anglais à l'oral comme à l'écrit pour répondre aux enjeux du poste.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelle",
        "ft_reference": "1982678",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL",
                "PostgreSQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    },
    {
        "source": "France Travail",
        "job_title": "Ingénieur(e) DBA / Base de données expérimenté(e) - DSI - Ile de France (H/F)",
        "job": "Other",
        "contract_type": "CDI",
        "salary": null,
        "company": null,
        "location_raw": "NANTERRE 92",
        "location": "92",
        "remote": null,
        "experience_raw": "Débutant accepté",
        "experience": "débutant accepté",
        "education_level_raw": null,
        "education_level": null,
        "publication_date": "2025-02-08",
        "company_data": {
            "sector": null,
            "company_size": "Une offre présentée par Talents Handicap : le forum en ligne au service de l'emploi des personnes en situation de handicap. \n\nAvec près de 10 ans d'expérience, des dizaines de forums réalisés, plus d'une centaine d'entreprises partenaires et plus de 130 000 visiteurs uniques par an, le forum en ligne Talents Handicap s'est installé comme une référence au service de l'emploi des personnes en situation de handicap. \n\nCette année, Talents Handicap propose 5 forum...",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/1982669",
        "description": "En tant qu&#039;organisateur de forums de recrutement, Talents Handicap accompagne de très nombreuses entreprises &amp; organisations en France dans leurs recrutements de collaborateurs en situation de handicap. Participant actuellement à l&#039;un de nos forums. L'entreprise Sopra Steria recherche actuellement des profils :  Description de l'entrepriseSopra Steria, acteur majeur de la Tech en Europe avec  collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d'édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d'activité et des technologies innovantes à une approche résolument collaborative.\nSopra Steria place l'humain au centre de son action et s'engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En , le Groupe a réalisé un chiffre d'affaires de 5,8 milliards d'euros.\nThe world is how we shape itDescription du posteVous intégrez la Direction des Systèmes d'Information qui a pour rôle de garantir le bon fonctionnement des technologies de l'information au sein du Groupe Sopra Steria. Afin de répondre aux enjeux et à la stratégie numérique globale du Groupe, la DSI gère la conception, la mise en œuvre, et le déploiement de solutions informatiques fiables et adaptées aux besoins. Elle assure la gestion et l'optimisation des infrastructures technologiques ainsi que son maintien en condition opérationnelle et de sécurité. Au sein de la DSI du groupe Sopra Steria, vous êtes intégré(e) à une équipe de 5 personnes qui assurent le déploiement, le support et l'exploitation des bases de données de production pour l'ensemble du groupe.Votre rôle et vos missions : En phase avec les priorités du groupe et les technologies émergentes, vous participez à l'évolution des infrastructures, des normes et des standards. Vous travaillez sur un parc d'une quarantaine de serveurs physiques et virtuels et de deux cents bases de données.Vous apporterez également votre expertise sur la gestion des données dans le cloud. Ainsi, vous effectuez les missions suivantes : Administrer le parc de serveurs de bases de données de groupe,Assurer leurs sécurisations et leurs sauvegardes/restaurations,Rédiger et maintenir les documentations techniques,Proposer et mettre en place des solutions d'optimisation des performances,Développer et maintenir les outils d'administration et d'industrialisation,Qualifier et valider les nouvelles versions des moteurs de bases de données,Prendre en charge les incidents N2 et N3,Analyser et traiter les demandes du Système d'Information (conseil et expertise, préconisation de bonnes pratiques)Accompagner et conseiller les équipes de développement sur les déploiements et bonnes pratiques des bases de données et de gestion des données dans le Cloud.Environnement technique : Moteurs de base de données : Oracle, SQL Server, MySQL / MariaDB, PostgreSQLEnvironnement de production en haute disponibilité (clustering, réplication)Systèmes d'exploitation : Windows Server, LinuxCloud AzureScripting PowerShell et BashTémoignage d'Anna, membre de l'équipe depuis 3 ans : « Au cours de ces trois dernières années en tant que DBA j'ai eu la chance de travailler sur de multiples SGBD et de pouvoir développer mes connaissances sur ces derniers. J'ai également eu l'opportunité de pouvoir diriger des projets transverses avec d'autres équipes de la DSI ce qui m'a permis de renforcer mes compétences en communication »QualificationsAyant au moins 5 ans d'expérience dans l'administration de bases de données multi-SGBD (Oracle et SQL Server, MySQL et PostgreSQL étant un plus), vous possédez de solides compétences en automatisation multi-plateformes (scripting PowerShell et Linux).Diplômé(e) d'un bac+5 et issu(e) d'une formation en Ecole d'Ingénieurs ou d'un équivalent Universitaire, vous avez des compétences et des connaissances sur les environnements de bases de données dans le Cloud.Autonome, pragmatique et rigoureux(se), vous savez être force de proposition et prendre des initiatives. Vous disposez de bonnes compétences relationnelles et appréciez travailler dans un environnement multiculturel (France, Inde, UKp>Vous maîtrisez l'anglais à l'oral comme à l'écrit pour répondre aux enjeux du poste.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelle",
        "ft_reference": "1982669",
        "skills": {
            "DataBase": [
                "SQL"
            ],
            "OS": [
                "Windows",
                "Linux"
            ],
            "DBMS": [
                "SQL Server",
                "MySQL",
                "PostgreSQL"
            ],
            "Other": [
                "Cloud"
            ],
            "EnSoftSkils": [
                "Communication"
            ]
        }
    }
]