[
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_paris?q=a4acfb2fdef1469051414f8389f464c2&o=214d2ad1-322f-4b0e-b979-2e137899b452",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_paris?q=a4acfb2fdef1469051414f8389f464c2&o=214d2ad1-322f-4b0e-b979-2e137899b452",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Big Data Developer / Engineer (Scala/Java) (f/m/d)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Deutsche Börse Group Prague",
        "location": "Prague",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Finance",
            "company_size": "1500",
            "creation_date": "2006",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "€4,337.6 million (2022)",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "c++,",
                "scalable",
                "scala",
                "scala,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "github,",
                "jenkins,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "jira,"
            ],
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dbg/jobs/big-data-developer-engineer-scala-java-f-m-d_prague?q=a4acfb2fdef1469051414f8389f464c2&o=ac51e127-c7f8-433a-abf1-af044c101171",
        "description": "Descriptif du posteYour career at Deutsche Börse GroupYour area of work: We’re looking for a highly motivated Big Data Developer/Engineer to join our international team to help us built reliable applications capable of processing sensitive data in a Big Data environment. If you are interested in financial markets, are fascinated by technology and like to work in a stimulating environment, then you are the person we are looking for. You’ll be working in the StatistiX division within the Clearing and Risk IT department of Deutsche Börse Group. Being the central data warehouse and data platform, StatistiX constitutes an integral part of Deutsche Börse’s IT systems, providing insightful data to internal and external users on a global scale. The data gathered, maintained and calculated by StatistiX is consumed by multiple stakeholders of the financial ecosystem. Within StatistiX, we are not only controlling manifold nexuses of data streams, but also act as Business Intelligence and Analytics platform. You’ll be part of the dynamic, committed and performance-oriented “StatistiX Dev Trading Regulation” team. The team is responsible for the creation and timely delivery of regulatory reports mainly consumed by external clients. Regulatory reporting is a rapidly emerging area within our company attracting a high degree of management attention. To a large part, you’ll be responsible for the development and maintenance of applications processing regulatory data. These applications, which process over a billion data records from the trading system every day, need to run reliably and are subject to constant change. Naturally, data correctness and integrity are of utmost importance. Overarching mission of the team is to implement regulatory business requirements within a scalable data platform architecture. In doing so, we take care of the entire lifecycle, from design and development to deployment in the production environment as well as ongoing maintenance and support. Your responsibilities: Built software based on requirements given by functional and business experts Function as a primary contributor in designing, coding, testing, debugging, documenting and supporting different types of Big Data applications with a focus on MiFID/MiFIR regulatory reporting Provide recommendations and feedback on solution design and development to facilitate and foster the growth of the team Become a competent expert with visible responsibility of certain applications and the used technology to deliver valuable input for the functional team Ensure the high-quality standards are met along the entire development process, from conceptual design to production deployment Your profile:  University degree in Computer Science or similar technical subject At least three years of experience in software development Interest in or basic knowledge of financial markets Knowledge in Scala / Spark, alternatively of object-oriented programming languages such as Java, Scala, C++, Python, etc.  Able to work independently in a solution-oriented manner while thinking responsibly and pragmatically  Experience with other technologies used by the team will be an added advantage (e.g. GitHub, Jira, Oracle SQL, Control-M, Jenkins, Kafka, etc.) Excellent written and verbal communication skills in English; German will be a plus Eager to learn about new technologies and business matters, willingness to bring the team to the next level"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Big Data Developer / Engineer (Scala/Java) (f/m/d)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Deutsche Börse Group Prague",
        "location": "Prague",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Finance",
            "company_size": "1500",
            "creation_date": "2006",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "€4,337.6 million (2022)",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "c++,",
                "scalable",
                "scala",
                "scala,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "github,",
                "jenkins,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "jira,"
            ],
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dbg/jobs/big-data-developer-engineer-scala-java-f-m-d_prague?q=a4acfb2fdef1469051414f8389f464c2&o=ac51e127-c7f8-433a-abf1-af044c101171",
        "description": "Descriptif du posteYour career at Deutsche Börse GroupYour area of work: We’re looking for a highly motivated Big Data Developer/Engineer to join our international team to help us built reliable applications capable of processing sensitive data in a Big Data environment. If you are interested in financial markets, are fascinated by technology and like to work in a stimulating environment, then you are the person we are looking for. You’ll be working in the StatistiX division within the Clearing and Risk IT department of Deutsche Börse Group. Being the central data warehouse and data platform, StatistiX constitutes an integral part of Deutsche Börse’s IT systems, providing insightful data to internal and external users on a global scale. The data gathered, maintained and calculated by StatistiX is consumed by multiple stakeholders of the financial ecosystem. Within StatistiX, we are not only controlling manifold nexuses of data streams, but also act as Business Intelligence and Analytics platform. You’ll be part of the dynamic, committed and performance-oriented “StatistiX Dev Trading Regulation” team. The team is responsible for the creation and timely delivery of regulatory reports mainly consumed by external clients. Regulatory reporting is a rapidly emerging area within our company attracting a high degree of management attention. To a large part, you’ll be responsible for the development and maintenance of applications processing regulatory data. These applications, which process over a billion data records from the trading system every day, need to run reliably and are subject to constant change. Naturally, data correctness and integrity are of utmost importance. Overarching mission of the team is to implement regulatory business requirements within a scalable data platform architecture. In doing so, we take care of the entire lifecycle, from design and development to deployment in the production environment as well as ongoing maintenance and support. Your responsibilities: Built software based on requirements given by functional and business experts Function as a primary contributor in designing, coding, testing, debugging, documenting and supporting different types of Big Data applications with a focus on MiFID/MiFIR regulatory reporting Provide recommendations and feedback on solution design and development to facilitate and foster the growth of the team Become a competent expert with visible responsibility of certain applications and the used technology to deliver valuable input for the functional team Ensure the high-quality standards are met along the entire development process, from conceptual design to production deployment Your profile:  University degree in Computer Science or similar technical subject At least three years of experience in software development Interest in or basic knowledge of financial markets Knowledge in Scala / Spark, alternatively of object-oriented programming languages such as Java, Scala, C++, Python, etc.  Able to work independently in a solution-oriented manner while thinking responsibly and pragmatically  Experience with other technologies used by the team will be an added advantage (e.g. GitHub, Jira, Oracle SQL, Control-M, Jenkins, Kafka, etc.) Excellent written and verbal communication skills in English; German will be a plus Eager to learn about new technologies and business matters, willingness to bring the team to the next level"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Big Data (H/F/NB) - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Keyrus",
        "location": "Levallois-Perret",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Organisation / Management",
            "company_size": "3500",
            "creation_date": "1996",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "370 Millions d'Euros (2023)",
            "proportion_female": "43",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java,",
                "(java,",
                "c++,",
                "c#)",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "mongodb,",
                "cassandra,",
                "hbase,",
                "elasticsearch/solr"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "(azure),…",
                "azure,",
                "gcp,"
            ],
            "DevTools": [
                "digital",
                "artificielledigital",
                "digitalesconseil",
                "légitimité",
                "#digitaladdict,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase,",
                "cassandra,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloud",
                "cloud",
                "cloud",
                "cloudera,",
                "cloud",
                "cloud",
                "clouds",
                "(cloudera,"
            ],
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/keyrus/jobs/tech-lead-big-data-h-f-nb-paris_levallois-perret_KEYRU_lweXKaZ?q=a4acfb2fdef1469051414f8389f464c2&o=25f33217-da38-410a-921a-1011df491a2d",
        "description": "Descriptif du posteQui sommes-nous ? Une success story dans la Data et le Digital !Notre mission ? Des projets à forte valeur ajoutée pour accroître la performance et la compétitivité des entreprises, faciliter et accélérer leur transformation.Notre expertise depuis plus de 20 ans ? Le conseil et l'intégration de solutions innovantes autour de trois domaines :Data IntelligenceBusiness Intelligence, Big Data & Analytics, Intelligence ArtificielleDigital ExperienceConseil, Stratégie & Performance DigitalesConseil en Management & TransformationStratégie & Innovation, Pilotage de la Performance & Accompagnement des ProjetsNous sommes plus de 3200 talents sur plus de 18 pays et 4 continents. Notre ADN ? Innover et entreprendre. Tech Lead Big Data H/FVous êtes (ou avez l’âme d’) un leader ?Vous avez une expérience significative dans la mise en place de plateformes et d’Architectures Big Data ?Ça tombe bien, nous avons justement besoin de votre expérience pour accompagner nos clients dans la mise en place de leurs projets Big Data et Cloud !L’équipeAu sein de l’une de nos Business Unit de Conseil, d’Expertise et de Delivery Data, vous intègrerez une équipe de Data Specialists (Big Data, Data Science, Data Gouvernance, Data Viz…), capables d’accompagner nos clients dans la mise en œuvre d’une stratégie data globale.Intéressé(e) ? Lisez la suite …  Le job :    Expertise technique et animation transversale Mise en œuvre d’architectures Big Data, potentiellement déployées en cloud ; Partenariat avec l’équipe R&D Keyrus et contribution à l’animation technique transversale au travers de réunions régulières ;    Capitalisation des connaissances (production de documents techniques projets et développement des compétences des consultants en charge du déploiement pour les clients (binômage et accompagnement ponctuel) ;    Participation au recrutement de nouveaux talents (validation technique de profils).  Veille et communication  Assurer une veille technologique permanente pour garantir l’actualisation des compétences    Assurer une évangélisation en interne Keyrus sur les thématiques du big data au travers de l’animation de Meetup ou d’afterwork périodiques sur ces thèmes.    Former et accompagner à la montée des compétences des collaborateurs Big Data ;    Assurer le rôle de speaker tant en interne (réunion mensuelle, séminaire/workshop,…) qu’en externe (salon, forum d’écoles, Meetup,…) ;    Représenter Keyrus et son savoir-faire Big Data auprès des écoles/universités majeures du marché Big Data ;    Participation au développement et à l’animation de relations partenaires avec les éditeurs des marchés Big Data et Cloud : Cloudera, Datastax, Amazon (WS), Microsoft (Azure),…   Votre profil : Vous êtes diplômé(e) d’un Bac +5 en informatique (école d'ingénieur ou master – avec idéalement une filière orientée Big Data ou Cloud Computing) avec à minima une 1ère expérience significative dans la mise en oeuvre de technologies Big Data.Compétences requises/attendues :  Maîtrise de l’écosystème Hadoop (HDFS, Pig, Hive, Sqoop,…), Spark, Kafka, ElasticSearch/SolR ;    Maitrise de l’un des langages de programmation suivant : Java, Scala, ou Python (dans un contexte Big Data) ; Maitrise de la programmation orientée objet et d’un langage associé (Java, C++, C#) ;  Connaissance des concepts NoSQL et maîtrise d’au moins une solution parmi celles-ci : HBase, Cassandra, DynamoDB, DocumentDB, Big Table, MongoDB, Redis, Riak … ; Capacité à évoluer dans un environnement anglophone A minima, une connaissance fondamentale des algorithmes de Machine Learning. Qualités requises :    Vous avez conscience que vous serez un des piliers de l’activité et que votre légitimité technique passe notamment par l’émulation et le partage des connaissances au sein de l’équipe ;  Vous avez besoin d’apprendre en permanence ; Vous êtes un(e) véritable « Data Geek », et vous avez un état d’esprit de gagnant Vous avez la capacité à expliquer/vulgariser et vous avez les qualités et compétences pour rassurer et convaincre vos interlocuteurs sur la pertinence de vos préconisations ; Vous avez un état d’esprit de gagnant et vous portiez à l’adolescence un tee-shirt portant l’inscription « The second place is the first looser » ; Vous ne vivez pas sur vos acquis, vous avez besoin d’apprendre en permanence et vous pensez qu’un sujet que vous ne connaissez pas est avant tout un sujet que vous ne connaissez pas encore ; Vous êtes bien sûr sympa et vous disposez d’un relationnel de situation. Le conflit et la polémique, très peu pour vous. Vous préférez fédérer, convaincre et rallier les sceptiques à vos idées. Vos petits plus appréciables :     La maîtrise d’un écosystème Cloud (AWS, Azure, GCP, Openstack) ;  La connaissance des outils d’automatisation du provisionning propre aux clouds publics ;    Connaissance des bonnes pratiques Devops d’intégration continue Avoir déjà évolué dans le monde du conseil en ingénierie Big Data ;  Disposer d’une certification éditeur dans le domaine du Big Data (Cloudera, Hortonworks,…).   Pourquoi nous rejoindre ? Pour intégrer une communauté d’experts curieux et passionnés  et évoluer dans un environnement multiculturel, formateur et favorisant la mobilité internationale.Parce que vous êtes #DataGeek, #DigitalAddict, #InnovationLover !A travers une Mission Santé-Handicap dédiée, Keyrus déploie une politique de recrutement et met en place un environnement Handi-accueillants. Tous nos postes sont ouverts aux personnes en situation de handicap. Keyrus a été classé dans le palmarès Le Point « Les entreprises les plus responsables de France 2022 » sur la base d'indicateurs dérivés, entre autres, de rapports sur la RSE.#KeyrusRocks #YouRockKeyrus est une entreprise où il fait bon vivre et travailler !Découvrez : La vie chez Keyrus en 60 sec Keyrus en 3 mots Nos animations pour nos collaborateurs sur Facebook et sur Instagram. Notre vidéo par Welcome To The Jungle   "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Big Data (H/F/NB) - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Keyrus",
        "location": "Levallois-Perret",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Organisation / Management",
            "company_size": "3500",
            "creation_date": "1996",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "370 Millions d'Euros (2023)",
            "proportion_female": "43",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java,",
                "(java,",
                "c++,",
                "c#)",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "mongodb,",
                "cassandra,",
                "hbase,",
                "elasticsearch/solr"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "(azure),…",
                "azure,",
                "gcp,"
            ],
            "DevTools": [
                "digital",
                "artificielledigital",
                "digitalesconseil",
                "légitimité",
                "#digitaladdict,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase,",
                "cassandra,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloud",
                "cloud",
                "cloud",
                "cloudera,",
                "cloud",
                "cloud",
                "clouds",
                "(cloudera,"
            ],
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/keyrus/jobs/tech-lead-big-data-h-f-nb-paris_levallois-perret_KEYRU_lweXKaZ?q=a4acfb2fdef1469051414f8389f464c2&o=25f33217-da38-410a-921a-1011df491a2d",
        "description": "Descriptif du posteQui sommes-nous ? Une success story dans la Data et le Digital !Notre mission ? Des projets à forte valeur ajoutée pour accroître la performance et la compétitivité des entreprises, faciliter et accélérer leur transformation.Notre expertise depuis plus de 20 ans ? Le conseil et l'intégration de solutions innovantes autour de trois domaines :Data IntelligenceBusiness Intelligence, Big Data & Analytics, Intelligence ArtificielleDigital ExperienceConseil, Stratégie & Performance DigitalesConseil en Management & TransformationStratégie & Innovation, Pilotage de la Performance & Accompagnement des ProjetsNous sommes plus de 3200 talents sur plus de 18 pays et 4 continents. Notre ADN ? Innover et entreprendre. Tech Lead Big Data H/FVous êtes (ou avez l’âme d’) un leader ?Vous avez une expérience significative dans la mise en place de plateformes et d’Architectures Big Data ?Ça tombe bien, nous avons justement besoin de votre expérience pour accompagner nos clients dans la mise en place de leurs projets Big Data et Cloud !L’équipeAu sein de l’une de nos Business Unit de Conseil, d’Expertise et de Delivery Data, vous intègrerez une équipe de Data Specialists (Big Data, Data Science, Data Gouvernance, Data Viz…), capables d’accompagner nos clients dans la mise en œuvre d’une stratégie data globale.Intéressé(e) ? Lisez la suite …  Le job :    Expertise technique et animation transversale Mise en œuvre d’architectures Big Data, potentiellement déployées en cloud ; Partenariat avec l’équipe R&D Keyrus et contribution à l’animation technique transversale au travers de réunions régulières ;    Capitalisation des connaissances (production de documents techniques projets et développement des compétences des consultants en charge du déploiement pour les clients (binômage et accompagnement ponctuel) ;    Participation au recrutement de nouveaux talents (validation technique de profils).  Veille et communication  Assurer une veille technologique permanente pour garantir l’actualisation des compétences    Assurer une évangélisation en interne Keyrus sur les thématiques du big data au travers de l’animation de Meetup ou d’afterwork périodiques sur ces thèmes.    Former et accompagner à la montée des compétences des collaborateurs Big Data ;    Assurer le rôle de speaker tant en interne (réunion mensuelle, séminaire/workshop,…) qu’en externe (salon, forum d’écoles, Meetup,…) ;    Représenter Keyrus et son savoir-faire Big Data auprès des écoles/universités majeures du marché Big Data ;    Participation au développement et à l’animation de relations partenaires avec les éditeurs des marchés Big Data et Cloud : Cloudera, Datastax, Amazon (WS), Microsoft (Azure),…   Votre profil : Vous êtes diplômé(e) d’un Bac +5 en informatique (école d'ingénieur ou master – avec idéalement une filière orientée Big Data ou Cloud Computing) avec à minima une 1ère expérience significative dans la mise en oeuvre de technologies Big Data.Compétences requises/attendues :  Maîtrise de l’écosystème Hadoop (HDFS, Pig, Hive, Sqoop,…), Spark, Kafka, ElasticSearch/SolR ;    Maitrise de l’un des langages de programmation suivant : Java, Scala, ou Python (dans un contexte Big Data) ; Maitrise de la programmation orientée objet et d’un langage associé (Java, C++, C#) ;  Connaissance des concepts NoSQL et maîtrise d’au moins une solution parmi celles-ci : HBase, Cassandra, DynamoDB, DocumentDB, Big Table, MongoDB, Redis, Riak … ; Capacité à évoluer dans un environnement anglophone A minima, une connaissance fondamentale des algorithmes de Machine Learning. Qualités requises :    Vous avez conscience que vous serez un des piliers de l’activité et que votre légitimité technique passe notamment par l’émulation et le partage des connaissances au sein de l’équipe ;  Vous avez besoin d’apprendre en permanence ; Vous êtes un(e) véritable « Data Geek », et vous avez un état d’esprit de gagnant Vous avez la capacité à expliquer/vulgariser et vous avez les qualités et compétences pour rassurer et convaincre vos interlocuteurs sur la pertinence de vos préconisations ; Vous avez un état d’esprit de gagnant et vous portiez à l’adolescence un tee-shirt portant l’inscription « The second place is the first looser » ; Vous ne vivez pas sur vos acquis, vous avez besoin d’apprendre en permanence et vous pensez qu’un sujet que vous ne connaissez pas est avant tout un sujet que vous ne connaissez pas encore ; Vous êtes bien sûr sympa et vous disposez d’un relationnel de situation. Le conflit et la polémique, très peu pour vous. Vous préférez fédérer, convaincre et rallier les sceptiques à vos idées. Vos petits plus appréciables :     La maîtrise d’un écosystème Cloud (AWS, Azure, GCP, Openstack) ;  La connaissance des outils d’automatisation du provisionning propre aux clouds publics ;    Connaissance des bonnes pratiques Devops d’intégration continue Avoir déjà évolué dans le monde du conseil en ingénierie Big Data ;  Disposer d’une certification éditeur dans le domaine du Big Data (Cloudera, Hortonworks,…).   Pourquoi nous rejoindre ? Pour intégrer une communauté d’experts curieux et passionnés  et évoluer dans un environnement multiculturel, formateur et favorisant la mobilité internationale.Parce que vous êtes #DataGeek, #DigitalAddict, #InnovationLover !A travers une Mission Santé-Handicap dédiée, Keyrus déploie une politique de recrutement et met en place un environnement Handi-accueillants. Tous nos postes sont ouverts aux personnes en situation de handicap. Keyrus a été classé dans le palmarès Le Point « Les entreprises les plus responsables de France 2022 » sur la base d'indicateurs dérivés, entre autres, de rapports sur la RSE.#KeyrusRocks #YouRockKeyrus est une entreprise où il fait bon vivre et travailler !Découvrez : La vie chez Keyrus en 60 sec Keyrus en 3 mots Nos animations pour nos collaborateurs sur Facebook et sur Instagram. Notre vidéo par Welcome To The Jungle   "
    },
    {
        "source": "welcometothejungle",
        "job_title": "BigData Engineer Cloudera",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "BTI Advisory",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Application mobile, IT / Digital, Transformation",
            "company_size": "36",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "4 millions en 2022",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).vous",
                "bash,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera",
                "cloudera",
                "cloudera"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/bti-advisory/jobs/bigdata-engineer-cloudera-h-f_paris?q=a4acfb2fdef1469051414f8389f464c2&o=bf69bb32-d8ff-487c-99ef-a2c44b19b95c",
        "description": "Descriptif du posteBigData Engineer Cloudera H/F/XContexte :BTI-Advisory est un cabinet de conseil en IT fondé en 2016, 100% indépendant, qui a pour vocation de co-construire avec des entreprises leurs transformations digitales afin de mettre en lumière et d’optimiser leurs potentiels tout en ayant un impact sociétal positif et durable.Pour apporter des réponses durables et adaptées aux besoins particuliers de nos clients, nous avons développé une offre de services augmentée qui s’articule de la manière suivante :Notre expertise métier permettant d’accompagner nos clients de la construction de la vision numérique à l’implémentation de celle-ci.Des centres d’excellences qui portent nos convictions et réunissent des expertises de haut niveau pour assister nos clients à adresser des problématiques technologiques et métiers.Et enfin une offre de services augmentée avec notre écosystème de partenaires ciblés.Ce poste est fait pour vous si :Vous êtes diplômé(e) d’une école d’ingénieur ou d’une formation universitaire reconnue en informatique ou un domaine connexe.Vous disposez d’au moins 5 ans d’expérience avérée dans les infrastructures Big Data, avec une expertise spécifique sur Cloudera Data Platform, notamment Hadoop Cloudera HDFS.Vous maîtrisez des technologies clés telles que Hadoop, Spark, Kafka, ainsi que des langages de script (ksh, bash, python).Vous avez une expérience solide en gestion de projet Agile, avec une capacité à endosser les rôles de Product Owner et de Scrum Master.Vous êtes compétent(e) en gestion de la sécurité des données et en cyber-sécurité, avec une expérience dans la mise en œuvre de solutions de sécurité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "BigData Engineer Cloudera",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "BTI Advisory",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Application mobile, IT / Digital, Transformation",
            "company_size": "36",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "4 millions en 2022",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).vous",
                "bash,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera",
                "cloudera",
                "cloudera"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/bti-advisory/jobs/bigdata-engineer-cloudera-h-f_paris?q=a4acfb2fdef1469051414f8389f464c2&o=bf69bb32-d8ff-487c-99ef-a2c44b19b95c",
        "description": "Descriptif du posteBigData Engineer Cloudera H/F/XContexte :BTI-Advisory est un cabinet de conseil en IT fondé en 2016, 100% indépendant, qui a pour vocation de co-construire avec des entreprises leurs transformations digitales afin de mettre en lumière et d’optimiser leurs potentiels tout en ayant un impact sociétal positif et durable.Pour apporter des réponses durables et adaptées aux besoins particuliers de nos clients, nous avons développé une offre de services augmentée qui s’articule de la manière suivante :Notre expertise métier permettant d’accompagner nos clients de la construction de la vision numérique à l’implémentation de celle-ci.Des centres d’excellences qui portent nos convictions et réunissent des expertises de haut niveau pour assister nos clients à adresser des problématiques technologiques et métiers.Et enfin une offre de services augmentée avec notre écosystème de partenaires ciblés.Ce poste est fait pour vous si :Vous êtes diplômé(e) d’une école d’ingénieur ou d’une formation universitaire reconnue en informatique ou un domaine connexe.Vous disposez d’au moins 5 ans d’expérience avérée dans les infrastructures Big Data, avec une expertise spécifique sur Cloudera Data Platform, notamment Hadoop Cloudera HDFS.Vous maîtrisez des technologies clés telles que Hadoop, Spark, Kafka, ainsi que des langages de script (ksh, bash, python).Vous avez une expérience solide en gestion de projet Agile, avec une capacité à endosser les rôles de Product Owner et de Scrum Master.Vous êtes compétent(e) en gestion de la sécurité des données et en cyber-sécurité, avec une expérience dans la mise en œuvre de solutions de sécurité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data H/F",
        "contract_type": "CDI",
        "salary": "35K à 45K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "java."
            ],
            "DataBase": [
                "sql",
                "sql,",
                "hbase,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "hadoop",
                "spark,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera,",
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/developpeur-big-data-h-f_le-mans?q=a4acfb2fdef1469051414f8389f464c2&o=01f172a9-2687-417a-a7bd-83e5f84503a6",
        "description": "Descriptif du posteDans le cadre de notre principal projet Big Data, nous recherchons un Développeur Big Data pour rejoindre notre équipe de 15 consultants travaillant au sein de l’écosystème Hadoop, spark, cloudera, hive, les missions principales consisteront à : Analyser des spécifications fonctionnelles et rédiger des spécifications techniques    Implémenter des nouvelles fonctionnalités  Développer les flux Talend Concevoir et optimiser des requêtes SQL    Participer à la recette technique et fonctionnelle Assurer une maintenance et un support des solutions mises en œuvre Participer à la rédaction des documentations techniques    Vous pourrez être amené à prendre en charge une activité de RUN autour de SQL, Spark, Hive, Cloudera, Java, Hbase, Talend.Profil :De formation supérieure, vous justifiez d'une expérience significative de 3 ans minimum en développement Big Data ou en développement Java. Vous avez idéalement abordé l'environnement Hadoop et Talend. Rigoureux(se), autonome et doté(e) d'un bon relationnel, vous êtes attaché(e) à la satisfaction du client et vos qualités humaines feront la différence.Chez SII Ouest, nous souhaitons un process de recrutement simple et clair :· Un premier échange téléphonique avec un(e) RH· Un entretien avec un(e) RH + un(e) Business Manager· Un échange technique avec un Expert TechniqueL’implantation SII Le Mans, c’est 105 consultants qui interviennent en ingénierie de développement logiciel, infrastructure réseaux et sécurité. Axé sur la proximité collaborateurs et clients, chez SII Le Mans nous cherchons perpétuellement à développer notre expertise et savoir-faire au service de nos clients locaux. Dans le cadre agréable du quartier de la gare du Mans, venez participer à l’ambiance conviviale et stimulante de notre implantation (parrainage, petit déjeuner d’équipe, soirées jeux, afterwork …).Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays. En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data H/F",
        "contract_type": "CDI",
        "salary": "35K à 45K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "java."
            ],
            "DataBase": [
                "sql",
                "sql,",
                "hbase,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "hadoop",
                "spark,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera,",
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/developpeur-big-data-h-f_le-mans?q=a4acfb2fdef1469051414f8389f464c2&o=01f172a9-2687-417a-a7bd-83e5f84503a6",
        "description": "Descriptif du posteDans le cadre de notre principal projet Big Data, nous recherchons un Développeur Big Data pour rejoindre notre équipe de 15 consultants travaillant au sein de l’écosystème Hadoop, spark, cloudera, hive, les missions principales consisteront à : Analyser des spécifications fonctionnelles et rédiger des spécifications techniques    Implémenter des nouvelles fonctionnalités  Développer les flux Talend Concevoir et optimiser des requêtes SQL    Participer à la recette technique et fonctionnelle Assurer une maintenance et un support des solutions mises en œuvre Participer à la rédaction des documentations techniques    Vous pourrez être amené à prendre en charge une activité de RUN autour de SQL, Spark, Hive, Cloudera, Java, Hbase, Talend.Profil :De formation supérieure, vous justifiez d'une expérience significative de 3 ans minimum en développement Big Data ou en développement Java. Vous avez idéalement abordé l'environnement Hadoop et Talend. Rigoureux(se), autonome et doté(e) d'un bon relationnel, vous êtes attaché(e) à la satisfaction du client et vos qualités humaines feront la différence.Chez SII Ouest, nous souhaitons un process de recrutement simple et clair :· Un premier échange téléphonique avec un(e) RH· Un entretien avec un(e) RH + un(e) Business Manager· Un échange technique avec un Expert TechniqueL’implantation SII Le Mans, c’est 105 consultants qui interviennent en ingénierie de développement logiciel, infrastructure réseaux et sécurité. Axé sur la proximité collaborateurs et clients, chez SII Le Mans nous cherchons perpétuellement à développer notre expertise et savoir-faire au service de nos clients locaux. Dans le cadre agréable du quartier de la gare du Mans, venez participer à l’ambiance conviviale et stimulante de notre implantation (parrainage, petit déjeuner d’équipe, soirées jeux, afterwork …).Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays. En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Big Data H/F",
        "contract_type": "CDI",
        "salary": "40K à 50K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/architecte-big-data-h-f_le-mans?q=a4acfb2fdef1469051414f8389f464c2&o=6db465bc-54b2-4ff1-a628-842fdb7700dd",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et les activités du groupe, nous recherchons un Architecte Big Data H/FEn tant qu’interlocuteur privilégié sur la région du Mans, vous aurez en charge le développement de notre offre technique Big Data et la promotion de notre Delivry Center. Il s'agira aussi d'assurer le suivi technique, la mise en place d'architectures innovantes de nos projets ainsi que le suivi opérationnel des consultants en tant que référent (équipe d'une quinzaine collaborateurs).Vous interviendrez dans le cadre des activités suivantes : Délivrer des missions d’expertise et de conseil auprès de nos clients  Assurer et suivre le déploiement d'offres techniques pour nos projets  Capitalisation des savoirs faire et références du Groupe SII   Dans une dimension transverse, contribuer à la définition et à la construction marketing de nos offres Data auprès de nos clients  Choix stratégiques et mise en œuvre des partenariats pour le renforcement de cette offre   Accompagnement dans la commercialisation de cette offre (formation et coaching des équipes commerciales)   Communication (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …)   Veille technologique (Participation aux évènements du domaine Big Data)    Animation de la communauté Big Data transverse SII Contribution à la gouvernance techno de SII OUEST et largement au plan national    Gestion des offres et des compétences internesProfilDe formation supérieure (Bac +4/5) en informatique, vous avez une expérience technique confirmée (minimum 3 ans) en contexte projets Big Data, idéalement dans une entreprise de service numérique (ESN) ou en ETI. Vous connaissez précisément l’écosystème existant (opensource/buy), vous avez des compétences solides dans la construction/conception et mise en place d’architecture technique BigData.Déterminé, à l'écoute et autonome, devenez un expert reconnu sur votre territoire et pour le Groupe !Rejoindre SII Ouest, c’est aussi :   Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …)   Une ambiance conviviale (Petit déjeuner à l’agence, Afterworks, Soirées d’Agence, …)   Jusqu’à 50% de télétravail (on privilégie l’équilibre vie pro/vie perso tout en gardant le lien avec nos collaborateurs !) Une QVT reconnue (pour la 7ème année consécutive, nous sommes certifiés Great Place to Work)Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !#LI-CM8"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Big Data H/F",
        "contract_type": "CDI",
        "salary": "40K à 50K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/architecte-big-data-h-f_le-mans?q=a4acfb2fdef1469051414f8389f464c2&o=6db465bc-54b2-4ff1-a628-842fdb7700dd",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et les activités du groupe, nous recherchons un Architecte Big Data H/FEn tant qu’interlocuteur privilégié sur la région du Mans, vous aurez en charge le développement de notre offre technique Big Data et la promotion de notre Delivry Center. Il s'agira aussi d'assurer le suivi technique, la mise en place d'architectures innovantes de nos projets ainsi que le suivi opérationnel des consultants en tant que référent (équipe d'une quinzaine collaborateurs).Vous interviendrez dans le cadre des activités suivantes : Délivrer des missions d’expertise et de conseil auprès de nos clients  Assurer et suivre le déploiement d'offres techniques pour nos projets  Capitalisation des savoirs faire et références du Groupe SII   Dans une dimension transverse, contribuer à la définition et à la construction marketing de nos offres Data auprès de nos clients  Choix stratégiques et mise en œuvre des partenariats pour le renforcement de cette offre   Accompagnement dans la commercialisation de cette offre (formation et coaching des équipes commerciales)   Communication (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …)   Veille technologique (Participation aux évènements du domaine Big Data)    Animation de la communauté Big Data transverse SII Contribution à la gouvernance techno de SII OUEST et largement au plan national    Gestion des offres et des compétences internesProfilDe formation supérieure (Bac +4/5) en informatique, vous avez une expérience technique confirmée (minimum 3 ans) en contexte projets Big Data, idéalement dans une entreprise de service numérique (ESN) ou en ETI. Vous connaissez précisément l’écosystème existant (opensource/buy), vous avez des compétences solides dans la construction/conception et mise en place d’architecture technique BigData.Déterminé, à l'écoute et autonome, devenez un expert reconnu sur votre territoire et pour le Groupe !Rejoindre SII Ouest, c’est aussi :   Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …)   Une ambiance conviviale (Petit déjeuner à l’agence, Afterworks, Soirées d’Agence, …)   Jusqu’à 50% de télétravail (on privilégie l’équilibre vie pro/vie perso tout en gardant le lien avec nos collaborateurs !) Une QVT reconnue (pour la 7ème année consécutive, nous sommes certifiés Great Place to Work)Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !#LI-CM8"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Big Data F/H",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Groupe SII",
        "location": "Rennes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/architecte-big-data-f-h_rennes?q=a4acfb2fdef1469051414f8389f464c2&o=b1e2b55d-80a8-427d-95f4-5beb9e2014d3",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et soutenir les activités du Groupe, nous recherchons un Architecte Big Data à Rennes.En tant qu’interlocuteur privilégié sur notre agence rennaise, vous aurez en charge le développement de notre offre technique Big Data, le suivi technique des projets et l'accompagnent de certains de nos clients dans la réussite de leurs projets les plus ambitieux.Vos missions d'expert en quelques lignes•    Conseiller nos clients sur des interventions ponctuelles : auditer les processus et fournir des préconisations en termes de méthodes et d’outils, participer au processus d’amélioration continue chez nos clients…•    Accompagner les équipes au sein de nos projets.•    Réaliser de la formation : de leur création à la dispense (interne et externe), en passant par le mentoring des futurs formateurs.•    Réaliser de la veille, du prototypage, de l'innovation... (Avec suffisamment de temps pour être aboutis !)•    Participer à des réponses à appel d’offre de la qualification du besoin à la soutenance de la solution sur des dossiers où la dimension technique est importante.Au-delà de ces missions au quotidien, il s’agira avant tout de développer notre offre technique Big Data:•    Capitalisation des savoirs faires et références du Groupe•    En liaison avec l’équipe commerciale et la Direction du Développement du Groupe, contribution à la définition et marketing de cette offre portée auprès de nos clients•    Choix stratégiques et mise en œuvre des partenariats pour le renforcement de cette offre•    Communication (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …)Profil :De formation supérieure (Bac +4/5) en informatique (une spécialisation Big Data serait un plus), vous avez une expérience technique confirmée (minimum 5 ans) en contexte projets Big Data, idéalement dans une entreprise de service numérique (ESN) ou en ETI. Vous connaissez précisément l’écosystème existant (opensource/buy), vous avez des compétences solides dans la construction/conception et mise en place d’architecture technique BigData.Déterminé, à l'écoute et autonome, devenez un expert reconnu au sein de l’agence et pour le Groupe!Rejoindre SII Ouest, c’est aussi : Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour, JFTL ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …) Une ambiance conviviale (Petit déjeuner à l’agence tous les vendredi matins, Afterworks, Soirées d’Agence, …)Chez SII Ouest, nous souhaitons un process de recrutement simple et clair :    Un premier échange téléphonique avec un(e) RH  Un entretien avec un(e) RH + un(e) Business Manager    Un échange technique avec un Expert TechniqueQui sommes-nous ?Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés.Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières.En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante.Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Big Data F/H",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Groupe SII",
        "location": "Rennes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/architecte-big-data-f-h_rennes?q=a4acfb2fdef1469051414f8389f464c2&o=b1e2b55d-80a8-427d-95f4-5beb9e2014d3",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et soutenir les activités du Groupe, nous recherchons un Architecte Big Data à Rennes.En tant qu’interlocuteur privilégié sur notre agence rennaise, vous aurez en charge le développement de notre offre technique Big Data, le suivi technique des projets et l'accompagnent de certains de nos clients dans la réussite de leurs projets les plus ambitieux.Vos missions d'expert en quelques lignes•    Conseiller nos clients sur des interventions ponctuelles : auditer les processus et fournir des préconisations en termes de méthodes et d’outils, participer au processus d’amélioration continue chez nos clients…•    Accompagner les équipes au sein de nos projets.•    Réaliser de la formation : de leur création à la dispense (interne et externe), en passant par le mentoring des futurs formateurs.•    Réaliser de la veille, du prototypage, de l'innovation... (Avec suffisamment de temps pour être aboutis !)•    Participer à des réponses à appel d’offre de la qualification du besoin à la soutenance de la solution sur des dossiers où la dimension technique est importante.Au-delà de ces missions au quotidien, il s’agira avant tout de développer notre offre technique Big Data:•    Capitalisation des savoirs faires et références du Groupe•    En liaison avec l’équipe commerciale et la Direction du Développement du Groupe, contribution à la définition et marketing de cette offre portée auprès de nos clients•    Choix stratégiques et mise en œuvre des partenariats pour le renforcement de cette offre•    Communication (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …)Profil :De formation supérieure (Bac +4/5) en informatique (une spécialisation Big Data serait un plus), vous avez une expérience technique confirmée (minimum 5 ans) en contexte projets Big Data, idéalement dans une entreprise de service numérique (ESN) ou en ETI. Vous connaissez précisément l’écosystème existant (opensource/buy), vous avez des compétences solides dans la construction/conception et mise en place d’architecture technique BigData.Déterminé, à l'écoute et autonome, devenez un expert reconnu au sein de l’agence et pour le Groupe!Rejoindre SII Ouest, c’est aussi : Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour, JFTL ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …) Une ambiance conviviale (Petit déjeuner à l’agence tous les vendredi matins, Afterworks, Soirées d’Agence, …)Chez SII Ouest, nous souhaitons un process de recrutement simple et clair :    Un premier échange téléphonique avec un(e) RH  Un entretien avec un(e) RH + un(e) Business Manager    Un échange technique avec un Expert TechniqueQui sommes-nous ?Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés.Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés !Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières.En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante.Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Tours",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_tours_CGI_VG7dMjQ?q=a4acfb2fdef1469051414f8389f464c2&o=e55a1117-9067-4282-8827-bd835ee28920",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Tours",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_tours_CGI_VG7dMjQ?q=a4acfb2fdef1469051414f8389f464c2&o=e55a1117-9067-4282-8827-bd835ee28920",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Montpellier",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_montpellier_CGI_NoLaNaP?q=a4acfb2fdef1469051414f8389f464c2&o=a61a27f7-b01b-44ea-baaa-02585e052d73",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Montpellier",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_montpellier_CGI_NoLaNaP?q=a4acfb2fdef1469051414f8389f464c2&o=a61a27f7-b01b-44ea-baaa-02585e052d73",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Toulouse",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_toulouse_CGI_dAk6RAk?q=a4acfb2fdef1469051414f8389f464c2&o=262ada03-6fb5-4083-a660-36be0d3b72af",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Expert(e) Big Data F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Toulouse",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.vous",
                "java,",
                "scala,"
            ],
            "DataBase": [
                "nosql",
                "nosql",
                "(mongodb,",
                "cassandra…)",
                "neo4j,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra…)"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(devops,",
                "ci/cd…)-"
            ],
            "EnSoftSkils": [
                "communications",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/expert-big-data-f-h_toulouse_CGI_dAk6RAk?q=a4acfb2fdef1469051414f8389f464c2&o=262ada03-6fb5-4083-a660-36be0d3b72af",
        "description": "Descriptif du poste Vous êtes passionné par le domaine de la Data et avez déjà une expérience significative sur des problématiques de data engineering : construction de pipelines de données (batch/streaming), industrialisation d’applications data science, modélisation de base de données, …Vous disposez de connaissances sur un ou plusieurs outils Big Data (Hadoop, Spark, Hive, Kafka, nifi…) et/ou NoSQL (MongoDB, Neo4j, Cassandra…) et vous maitrisez un des trois langages suivants : Java, Scala, Python.Vous souhaitez diversifier vos compétences Big Data pour être toujours à la pointe des nouvelles technologies et souhaitez rejoindre une entité spécialisée dans la data et l’innovation ? Vous évoluerez sur des projets d'envergure nationaux et internationaux, dans des environnements métiers variés avec un niveau de responsabilité élevé. Vous aurez également la possibilité de monter en compétences sur d’autres outils Big Data que ceux de votre domaine de compétences initial.En tant que Data Engineer, vous serez intégré.e à un pôle de consultants.es spécialistes du Big Data intervenants sur des projets stimulants.Vos missions seront :- Analyser, conseiller, et faire des recommandations de façon à améliorer l'efficience et l'efficacité des solutions mises en place- Travailler en collaboration avec les ingénieurs techniques et autres experts.es afin de rechercher et fournir des réponses aux problématiques techniques- Réaliser les travaux d’implémentation des solutions (préparation des données, industrialisation des modèles, communications entre les différentes technologies,…)- Produire les projets en mode agile avec des processus et outils de développement de dernière génération (DevOps, Git, CI/CD…)- Participer à l'élaboration et la révision de normes / documentation technique- Animer des formations internes. Accompagner la montée en compétences des équipes- Assurer un support technique Big Data aux équipes et aux clients au quotidienFort d’une intégration réussie, de nombreuses possibilités d’évolutions de carrière s’offriront rapidement à vous, dans l’animation de la filière technique ou dans le consulting de solutions Data.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead Data Engineer  - H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Free",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": "Sans diplôme",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Electronique / Télécommunications",
            "company_size": "189",
            "creation_date": "1999",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "3 266 498 000 €",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python,",
                "java,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "bigquery,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/free/jobs/lead-data-engineer-h-f_paris_FREE_DZyGOMo?q=a4acfb2fdef1469051414f8389f464c2&o=d1935615-ecde-4736-8d15-b723046d6377",
        "description": "Descriptif du posteSituée dans le 8e arrondissement de Paris, Freebox est la filiale R&D d’Iliad qui développe et industrialise les boxs Free, ainsi que les Applications Mobiles associées. Dans le cadre du développement et de la structuration de l’activité Data au sein du groupe ILIAD, nous recherchons un(e) Lead Data Engineer pour rejoindre et manager une équipe Data au sein de la filiale FREEBOX.Tes missions :Développer et maintenir l’infrastructure de la plateforme Data en collaboration avec le Data Engineer de l’équipePrendre connaissance de l’architecture de collecte de donnés actuellement en productionElaborer, participer et encadrer la migration de notre infrastructure cloud et de la stack actuelle vers une infra et stack uniformisées à l’échelle du groupe ILIAD Automatiser en production le déploiement et l’exécution de la plateforme DataRépondre aux contraintes de volumétrie, de criticité, de haute disponibilité et de temps réel propres aux données FreeboxMettre en place des solutions de monitoring de la plateforme et assurer la qualité des donnéesConcevoir, développer, mettre en production et gérer les pipelines d’ETLAnalyser et valoriser la data produite par Freebox et mettre à disposition la donnée pertinente pour l’analyse croisée au niveau groupeDévelopper et maintenir des produits de machine learning et d’intelligence artificielle pertinents pour l’activité de Freebox (maintenance prédictive, détection d’anomalies, etc.)Élaborer, conjointement avec les équipes groupe, la roadmap de votre équipe afin de répondre aux besoins data de la filiale et du groupeManager et développer l’équipe data Freebox au sein de la fonction data groupeStack Freebox : Python, Flask, Java, Apache Beam, … Infra Freebox : GCP (IAM, Load balancing, BigQuery, DataFlow, Cloud Run, Pub/Sub …)Stack groupe : Python, SQL, ClickhouseInfra groupe : cloud privé / on premiseQui sommes-nous ? Depuis 20 ans, nous avons gardé un fort esprit entrepreneurial. Nos 60 collaborateurs conçoivent, développent et industrialisent les produits utilisés par nos 7 millions de foyers d’abonnés.Seul opérateur à internaliser sa R&D en France, Freebox développe de A à Z ses produits afin de contrôler leur fonctionnement et leur qualité. En favorisant de petites équipes et une organisation horizontale, nous t’offrons la possibilité d’avoir un impact considérable sur le ou les produits de ton périmètre.Ce que nous te proposons : Un environnement avec une forte culture tech et des projets à la hauteur de tes ambitionsL’utilisation et la contribution à de nombreux projets open source De rejoindre une entreprise et une équipe à taille humaineUn environnement de travail unique au coeur de ParisUn cadre social agréable et adapté (télétravail partiel, RTT, prise en charge des repas, etc.)Notre équipe Data : Une Data/Business Analyst Un Data Engineer (recrutement en cours)Un Lead Data Engineer (recrutement en cours)"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead Data Engineer  - H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Free",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": "Sans diplôme",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Electronique / Télécommunications",
            "company_size": "189",
            "creation_date": "1999",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "3 266 498 000 €",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python,",
                "java,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "bigquery,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/free/jobs/lead-data-engineer-h-f_paris_FREE_DZyGOMo?q=a4acfb2fdef1469051414f8389f464c2&o=d1935615-ecde-4736-8d15-b723046d6377",
        "description": "Descriptif du posteSituée dans le 8e arrondissement de Paris, Freebox est la filiale R&D d’Iliad qui développe et industrialise les boxs Free, ainsi que les Applications Mobiles associées. Dans le cadre du développement et de la structuration de l’activité Data au sein du groupe ILIAD, nous recherchons un(e) Lead Data Engineer pour rejoindre et manager une équipe Data au sein de la filiale FREEBOX.Tes missions :Développer et maintenir l’infrastructure de la plateforme Data en collaboration avec le Data Engineer de l’équipePrendre connaissance de l’architecture de collecte de donnés actuellement en productionElaborer, participer et encadrer la migration de notre infrastructure cloud et de la stack actuelle vers une infra et stack uniformisées à l’échelle du groupe ILIAD Automatiser en production le déploiement et l’exécution de la plateforme DataRépondre aux contraintes de volumétrie, de criticité, de haute disponibilité et de temps réel propres aux données FreeboxMettre en place des solutions de monitoring de la plateforme et assurer la qualité des donnéesConcevoir, développer, mettre en production et gérer les pipelines d’ETLAnalyser et valoriser la data produite par Freebox et mettre à disposition la donnée pertinente pour l’analyse croisée au niveau groupeDévelopper et maintenir des produits de machine learning et d’intelligence artificielle pertinents pour l’activité de Freebox (maintenance prédictive, détection d’anomalies, etc.)Élaborer, conjointement avec les équipes groupe, la roadmap de votre équipe afin de répondre aux besoins data de la filiale et du groupeManager et développer l’équipe data Freebox au sein de la fonction data groupeStack Freebox : Python, Flask, Java, Apache Beam, … Infra Freebox : GCP (IAM, Load balancing, BigQuery, DataFlow, Cloud Run, Pub/Sub …)Stack groupe : Python, SQL, ClickhouseInfra groupe : cloud privé / on premiseQui sommes-nous ? Depuis 20 ans, nous avons gardé un fort esprit entrepreneurial. Nos 60 collaborateurs conçoivent, développent et industrialisent les produits utilisés par nos 7 millions de foyers d’abonnés.Seul opérateur à internaliser sa R&D en France, Freebox développe de A à Z ses produits afin de contrôler leur fonctionnement et leur qualité. En favorisant de petites équipes et une organisation horizontale, nous t’offrons la possibilité d’avoir un impact considérable sur le ou les produits de ton périmètre.Ce que nous te proposons : Un environnement avec une forte culture tech et des projets à la hauteur de tes ambitionsL’utilisation et la contribution à de nombreux projets open source De rejoindre une entreprise et une équipe à taille humaineUn environnement de travail unique au coeur de ParisUn cadre social agréable et adapté (télétravail partiel, RTT, prise en charge des repas, etc.)Notre équipe Data : Une Data/Business Analyst Un Data Engineer (recrutement en cours)Un Lead Data Engineer (recrutement en cours)"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Big Data - Services Financiers - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-27",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "ooziescala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "shellgitlab,",
                "jenkins,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-services-financiers-bordeaux_merignac_SS_VXkdPK9?q=a4acfb2fdef1469051414f8389f464c2&o=26c9bbdd-8c18-4e7a-b6b4-08aeb609c30e",
        "description": "Descriptif du posteVotre futur environnement de travailIntégré(e) au sein d’une équipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participerez à un projet Big Data, en mode Agile, et interviendrez en tant que référent technique au sein de votre équipe.Votre rôle et missions :A cette occasion vous serez amené à :Apporter votre expertise et votre expérience à vos collègues lors des phases de conception et développement ;Accompagner vos collègues dans leur montée en compétence technique au sein du projet ;Définir et implémenter des solutions au sein d’un périmètre applicatif existant ;Proposer des idées d’amélioration continue à votre client et à votre équipe (revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie) ;Concevoir et développer des sujets complexes.Environnement du projet : Méthodologie projet : Mode Agile (Framework Scrum).Environnement technique :Hdfs, hive, spark, oozieScala, HQL, ShellGitLab, Nexus, Maven, Jenkins, SonarEnvironnement fonctionnel :Alimentation d’un DataLake jusqu‘au build d’un moteur de calculIntervention sur la mise en place de règles relatives aux normes BâloisesInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Big Data - Services Financiers - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-27",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "ooziescala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "shellgitlab,",
                "jenkins,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-services-financiers-bordeaux_merignac_SS_VXkdPK9?q=a4acfb2fdef1469051414f8389f464c2&o=26c9bbdd-8c18-4e7a-b6b4-08aeb609c30e",
        "description": "Descriptif du posteVotre futur environnement de travailIntégré(e) au sein d’une équipe Sopra Steria, pour un de nos Grands Comptes Bancaires, vous participerez à un projet Big Data, en mode Agile, et interviendrez en tant que référent technique au sein de votre équipe.Votre rôle et missions :A cette occasion vous serez amené à :Apporter votre expertise et votre expérience à vos collègues lors des phases de conception et développement ;Accompagner vos collègues dans leur montée en compétence technique au sein du projet ;Définir et implémenter des solutions au sein d’un périmètre applicatif existant ;Proposer des idées d’amélioration continue à votre client et à votre équipe (revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie) ;Concevoir et développer des sujets complexes.Environnement du projet : Méthodologie projet : Mode Agile (Framework Scrum).Environnement technique :Hdfs, hive, spark, oozieScala, HQL, ShellGitLab, Nexus, Maven, Jenkins, SonarEnvironnement fonctionnel :Alimentation d’un DataLake jusqu‘au build d’un moteur de calculIntervention sur la mise en place de règles relatives aux normes BâloisesInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Administrateur plateforme BigData H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Thales",
        "location": "Toulouse",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "Logiciels, Cybersécurité, Aéronautique / Spatiale",
            "company_size": "80000",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "19Mds€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "bash"
            ],
            "DataBase": [
                "cassandra,",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "hadoop",
                "hadoop",
                "(hadoop,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": [
                "linux.vous"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "radiocommunications,",
                "initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/thales/jobs/administrateur-plateforme-bigdata-h-f_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=b0af4066-7abe-49b2-9ab3-eef022fdcf33",
        "description": "Descriptif du posteQUI SOMMES-NOUS ?Construisons ensemble un avenir de confianceThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d’activité : Défense & Sécurité, Aéronautique & Spatial, et Cybersécurité & Identité numérique. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l’environnement et plus inclusif. Le Groupe investit près de 4 milliards d’euros par an en Recherche & Développement, notamment dans des domaines clés de l’innovation tels que l’IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.Nos engagements, vos avantagesUne réussite commune portée par notre culture et excellence technologique, votre expérience et notre ambition partagéeUn package de rémunération attractif (épargne salariale, variable ou 13ième mois selon les postes, restaurant d’entreprise,…)La possibilité de développer vos compétences en continu grâce à nos parcours de formation et nos académies internes #ENTREPRISEAPPRENANTENotre attention portée à votre équilibre personnel et professionnel (Accord télétravail, RTT, congés d’ancienneté, jours enfants malades, guide parentalité, crèches, CSE / ASC,… )Des communautés internes permettant de vous engager sur les sujets qui vous tiennent à cœur : innovation, diversité, environnementUn environnement inclusif et bienveillant où vous êtes accueilli et valorisé avec notre politique handi-accueillante, notre charte LGBT+, notre initiative #StOpe pour lutter contre le sexisme.Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ? De formation universitaire ou ingénieur, vous justifiez d’une première expérience d’administration système ou de développement et conception de logiciels utilisant des technologies permettant le traitement massif de données.Vous avez des compétences sur les outils et langages tels que Java, Bash et une bonne connaissance des systèmes Linux.Vous avez une expérience sur les technologies BigData (Hadoop, MapReduce, Yarn), des connaissances sur les bases de données et systèmes de fichiers distribués (HDFS, Elasticsearch, Cassandra, MooseFS …). Vous êtes reconnu pour êtes attentifs aux enjeux de vos clients et projets ?Vous être proactif et force de proposition ?Votre esprit scientifique vous pousse chaque jour à apprendre de nouvelles choses et affronter de nouveaux défis ?Vous êtes donc prêt à rejoindre nos équipes et le poste d’administrateur plateforme Big Data est fait pour vous !CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE ? Au sein d’une équipe, vous serez en interaction avec nos clients pour comprendre et répondre à leurs besoins liés à leurs missions scientifiques opérationnelles.Vous serez chargé de l’administration, du maintien en conditions opérationnelles et de l’évolution de 5 plateformes de traitement BigData avec pour principaux composants :Les OS basés sur RedHat ;Le framework bigdata Hadoop et son API Mapreduce ;Le système de fichier distribué MooseFS.En nous rejoignant, vous vous verrez confier les missions suivantes :Le suivi des traitements Hadoop et l’optimisation de la configuration en vue d’atteindre les objectifs de performances ;L'analyse des problèmes et le suivi d’investigation sur constat d’anomalie en lien avec les différents intervenants du projet ;Le support aux utilisateurs et l’expertise sur toutes les couches logicielles ;L'administration de l’ensemble des services déployés sur les plateformes (Hadoop, ELK, produits internes …) incluant la configuration et la gestion des ressources ;La maintenance et le support des outils de supervision : Zabbix, ELK, Nagios ;Le suivi du déploiement de nouveau matériel ;Agir en tant qu'interface avec le client et les autres contributeurs du projet.Thales reconnait tous les talents, la diversité est notre meilleur atout. Postulez et rejoignez nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Administrateur plateforme BigData H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Thales",
        "location": "Toulouse",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "Logiciels, Cybersécurité, Aéronautique / Spatiale",
            "company_size": "80000",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "19Mds€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "bash"
            ],
            "DataBase": [
                "cassandra,",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(hadoop,",
                "hadoop",
                "hadoop",
                "(hadoop,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": [
                "linux.vous"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": [
                "cassandra,"
            ],
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "radiocommunications,",
                "initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/thales/jobs/administrateur-plateforme-bigdata-h-f_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=b0af4066-7abe-49b2-9ab3-eef022fdcf33",
        "description": "Descriptif du posteQUI SOMMES-NOUS ?Construisons ensemble un avenir de confianceThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d’activité : Défense & Sécurité, Aéronautique & Spatial, et Cybersécurité & Identité numérique. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l’environnement et plus inclusif. Le Groupe investit près de 4 milliards d’euros par an en Recherche & Développement, notamment dans des domaines clés de l’innovation tels que l’IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.Nos engagements, vos avantagesUne réussite commune portée par notre culture et excellence technologique, votre expérience et notre ambition partagéeUn package de rémunération attractif (épargne salariale, variable ou 13ième mois selon les postes, restaurant d’entreprise,…)La possibilité de développer vos compétences en continu grâce à nos parcours de formation et nos académies internes #ENTREPRISEAPPRENANTENotre attention portée à votre équilibre personnel et professionnel (Accord télétravail, RTT, congés d’ancienneté, jours enfants malades, guide parentalité, crèches, CSE / ASC,… )Des communautés internes permettant de vous engager sur les sujets qui vous tiennent à cœur : innovation, diversité, environnementUn environnement inclusif et bienveillant où vous êtes accueilli et valorisé avec notre politique handi-accueillante, notre charte LGBT+, notre initiative #StOpe pour lutter contre le sexisme.Thales propose des systèmes d’information et de communication sécurisés et interopérables pour les forces armées, les forces de sécurité et les opérateurs d’importance vitale. Ces activités, qui regroupent radiocommunications, réseaux, systèmes de protection, systèmes d’information critiques et cybersécurité, répondent aux besoins de marchés où l’utilisation des nouvelles technologies numériques est déterminante. Thales intervient tout au long de la chaîne de valeur, des équipements aux systèmes en passant par le soutien logistique et les services associés.Nos équipes de l’activité Systèmes d’information critiques et cybersécurité fournissent des services et des solutions globales optimisant la performance, la résilience et la sécurité des systèmes d’information afin de faire face aux ruptures technologiques et aux cybermenaces.QUI ETES-VOUS ? De formation universitaire ou ingénieur, vous justifiez d’une première expérience d’administration système ou de développement et conception de logiciels utilisant des technologies permettant le traitement massif de données.Vous avez des compétences sur les outils et langages tels que Java, Bash et une bonne connaissance des systèmes Linux.Vous avez une expérience sur les technologies BigData (Hadoop, MapReduce, Yarn), des connaissances sur les bases de données et systèmes de fichiers distribués (HDFS, Elasticsearch, Cassandra, MooseFS …). Vous êtes reconnu pour êtes attentifs aux enjeux de vos clients et projets ?Vous être proactif et force de proposition ?Votre esprit scientifique vous pousse chaque jour à apprendre de nouvelles choses et affronter de nouveaux défis ?Vous êtes donc prêt à rejoindre nos équipes et le poste d’administrateur plateforme Big Data est fait pour vous !CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE ? Au sein d’une équipe, vous serez en interaction avec nos clients pour comprendre et répondre à leurs besoins liés à leurs missions scientifiques opérationnelles.Vous serez chargé de l’administration, du maintien en conditions opérationnelles et de l’évolution de 5 plateformes de traitement BigData avec pour principaux composants :Les OS basés sur RedHat ;Le framework bigdata Hadoop et son API Mapreduce ;Le système de fichier distribué MooseFS.En nous rejoignant, vous vous verrez confier les missions suivantes :Le suivi des traitements Hadoop et l’optimisation de la configuration en vue d’atteindre les objectifs de performances ;L'analyse des problèmes et le suivi d’investigation sur constat d’anomalie en lien avec les différents intervenants du projet ;Le support aux utilisateurs et l’expertise sur toutes les couches logicielles ;L'administration de l’ensemble des services déployés sur les plateformes (Hadoop, ELK, produits internes …) incluant la configuration et la gestion des ressources ;La maintenance et le support des outils de supervision : Zabbix, ELK, Nagios ;Le suivi du déploiement de nouveau matériel ;Agir en tant qu'interface avec le client et les autres contributeurs du projet.Thales reconnait tous les talents, la diversité est notre meilleur atout. Postulez et rejoignez nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Ingénieur Big Data & architecture distribuée",
        "contract_type": "Stage(5 à 9 mois)",
        "salary": "Non spécifié",
        "company": "Look Up Space",
        "location": "Toulouse",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-11",
        "company_data": {
            "sector": "Aéronautique / Spatiale",
            "company_size": "39",
            "creation_date": "2022",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "n.a.",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).connaissance",
                "(java,"
            ],
            "DataBase": [
                "elasticsearch",
                "elasticsearch",
                "elasticsearch"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes.responsabilités",
                "kubernetes.compétences"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes.responsabilités",
                "kubernetes.compétences"
            ],
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "alertes.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/look-up-space/jobs/stage-ingenieur-big-data-arhitecture-distribuee_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=1e5181e7-e617-4a7d-9b80-9f0c44268efa",
        "description": "Descriptif du posteMission du Stage :Votre mission consistera à renforcer notre solution en matière de suivi applicatif lié à la bonne exécution de nos pipelines de traitement de données Big Data (de manière massive comme au fil de l’eau). Vous serez responsable de l’intégration de sondes remontants évènements et métriques, de la configuration et de l’optimisation d’outils de dashboarding, alerting et indexation de données massives (Time Series). Vous intègrerez la solution en suivant les bonnes pratiques liées aux solutions cloud natives. Vous serez amenés à interagir avec des solutions Open Source telles que Prometheus, Alerta, Alertmanager, Grafana, ElasticSearch et Loki pour garantir une visibilité complète de notre stack applicative Kubernetes.Responsabilités :Etude, présentation et défense de l’architecture détaillée de la solution.Définition du format et puits de collecte des évènements et métriques d’intérêtConfiguration de la solution de centralisation et la recherche d’évènements et métriques.Vérifier le fonctionnement de collecte en mode batch comme stream.Analyse des données d’ingestion pour identifier les performances anormales et les problèmes potentiels.Développement de tableaux de bord complets en participant à la définition de l’expérience utilisateur souhaitée.Gestion des canaux de notification des alertes.Collaboration avec les équipes de développement pour l’instrumentation des applications.Compétences / appétences souhaitées:Connaissance en architectures distribuées, big data comme cloud natives.Connaissance des outils de monitoring tels que Prometheus, Alerta, Alertmanager, Grafana, ElasticSearch et Loki.Compréhension des concepts de métrics, stack d’observabilité et centralisation de logs applicatifs.Connaissance de Kubernetes.Compétences en programmation (Java, Python).Connaissance de ElasticSearch et Apache Spark est un plus.Autonomie, créativité et esprit d’équipe.Force de proposition et capacité à s’appuyer sur la communauté open source pour répondre à une problématique."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Ingénieur Big Data & architecture distribuée",
        "contract_type": "Stage(5 à 9 mois)",
        "salary": "Non spécifié",
        "company": "Look Up Space",
        "location": "Toulouse",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-11",
        "company_data": {
            "sector": "Aéronautique / Spatiale",
            "company_size": "39",
            "creation_date": "2022",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "n.a.",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).connaissance",
                "(java,"
            ],
            "DataBase": [
                "elasticsearch",
                "elasticsearch",
                "elasticsearch"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes.responsabilités",
                "kubernetes.compétences"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes.responsabilités",
                "kubernetes.compétences"
            ],
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "alertes.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/look-up-space/jobs/stage-ingenieur-big-data-arhitecture-distribuee_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=1e5181e7-e617-4a7d-9b80-9f0c44268efa",
        "description": "Descriptif du posteMission du Stage :Votre mission consistera à renforcer notre solution en matière de suivi applicatif lié à la bonne exécution de nos pipelines de traitement de données Big Data (de manière massive comme au fil de l’eau). Vous serez responsable de l’intégration de sondes remontants évènements et métriques, de la configuration et de l’optimisation d’outils de dashboarding, alerting et indexation de données massives (Time Series). Vous intègrerez la solution en suivant les bonnes pratiques liées aux solutions cloud natives. Vous serez amenés à interagir avec des solutions Open Source telles que Prometheus, Alerta, Alertmanager, Grafana, ElasticSearch et Loki pour garantir une visibilité complète de notre stack applicative Kubernetes.Responsabilités :Etude, présentation et défense de l’architecture détaillée de la solution.Définition du format et puits de collecte des évènements et métriques d’intérêtConfiguration de la solution de centralisation et la recherche d’évènements et métriques.Vérifier le fonctionnement de collecte en mode batch comme stream.Analyse des données d’ingestion pour identifier les performances anormales et les problèmes potentiels.Développement de tableaux de bord complets en participant à la définition de l’expérience utilisateur souhaitée.Gestion des canaux de notification des alertes.Collaboration avec les équipes de développement pour l’instrumentation des applications.Compétences / appétences souhaitées:Connaissance en architectures distribuées, big data comme cloud natives.Connaissance des outils de monitoring tels que Prometheus, Alerta, Alertmanager, Grafana, ElasticSearch et Loki.Compréhension des concepts de métrics, stack d’observabilité et centralisation de logs applicatifs.Connaissance de Kubernetes.Compétences en programmation (Java, Python).Connaissance de ElasticSearch et Apache Spark est un plus.Autonomie, créativité et esprit d’équipe.Force de proposition et capacité à s’appuyer sur la communauté open source pour répondre à une problématique."
    },
    {
        "source": "welcometothejungle",
        "job_title": "DevOps & Big data engineer ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EFFICIENT IP",
        "location": "La Garenne-Colombes",
        "remote": "Télétravail occasionnel",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "Logiciels, SaaS / Cloud Services, Cybersécurité",
            "company_size": "280",
            "creation_date": "2004",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "devops"
            ],
            "EnSoftSkils": [
                "applications.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/efficient-ip/jobs/data-engineer_la-garenne-colombes?q=a4acfb2fdef1469051414f8389f464c2&o=98d25c25-71b5-4b08-bdf5-85fb063088d5",
        "description": "Descriptif du posteEn tant que Devops & Big data Engineer vos missions seront de :Automatisation : Développer des scripts et des outils pour automatiser l’ingestion, le traitement et le déploiement des données dans le data lake.Infrastructure as Code (IaC) : Utiliser des outils d’automatisation pour gérer l’infrastructure du data lakeSurveillance et observabilité : Implémenter des solutions de monitoring, logging et alerting pour assurer la performance et la disponibilité des systèmes.Sécurité : Intégrer des pratiques de sécurité dans les pipelines DevOps pour protéger les données et les applications.Collaboration : Travailler étroitement avec les développeurs pour comprendre les besoins et fournir des solutions adaptées."
    },
    {
        "source": "welcometothejungle",
        "job_title": "DevOps & Big data engineer ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EFFICIENT IP",
        "location": "La Garenne-Colombes",
        "remote": "Télétravail occasionnel",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "Logiciels, SaaS / Cloud Services, Cybersécurité",
            "company_size": "280",
            "creation_date": "2004",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "devops"
            ],
            "EnSoftSkils": [
                "applications.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/efficient-ip/jobs/data-engineer_la-garenne-colombes?q=a4acfb2fdef1469051414f8389f464c2&o=98d25c25-71b5-4b08-bdf5-85fb063088d5",
        "description": "Descriptif du posteEn tant que Devops & Big data Engineer vos missions seront de :Automatisation : Développer des scripts et des outils pour automatiser l’ingestion, le traitement et le déploiement des données dans le data lake.Infrastructure as Code (IaC) : Utiliser des outils d’automatisation pour gérer l’infrastructure du data lakeSurveillance et observabilité : Implémenter des solutions de monitoring, logging et alerting pour assurer la performance et la disponibilité des systèmes.Sécurité : Intégrer des pratiques de sécurité dans les pipelines DevOps pour protéger les données et les applications.Collaboration : Travailler étroitement avec les développeurs pour comprendre les besoins et fournir des solutions adaptées."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Administratrice / Administrateur Big Data",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Banque Postale",
        "location": "Toulouse",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-06",
        "company_data": {
            "sector": "Banque, Finance",
            "company_size": "2739",
            "creation_date": "2006",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": "5,7Md €",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,"
            ],
            "DataBase": [
                "db2/sql/postgresql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark)votre"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "gitlab,",
                "digitales"
            ],
            "OS": [
                "unix/linux",
                "windows"
            ],
            "DBMS": [
                "db2/sql/postgresql,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,",
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,",
                "openshift"
            ],
            "Collaboration": null,
            "Other": [
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-banque-postale/jobs/administratrice-administrateur-big-data_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=276bc7d6-a459-4f7c-90e9-a55eebaef155",
        "description": "Descriptif du posteEn tant qu'Administratrice /Administrateur Big Data, vous garantissez la performance des applications sur le périmètre Big Data pour assurer leur disponibilité et leur maintien en condition opérationnelle. Et après ? Notre organisation en mode missions vous ouvrira des perspectives pour progresser, développer vos compétences et vous étonner ! A la DSI de la Banque Postale et Assurance (1800 collaborateurs à Nantes, Toulouse, Issy-Les-Moulineaux, Gradignan), vos actions auront un impact positif sur nos clients pour une finance plus responsable et une transition juste.Vos missionsAdministrer au quotidien les composants applicatifs de vôtre périmètre,Intégrer les nouveaux composants applicatifs et réaliser les mises en production,Rédiger des scripts pour la conception d'outils d'aide à l'exploitation,Participer aux campagnes de tests unitaires et d'assemblage et aux recettes d'exploitation,Rédiger la documentation : dossier de mise en exploitation, prescription de surveillance, consigne de reprise, de MEP, de retour en arrière et d'exploitabilité du composant…,Valider les scénarios de retour arrière sur la mise en production,Maintenir le Plan de Reprise d'Activité (PRA),Contribuer au suivi de la QS conformément aux engagements contractuels,Participer à l'analyse des demandes émises par les chefs de projets EtudesPrendre en charge les activités de Maintien en Condition Opérationnel (MCO),Assister les utilisateurs dans la résolution d'incidents de niveau 2, traitement des habilitationsAssurer des reportingsEnvironnement technique : Système Unix/Linux (80%) & Windows (20%), Openshift V4, Kubernetes, Gitlab, IWS, Habilitation (Ranger, Ambari, Ldap), Splunk/Nagios/Zabbix, Python, Shell, PowerShell, HIVE, DB2/SQL/PostgreSQL, Big data (Solar, Hadoop, Cloudera, Kafka, SPARK)VOTRE EQUIPEAu sein de la Direction Capacités Digitales et Data (220 personnes), le Domaine DATA (65 personnes) regroupe l'ensemble des capacités DATA (Big DATA & Décisionnel) et supporte la transformation du Groupe au travers de la mise à disposition de socles techniques et de solutions transverses adaptés aux usages du Groupe.Vous rejoignez la System Team RSTBD (Release Système Team Big Data), composée de 9 personnes : 1 leader d'équipe, 2 Responsables d'exploitation applicatif et 6 administrateurs Big Data. Vous collaborez étroitement avec les équipes du delivery, infra Big Data, sécurité, réseau ou supervision…Dans le cadre de vos missions, vous effectuez des astreintes ou des actions en HNO (Heure Non Ouvrée)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Administratrice / Administrateur Big Data",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Banque Postale",
        "location": "Toulouse",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-06",
        "company_data": {
            "sector": "Banque, Finance",
            "company_size": "2739",
            "creation_date": "2006",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": "5,7Md €",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,"
            ],
            "DataBase": [
                "db2/sql/postgresql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark)votre"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "gitlab,",
                "digitales"
            ],
            "OS": [
                "unix/linux",
                "windows"
            ],
            "DBMS": [
                "db2/sql/postgresql,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,",
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,",
                "openshift"
            ],
            "Collaboration": null,
            "Other": [
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-banque-postale/jobs/administratrice-administrateur-big-data_toulouse?q=a4acfb2fdef1469051414f8389f464c2&o=276bc7d6-a459-4f7c-90e9-a55eebaef155",
        "description": "Descriptif du posteEn tant qu'Administratrice /Administrateur Big Data, vous garantissez la performance des applications sur le périmètre Big Data pour assurer leur disponibilité et leur maintien en condition opérationnelle. Et après ? Notre organisation en mode missions vous ouvrira des perspectives pour progresser, développer vos compétences et vous étonner ! A la DSI de la Banque Postale et Assurance (1800 collaborateurs à Nantes, Toulouse, Issy-Les-Moulineaux, Gradignan), vos actions auront un impact positif sur nos clients pour une finance plus responsable et une transition juste.Vos missionsAdministrer au quotidien les composants applicatifs de vôtre périmètre,Intégrer les nouveaux composants applicatifs et réaliser les mises en production,Rédiger des scripts pour la conception d'outils d'aide à l'exploitation,Participer aux campagnes de tests unitaires et d'assemblage et aux recettes d'exploitation,Rédiger la documentation : dossier de mise en exploitation, prescription de surveillance, consigne de reprise, de MEP, de retour en arrière et d'exploitabilité du composant…,Valider les scénarios de retour arrière sur la mise en production,Maintenir le Plan de Reprise d'Activité (PRA),Contribuer au suivi de la QS conformément aux engagements contractuels,Participer à l'analyse des demandes émises par les chefs de projets EtudesPrendre en charge les activités de Maintien en Condition Opérationnel (MCO),Assister les utilisateurs dans la résolution d'incidents de niveau 2, traitement des habilitationsAssurer des reportingsEnvironnement technique : Système Unix/Linux (80%) & Windows (20%), Openshift V4, Kubernetes, Gitlab, IWS, Habilitation (Ranger, Ambari, Ldap), Splunk/Nagios/Zabbix, Python, Shell, PowerShell, HIVE, DB2/SQL/PostgreSQL, Big data (Solar, Hadoop, Cloudera, Kafka, SPARK)VOTRE EQUIPEAu sein de la Direction Capacités Digitales et Data (220 personnes), le Domaine DATA (65 personnes) regroupe l'ensemble des capacités DATA (Big DATA & Décisionnel) et supporte la transformation du Groupe au travers de la mise à disposition de socles techniques et de solutions transverses adaptés aux usages du Groupe.Vous rejoignez la System Team RSTBD (Release Système Team Big Data), composée de 9 personnes : 1 leader d'équipe, 2 Responsables d'exploitation applicatif et 6 administrateurs Big Data. Vous collaborez étroitement avec les équipes du delivery, infra Big Data, sécurité, réseau ou supervision…Dans le cadre de vos missions, vous effectuez des astreintes ou des actions en HNO (Heure Non Ouvrée)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert Big Data (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-expert-gcp-h-f_suresnes?q=a4acfb2fdef1469051414f8389f464c2&o=28906971-1c7b-415a-a890-4a7df39df69e",
        "description": "Descriptif du posteSi tu aimes concevoir et fabriquer des pipelines permettant de transformer des données dans un format exploitable, c’est que la data Ingénierie est ton domaine de prédilection.Tu aimes relever des challenges de volumétries massives, de résilience et de vélocité des données alors l’équipe DATA Factorii t’attend !Mais qu’est-ce que l’équipe DATA Factorii adresse ?En tant que Expert Big Data H/F, tes missions seront de :Définir et déployer le socle technologique d’un DatalakeConseiller et concevoir une architecture de donnéesImplémenter l’intégration des données au sein de votre DatalakeIdentifier, étudier et prototyper des cas d’usage stratégiquesIndustrialiser vos projets Big Data dans des environnements cloud"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert Big Data (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-expert-gcp-h-f_suresnes?q=a4acfb2fdef1469051414f8389f464c2&o=28906971-1c7b-415a-a890-4a7df39df69e",
        "description": "Descriptif du posteSi tu aimes concevoir et fabriquer des pipelines permettant de transformer des données dans un format exploitable, c’est que la data Ingénierie est ton domaine de prédilection.Tu aimes relever des challenges de volumétries massives, de résilience et de vélocité des données alors l’équipe DATA Factorii t’attend !Mais qu’est-ce que l’équipe DATA Factorii adresse ?En tant que Expert Big Data H/F, tes missions seront de :Définir et déployer le socle technologique d’un DatalakeConseiller et concevoir une architecture de donnéesImplémenter l’intégration des données au sein de votre DatalakeIdentifier, étudier et prototyper des cas d’usage stratégiquesIndustrialiser vos projets Big Data dans des environnements cloud"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Alternance en Big Data, Dev et IA ",
        "contract_type": "Alternance(24 mois)",
        "salary": "Non spécifié",
        "company": "IPSSI",
        "location": "Nice",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-04",
        "company_data": {
            "sector": "Education, EdTech, Formation",
            "company_size": "36",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "10 millions",
            "proportion_female": "65",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ipssi/jobs/alternance-en-big-data-dev-et-ia_nice_IPSSI_6KXOdb7?q=a4acfb2fdef1469051414f8389f464c2&o=882402f0-6465-49a3-8458-2c1ca3d021f0",
        "description": "Descriptif du posteVos missions :Implanter une architecture de données de plusieurs logiciels, SI, intégration de façon à rendre nos données (a) robuste, (b) exploitable de façon optimale sans déperdition, (c) protégé, et (d) fluide. Nous devons établir une architecture de données OPTIMALE pour l’exploitation des données afin qu’on puisse mettre en place des outils de ML qui affectera notre prise de décision pour de futurs choix stratégiquesIntégrer plusieurs API dans les différents CRM utilisé par les différentes entitésConcevoir & optimiser un algorithme 1.0 à 5 facteurs pour éventuellement l’optimiser pendant l’apprentissage de façon à accroitre le nombre de facteurs pour avoir une meilleure prédictibilité.Vos tâches :Participer au déploiement de solutions Machine LearningAnalyser des jeux de données complexes et mettre en œuvre des modèles d’apprentissage automatique.Collaborer avec votre N+1 qui imposera aux équipes des méthodes de travail nouvelles favorisant l’exploitation de donnéesParticiper à la mise en place de tests, au suivi des performances des algorithmes et à l’amélioration continue des projets IA.Rédiger des rapports techniques et assurer la documentation des projets en cours."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Alternance en Big Data, Dev et IA ",
        "contract_type": "Alternance(24 mois)",
        "salary": "Non spécifié",
        "company": "IPSSI",
        "location": "Nice",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-04",
        "company_data": {
            "sector": "Education, EdTech, Formation",
            "company_size": "36",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "10 millions",
            "proportion_female": "65",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ipssi/jobs/alternance-en-big-data-dev-et-ia_nice_IPSSI_6KXOdb7?q=a4acfb2fdef1469051414f8389f464c2&o=882402f0-6465-49a3-8458-2c1ca3d021f0",
        "description": "Descriptif du posteVos missions :Implanter une architecture de données de plusieurs logiciels, SI, intégration de façon à rendre nos données (a) robuste, (b) exploitable de façon optimale sans déperdition, (c) protégé, et (d) fluide. Nous devons établir une architecture de données OPTIMALE pour l’exploitation des données afin qu’on puisse mettre en place des outils de ML qui affectera notre prise de décision pour de futurs choix stratégiquesIntégrer plusieurs API dans les différents CRM utilisé par les différentes entitésConcevoir & optimiser un algorithme 1.0 à 5 facteurs pour éventuellement l’optimiser pendant l’apprentissage de façon à accroitre le nombre de facteurs pour avoir une meilleure prédictibilité.Vos tâches :Participer au déploiement de solutions Machine LearningAnalyser des jeux de données complexes et mettre en œuvre des modèles d’apprentissage automatique.Collaborer avec votre N+1 qui imposera aux équipes des méthodes de travail nouvelles favorisant l’exploitation de donnéesParticiper à la mise en place de tests, au suivi des performances des algorithmes et à l’amélioration continue des projets IA.Rédiger des rapports techniques et assurer la documentation des projets en cours."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Alternance en Big Data, Dev et IA ",
        "contract_type": "Alternance(24 mois)",
        "salary": "Non spécifié",
        "company": "IPSSI",
        "location": "Nice",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-04",
        "company_data": {
            "sector": "Education, EdTech, Formation",
            "company_size": "36",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "10 millions",
            "proportion_female": "65",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ipssi/jobs/alternance-en-big-data-dev-et-ia_nice?q=a4acfb2fdef1469051414f8389f464c2&o=590b18a4-aa08-4486-93a8-d8d095a849ef",
        "description": "Descriptif du posteVos missions :Implanter une architecture de données de plusieurs logiciels, SI, intégration de façon à rendre nos données (a) robuste, (b) exploitable de façon optimale sans déperdition, (c) protégé, et (d) fluide. Nous devons établir une architecture de données OPTIMALE pour l’exploitation des données afin qu’on puisse mettre en place des outils de ML qui affectera notre prise de décision pour de futurs choix stratégiquesIntégrer plusieurs API dans les différents CRM utilisé par les différentes entitésConcevoir & optimiser un algorithme 1.0 à 5 facteurs pour éventuellement l’optimiser pendant l’apprentissage de façon à accroitre le nombre de facteurs pour avoir une meilleure prédictibilité.Vos tâches :Participer au déploiement de solutions Machine LearningAnalyser des jeux de données complexes et mettre en œuvre des modèles d’apprentissage automatique.Collaborer avec votre N+1 qui imposera aux équipes des méthodes de travail nouvelles favorisant l’exploitation de donnéesParticiper à la mise en place de tests, au suivi des performances des algorithmes et à l’amélioration continue des projets IA.Rédiger des rapports techniques et assurer la documentation des projets en cours."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Alternance en Big Data, Dev et IA ",
        "contract_type": "Alternance(24 mois)",
        "salary": "Non spécifié",
        "company": "IPSSI",
        "location": "Nice",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-04",
        "company_data": {
            "sector": "Education, EdTech, Formation",
            "company_size": "36",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "10 millions",
            "proportion_female": "65",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ipssi/jobs/alternance-en-big-data-dev-et-ia_nice?q=a4acfb2fdef1469051414f8389f464c2&o=590b18a4-aa08-4486-93a8-d8d095a849ef",
        "description": "Descriptif du posteVos missions :Implanter une architecture de données de plusieurs logiciels, SI, intégration de façon à rendre nos données (a) robuste, (b) exploitable de façon optimale sans déperdition, (c) protégé, et (d) fluide. Nous devons établir une architecture de données OPTIMALE pour l’exploitation des données afin qu’on puisse mettre en place des outils de ML qui affectera notre prise de décision pour de futurs choix stratégiquesIntégrer plusieurs API dans les différents CRM utilisé par les différentes entitésConcevoir & optimiser un algorithme 1.0 à 5 facteurs pour éventuellement l’optimiser pendant l’apprentissage de façon à accroitre le nombre de facteurs pour avoir une meilleure prédictibilité.Vos tâches :Participer au déploiement de solutions Machine LearningAnalyser des jeux de données complexes et mettre en œuvre des modèles d’apprentissage automatique.Collaborer avec votre N+1 qui imposera aux équipes des méthodes de travail nouvelles favorisant l’exploitation de donnéesParticiper à la mise en place de tests, au suivi des performances des algorithmes et à l’amélioration continue des projets IA.Rédiger des rapports techniques et assurer la documentation des projets en cours."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Big Data confirmé - Data Factory - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-26",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java-sparkpython,",
                "java-sparkpython,",
                "spark-scala,"
            ],
            "DataBase": [
                "sqlune"
            ],
            "DataAnalytics": null,
            "BigData": [
                ":pyspark,",
                "spark-scala,",
                "java-sparkpython,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,",
                "bigqueryvous"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-confirme-data-factory-bordeaux_merignac_SS_o5Yq0ep?q=a4acfb2fdef1469051414f8389f464c2&o=6ac420d2-8875-4c6c-b374-7c0968aad81d",
        "description": "Descriptif du posteVotre futur environnement de travail :Intégré(e) au sein de notre Data Factory de plus de 120 Data Ingénieurs, vous contribuez à un projet Big Data, et intervenez en tant que référent technique pour un de nos Grands Comptes.Votre rôle et missions :A cette occasion vous serez amené(e) à :Apporter votre expertise et votre expérience à votre équipe lors des phases de conception et développement ;Définir et implémenter des solutions d'ingestion, de préparation, de stockage, de calcul et d'exposition - sur l'ensemble du pipeline de données ;Proposer des idées d’amélioration continue à votre client et à votre équipe - revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie ;Concevoir et développer des solutions complexes ;Industrialisation, mise en place de CI/CD ;Accompagner vos collaborateurs dans leur montée en compétence au sein du projet ;Vous êtes membre actif de la communauté Data Sopra Steria ;Vous maintenez vos compétences en suivant les parcours de certification avec nos partenaires Editeurs et Cloud Provider.Environnement technique :Solutions du marché :ETL/ELT : Datastage, Talend, Informatica, SemarchyData Solution : Databricks, Snowflake, Cloudera, BigQueryVous maitrisez et êtes certifié(e) sur au moins l'une de ces solutions du marché.Langages :PySpark, Spark-Scala, Java-SparkPython, Shell, SQLUne maitrise de ces langages est attendue.Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Big Data confirmé - Data Factory - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-26",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java-sparkpython,",
                "java-sparkpython,",
                "spark-scala,"
            ],
            "DataBase": [
                "sqlune"
            ],
            "DataAnalytics": null,
            "BigData": [
                ":pyspark,",
                "spark-scala,",
                "java-sparkpython,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,",
                "bigqueryvous"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-big-data-confirme-data-factory-bordeaux_merignac_SS_o5Yq0ep?q=a4acfb2fdef1469051414f8389f464c2&o=6ac420d2-8875-4c6c-b374-7c0968aad81d",
        "description": "Descriptif du posteVotre futur environnement de travail :Intégré(e) au sein de notre Data Factory de plus de 120 Data Ingénieurs, vous contribuez à un projet Big Data, et intervenez en tant que référent technique pour un de nos Grands Comptes.Votre rôle et missions :A cette occasion vous serez amené(e) à :Apporter votre expertise et votre expérience à votre équipe lors des phases de conception et développement ;Définir et implémenter des solutions d'ingestion, de préparation, de stockage, de calcul et d'exposition - sur l'ensemble du pipeline de données ;Proposer des idées d’amélioration continue à votre client et à votre équipe - revue de procédures, mise en place de nouveaux outils dans le cadre de livraison, test ou qualimétrie ;Concevoir et développer des solutions complexes ;Industrialisation, mise en place de CI/CD ;Accompagner vos collaborateurs dans leur montée en compétence au sein du projet ;Vous êtes membre actif de la communauté Data Sopra Steria ;Vous maintenez vos compétences en suivant les parcours de certification avec nos partenaires Editeurs et Cloud Provider.Environnement technique :Solutions du marché :ETL/ELT : Datastage, Talend, Informatica, SemarchyData Solution : Databricks, Snowflake, Cloudera, BigQueryVous maitrisez et êtes certifié(e) sur au moins l'une de ces solutions du marché.Langages :PySpark, Spark-Scala, Java-SparkPython, Shell, SQLUne maitrise de ces langages est attendue.Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data Confirmé H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EXTIA",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "Ingénieries Spécialisées, IT / Digital, Stratégie",
            "company_size": "2500",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "scala,vous"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "nosql",
                "mongodb,",
                "hbase",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop",
                "spark,dataingestion"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": [
                "jenkins"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase"
            ],
            "Automation": [
                "ansible,",
                "airflow"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "(cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/extia/jobs/developpeur-big-data-confirme-h-f_nantes?q=a4acfb2fdef1469051414f8389f464c2&o=a033db98-e7d0-48cf-a4f4-dfda59aa76cb",
        "description": "Descriptif du posteDESCRIPTION DU POSTE​Au sein d'une équipe de développeurs passionnés comme vous, vous serez amené à :Comprendre et analyser fonctionnellement et techniquement l'environnement Big Data distribué dans lequel vous allez évoluer,Contribuer au cadrage du projet, rédiger les spécifications techniques, mettre en place des environnements de développement et développer sur des langages Big Data,Réaliser les phases de tests et les corrections des anomalies éventuelles,Mettre en place et tenir à jour la documentation technique et les outils de restitution,Être force de proposition pour une amélioration continue de la performance de la plateforme,Effectuer une veille technologique permanente.PROFIL RECHERCHEIssu(e) d'une formation supérieure en informatique :Vous justifiez d’une expérience de 3 ans minimum en développement dans un environnement Big Data Hadoop (Cloudera, Hortonworks ou MapR),Vous êtes familier des technologies Big Data suivantes (ou autre/s outils similaire/s) :Base de données type SQL permettant le requêtage : Hive ou Pig idéalement,Base noSQL : Elasticsearch, MongoDB, Hbase ou Impala par exemple,Programmation distribuée : Hadoop ou Spark,DataIngestion : Scoop ou Kafka, éventuellement Flume,DataVisualisation : Kibana.Vous possédez des compétences en développement JAVA, R ou Scala,Vous vous intéressez aux méthodologies devops et avez connaissance de l’environnement AWS ou GCP. Des bases sur Ansible, Jenkins et Airflow par exemple, sont appréciées.  Processus de recrutement> 1. Échangez avec un ou une chargée de recrutement pour un premier contact téléphonique> 2. Rencontrez un ou une Ingénieure d’Affaires (Business Manager) sur vos souhaits d’évolution> 3. Approfondissez avec nos responsables et directeurs d’agence pour connaître la vision de l'agenceSelon votre profil, des tests ou entretiens techniques pourront vous être demandés. Tout au long du processus, vous pourrez échanger avec nos consultants pour en savoir + sur leur quotidien chez nous !   Les petits plus🏠 Télétravail possible👛 100% des frais de transports en communs pris en charge, des tickets restaurant et une mutuelle haut de gamme🎁 Un CSE avantageux et des challenges tout au long de l'année ! #greatplacetolive📈 Des primes à hauteur des performances de l'année et de l'implication🎉 250 événements par an pour rencontrer tes collègues et des locaux feel good #lifeatextia📢 Des formations, conférences et une plateforme d'e-learning avec LinkedIn pour monter en compétences #greatplacetolearn👩‍ Des Communautés Métiers et du Mentorat pour partager son expertise et en apprendre sur de nombreux sujets #greatplacetoshare🕹️ Une communauté de e-sport : Extia Gaming ! #greatplacetoplay#LI-MM3"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data Confirmé H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EXTIA",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "Ingénieries Spécialisées, IT / Digital, Stratégie",
            "company_size": "2500",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "scala,vous"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "nosql",
                "mongodb,",
                "hbase",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop",
                "spark,dataingestion"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": [
                "jenkins"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase"
            ],
            "Automation": [
                "ansible,",
                "airflow"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "(cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/extia/jobs/developpeur-big-data-confirme-h-f_nantes?q=a4acfb2fdef1469051414f8389f464c2&o=a033db98-e7d0-48cf-a4f4-dfda59aa76cb",
        "description": "Descriptif du posteDESCRIPTION DU POSTE​Au sein d'une équipe de développeurs passionnés comme vous, vous serez amené à :Comprendre et analyser fonctionnellement et techniquement l'environnement Big Data distribué dans lequel vous allez évoluer,Contribuer au cadrage du projet, rédiger les spécifications techniques, mettre en place des environnements de développement et développer sur des langages Big Data,Réaliser les phases de tests et les corrections des anomalies éventuelles,Mettre en place et tenir à jour la documentation technique et les outils de restitution,Être force de proposition pour une amélioration continue de la performance de la plateforme,Effectuer une veille technologique permanente.PROFIL RECHERCHEIssu(e) d'une formation supérieure en informatique :Vous justifiez d’une expérience de 3 ans minimum en développement dans un environnement Big Data Hadoop (Cloudera, Hortonworks ou MapR),Vous êtes familier des technologies Big Data suivantes (ou autre/s outils similaire/s) :Base de données type SQL permettant le requêtage : Hive ou Pig idéalement,Base noSQL : Elasticsearch, MongoDB, Hbase ou Impala par exemple,Programmation distribuée : Hadoop ou Spark,DataIngestion : Scoop ou Kafka, éventuellement Flume,DataVisualisation : Kibana.Vous possédez des compétences en développement JAVA, R ou Scala,Vous vous intéressez aux méthodologies devops et avez connaissance de l’environnement AWS ou GCP. Des bases sur Ansible, Jenkins et Airflow par exemple, sont appréciées.  Processus de recrutement> 1. Échangez avec un ou une chargée de recrutement pour un premier contact téléphonique> 2. Rencontrez un ou une Ingénieure d’Affaires (Business Manager) sur vos souhaits d’évolution> 3. Approfondissez avec nos responsables et directeurs d’agence pour connaître la vision de l'agenceSelon votre profil, des tests ou entretiens techniques pourront vous être demandés. Tout au long du processus, vous pourrez échanger avec nos consultants pour en savoir + sur leur quotidien chez nous !   Les petits plus🏠 Télétravail possible👛 100% des frais de transports en communs pris en charge, des tickets restaurant et une mutuelle haut de gamme🎁 Un CSE avantageux et des challenges tout au long de l'année ! #greatplacetolive📈 Des primes à hauteur des performances de l'année et de l'implication🎉 250 événements par an pour rencontrer tes collègues et des locaux feel good #lifeatextia📢 Des formations, conférences et une plateforme d'e-learning avec LinkedIn pour monter en compétences #greatplacetolearn👩‍ Des Communautés Métiers et du Mentorat pour partager son expertise et en apprendre sur de nombreux sujets #greatplacetoshare🕹️ Une communauté de e-sport : Extia Gaming ! #greatplacetoplay#LI-MM3"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data Sénior H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EXTIA",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "Ingénieries Spécialisées, IT / Digital, Stratégie",
            "company_size": "2500",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "scala,vous"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "nosql",
                "mongodb,",
                "hbase",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop",
                "spark,dataingestion"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": [
                "jenkins"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase"
            ],
            "Automation": [
                "ansible,",
                "airflow"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "(cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/extia/jobs/developpeur-big-data-senior-h-f_nantes?q=a4acfb2fdef1469051414f8389f464c2&o=f86114a8-5289-420a-bf00-a158fc22805e",
        "description": "Descriptif du posteDESCRIPTION DU POSTE​Au sein d'une équipe de développeurs passionnés comme vous, vous serez amené à :Comprendre et analyser fonctionnellement et techniquement l'environnement Big Data distribué dans lequel vous allez évoluer,Contribuer au cadrage du projet, rédiger les spécifications techniques, mettre en place des environnements de développement et développer sur des langages Big Data,Réaliser les phases de tests et les corrections des anomalies éventuelles,Mettre en place et tenir à jour la documentation technique et les outils de restitution,Être force de proposition pour une amélioration continue de la performance de la plateforme,Effectuer une veille technologique permanente.PROFIL RECHERCHEIssu(e) d'une formation supérieure en informatique :Vous justifiez d’une expérience de 6 ans minimum en développement dans un environnement Big Data Hadoop (Cloudera, Hortonworks ou MapR),Vous êtes familier des technologies Big Data suivantes (ou autre/s outils similaire/s) :Base de données type SQL permettant le requêtage : Hive ou Pig idéalement,Base noSQL : Elasticsearch, MongoDB, Hbase ou Impala par exemple,Programmation distribuée : Hadoop ou Spark,DataIngestion : Scoop ou Kafka, éventuellement Flume,DataVisualisation : Kibana.Vous possédez des compétences en développement JAVA, R ou Scala,Vous vous intéressez aux méthodologies devops et avez connaissance de l’environnement AWS ou GCP. Des bases sur Ansible, Jenkins et Airflow par exemple, sont appréciées.  Processus de recrutement> 1. Échangez avec un ou une chargée de recrutement pour un premier contact téléphonique> 2. Rencontrez un ou une Ingénieure d’Affaires (Business Manager) sur vos souhaits d’évolution> 3. Approfondissez avec nos responsables et directeurs d’agence pour connaître la vision de l'agenceSelon votre profil, des tests ou entretiens techniques pourront vous être demandés. Tout au long du processus, vous pourrez échanger avec nos consultants pour en savoir + sur leur quotidien chez nous !   Les petits plus🏠 Télétravail possible👛 100% des frais de transports en communs pris en charge, des tickets restaurant et une mutuelle haut de gamme🎁 Un CSE avantageux et des challenges tout au long de l'année ! #greatplacetolive📈 Des primes à hauteur des performances de l'année et de l'implication🎉 250 événements par an pour rencontrer tes collègues et des locaux feel good #lifeatextia📢 Des formations, conférences et une plateforme d'e-learning avec LinkedIn pour monter en compétences #greatplacetolearn👩‍ Des Communautés Métiers et du Mentorat pour partager son expertise et en apprendre sur de nombreux sujets #greatplacetoshare🕹️ Une communauté de e-sport : Extia Gaming ! #greatplacetoplay#LI-MM3"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Big Data Sénior H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EXTIA",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "Ingénieries Spécialisées, IT / Digital, Stratégie",
            "company_size": "2500",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java,",
                "scala,vous"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "nosql",
                "mongodb,",
                "hbase",
                "elasticsearch,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "hadoop",
                "hadoop",
                "spark,dataingestion"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": [
                "jenkins"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": [
                "hbase"
            ],
            "Automation": [
                "ansible,",
                "airflow"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "(cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/extia/jobs/developpeur-big-data-senior-h-f_nantes?q=a4acfb2fdef1469051414f8389f464c2&o=f86114a8-5289-420a-bf00-a158fc22805e",
        "description": "Descriptif du posteDESCRIPTION DU POSTE​Au sein d'une équipe de développeurs passionnés comme vous, vous serez amené à :Comprendre et analyser fonctionnellement et techniquement l'environnement Big Data distribué dans lequel vous allez évoluer,Contribuer au cadrage du projet, rédiger les spécifications techniques, mettre en place des environnements de développement et développer sur des langages Big Data,Réaliser les phases de tests et les corrections des anomalies éventuelles,Mettre en place et tenir à jour la documentation technique et les outils de restitution,Être force de proposition pour une amélioration continue de la performance de la plateforme,Effectuer une veille technologique permanente.PROFIL RECHERCHEIssu(e) d'une formation supérieure en informatique :Vous justifiez d’une expérience de 6 ans minimum en développement dans un environnement Big Data Hadoop (Cloudera, Hortonworks ou MapR),Vous êtes familier des technologies Big Data suivantes (ou autre/s outils similaire/s) :Base de données type SQL permettant le requêtage : Hive ou Pig idéalement,Base noSQL : Elasticsearch, MongoDB, Hbase ou Impala par exemple,Programmation distribuée : Hadoop ou Spark,DataIngestion : Scoop ou Kafka, éventuellement Flume,DataVisualisation : Kibana.Vous possédez des compétences en développement JAVA, R ou Scala,Vous vous intéressez aux méthodologies devops et avez connaissance de l’environnement AWS ou GCP. Des bases sur Ansible, Jenkins et Airflow par exemple, sont appréciées.  Processus de recrutement> 1. Échangez avec un ou une chargée de recrutement pour un premier contact téléphonique> 2. Rencontrez un ou une Ingénieure d’Affaires (Business Manager) sur vos souhaits d’évolution> 3. Approfondissez avec nos responsables et directeurs d’agence pour connaître la vision de l'agenceSelon votre profil, des tests ou entretiens techniques pourront vous être demandés. Tout au long du processus, vous pourrez échanger avec nos consultants pour en savoir + sur leur quotidien chez nous !   Les petits plus🏠 Télétravail possible👛 100% des frais de transports en communs pris en charge, des tickets restaurant et une mutuelle haut de gamme🎁 Un CSE avantageux et des challenges tout au long de l'année ! #greatplacetolive📈 Des primes à hauteur des performances de l'année et de l'implication🎉 250 événements par an pour rencontrer tes collègues et des locaux feel good #lifeatextia📢 Des formations, conférences et une plateforme d'e-learning avec LinkedIn pour monter en compétences #greatplacetolearn👩‍ Des Communautés Métiers et du Mentorat pour partager son expertise et en apprendre sur de nombreux sujets #greatplacetoshare🕹️ Une communauté de e-sport : Extia Gaming ! #greatplacetoplay#LI-MM3"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Développement Outils Big Data & Analytics en Finance",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Opensee",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-02",
        "company_data": {
            "sector": "IT / Digital, FinTech / InsurTech, Big Data",
            "company_size": "80",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).",
                "python,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/opensee/jobs/stage-developpement-outils-big-data-analytics-en-finance_paris_OPENS_PAQ8KdP?q=a4acfb2fdef1469051414f8389f464c2&o=ffd85e5f-5e5c-4ee0-af58-d44384709e03",
        "description": "Descriptif du posteDescription du poste En tant que stagiaire dans l’équipe Analytics & AI, vous devrez aider à la création et à la maintenance de la couche Produit (couche contenant des outils d’analyse Big Data pour la finance, écrits en Python). Vous avez une appétence pour la finance et vous assisterez dans la maintenance des services que notre FinTech propose aux clients. Ces services peuvent utiliser des algorithmes calculatoires simples ou plus complexes.En détails :Aider à la création et à la maintenance de la couche Produit, située entre la couche fonctionnelle (back-end) et la couche UI (front-end) de la solution Opensee.Comprendre les besoins des clients (institutions financières).Développer des outils en Python, que ce soit des solutions spécifiques pour certains clients ou des solutions plus génériques.Contribuer à tous les aspects des améliorations des outils, que cela soit l’amélioration de la performance, plateforme de tests et documentation.Contribuer au support et à l’analyse des incidents sur les services proposés."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Développement Outils Big Data & Analytics en Finance",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Opensee",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-02",
        "company_data": {
            "sector": "IT / Digital, FinTech / InsurTech, Big Data",
            "company_size": "80",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python).",
                "python,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/opensee/jobs/stage-developpement-outils-big-data-analytics-en-finance_paris_OPENS_PAQ8KdP?q=a4acfb2fdef1469051414f8389f464c2&o=ffd85e5f-5e5c-4ee0-af58-d44384709e03",
        "description": "Descriptif du posteDescription du poste En tant que stagiaire dans l’équipe Analytics & AI, vous devrez aider à la création et à la maintenance de la couche Produit (couche contenant des outils d’analyse Big Data pour la finance, écrits en Python). Vous avez une appétence pour la finance et vous assisterez dans la maintenance des services que notre FinTech propose aux clients. Ces services peuvent utiliser des algorithmes calculatoires simples ou plus complexes.En détails :Aider à la création et à la maintenance de la couche Produit, située entre la couche fonctionnelle (back-end) et la couche UI (front-end) de la solution Opensee.Comprendre les besoins des clients (institutions financières).Développer des outils en Python, que ce soit des solutions spécifiques pour certains clients ou des solutions plus génériques.Contribuer à tous les aspects des améliorations des outils, que cela soit l’amélioration de la performance, plateforme de tests et documentation.Contribuer au support et à l’analyse des incidents sur les services proposés."
    },
    {
        "source": "welcometothejungle",
        "job_title": "STAGE - Développeur Logiciel Big Data - F/H",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Thales",
        "location": "Élancourt",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-29",
        "company_data": {
            "sector": "Logiciels, Cybersécurité, Aéronautique / Spatiale",
            "company_size": "80000",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "19Mds€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python…)",
                "(javascript,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "html,",
                "cloud"
            ],
            "EnSoftSkils": [
                "initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/thales/jobs/stage-developpeur-logiciel-big-data-f-h_elancourt?q=a4acfb2fdef1469051414f8389f464c2&o=bed305c9-d996-40aa-920a-2d950a44bdbb",
        "description": "Descriptif du posteQUI SOMMES-NOUS ?Construisons ensemble un avenir de confianceThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d’activité : Défense & Sécurité, Aéronautique & Spatial, et Cybersécurité & Identité numérique. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l’environnement et plus inclusif. Le Groupe investit près de 4 milliards d’euros par an en Recherche & Développement, notamment dans des domaines clés de l’innovation tels que l’IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.Nos engagements, vos avantagesUne réussite commune portée par notre culture et excellence technologique, votre expérience et notre ambition partagéeUn package de rémunération attractif (épargne salariale, variable ou 13ième mois selon les postes, restaurant d’entreprise,…)La possibilité de développer vos compétences en continu grâce à nos parcours de formation et nos académies internes #ENTREPRISEAPPRENANTENotre attention portée à votre équilibre personnel et professionnel (Accord télétravail, RTT, congés d’ancienneté, jours enfants malades, guide parentalité, crèches, CSE / ASC,… )Des communautés internes permettant de vous engager sur les sujets qui vous tiennent à cœur : innovation, diversité, environnementUn environnement inclusif et bienveillant où vous êtes accueilli et valorisé avec notre politique handi-accueillante, notre charte LGBT+, notre initiative #StOpe pour lutter contre le sexisme.L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Le site d’Élancourt est un centre de développement des hautes technologies, liées au domaine des Radars de conduite de tir et de surveillance, ainsi que des solutions de Guerre Électronique.Vous préparez une formation de niveau BAC+5 en informatique et vous recherchez un stage d'une durée de 6 mois?Vous maîtrisez les langages de programmation (Javascript, HTML, CSS, Python…) ?Vous avez des connaissances en logiciel pour des applications Big Data ?Vous avez déjà abordé un projet de développement de solution pour des exploitations big data ?Vous avez des notions en technologies big data ?Vous faites preuve de rigueur, d'autonomie et d'organisation ?Alors ce qui suit va vous intéresser ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Le site d’Élancourt est un centre de développement des hautes technologies, liées au domaine des Radars de conduite de tir et de surveillance, ainsi que des solutions de Guerre Électronique.Le Département Simulation de la Direction Technique a en charge le développement et la promotion aux services des utilisateurs (internes, externes) de simulation de différents niveaux concourant à la qualification des systèmes embarqués développés par la Country Business Unit DMS (Radar et détection passive électromagnétique), concourant à la spécification des futurs systèmes, concourant à la formation et à l'entraînement de l'utilisateur final.En rejoignant ce Département Simulation de la Direction Technique, dans le cadre du développement des produits et services numériques de simulation vous aurez pour principale mission, d’améliorer les moyens d'analyse de données issues des simulations ou d'équipements réel.Dans ce contexte, vous vous verrez confier les missions suivantes :   - Développer / Améliorer les mécanismes basés sur une approche «  big data »  pour la collecte, la mise en forme et le filtrage des données   - Développer / Améliorer les interfaces permettant à l'utilisateur de visualiser / sélectionner des données   - Développer / Améliorer les mécanismes d'exportation de données afin de les utiliser dans d'autres outils   - Développer de nouvelles fonctionnalités d’aide à l’analyse (détection automatiques de valeurs anormales, instabilités…)La perspective de rejoindre une équipe de passionnés vous intéresse ? Alors, rejoignez-nous en postulant à cette offre.Tous nos stages sont conventionnés et soumis à une gratification dont le montant est déterminé selon votre niveau d’études.Thales reconnait tous les talents, la diversité est notre meilleur atout. Postulez et rejoignez nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "STAGE - Développeur Logiciel Big Data - F/H",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Thales",
        "location": "Élancourt",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-29",
        "company_data": {
            "sector": "Logiciels, Cybersécurité, Aéronautique / Spatiale",
            "company_size": "80000",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "19Mds€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python…)",
                "(javascript,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "html,",
                "cloud"
            ],
            "EnSoftSkils": [
                "initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/thales/jobs/stage-developpeur-logiciel-big-data-f-h_elancourt?q=a4acfb2fdef1469051414f8389f464c2&o=bed305c9-d996-40aa-920a-2d950a44bdbb",
        "description": "Descriptif du posteQUI SOMMES-NOUS ?Construisons ensemble un avenir de confianceThales est un leader mondial des hautes technologies spécialisé dans trois secteurs d’activité : Défense & Sécurité, Aéronautique & Spatial, et Cybersécurité & Identité numérique. Il développe des produits et solutions qui contribuent à un monde plus sûr, plus respectueux de l’environnement et plus inclusif. Le Groupe investit près de 4 milliards d’euros par an en Recherche & Développement, notamment dans des domaines clés de l’innovation tels que l’IA, la cybersécurité, le quantique, les technologies du cloud et la 6G. Thales compte près de 81 000 collaborateurs dans 68 pays.Nos engagements, vos avantagesUne réussite commune portée par notre culture et excellence technologique, votre expérience et notre ambition partagéeUn package de rémunération attractif (épargne salariale, variable ou 13ième mois selon les postes, restaurant d’entreprise,…)La possibilité de développer vos compétences en continu grâce à nos parcours de formation et nos académies internes #ENTREPRISEAPPRENANTENotre attention portée à votre équilibre personnel et professionnel (Accord télétravail, RTT, congés d’ancienneté, jours enfants malades, guide parentalité, crèches, CSE / ASC,… )Des communautés internes permettant de vous engager sur les sujets qui vous tiennent à cœur : innovation, diversité, environnementUn environnement inclusif et bienveillant où vous êtes accueilli et valorisé avec notre politique handi-accueillante, notre charte LGBT+, notre initiative #StOpe pour lutter contre le sexisme.L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Le site d’Élancourt est un centre de développement des hautes technologies, liées au domaine des Radars de conduite de tir et de surveillance, ainsi que des solutions de Guerre Électronique.Vous préparez une formation de niveau BAC+5 en informatique et vous recherchez un stage d'une durée de 6 mois?Vous maîtrisez les langages de programmation (Javascript, HTML, CSS, Python…) ?Vous avez des connaissances en logiciel pour des applications Big Data ?Vous avez déjà abordé un projet de développement de solution pour des exploitations big data ?Vous avez des notions en technologies big data ?Vous faites preuve de rigueur, d'autonomie et d'organisation ?Alors ce qui suit va vous intéresser ! CE QUE NOUS POUVONS ACCOMPLIR ENSEMBLE :L’activité Systèmes de missions de défense fournit des équipements, des solutions et des services liés aux systèmes de combat électroniques, de surveillance et de reconnaissance, de combat naval, de surface et de lutte sous la mer.Le site d’Élancourt est un centre de développement des hautes technologies, liées au domaine des Radars de conduite de tir et de surveillance, ainsi que des solutions de Guerre Électronique.Le Département Simulation de la Direction Technique a en charge le développement et la promotion aux services des utilisateurs (internes, externes) de simulation de différents niveaux concourant à la qualification des systèmes embarqués développés par la Country Business Unit DMS (Radar et détection passive électromagnétique), concourant à la spécification des futurs systèmes, concourant à la formation et à l'entraînement de l'utilisateur final.En rejoignant ce Département Simulation de la Direction Technique, dans le cadre du développement des produits et services numériques de simulation vous aurez pour principale mission, d’améliorer les moyens d'analyse de données issues des simulations ou d'équipements réel.Dans ce contexte, vous vous verrez confier les missions suivantes :   - Développer / Améliorer les mécanismes basés sur une approche «  big data »  pour la collecte, la mise en forme et le filtrage des données   - Développer / Améliorer les interfaces permettant à l'utilisateur de visualiser / sélectionner des données   - Développer / Améliorer les mécanismes d'exportation de données afin de les utiliser dans d'autres outils   - Développer de nouvelles fonctionnalités d’aide à l’analyse (détection automatiques de valeurs anormales, instabilités…)La perspective de rejoindre une équipe de passionnés vous intéresse ? Alors, rejoignez-nous en postulant à cette offre.Tous nos stages sont conventionnés et soumis à une gratification dont le montant est déterminé selon votre niveau d’études.Thales reconnait tous les talents, la diversité est notre meilleur atout. Postulez et rejoignez nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Ingénieur(e) études et développement Big Data – Transport - Nantes",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "technologiquespark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git/jenkinsles",
                "git/jenkinsles"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/stage-ingenieur-etudes-et-developpement-big-data-transport-nantes_nantes_SS_2OA9QNO?q=a4acfb2fdef1469051414f8389f464c2&o=6f2e4462-ac07-46ef-9fa0-eebd72b0ba6f",
        "description": "Descriptif du posteVotre environnement de travail Dans le cadre de la transformation du SI Post-Opérationnel vers l’offre Big Data d’un acteur majeur du transport logistique, vous intervenez sur les phases de réalisation des solutions délivrées et sur les phases amont d’études :Etudes fonctionnelles et techniques ;Ingestion des flux de données ;Modélisation et traitements des données ;Restitution et valorisation des données au sein de solution de data visualisation.Votre rôle et vos missionsVous intégrez donc le Centre de compétences BI & Big Data qui accompagne notre client sur les technologies de traitement et de valorisation des données.Nos équipes à taille humaine y mènent des projets Agiles, entourées de leaders techniques apportant leur expertise, au quotidien et lors de formations dédiées. Ils vous encadrent sur vos missions, avec votre Project manager et tuteur de stage.Environnement technologiqueSpark, Scala, Kafka, Nifi, Cloud, K8s, Airflow, Power BI, Git/JenkinsLes apports du stage Ce stage vous permet de :Découvrir le framework Scrum ;Approfondir votre connaissance des environnements Big Data ;Concevoir des solutions industrielles à forte plus-value métier ;Imaginer des usages de la donnée et développer sa force de proposition ;Disposer d’un environnement de travail présentant une solide expertise technologique ;Interagir au sein d’équipes multidisciplinaires.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressant : des titres restaurants, accès aux subventions des activités sociales & culturelles.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria AcademyLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».De très nombreuses opportunités en CDI peuvent vous attendre à l’issue du stage.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Ingénieur(e) études et développement Big Data – Transport - Nantes",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "technologiquespark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "git/jenkinsles",
                "git/jenkinsles"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/stage-ingenieur-etudes-et-developpement-big-data-transport-nantes_nantes_SS_2OA9QNO?q=a4acfb2fdef1469051414f8389f464c2&o=6f2e4462-ac07-46ef-9fa0-eebd72b0ba6f",
        "description": "Descriptif du posteVotre environnement de travail Dans le cadre de la transformation du SI Post-Opérationnel vers l’offre Big Data d’un acteur majeur du transport logistique, vous intervenez sur les phases de réalisation des solutions délivrées et sur les phases amont d’études :Etudes fonctionnelles et techniques ;Ingestion des flux de données ;Modélisation et traitements des données ;Restitution et valorisation des données au sein de solution de data visualisation.Votre rôle et vos missionsVous intégrez donc le Centre de compétences BI & Big Data qui accompagne notre client sur les technologies de traitement et de valorisation des données.Nos équipes à taille humaine y mènent des projets Agiles, entourées de leaders techniques apportant leur expertise, au quotidien et lors de formations dédiées. Ils vous encadrent sur vos missions, avec votre Project manager et tuteur de stage.Environnement technologiqueSpark, Scala, Kafka, Nifi, Cloud, K8s, Airflow, Power BI, Git/JenkinsLes apports du stage Ce stage vous permet de :Découvrir le framework Scrum ;Approfondir votre connaissance des environnements Big Data ;Concevoir des solutions industrielles à forte plus-value métier ;Imaginer des usages de la donnée et développer sa force de proposition ;Disposer d’un environnement de travail présentant une solide expertise technologique ;Interagir au sein d’équipes multidisciplinaires.Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressant : des titres restaurants, accès aux subventions des activités sociales & culturelles.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria AcademyLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».De très nombreuses opportunités en CDI peuvent vous attendre à l’issue du stage.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Ingénieur(e) études et développement Big Data – Transport - Nantes",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "technologiquespark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale",
                "digital",
                "git/jenkinsles",
                "git/jenkinsles"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/stage-ingenieur-etudes-et-developpement-big-data-transport-nantes_nantes_SS_zRWxOZK?q=a4acfb2fdef1469051414f8389f464c2&o=5c625544-adc9-4915-8625-70aa3fedaae0",
        "description": "Descriptif du posteDescription de l’entreprise Sopra Steria, acteur majeur de la Tech en Europe avec 56 000 collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En 2023, le Groupe a réalisé un chiffre d’affaires de 5,8 milliards d’euros.The world is how we shape itDescription du poste Votre environnement de travailDans le cadre de la transformation du SI Post-Opérationnel vers l’offre Big Data d’un acteur majeur du transport logistique, vous intervenez sur les phases de réalisation des solutions délivrées et sur les phases amont d’études :Etudes fonctionnelles et techniques ;Ingestion des flux de données ;Modélisation et traitements des données ;Restitution et valorisation des données au sein de solution de data visualisation.Votre rôle et vos missionsVous intégrez donc le Centre de compétences BI & Big Data qui accompagne notre client sur les technologies de traitement et de valorisation des données.Nos équipes à taille humaine y mènent des projets Agiles, entourées de leaders techniques apportant leur expertise, au quotidien et lors de formations dédiées. Ils vous encadrent sur vos missions, avec votre Project manager et tuteur de stage.Environnement technologiqueSpark, Scala, Kafka, Nifi, Cloud, K8s, Airflow, Power BI, Git/JenkinsLes apports du stageCe stage vous permet de :Découvrir le framework Scrum ;Approfondir votre connaissance des environnements Big Data ;Concevoir des solutions industrielles à forte plus-value métier ;Imaginer des usages de la donnée et développer sa force de proposition ;Disposer d’un environnement de travail présentant une solide expertise technologique ;Interagir au sein d’équipes multidisciplinaires.Qualifications Votre profilVous êtes curieux (se), vous avez le sens du service, un bon relationnel et vous aimez travailler en équipe. Vous avez de bonnes capacités d’adaptation et vous êtes force de proposition.Actuellement en dernière année d’école d’Ingénieurs, en Master 2 informatique ou formation équivalente, vous avez des aptitudes à résoudre des problèmes complexes et vous avez une bonne compréhension des bases de données relationnelles.Informations supplémentaires Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.Un package avantages intéressant : des titres restaurants, accès aux subventions des activités sociales & culturelles.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria AcademyLa possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».De très nombreuses opportunités en CDI peuvent vous attendre à l’issue du stage.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Ingénieur(e) études et développement Big Data – Transport - Nantes",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "technologiquespark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale",
                "digital",
                "git/jenkinsles",
                "git/jenkinsles"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/stage-ingenieur-etudes-et-developpement-big-data-transport-nantes_nantes_SS_zRWxOZK?q=a4acfb2fdef1469051414f8389f464c2&o=5c625544-adc9-4915-8625-70aa3fedaae0",
        "description": "Descriptif du posteDescription de l’entreprise Sopra Steria, acteur majeur de la Tech en Europe avec 56 000 collaborateurs dans près de 30 pays, est reconnu pour ses activités de conseil, de services numériques et d’édition de logiciels. Il aide ses clients à mener leur transformation digitale et à obtenir des bénéfices concrets et durables. Le Groupe apporte une réponse globale aux enjeux de compétitivité des grandes entreprises et organisations, combinant une connaissance approfondie des secteurs d’activité et des technologies innovantes à une approche résolument collaborative.Sopra Steria place l’humain au centre de son action et s’engage auprès de ses clients à tirer le meilleur parti du digital pour construire un avenir positif. En 2023, le Groupe a réalisé un chiffre d’affaires de 5,8 milliards d’euros.The world is how we shape itDescription du poste Votre environnement de travailDans le cadre de la transformation du SI Post-Opérationnel vers l’offre Big Data d’un acteur majeur du transport logistique, vous intervenez sur les phases de réalisation des solutions délivrées et sur les phases amont d’études :Etudes fonctionnelles et techniques ;Ingestion des flux de données ;Modélisation et traitements des données ;Restitution et valorisation des données au sein de solution de data visualisation.Votre rôle et vos missionsVous intégrez donc le Centre de compétences BI & Big Data qui accompagne notre client sur les technologies de traitement et de valorisation des données.Nos équipes à taille humaine y mènent des projets Agiles, entourées de leaders techniques apportant leur expertise, au quotidien et lors de formations dédiées. Ils vous encadrent sur vos missions, avec votre Project manager et tuteur de stage.Environnement technologiqueSpark, Scala, Kafka, Nifi, Cloud, K8s, Airflow, Power BI, Git/JenkinsLes apports du stageCe stage vous permet de :Découvrir le framework Scrum ;Approfondir votre connaissance des environnements Big Data ;Concevoir des solutions industrielles à forte plus-value métier ;Imaginer des usages de la donnée et développer sa force de proposition ;Disposer d’un environnement de travail présentant une solide expertise technologique ;Interagir au sein d’équipes multidisciplinaires.Qualifications Votre profilVous êtes curieux (se), vous avez le sens du service, un bon relationnel et vous aimez travailler en équipe. Vous avez de bonnes capacités d’adaptation et vous êtes force de proposition.Actuellement en dernière année d’école d’Ingénieurs, en Master 2 informatique ou formation équivalente, vous avez des aptitudes à résoudre des problèmes complexes et vous avez une bonne compréhension des bases de données relationnelles.Informations supplémentaires Un accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions.Un package avantages intéressant : des titres restaurants, accès aux subventions des activités sociales & culturelles.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria AcademyLa possibilité de s’engager auprès de notre fondation ou de notre partenaire « Vendredi ».De très nombreuses opportunités en CDI peuvent vous attendre à l’issue du stage.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer H/F - CDI - Lyon",
        "contract_type": "CDI",
        "salary": "38K à 51K €",
        "company": "evoteo",
        "location": "Lyon",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "35",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "3",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python/javascript,",
                "(python/pyspark,",
                "python",
                "python/javascript,",
                "javascript"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(python/pyspark,",
                "spark,",
                "pysparkparticiper",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow)implémenter"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-h-f-cdi-lyon_lyon_EVOTE_q7XAYaq?q=a4acfb2fdef1469051414f8389f464c2&o=174540ca-e747-446e-8193-961c1f6fa7ae",
        "description": "Descriptif du posteVos missions :Au sein de l’équipe agile, vous serez en charge de :Contribuer à la migration de tous les assets (flux, batch en python/Javascript, API)Être en relation avec les équipes infrastructure ainsi qu’avec les autres équipes du train SafeAnalyser les anomalies et proposer les solutions, court / moyen termeDévelopper sous Databricks (Python/PySpark, SQL, Spark, Airflow)Implémenter et Maintenir les algorithmes (Batch MapReduce) et les APIs Rest : Javascript (le plus important), Python (ScikitLearn) ou PySparkParticiper à la modélisation et l’analyse de données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer H/F - CDI - Lyon",
        "contract_type": "CDI",
        "salary": "38K à 51K €",
        "company": "evoteo",
        "location": "Lyon",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "35",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "3",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python/javascript,",
                "(python/pyspark,",
                "python",
                "python/javascript,",
                "javascript"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "(python/pyspark,",
                "spark,",
                "pysparkparticiper",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow)implémenter"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/evoteo/jobs/data-engineer-h-f-cdi-lyon_lyon_EVOTE_q7XAYaq?q=a4acfb2fdef1469051414f8389f464c2&o=174540ca-e747-446e-8193-961c1f6fa7ae",
        "description": "Descriptif du posteVos missions :Au sein de l’équipe agile, vous serez en charge de :Contribuer à la migration de tous les assets (flux, batch en python/Javascript, API)Être en relation avec les équipes infrastructure ainsi qu’avec les autres équipes du train SafeAnalyser les anomalies et proposer les solutions, court / moyen termeDévelopper sous Databricks (Python/PySpark, SQL, Spark, Airflow)Implémenter et Maintenir les algorithmes (Batch MapReduce) et les APIs Rest : Javascript (le plus important), Python (ScikitLearn) ou PySparkParticiper à la modélisation et l’analyse de données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer DevOps (M/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Veolia",
        "location": "Saint-Maurice",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Environnement / Développement durable, Collectivités publiques et territoriales, Bâtiment / Travaux publics, Energie",
            "company_size": "213000",
            "creation_date": "1853",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": "42,9 Md€",
            "proportion_female": "20",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams:",
                "teams",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/veolia/jobs/data-engineer-devops-m-f_saint-maurice_VEOLI_Vdp7NdN?q=a4acfb2fdef1469051414f8389f464c2&o=5ff767d4-605a-4793-a655-59f4b80c9613",
        "description": "Descriptif du posteWe are looking for an experienced data engineer to join our team on this fantastic journey, working together to ensure that our customers get the best experience possible.We have a huge potential for analytics and machine learning, based on our IoT and enterprise data, which require solid data engineering.Your work will have very concrete outcomes and observable value.You will be fully integrated into the development team, which is organised in an Agile Scrum fashion, and with an excellent team spirit.You will:Design, develop, and test data pipeline infrastructures and database systemsCollaborate with data analysts and data scientists to build and improve data models, algorithms and predictive models according to the busines’s requirementsEnsure that all current data infrastructures and processes meet industry standardsUtilise cutting edge data engineering technologies and softwareSearch for elements of the data collection and processing that need improvement, and improve themImplement systems to monitor data quality for optimised accuracy and clarityDesign and implement scalable and high-performing solutionsCollaborate with several other teams: Product and Business Development teams for HUBGRADE, Corporate IS&T teams (Data Lake, Cybersecurity, ERP, Networking, FinOps, …), external Digital Partners.Continuously transfer knowledge to the Run&Support teamTake part in L3 supportIdentify synergies between software components and improve efficiency of development and code maintenanceKeep the product vision in mind while working on detailsHelp to build flexible, future-proof solutionsContinuously improve our agile development process, architecture, and engineering practicesMentor and coach less experienced engineers on the teamThe platform being very rich and diverse, you will have the opportunity to work on different areas and projects.Additional InformationAs an inclusive company, Veolia is committed to diversity and gives equal consideration to all applications, without discrimination."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer DevOps (M/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Veolia",
        "location": "Saint-Maurice",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Environnement / Développement durable, Collectivités publiques et territoriales, Bâtiment / Travaux publics, Energie",
            "company_size": "213000",
            "creation_date": "1853",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": "42,9 Md€",
            "proportion_female": "20",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams:",
                "teams",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/veolia/jobs/data-engineer-devops-m-f_saint-maurice_VEOLI_Vdp7NdN?q=a4acfb2fdef1469051414f8389f464c2&o=5ff767d4-605a-4793-a655-59f4b80c9613",
        "description": "Descriptif du posteWe are looking for an experienced data engineer to join our team on this fantastic journey, working together to ensure that our customers get the best experience possible.We have a huge potential for analytics and machine learning, based on our IoT and enterprise data, which require solid data engineering.Your work will have very concrete outcomes and observable value.You will be fully integrated into the development team, which is organised in an Agile Scrum fashion, and with an excellent team spirit.You will:Design, develop, and test data pipeline infrastructures and database systemsCollaborate with data analysts and data scientists to build and improve data models, algorithms and predictive models according to the busines’s requirementsEnsure that all current data infrastructures and processes meet industry standardsUtilise cutting edge data engineering technologies and softwareSearch for elements of the data collection and processing that need improvement, and improve themImplement systems to monitor data quality for optimised accuracy and clarityDesign and implement scalable and high-performing solutionsCollaborate with several other teams: Product and Business Development teams for HUBGRADE, Corporate IS&T teams (Data Lake, Cybersecurity, ERP, Networking, FinOps, …), external Digital Partners.Continuously transfer knowledge to the Run&Support teamTake part in L3 supportIdentify synergies between software components and improve efficiency of development and code maintenanceKeep the product vision in mind while working on detailsHelp to build flexible, future-proof solutionsContinuously improve our agile development process, architecture, and engineering practicesMentor and coach less experienced engineers on the teamThe platform being very rich and diverse, you will have the opportunity to work on different areas and projects.Additional InformationAs an inclusive company, Veolia is committed to diversity and gives equal consideration to all applications, without discrimination."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer  - H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CLS – Collecte Localisation Satellites",
        "location": "Ramonville-Saint-Agne",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-13",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "900",
            "creation_date": "1986",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "180",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws),sur"
            ],
            "DevTools": [
                "digitale",
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "(collaboration,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cls-group/jobs/data-engineer-h-f_ramonville-saint-agne_CCLS_JG1db4G?q=a4acfb2fdef1469051414f8389f464c2&o=792fac2d-9f5e-44b5-b83a-c63548c02202",
        "description": "Descriptif du posteLa cellule transfo & modélisation est une structure interne d’innovation transverse au sein du groupe CLS, constituée de Data Scientists, de développeurs et de Data Engineers. Son objectif principal est de concevoir des produits pour enrichir et valoriser la donnée dans les solutions CLS et de développer les pratiques data/IA au sein de CLS.Les Data Engineers travaillent à la fois sur des sujets d’innovation et de production. Dans leur rôle transverse, ils sont amenés à collaborer avec les équipes métier, développement, IT et travailler :Sur des plateformes de type datalake on-premise ou cloud (AWS),Sur une diversité grandissante de données (données satellites optiques et radars, météo, données océaniques, trajectoires, télémétrie…) dans un cadre de projet de transformation digitale de l’entreprise,Pour différents cas d’usage métier (sécurité maritime, pêches durables, surveillance de l’environnement…)Dans ce cadre, nous cherchons un Data Engineer pour renforcer l’équipe.Ce que nous attendons de vous :  Comprendre le besoin métier et formuler le problème en tenant compte des données envisagées, de l’infrastructure disponible et des contraintes du projet.Analyser les approches possibles et explorer des nouvelles technos si nécessaire.Concevoir et mettre en place des systèmes de données résilients et sécurisés (pub/sub, systèmes temps-réels, API,).Concevoir et implémenter des pipelines d’ingestion et de processing de données (structurées / non-structurées), à des fréquences variables (batch, micro-batch, temps réel.Mettre en œuvre des outils de stockage appropriés (base de données, stockage distribué…).Industrialiser, optimiser les traitements batch ou temps réel.Collaborer avec les Data Scientists lors de leur mise en œuvre de machine learning sur les plateformes big data.Participer ponctuellement à des appels d’offre : compréhension du besoin, chiffrage des activités, rédaction de la partie technique des propositions.Être force de proposition pour améliorer nos pratiques data (collaboration, pratiques de code, standardisation des solutions, …) au sein du Datalab, de la Direction Advanced Tech et de CLS au global.Contribuer à la transformation digitale sur les futurs sujets autour de la data : datalake, data mesh, data gouvernance,Participer activement à la vie d’équipe du Datalab (partage d’expérience, veille technologique)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer  - H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CLS – Collecte Localisation Satellites",
        "location": "Ramonville-Saint-Agne",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-13",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "900",
            "creation_date": "1986",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "180",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws),sur"
            ],
            "DevTools": [
                "digitale",
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "(collaboration,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cls-group/jobs/data-engineer-h-f_ramonville-saint-agne_CCLS_JG1db4G?q=a4acfb2fdef1469051414f8389f464c2&o=792fac2d-9f5e-44b5-b83a-c63548c02202",
        "description": "Descriptif du posteLa cellule transfo & modélisation est une structure interne d’innovation transverse au sein du groupe CLS, constituée de Data Scientists, de développeurs et de Data Engineers. Son objectif principal est de concevoir des produits pour enrichir et valoriser la donnée dans les solutions CLS et de développer les pratiques data/IA au sein de CLS.Les Data Engineers travaillent à la fois sur des sujets d’innovation et de production. Dans leur rôle transverse, ils sont amenés à collaborer avec les équipes métier, développement, IT et travailler :Sur des plateformes de type datalake on-premise ou cloud (AWS),Sur une diversité grandissante de données (données satellites optiques et radars, météo, données océaniques, trajectoires, télémétrie…) dans un cadre de projet de transformation digitale de l’entreprise,Pour différents cas d’usage métier (sécurité maritime, pêches durables, surveillance de l’environnement…)Dans ce cadre, nous cherchons un Data Engineer pour renforcer l’équipe.Ce que nous attendons de vous :  Comprendre le besoin métier et formuler le problème en tenant compte des données envisagées, de l’infrastructure disponible et des contraintes du projet.Analyser les approches possibles et explorer des nouvelles technos si nécessaire.Concevoir et mettre en place des systèmes de données résilients et sécurisés (pub/sub, systèmes temps-réels, API,).Concevoir et implémenter des pipelines d’ingestion et de processing de données (structurées / non-structurées), à des fréquences variables (batch, micro-batch, temps réel.Mettre en œuvre des outils de stockage appropriés (base de données, stockage distribué…).Industrialiser, optimiser les traitements batch ou temps réel.Collaborer avec les Data Scientists lors de leur mise en œuvre de machine learning sur les plateformes big data.Participer ponctuellement à des appels d’offre : compréhension du besoin, chiffrage des activités, rédaction de la partie technique des propositions.Être force de proposition pour améliorer nos pratiques data (collaboration, pratiques de code, standardisation des solutions, …) au sein du Datalab, de la Direction Advanced Tech et de CLS au global.Contribuer à la transformation digitale sur les futurs sujets autour de la data : datalake, data mesh, data gouvernance,Participer activement à la vie d’équipe du Datalab (partage d’expérience, veille technologique)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (m/f/d)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Deezer",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-24",
        "company_data": {
            "sector": "Média, Musique, Digital",
            "company_size": "600",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable,",
                "scalableparticipate"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams.what"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/deezer/jobs/data-engineer-m-f-d_paris?q=a4acfb2fdef1469051414f8389f464c2&o=da97c7c2-27cf-48fc-b087-b97dafc99dd4",
        "description": "Descriptif du posteData Platform is embedded within the Data Operations team whose mission is to provide deezer teams with reliable data, efficient and unified solutions that are easy to use.Data Platform engineers focus on building & maintaining a reliable, scalable, resource-efficient data platform, services to meet data users’ needs. At Deezer the “Data Platform” refers to the set of tools, services and frameworks available to access data & empower teams.What you will do:Design, develop and improve ingestion & transformation data pipelines Develop, deploy & manage data platform components (notebooks, orchestrator..)Ensure, with the support of the tech leader, that all the code written and the architecture is of high quality and scalableParticipate in the data community by collaborating with other data engineers, analysts and scientists Participate in projects planning, standups and retrospectivesBeing a technical support for your stakeholdersAnd much more!"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (m/f/d)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Deezer",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-24",
        "company_data": {
            "sector": "Média, Musique, Digital",
            "company_size": "600",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable,",
                "scalableparticipate"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams.what"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/deezer/jobs/data-engineer-m-f-d_paris?q=a4acfb2fdef1469051414f8389f464c2&o=da97c7c2-27cf-48fc-b087-b97dafc99dd4",
        "description": "Descriptif du posteData Platform is embedded within the Data Operations team whose mission is to provide deezer teams with reliable data, efficient and unified solutions that are easy to use.Data Platform engineers focus on building & maintaining a reliable, scalable, resource-efficient data platform, services to meet data users’ needs. At Deezer the “Data Platform” refers to the set of tools, services and frameworks available to access data & empower teams.What you will do:Design, develop and improve ingestion & transformation data pipelines Develop, deploy & manage data platform components (notebooks, orchestrator..)Ensure, with the support of the tech leader, that all the code written and the architecture is of high quality and scalableParticipate in the data community by collaborating with other data engineers, analysts and scientists Participate in projects planning, standups and retrospectivesBeing a technical support for your stakeholdersAnd much more!"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer GCP (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Apside",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 2",
        "education_level": null,
        "publication_date": "2025-01-12",
        "company_data": {
            "sector": "SaaS / Cloud Services, Big Data, Cybersécurité",
            "company_size": "3000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "232",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp",
                "(gcp)",
                "gcp"
            ],
            "DevTools": [
                "(github)"
            ],
            "OS": null,
            "DBMS": [
                "(bigquery,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": [
                "terraform"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "devops",
                "cloud",
                "cloud",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-gcp-f-h_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=6b6aabb9-8690-43d3-ae3b-c187b81e72c0",
        "description": "Descriptif du posteLe poste :Pour le compte de notre client acteur mondial de la beauté et cosmétique, tu interviendras dans la transformation d’un projet worlwide, où tu devras développer la Data Platform et l'ensemble des services Data qui seront exposés aux différentes équipes du client. Aussi, tu seras amené à développer des use cases data. Dans ce sens, tes missions seront les suivantes : Designer l'architecture et développer la solutionDéfinir et développer les Data ModelÊtre garant de la qualité du codeÊtre DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des développements)Environnement technique : GCP (BigQuery, Cloud Run, Cloud Build) SQL  Python DevOps (Github) API Development Terraform Méthodologie AgileRequirements:Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?Rejoins Apside Paris pour travailler sur nos projets de demain !Toi ? Tu as déjà travaillé sur Google Cloud Platform (GCP) ?Tu es autonome, rigoureux, et bon communiquant ?Tu souhaites participer à un projet d’envergure associant cloud et Big Data ?Alors ce poste de Data Engineer GCP est fait pour toi !Et la suite ?Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur !Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages :)Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences et te challenger.Les infos en plus !Télétravail ! 😊Un salaire attractif en fonction de ton expérience + différents avantagesUn groupe en pleine croissance avec un management bienveillantEt une évolution technique personnalisée avec la possibilité de se former via une plateforme interneTu souhaites donner un nouvel élan à ta carrière ? Rejoins la vie Apsidienne !Pour en savoir plus à www.apside.comSR"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer GCP (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Apside",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 2",
        "education_level": null,
        "publication_date": "2025-01-12",
        "company_data": {
            "sector": "SaaS / Cloud Services, Big Data, Cybersécurité",
            "company_size": "3000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "232",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp",
                "(gcp)",
                "gcp"
            ],
            "DevTools": [
                "(github)"
            ],
            "OS": null,
            "DBMS": [
                "(bigquery,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": [
                "terraform"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "devops",
                "cloud",
                "cloud",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/apside/jobs/data-engineer-gcp-f-h_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=6b6aabb9-8690-43d3-ae3b-c187b81e72c0",
        "description": "Descriptif du posteLe poste :Pour le compte de notre client acteur mondial de la beauté et cosmétique, tu interviendras dans la transformation d’un projet worlwide, où tu devras développer la Data Platform et l'ensemble des services Data qui seront exposés aux différentes équipes du client. Aussi, tu seras amené à développer des use cases data. Dans ce sens, tes missions seront les suivantes : Designer l'architecture et développer la solutionDéfinir et développer les Data ModelÊtre garant de la qualité du codeÊtre DevOps (Utilisation/mise en place de chaine CI/CD et support niveau L3 des développements)Environnement technique : GCP (BigQuery, Cloud Run, Cloud Build) SQL  Python DevOps (Github) API Development Terraform Méthodologie AgileRequirements:Envie de rejoindre une entreprise apprenante ? Engagée pour t’accompagner dans ton évolution professionnelle et dans tes projets personnels ?Rejoins Apside Paris pour travailler sur nos projets de demain !Toi ? Tu as déjà travaillé sur Google Cloud Platform (GCP) ?Tu es autonome, rigoureux, et bon communiquant ?Tu souhaites participer à un projet d’envergure associant cloud et Big Data ?Alors ce poste de Data Engineer GCP est fait pour toi !Et la suite ?Tu rencontres d’abord l’équipe RH pour parler de tes attentes, ton projet, ton futur !Puis les managers pour parler concret : missions, projets, parcours de carrière, et bien sûr salaire et avantages :)Et tu discutes avec un de nos Tech Leads, pour évaluer tes compétences et te challenger.Les infos en plus !Télétravail ! 😊Un salaire attractif en fonction de ton expérience + différents avantagesUn groupe en pleine croissance avec un management bienveillantEt une évolution technique personnalisée avec la possibilité de se former via une plateforme interneTu souhaites donner un nouvel élan à ta carrière ? Rejoins la vie Apsidienne !Pour en savoir plus à www.apside.comSR"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Analytics Engineer (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Younited",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "FinTech / InsurTech, Économie collaborative",
            "company_size": "600",
            "creation_date": "2009",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/younited/jobs/analytics-engineer-f-h_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=08ebb18e-42fb-4f75-8776-3328c0a2d937",
        "description": "Descriptif du poste📋 ContexteEn tant que Senior Analytics Engineer, tu rejoindras la team Data Engineering, l’équipe la plus transverse de tout Younited, en contact avec l’ensemble des métiers et en charge d’imaginer la meilleure base data sans que tout s’écroule !Tes responsabilités :Concevoir, mettre en œuvre, maintenir, documenter et promouvoir des produits de données robustes et pertinents (entrepôts, marts, exportations et tableaux de bord).Développer, optimiser et maintenir les pipelines ETL.Assister l’équipe commerciale dans le développement de leurs produits de données.Encadrer les utilisateurs de Younited, en les aidant à exploiter efficacement les produits de données et en favorisant leur indépendance dans les tâches liées aux données."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Analytics Engineer (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Younited",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "FinTech / InsurTech, Économie collaborative",
            "company_size": "600",
            "creation_date": "2009",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/younited/jobs/analytics-engineer-f-h_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=08ebb18e-42fb-4f75-8776-3328c0a2d937",
        "description": "Descriptif du poste📋 ContexteEn tant que Senior Analytics Engineer, tu rejoindras la team Data Engineering, l’équipe la plus transverse de tout Younited, en contact avec l’ensemble des métiers et en charge d’imaginer la meilleure base data sans que tout s’écroule !Tes responsabilités :Concevoir, mettre en œuvre, maintenir, documenter et promouvoir des produits de données robustes et pertinents (entrepôts, marts, exportations et tableaux de bord).Développer, optimiser et maintenir les pipelines ETL.Assister l’équipe commerciale dans le développement de leurs produits de données.Encadrer les utilisateurs de Younited, en les aidant à exploiter efficacement les produits de données et en favorisant leur indépendance dans les tâches liées aux données."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Data & IA [CDI]",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "WedR",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "30",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "4,6M",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "(git)communiquer"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/wedr/jobs/data-scientist-cdi_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=087c62bd-7bfa-4f3b-aaa0-c5e20dca4e15",
        "description": "Descriptif du posteTu as envie de faire partie d’un collectif d’entrepreneurs, tu recherches des passionnés de Tech pour développer vos expertises ? Pas de doute, tu as toqué à la bonne porte ! La communauté Tech Shakers de WedR regroupe les expertises suivantes : Cloud & DevOps, l’Architecture ouverte/API et enfin la Data & l’IA.MISSIONSContribuer aux projets Data et IA de nos clients, à toutes les étapes du projetDelivery projetQualifier le besoin avec les équipes métiers, et être capable de proposer des solutions techniques (IA/Data) pour y répondreExplorer et donner du sens à la donnée (de la collecte à l’analyse, en terminant par de la Data Viz)Sélectionner, implémenter et déployer des algorithmes de Machine Learning dans des environnements de productionParticiper à la qualité du code et des livrables :savoir mettre en place des tests unitaires et versionner les développements (Git)Communiquer clairement les résultats du projet à différents acteurs, du responsable technique à l’expert métierConseilÊtre capable de vulgariser auprès des équipes métier des concepts techniques/IA ainsi que les avancées techniquesFaire de la veille sur les nouvelles technologies / solutions / librairies utiles aux clients et projetsFormuler des convictions étayées sur les best practicesTravailler de concert avec les équipes produit pour suggérer des cas d’usages & méthode de delivery à nos clientsContribuer au développement interne de WedRParticiper à la définition de la roadmap et de la stratégie Data / IAParticiper activement à la génération de business Data / IA (pitchs, propales, recherche de contacts, etc.)Proposer et participer au développement d’outils internes divers, sur des sujets tels que la classification ou l’extraction d’informationParticiper au recrutement, à la montée en compétences et au management de l’équipe Data / IA"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Data & IA [CDI]",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "WedR",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "30",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "4,6M",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "(git)communiquer"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/wedr/jobs/data-scientist-cdi_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=087c62bd-7bfa-4f3b-aaa0-c5e20dca4e15",
        "description": "Descriptif du posteTu as envie de faire partie d’un collectif d’entrepreneurs, tu recherches des passionnés de Tech pour développer vos expertises ? Pas de doute, tu as toqué à la bonne porte ! La communauté Tech Shakers de WedR regroupe les expertises suivantes : Cloud & DevOps, l’Architecture ouverte/API et enfin la Data & l’IA.MISSIONSContribuer aux projets Data et IA de nos clients, à toutes les étapes du projetDelivery projetQualifier le besoin avec les équipes métiers, et être capable de proposer des solutions techniques (IA/Data) pour y répondreExplorer et donner du sens à la donnée (de la collecte à l’analyse, en terminant par de la Data Viz)Sélectionner, implémenter et déployer des algorithmes de Machine Learning dans des environnements de productionParticiper à la qualité du code et des livrables :savoir mettre en place des tests unitaires et versionner les développements (Git)Communiquer clairement les résultats du projet à différents acteurs, du responsable technique à l’expert métierConseilÊtre capable de vulgariser auprès des équipes métier des concepts techniques/IA ainsi que les avancées techniquesFaire de la veille sur les nouvelles technologies / solutions / librairies utiles aux clients et projetsFormuler des convictions étayées sur les best practicesTravailler de concert avec les équipes produit pour suggérer des cas d’usages & méthode de delivery à nos clientsContribuer au développement interne de WedRParticiper à la définition de la roadmap et de la stratégie Data / IAParticiper activement à la génération de business Data / IA (pitchs, propales, recherche de contacts, etc.)Proposer et participer au développement d’outils internes divers, sur des sujets tels que la classification ou l’extraction d’informationParticiper au recrutement, à la montée en compétences et au management de l’équipe Data / IA"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Cloud Azure (H/F)",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Klint",
        "location": "Levallois-Perret",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Logiciels, Digital Marketing / Data Marketing, IT / Digital",
            "company_size": "120",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "14",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java)déployer",
                "(scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure."
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudaccompagner",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/klint-consulting/jobs/data-engineer-cloud-azure-h-f_levallois-perret?q=80f6ac0930b006f8455c20e4f0d394af&o=d03e3fd8-272b-4130-b947-4ef8abb5177d",
        "description": "Descriptif du postePour renforcer notre équipe Data, et participer à la diversification de nos activités, nous recherchons un Data Engineer Cloud Azure.  Votre mission :  Participer au développement des prestations proposées autour du CloudAccompagner les consultants de l’équipe Data qui le souhaitent dans le développement de leurs compétences sur votre domaine d’expertiseConcevoir, implémenter et optimiser les modèles visant à stocker et traiter les donnéesContrôler et évaluer la qualité des modèlesImplémenter, optimiser et maintenir des algorithmes de traitement de données distribués (Scala, Spark, Java)Déployer et industrialiser les pipelines de collecte, d’ingestion et de stockage de donnéesSurveiller et assurer le bon fonctionnement des pipelines en productionAssurer une veille technologique sur l’IA et les Cloud Data PlatformParticiper à la définition, conception et/ou évolution de l’architecture, en intégrant de nouveaux composants (frameworks, bibliothèques…) permettant de mieux répondre aux besoins"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Cloud Azure (H/F)",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Klint",
        "location": "Levallois-Perret",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Logiciels, Digital Marketing / Data Marketing, IT / Digital",
            "company_size": "120",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "14",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java)déployer",
                "(scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure."
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudaccompagner",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/klint-consulting/jobs/data-engineer-cloud-azure-h-f_levallois-perret?q=80f6ac0930b006f8455c20e4f0d394af&o=d03e3fd8-272b-4130-b947-4ef8abb5177d",
        "description": "Descriptif du postePour renforcer notre équipe Data, et participer à la diversification de nos activités, nous recherchons un Data Engineer Cloud Azure.  Votre mission :  Participer au développement des prestations proposées autour du CloudAccompagner les consultants de l’équipe Data qui le souhaitent dans le développement de leurs compétences sur votre domaine d’expertiseConcevoir, implémenter et optimiser les modèles visant à stocker et traiter les donnéesContrôler et évaluer la qualité des modèlesImplémenter, optimiser et maintenir des algorithmes de traitement de données distribués (Scala, Spark, Java)Déployer et industrialiser les pipelines de collecte, d’ingestion et de stockage de donnéesSurveiller et assurer le bon fonctionnement des pipelines en productionAssurer une veille technologique sur l’IA et les Cloud Data PlatformParticiper à la définition, conception et/ou évolution de l’architecture, en intégrant de nouveaux composants (frameworks, bibliothèques…) permettant de mieux répondre aux besoins"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer PySpark - Data Factory - Services Financiers - Ile de France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-pyspark-data-factory-services-financiers-ile-de-france_paris_SS_ZQZRr03?q=80f6ac0930b006f8455c20e4f0d394af&o=7b86e236-93db-4258-9d5c-87b8521b4f9e",
        "description": "Descriptif du posteNotre Data FactoryVous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Paris ! Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.Rejoindre notre Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et mission :Dans le cadre de la mise en place du centre Data pour un grand acteur financier de l’état et selon votre appétence, vous participerez à plusieurs étapes de la chaîne :- La compréhension des besoins métiers et la traduction solution de data ingénierie- La mise en œuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;- La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;- Le traitement de la donnée jusqu'à l'exposition au métier ;- La mise en place de la chaine CI/CD et de sa supervision ;- La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients. Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore). Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer PySpark - Data Factory - Services Financiers - Ile de France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-pyspark-data-factory-services-financiers-ile-de-france_paris_SS_ZQZRr03?q=80f6ac0930b006f8455c20e4f0d394af&o=7b86e236-93db-4258-9d5c-87b8521b4f9e",
        "description": "Descriptif du posteNotre Data FactoryVous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Paris ! Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.Vous êtes accompagné(e) au développement de vos connaissances aux travers de différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.Rejoindre notre Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et mission :Dans le cadre de la mise en place du centre Data pour un grand acteur financier de l’état et selon votre appétence, vous participerez à plusieurs étapes de la chaîne :- La compréhension des besoins métiers et la traduction solution de data ingénierie- La mise en œuvre de solution d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;- La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;- Le traitement de la donnée jusqu'à l'exposition au métier ;- La mise en place de la chaine CI/CD et de sa supervision ;- La veille technologie avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients. Informations supplémentairesUn accord télétravail pour télétravailler jusqu'à 2 jours par semaine selon vos missions.Un package avantages intéressants : une mutuelle, un CSE, des titres restaurants, un accord d'intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 50 métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l'app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore). Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Services Financiers - Nantes",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-nantes_nantes_SS_DMz2RdN?q=80f6ac0930b006f8455c20e4f0d394af&o=55a975f1-7847-477c-84a0-4a108f914462",
        "description": "Descriptif du posteLa division « Services Financiers » de Sopra Steria se concentre sur la banque de détail, la banque privée et les services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA et Cloud. Nous accompagnons la transformation de nos clients dans les domaines des Crédits, Risques/Conformité et Moyens de Paiement.Composée d'environ 100 Data Ingénieurs, vous y rencontrerez des experts en Plateforme de Données, Data Architectes et autres spécialistes de la valorisation de la donnée.Vous serez accompagné(e) dans le développement de vos connaissances à travers divers parcours Data : ingestion, construction de datahub, transformation et valorisation de la donnée, modélisation et mise à disposition. Rejoindre la Data Factory Sopra Steria, c'est intégrer une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence, vous participez à :La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;La mise en œuvre de solutions d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;Le traitement de la donnée jusqu'à l'exposition au métier ;La mise en place de la chaine CI/CD et de sa supervision ;La veille technologique avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, RInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Des centaines de formations pour développer vos compétences et évoluer au sein du GroupeDes plateformes de formations en autonomie pour préparer vos certifications et accompagner votre développement personnelLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Services Financiers - Nantes",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-nantes_nantes_SS_DMz2RdN?q=80f6ac0930b006f8455c20e4f0d394af&o=55a975f1-7847-477c-84a0-4a108f914462",
        "description": "Descriptif du posteLa division « Services Financiers » de Sopra Steria se concentre sur la banque de détail, la banque privée et les services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA et Cloud. Nous accompagnons la transformation de nos clients dans les domaines des Crédits, Risques/Conformité et Moyens de Paiement.Composée d'environ 100 Data Ingénieurs, vous y rencontrerez des experts en Plateforme de Données, Data Architectes et autres spécialistes de la valorisation de la donnée.Vous serez accompagné(e) dans le développement de vos connaissances à travers divers parcours Data : ingestion, construction de datahub, transformation et valorisation de la donnée, modélisation et mise à disposition. Rejoindre la Data Factory Sopra Steria, c'est intégrer une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence, vous participez à :La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;La mise en œuvre de solutions d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;Le traitement de la donnée jusqu'à l'exposition au métier ;La mise en place de la chaine CI/CD et de sa supervision ;La veille technologique avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, RInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Des centaines de formations pour développer vos compétences et évoluer au sein du GroupeDes plateformes de formations en autonomie pour préparer vos certifications et accompagner votre développement personnelLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "DATA ENGINEER AWS (H/F)",
        "contract_type": "CDI",
        "salary": "70K €",
        "company": "LineUP7",
        "location": "Paris",
        "remote": "Télétravail total",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, Digital",
            "company_size": "90",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "pyspark,",
                "(spark),sur"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau)."
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "aws",
                "azure,",
                "(gcp,"
            ],
            "DevTools": [
                "digital",
                "digital",
                "digitales.",
                "git…esprit",
                "docker,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker,"
            ],
            "Collaboration": null,
            "Other": [
                "cloud,",
                "cloud/sales",
                "cloud).nous",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration",
                "d'initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lineup-7/jobs/data-engineer-aws-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=55e147d3-8551-4cd6-b812-59ca59365acb",
        "description": "Descriptif du posteA propos du poste...Nous recherchons un Data Engineer Senior pour rejoindre l’équipe Software. Tu joueras un rôle clé dans la conception, le développement et le déploiement de notre data plateforme clients. Tu travailleras en étroite collaboration avec nos équipes de chefs de projets, de développeurs et de consultants CRM pour créer des solutions data-driven robustes et évolutives.A ce titre, tu seras amené à : Participer activement à la conception et à l’évolution de notre data plateforme interne ainsi que les différents services qui la composent,Comprendre et maîtriser les différents modèles de données de nos clients en respectant leurs contraintes et leurs besoins spécifiques,Concevoir, développer et maintenir les pipelines de données,Garantir la qualité, la sécurité et l'intégrité des données tout au long du cycle de vie des projets,Collecter, transformer et enrichir les données provenant de multiples data sources,Collaborer étroitement avec les différentes équipes pour partager ton expertise technique,Réaliser une veille technique en vue de proposer des améliorations continues pour rester à la pointe des technologies,Rédiger des documentations fonctionnelles et techniques.Ce que LineUP7 t’offre…Une culture Team Spirit (intégration conviviale, soirée, séminaire/team building, management humain),Des challenges à relever et des opportunités à saisir dans un contexte de croissance,Un accompagnement pour monter en compétences, Une localisation idéale en plein cœur de Paris (quartier Montparnasse),Un accord de télétravail en place depuis 2019.Processus de recrutement Entretien RH avec un talent acquisitionEntretien opérationnel avec un manager et un consultant séniorEntretien technique (test) avec un consultant séniorEntretien final avec l'un de nos cofondateurÀ propos de LineUP7…LineUP7 est une agence conseil qui accompagne les entreprises dans l’optimisation de leurs expériences clients à travers la data et des outils de marketing digital CDP et marketing automation (SF Data Cloud, Imagino, SFMC, Adobe Campaign, Selligent…) mais aussi qui implémente et gère des outils de CRM (SF Service Cloud/Sales Cloud).Nous abordons les enjeux du digital avec un angle de vue et une approche innovante : la convergence. Les métiers de la Data, de la Technologie et du Marketing sont imbriqués au service de la performance des stratégies digitales. Depuis notre création en 2015, notre positionnement novateur séduit de nombreuses grandes entreprises (luxe, tourisme, banque, retail, immobilier…) Nous rejoindre, c’est travailler au sein d’une agence dynamique dans une ambiance conviviale avec des équipes soudées, qui favorise le développement des compétences et la progression de ses collaborateurs/collaboratrices !Nous avons à cœur d’offrir un cadre de travail agréable, sain et bienveillant.Bienvenue dans une agence qui conjugue le marketing et la technologie !Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.Requirements:A propos de toi...Master 2 en informatique (école d'ingénieur, faculté),Expérience professionnelle d’au moins cinq ans sur des projets Data engineering,Expérience professionnelle d’au moins un an sur  le Cloud AWS et ses services Data (RDS, Lambda, Kinesis, EMR, SageMaker, Glue, S3, Athena etc),Première expérience appréciée dans l'encadrement et la formation d'ingénieurs data junior,Maîtrise de Python 3, Pyspark,  SQL, Django…Maîtrise de AWS (RDS, EMR, Glue, S3, Athena, Lambda), Docker, Apache Superset, Git…Esprit analytique et appétence pour la Data/Big Data et la BI,Curiosité, autonomie, rigueur, esprit d’équipe et bon relationnel,Prise d'initiative et force de proposition.Et tu justifies en plus d’expériences : avec un framework de traitement de données distribuées (Spark),sur d’autres Cloud providers (GCP, Azure, …) et certifications appréciées,réalisées au sein d’une direction marketing ou sur des sujets data marketing (Consumer Data Platform, CRM, connaissance client etc…),avec des outils de data visualization (PowerBI, Tableau)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "DATA ENGINEER AWS (H/F)",
        "contract_type": "CDI",
        "salary": "70K €",
        "company": "LineUP7",
        "location": "Paris",
        "remote": "Télétravail total",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, Digital",
            "company_size": "90",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "pyspark,",
                "(spark),sur"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau)."
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "aws",
                "azure,",
                "(gcp,"
            ],
            "DevTools": [
                "digital",
                "digital",
                "digitales.",
                "git…esprit",
                "docker,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker,"
            ],
            "Collaboration": null,
            "Other": [
                "cloud,",
                "cloud/sales",
                "cloud).nous",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration",
                "d'initiative"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lineup-7/jobs/data-engineer-aws-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=55e147d3-8551-4cd6-b812-59ca59365acb",
        "description": "Descriptif du posteA propos du poste...Nous recherchons un Data Engineer Senior pour rejoindre l’équipe Software. Tu joueras un rôle clé dans la conception, le développement et le déploiement de notre data plateforme clients. Tu travailleras en étroite collaboration avec nos équipes de chefs de projets, de développeurs et de consultants CRM pour créer des solutions data-driven robustes et évolutives.A ce titre, tu seras amené à : Participer activement à la conception et à l’évolution de notre data plateforme interne ainsi que les différents services qui la composent,Comprendre et maîtriser les différents modèles de données de nos clients en respectant leurs contraintes et leurs besoins spécifiques,Concevoir, développer et maintenir les pipelines de données,Garantir la qualité, la sécurité et l'intégrité des données tout au long du cycle de vie des projets,Collecter, transformer et enrichir les données provenant de multiples data sources,Collaborer étroitement avec les différentes équipes pour partager ton expertise technique,Réaliser une veille technique en vue de proposer des améliorations continues pour rester à la pointe des technologies,Rédiger des documentations fonctionnelles et techniques.Ce que LineUP7 t’offre…Une culture Team Spirit (intégration conviviale, soirée, séminaire/team building, management humain),Des challenges à relever et des opportunités à saisir dans un contexte de croissance,Un accompagnement pour monter en compétences, Une localisation idéale en plein cœur de Paris (quartier Montparnasse),Un accord de télétravail en place depuis 2019.Processus de recrutement Entretien RH avec un talent acquisitionEntretien opérationnel avec un manager et un consultant séniorEntretien technique (test) avec un consultant séniorEntretien final avec l'un de nos cofondateurÀ propos de LineUP7…LineUP7 est une agence conseil qui accompagne les entreprises dans l’optimisation de leurs expériences clients à travers la data et des outils de marketing digital CDP et marketing automation (SF Data Cloud, Imagino, SFMC, Adobe Campaign, Selligent…) mais aussi qui implémente et gère des outils de CRM (SF Service Cloud/Sales Cloud).Nous abordons les enjeux du digital avec un angle de vue et une approche innovante : la convergence. Les métiers de la Data, de la Technologie et du Marketing sont imbriqués au service de la performance des stratégies digitales. Depuis notre création en 2015, notre positionnement novateur séduit de nombreuses grandes entreprises (luxe, tourisme, banque, retail, immobilier…) Nous rejoindre, c’est travailler au sein d’une agence dynamique dans une ambiance conviviale avec des équipes soudées, qui favorise le développement des compétences et la progression de ses collaborateurs/collaboratrices !Nous avons à cœur d’offrir un cadre de travail agréable, sain et bienveillant.Bienvenue dans une agence qui conjugue le marketing et la technologie !Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.Requirements:A propos de toi...Master 2 en informatique (école d'ingénieur, faculté),Expérience professionnelle d’au moins cinq ans sur des projets Data engineering,Expérience professionnelle d’au moins un an sur  le Cloud AWS et ses services Data (RDS, Lambda, Kinesis, EMR, SageMaker, Glue, S3, Athena etc),Première expérience appréciée dans l'encadrement et la formation d'ingénieurs data junior,Maîtrise de Python 3, Pyspark,  SQL, Django…Maîtrise de AWS (RDS, EMR, Glue, S3, Athena, Lambda), Docker, Apache Superset, Git…Esprit analytique et appétence pour la Data/Big Data et la BI,Curiosité, autonomie, rigueur, esprit d’équipe et bon relationnel,Prise d'initiative et force de proposition.Et tu justifies en plus d’expériences : avec un framework de traitement de données distribuées (Spark),sur d’autres Cloud providers (GCP, Azure, …) et certifications appréciées,réalisées au sein d’une direction marketing ou sur des sujets data marketing (Consumer Data Platform, CRM, connaissance client etc…),avec des outils de data visualization (PowerBI, Tableau)."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Data Engineer",
        "contract_type": "CDI",
        "salary": "52,5K à 65K €",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/senior-data-engineer_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=797ba23f-11e0-4b83-a47a-f7088f74ba98",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Senior Data Engineer (H/F).Rattaché(e) au Lead Dataflow, vos travaux d’innovation et de recherche en data engineering permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Dataflow, vous aurez pour missions :Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,Déployer des pipelines de données et les modèles ci-dessus en production notamment  en concevant et en développant une architecture en micro-services,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Participer à l’amélioration des étapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests, data lineage,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Data Engineer",
        "contract_type": "CDI",
        "salary": "52,5K à 65K €",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/senior-data-engineer_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=797ba23f-11e0-4b83-a47a-f7088f74ba98",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Senior Data Engineer (H/F).Rattaché(e) au Lead Dataflow, vos travaux d’innovation et de recherche en data engineering permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Dataflow, vous aurez pour missions :Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,Déployer des pipelines de données et les modèles ci-dessus en production notamment  en concevant et en développant une architecture en micro-services,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Participer à l’amélioration des étapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests, data lineage,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/data-engineer_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=2868738f-b442-4353-862a-cbedb4d089a0",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Data Engineer (H/F). Rattaché(e) au Lead Dataflow, vos travaux d’innovation et de recherche en data engineering permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Dataflow, vous aurez pour missions :Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,Déployer des pipelines de données et les modèles ci-dessus en production notamment  en concevant et en développant une architecture en micro-services,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Participer à l’amélioration des étapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests, data lineage,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/data-engineer_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=2868738f-b442-4353-862a-cbedb4d089a0",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Data Engineer (H/F). Rattaché(e) au Lead Dataflow, vos travaux d’innovation et de recherche en data engineering permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Dataflow, vous aurez pour missions :Définir, développer et mettre en place et maintenir les outils et infrastructures adéquats à la conception d’algorithmes de data science et de recherche opérationnelle, intégrant les contraintes liées à des volumes de données très importants, à des modèles de grande dimension, au temps réel, ainsi qu’à la sécurité, la disponibilité et la performance,Déployer des pipelines de données et les modèles ci-dessus en production notamment  en concevant et en développant une architecture en micro-services,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Participer à l’amélioration des étapes du workflow scientifique de Lucky Cart: phase de recherche sur des environnements de calculs distribués, développement d’outils, mise en production, et tests, data lineage,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stagiaire Data Engineer H/F",
        "contract_type": "Stage(6 mois)",
        "salary": "Non spécifié",
        "company": "Redpill",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Média, Marketing / Communication",
            "company_size": "83",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "8,8M € en 2022",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/redpill/jobs/stagiaire-data-engineer-h-f_paris_REDPI_bXXpOPo?q=80f6ac0930b006f8455c20e4f0d394af&o=20f388a7-4334-4641-ba10-4e1c4123343e",
        "description": "Descriptif du posteErmes, meilleure plateforme marketing Data et IA, cible une audience de grande qualité parmi 55 millions de profils pour les campagnes de ses clients, et met à leur disposition un outil automatisé, utilisable en self-service, pour leur création. Ermes est membre du groupe Redpill, qui concentre les meilleurs experts en technologie, création et design, data, marketing et media, pour accompagner les entreprises dans un monde en pleine transformation numérique.Le département Data de chez Ermes est à la recherche d’un(e) stagiaire Data Scientist pour une durée de 6 mois, à partir de novembre 2024.Notre talentueuse équipe Data, constituée de Data Analysts, Data Scientists, Data Engineer et Chief Data Officer serait ravie de t’accueillir dans nos locaux de la rue de Lisbonne à Paris 8ème pour soutenir nos missions chez Ermes.Au coeur de l’Adtech, et sous la tutelle du Chief Data Officer, tu seras amené(e) à contribuer à des projets Data très variés, qui mettront à profit tes acquis et te feront monter en compétences.Les enjeux du poste :- Qualité : optimisation de l’exploitation de la data- Conformité : clean données obsolètes / MàJ régulières…- Process : onboarding / géométrie des profils de la base / update des bases / modélisation / dédoublonnage- Gouvernance : appliquer les méthodologies et directives de l’équipe Data- Conseil : filtrage / optimisation de la pipeline / automatisation / stratégie statistiqueLes missions Ermes en Data Engineer:Tu participeras activement à :Répondre de manière autonome et rapide aux requêtes des équipes en interne, par ordre de prioritéProcess / industrialiser / automatiser des traitements dataRecueillir, analyser des sets de données pertinents pour l’entrepriseProgrammer des algorithmes d’investigation et d’amélioration du ciblage d’audienceModéliser, prédire, optimiser, calculer des risquesPrendre part à la veille technologique (collecte, traitement, qualité des données)Collaborer à nos data analysts de l’équipe ainsi qu’aux départements transversauxRédiger des documentations adaptées et les mettre à jour"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stagiaire Data Engineer H/F",
        "contract_type": "Stage(6 mois)",
        "salary": "Non spécifié",
        "company": "Redpill",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Média, Marketing / Communication",
            "company_size": "83",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "8,8M € en 2022",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/redpill/jobs/stagiaire-data-engineer-h-f_paris_REDPI_bXXpOPo?q=80f6ac0930b006f8455c20e4f0d394af&o=20f388a7-4334-4641-ba10-4e1c4123343e",
        "description": "Descriptif du posteErmes, meilleure plateforme marketing Data et IA, cible une audience de grande qualité parmi 55 millions de profils pour les campagnes de ses clients, et met à leur disposition un outil automatisé, utilisable en self-service, pour leur création. Ermes est membre du groupe Redpill, qui concentre les meilleurs experts en technologie, création et design, data, marketing et media, pour accompagner les entreprises dans un monde en pleine transformation numérique.Le département Data de chez Ermes est à la recherche d’un(e) stagiaire Data Scientist pour une durée de 6 mois, à partir de novembre 2024.Notre talentueuse équipe Data, constituée de Data Analysts, Data Scientists, Data Engineer et Chief Data Officer serait ravie de t’accueillir dans nos locaux de la rue de Lisbonne à Paris 8ème pour soutenir nos missions chez Ermes.Au coeur de l’Adtech, et sous la tutelle du Chief Data Officer, tu seras amené(e) à contribuer à des projets Data très variés, qui mettront à profit tes acquis et te feront monter en compétences.Les enjeux du poste :- Qualité : optimisation de l’exploitation de la data- Conformité : clean données obsolètes / MàJ régulières…- Process : onboarding / géométrie des profils de la base / update des bases / modélisation / dédoublonnage- Gouvernance : appliquer les méthodologies et directives de l’équipe Data- Conseil : filtrage / optimisation de la pipeline / automatisation / stratégie statistiqueLes missions Ermes en Data Engineer:Tu participeras activement à :Répondre de manière autonome et rapide aux requêtes des équipes en interne, par ordre de prioritéProcess / industrialiser / automatiser des traitements dataRecueillir, analyser des sets de données pertinents pour l’entrepriseProgrammer des algorithmes d’investigation et d’amélioration du ciblage d’audienceModéliser, prédire, optimiser, calculer des risquesPrendre part à la veille technologique (collecte, traitement, qualité des données)Collaborer à nos data analysts de l’équipe ainsi qu’aux départements transversauxRédiger des documentations adaptées et les mettre à jour"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Confirmé.e",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java",
                "scalabilité,"
            ],
            "DataBase": [
                "postgresql)connaissance",
                "postgresqllakehouse"
            ],
            "DataAnalytics": [
                "(pandas,"
            ],
            "BigData": [
                "spark",
                "(pyspark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "azure),",
                "gcp"
            ],
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": [
                "postgresql)connaissance",
                "postgresqllakehouse",
                "snowflake,",
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,"
            ],
            "InfrastructureAsCode": [
                "(terraform)expérience"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,"
            ],
            "Collaboration": null,
            "Other": [
                "mle/mlops",
                "uml,",
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-confirme-cdi-paris_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=5289e6f3-19c2-40cc-b99a-d2671d6eff50",
        "description": "Descriptif du posteAu sein de notre DataLab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à son évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec vos pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager votre savoir-faire entre les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big DataAssurer une veille technologique et savoir mener à bien un projet de R&DTu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement: :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ETL : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse : Delta LakeConnaissance message broker, RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Confirmé.e",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java",
                "scalabilité,"
            ],
            "DataBase": [
                "postgresql)connaissance",
                "postgresqllakehouse"
            ],
            "DataAnalytics": [
                "(pandas,"
            ],
            "BigData": [
                "spark",
                "(pyspark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "azure),",
                "gcp"
            ],
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": [
                "postgresql)connaissance",
                "postgresqllakehouse",
                "snowflake,",
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,"
            ],
            "InfrastructureAsCode": [
                "(terraform)expérience"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,"
            ],
            "Collaboration": null,
            "Other": [
                "mle/mlops",
                "uml,",
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-confirme-cdi-paris_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=5289e6f3-19c2-40cc-b99a-d2671d6eff50",
        "description": "Descriptif du posteAu sein de notre DataLab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à son évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec vos pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager votre savoir-faire entre les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big DataAssurer une veille technologique et savoir mener à bien un projet de R&DTu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement: :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ETL : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse : Delta LakeConnaissance message broker, RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant.e Data engineer confirmé.e",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Kanbios",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "55",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "5,5 ",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-data-engineer-confirme-e_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=822f1d34-7d14-4ebf-a698-b69aa8498ae2",
        "description": "Descriptif du poste🎯 Nous recherchons un(e) Data Engineer confirmé(e) pour rejoindre notre pôle Data ! 🎯Vous serez en charge de la conception et de la maintenance de pipelines de données robustes, garantissant la qualité et l’intégrité des données.Vos missions si vous nous rejoignez : 🚀 Chez le client :Participer à l’analyse des besoins des clients et à la définition des solutions techniques adaptées.Concevoir, développer et maintenir des pipelines de données.Collaborer avec les équipes clientes pour améliorer et optimiser les infrastructures de données.Développer des solutions de traitement et de transformation de données. Veiller à la qualité́, l’intégrité́ et la sécurité́ des données.  Participer à l’intégration de nouveaux outils et technologies selon les projets.Assurer un suivi et un reporting régulier auprès des clients. 🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de template de code pour accélérer nos projets et mettre en place les bonnes pratiques.Effectuer une veille technologique pour rester à jour sur les dernières avancées en matière Data science.Participer à la construction de propositions commerciales et de présentations stratégiques."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant.e Data engineer confirmé.e",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Kanbios",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "55",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "5,5 ",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-data-engineer-confirme-e_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=822f1d34-7d14-4ebf-a698-b69aa8498ae2",
        "description": "Descriptif du poste🎯 Nous recherchons un(e) Data Engineer confirmé(e) pour rejoindre notre pôle Data ! 🎯Vous serez en charge de la conception et de la maintenance de pipelines de données robustes, garantissant la qualité et l’intégrité des données.Vos missions si vous nous rejoignez : 🚀 Chez le client :Participer à l’analyse des besoins des clients et à la définition des solutions techniques adaptées.Concevoir, développer et maintenir des pipelines de données.Collaborer avec les équipes clientes pour améliorer et optimiser les infrastructures de données.Développer des solutions de traitement et de transformation de données. Veiller à la qualité́, l’intégrité́ et la sécurité́ des données.  Participer à l’intégration de nouveaux outils et technologies selon les projets.Assurer un suivi et un reporting régulier auprès des clients. 🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de template de code pour accélérer nos projets et mettre en place les bonnes pratiques.Effectuer une veille technologique pour rester à jour sur les dernières avancées en matière Data science.Participer à la construction de propositions commerciales et de présentations stratégiques."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer_bruxelles?q=80f6ac0930b006f8455c20e4f0d394af&o=bbf3d271-db82-4342-9417-6e00030c20ab",
        "description": "Descriptif du posteWhat will be your tasks with us?Concretely on a daily basis, you will work in AGILE mode and as a team (made up of Data Scientists, architects, Devops coach, etc.). You’ll support our customers on their Data, delivery & release challenges.You will be working in the following areas:Consulting & expertise among our customers on their strategic projects:Analyze our customers’ strategic challenges around Data issuesMake your contribution to define their ambitions and their Data roadmapAudit & projects framing (architecture, methodology, code quality)Achievements/ support of projects that involve Data centric architecture set upR&D and Solutions:Participation in the development of internal solutionsProposal and creation of innovative solutions"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer_bruxelles?q=80f6ac0930b006f8455c20e4f0d394af&o=bbf3d271-db82-4342-9417-6e00030c20ab",
        "description": "Descriptif du posteWhat will be your tasks with us?Concretely on a daily basis, you will work in AGILE mode and as a team (made up of Data Scientists, architects, Devops coach, etc.). You’ll support our customers on their Data, delivery & release challenges.You will be working in the following areas:Consulting & expertise among our customers on their strategic projects:Analyze our customers’ strategic challenges around Data issuesMake your contribution to define their ambitions and their Data roadmapAudit & projects framing (architecture, methodology, code quality)Achievements/ support of projects that involve Data centric architecture set upR&D and Solutions:Participation in the development of internal solutionsProposal and creation of innovative solutions"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Snowflake (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Levallois-Perret",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-12",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": [
                "snowflake",
                "snowflake",
                "snowflake",
                "snowflake"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-snowflake-h-f_levallois-perret?q=80f6ac0930b006f8455c20e4f0d394af&o=46f8b2bd-d294-40fb-aca5-7966e0a3929e",
        "description": "Descriptif du posteEn résumé :  Poste : Data Engineer Snowflake (H/F)  Localité : Levallois-Perret   Type de contrat : CDI  Niveau d’expérience : au moins 2 ans  Rythme d’emploi : Hybride     Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez \" Data Engineer Snowflake (H/F)\"   pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !  En tant qu'Ingénieur de Données Snowflake chez Micropole, vous jouerez un rôle clé dans la conception, la mise en œuvre et l'optimisation des infrastructure de données sur la plateforme Snowflake de nos clients. Vous collaborerez étroitement avec les data scientists, les analystes et d'autres parties prenantes pour soutenir la prise de décision basée sur les données dans l'ensemble des organisations de nos clients.  Responsabilités Clés    Concevoir, construire,      installer, tester et maintenir des systèmes de gestion de données hautement      évolutifs.  Assurer que les systèmes      répondent aux exigences métiers et aux pratiques de l'industrie.  Construire des      algorithmes de haute performance, des prototypes, des modèles prédictifs      et des preuves de concept.  Intégrer de nouvelles      technologies de gestion de données et outils d'ingénierie logicielle dans      les structures existantes.  Créer des outils de      données pour les équipes d'analytique et de science des données afin de      les aider à construire et optimiser notre produit.  Utiliser une variété de      langues et d'outils pour assembler les systèmes ensemble.  Recommander des moyens      d'améliorer la fiabilité, l'efficacité et la qualité des données.  Collaborer avec les      architectes de données, les modélisateurs et les membres de l'équipe IT      sur les objectifs des projets. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Snowflake (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Levallois-Perret",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-12",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": [
                "snowflake",
                "snowflake",
                "snowflake",
                "snowflake"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-snowflake-h-f_levallois-perret?q=80f6ac0930b006f8455c20e4f0d394af&o=46f8b2bd-d294-40fb-aca5-7966e0a3929e",
        "description": "Descriptif du posteEn résumé :  Poste : Data Engineer Snowflake (H/F)  Localité : Levallois-Perret   Type de contrat : CDI  Niveau d’expérience : au moins 2 ans  Rythme d’emploi : Hybride     Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez \" Data Engineer Snowflake (H/F)\"   pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !  En tant qu'Ingénieur de Données Snowflake chez Micropole, vous jouerez un rôle clé dans la conception, la mise en œuvre et l'optimisation des infrastructure de données sur la plateforme Snowflake de nos clients. Vous collaborerez étroitement avec les data scientists, les analystes et d'autres parties prenantes pour soutenir la prise de décision basée sur les données dans l'ensemble des organisations de nos clients.  Responsabilités Clés    Concevoir, construire,      installer, tester et maintenir des systèmes de gestion de données hautement      évolutifs.  Assurer que les systèmes      répondent aux exigences métiers et aux pratiques de l'industrie.  Construire des      algorithmes de haute performance, des prototypes, des modèles prédictifs      et des preuves de concept.  Intégrer de nouvelles      technologies de gestion de données et outils d'ingénierie logicielle dans      les structures existantes.  Créer des outils de      données pour les équipes d'analytique et de science des données afin de      les aider à construire et optimiser notre produit.  Utiliser une variété de      langues et d'outils pour assembler les systèmes ensemble.  Recommander des moyens      d'améliorer la fiabilité, l'efficacité et la qualité des données.  Collaborer avec les      architectes de données, les modélisateurs et les membres de l'équipe IT      sur les objectifs des projets. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=c868d636-2fca-49fd-9198-e04fb2e59d0d",
        "description": "Descriptif du posteDans le cadre de la modernisation du backend, le socle du processing de données est ré-écrit sur une technologie BigData, ce qui permet d'élargir l'offre de services proposée aux utilisateurs. Dans ce cadre, la mission consiste à : Contribuer à l'analyse des besoins des différents métiers : analyse de données, BI, Big Data.Contribuer à la définition des solutions dans l'environnement applicatif (Cloud Platform / Spark Data processing). Récupérer les données sur les assets à partir d'une base de données RedShift.Traiter les données afin de garantir une qualité de données optimale.Exploiter les données et faire des restitutions dans les datasets / datamarts.Appliquer les mises en forme et agrégations sur les données.Etablir des comparaisons entre les données et des restitutions pertinentes selon les besoins métiers."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-11",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "(cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=c868d636-2fca-49fd-9198-e04fb2e59d0d",
        "description": "Descriptif du posteDans le cadre de la modernisation du backend, le socle du processing de données est ré-écrit sur une technologie BigData, ce qui permet d'élargir l'offre de services proposée aux utilisateurs. Dans ce cadre, la mission consiste à : Contribuer à l'analyse des besoins des différents métiers : analyse de données, BI, Big Data.Contribuer à la définition des solutions dans l'environnement applicatif (Cloud Platform / Spark Data processing). Récupérer les données sur les assets à partir d'une base de données RedShift.Traiter les données afin de garantir une qualité de données optimale.Exploiter les données et faire des restitutions dans les datasets / datamarts.Appliquer les mises en forme et agrégations sur les données.Etablir des comparaisons entre les données et des restitutions pertinentes selon les besoins métiers."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer F/H",
        "contract_type": "CDI",
        "salary": "56K à 64K €",
        "company": "Matmut",
        "location": "Rueil-Malmaison",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "6529",
            "creation_date": "1961",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "2923 millions d'euros ",
            "proportion_female": "66",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp/sens:-amélioration"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "mlops",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration",
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/matmut-fr/jobs/data-engineer-f-h_rueil-malmaison?q=80f6ac0930b006f8455c20e4f0d394af&o=599d37d3-bf79-494d-858c-6e2539fc116e",
        "description": "Descriptif du posteÀ la Matmut, nous n'exerçons pas juste un métier. Pour nous, sens et ambition sont indissociables. Nous rendons l'assurance accessible et équitable grâce à notre modèle mutualiste. Responsabilité, proximité, efficacité nous guident pour satisfaire chaque jour nos clients sociétaires. C'est aussi ce qui vous anime ? PAS JUSTE UN QUOTIDIEN !Être Data Engineer à la Matmut c'est Intervenir en tant qu'acteur majeur de la réalisation des missions de l'équipe : delivery de cas d'usages industrialisés et construction de la plateforme et des outils de la direction.Vos missions :-Industrialiser des cas d'usage métier datasciences en collaboration étroite avec les Data Analyst, les Data Scientist et les équipes IT -Préparer des données issues de la plateforme en collaboration avec les Data Scientist-Industrialiser les différents codes applicatifs & Gérer des flux de données sur la plateforme data-Pré-industrialiser des modèles de Machines Learning préparés par les Data Scientist (packaging, déploiement, monitoring des modèles, …) & back-testing en collaboration avec les équipes IT-Superviser les flux d'alimentation du data lake-Assurer le suivi de la mise en production & la réalisation du projet dans son ensemble-Contribuer à la construction de la plateforme data Matmut (outils, process, pratiques d'industrialisation) - plateforme GCP/SENS:-Amélioration & Mise en place des outils de Devops au sein de l'équipe-Amélioration & Maintenance de Template projets (architecture type, automatisation des builds & deploy, CICD, …)-Mise en place de bonnes pratiques (code, normes, gouvernance des outils, …)-Développement de librairies internes pour réutilisation des traitements-Outillage MLOps (reproductibilité, standardisation et automatisation des packaging et déploiement, automatisation des réentrainements, triggers, process, …)-Accompagner la migration de cloud & Contribuer aux discussions sur le choix d'architecture-Participer & représenter la direction Data aux réunions, avec les équipes métier et IT, afin de collecter des informations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer F/H",
        "contract_type": "CDI",
        "salary": "56K à 64K €",
        "company": "Matmut",
        "location": "Rueil-Malmaison",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "6529",
            "creation_date": "1961",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "2923 millions d'euros ",
            "proportion_female": "66",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp/sens:-amélioration"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "mlops",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration",
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/matmut-fr/jobs/data-engineer-f-h_rueil-malmaison?q=80f6ac0930b006f8455c20e4f0d394af&o=599d37d3-bf79-494d-858c-6e2539fc116e",
        "description": "Descriptif du posteÀ la Matmut, nous n'exerçons pas juste un métier. Pour nous, sens et ambition sont indissociables. Nous rendons l'assurance accessible et équitable grâce à notre modèle mutualiste. Responsabilité, proximité, efficacité nous guident pour satisfaire chaque jour nos clients sociétaires. C'est aussi ce qui vous anime ? PAS JUSTE UN QUOTIDIEN !Être Data Engineer à la Matmut c'est Intervenir en tant qu'acteur majeur de la réalisation des missions de l'équipe : delivery de cas d'usages industrialisés et construction de la plateforme et des outils de la direction.Vos missions :-Industrialiser des cas d'usage métier datasciences en collaboration étroite avec les Data Analyst, les Data Scientist et les équipes IT -Préparer des données issues de la plateforme en collaboration avec les Data Scientist-Industrialiser les différents codes applicatifs & Gérer des flux de données sur la plateforme data-Pré-industrialiser des modèles de Machines Learning préparés par les Data Scientist (packaging, déploiement, monitoring des modèles, …) & back-testing en collaboration avec les équipes IT-Superviser les flux d'alimentation du data lake-Assurer le suivi de la mise en production & la réalisation du projet dans son ensemble-Contribuer à la construction de la plateforme data Matmut (outils, process, pratiques d'industrialisation) - plateforme GCP/SENS:-Amélioration & Mise en place des outils de Devops au sein de l'équipe-Amélioration & Maintenance de Template projets (architecture type, automatisation des builds & deploy, CICD, …)-Mise en place de bonnes pratiques (code, normes, gouvernance des outils, …)-Développement de librairies internes pour réutilisation des traitements-Outillage MLOps (reproductibilité, standardisation et automatisation des packaging et déploiement, automatisation des réentrainements, triggers, process, …)-Accompagner la migration de cloud & Contribuer aux discussions sur le choix d'architecture-Participer & représenter la direction Data aux réunions, avec les équipes métier et IT, afin de collecter des informations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer / GCP (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Levallois-Perret",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcplocalité",
                "gcp",
                "gcp.",
                "gcp."
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloud.",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret_MICRO_Pl4NJMk?q=80f6ac0930b006f8455c20e4f0d394af&o=e5557cdd-5995-4d25-8c16-2dd54b268b56",
        "description": "Descriptif du posteEn résumé :  Poste : Data Engineer / GCPLocalité : Levallois-PerretType de contrat : CDINiveau d’expérience : au moins 3 ansVous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes, vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer / GCP (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Levallois-Perret",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcplocalité",
                "gcp",
                "gcp.",
                "gcp."
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloud.",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-gcp-h-f_levallois-perret_MICRO_Pl4NJMk?q=80f6ac0930b006f8455c20e4f0d394af&o=e5557cdd-5995-4d25-8c16-2dd54b268b56",
        "description": "Descriptif du posteEn résumé :  Poste : Data Engineer / GCPLocalité : Levallois-PerretType de contrat : CDINiveau d’expérience : au moins 3 ansVous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?Si vous avez répondu « Oui » à chacune de ces questions alors devenez Data Engineer pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !Au sein de notre agence basée à levallois-Perret, vous rejoindrez nos experts Cloud. En tant que Data Engineer GCP (F/H) , vous accompagnerez les directions métiers dans l'évaluation de l'efficacité de leur processus et dans leur stratégie pour optimiser leur performance. Dans vos missions quotidiennes, vous serez amené(e) à : Développer et maintenir des cas d’usages clients avec les outils et les infrastructures Big Data / Cloud GCP. Modéliser et analyser des données dans le Cloud. Garantir la sécurité / compliance des données ; Apporter votre réflexion sur des problématiques métiers à travers l’exploitation et la compréhension des données. Identifier les sources de données les plus pertinentes et restituer des résultats de façon concise et visuelle ; Réaliser une veille technologique pour être à la pointe sur les solutions cloud & Data ; Participer au développement de notre centre d’excellence GCP. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer confirmé (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CCR Re",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "Assurance",
            "company_size": "178",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "1 186  ",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digital",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ccr-re/jobs/data-engineer-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=0a0448b2-6485-4889-9cfd-ae2574ea5d4d",
        "description": "Descriptif du posteCCR Re a créé une Digital Factory dont l’ADN est : « l’innovation par la data ». Pour répondre à cette ligne de conduite et pour accélérer l’ensemble des projets d’innovation de l’entreprise, la « Digital Factory » met en place une plateforme data et une démarche « Data centric ».Pour renforcer notre Pôle Data & Visualisation, nous sommes à la recherche d’une ou d’un Data Engineer confirmé qui sera contributeur de cette démarche « Data centric » (en traitant des activités d’ingestion puis de mise à disposition de ces données aux métiers), d’accès simplifié à la donnée (Self BI) et de la gouvernance associée.MissionsAu sein du Pôle Data & Visualisation (de la Digital Factory) dans le cadre d’un CDI, vous aurez la charge de la collecte et la mise à disposition des données au sein de l’entreprise ainsi que l’industrialisation et la mise en production des traitements sur les données.Par conséquent, vous interviendrez sur différentes missions comprenant :Ingestion des données :Recueillir les besoins métiers utilisateurs de solutions de collecte et stockage de la donnée.Développer (de manière industrialisée) la pipeline d’ingestion de la donnée : collecte | stockage | transformation de la donnée.Réaliser les tests unitaires et d’intégration.Mise à disposition des données aux équipes demandeuses / utilisatrices :Définir le modèle de données le plus pertinent par rapport à un cas d’usage métier.Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues.Gérer, maintenir et documenter les bases de données (brutes & orientées vues métier).Assurer le suivi de production et la maintenance. Gouvernance de la donnée :S’intégrer dans le processus de gouvernance de données (catalogue de données | lineage | qualité de données). Supervision :Coaching | accompagnement d’un data engineer alternant. Communication et adoption : Accompagnement des équipes métiers dans leur accès à la donnée."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer confirmé (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CCR Re",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "Assurance",
            "company_size": "178",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "42",
            "turnover_in_millions": "1 186  ",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digital",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ccr-re/jobs/data-engineer-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=0a0448b2-6485-4889-9cfd-ae2574ea5d4d",
        "description": "Descriptif du posteCCR Re a créé une Digital Factory dont l’ADN est : « l’innovation par la data ». Pour répondre à cette ligne de conduite et pour accélérer l’ensemble des projets d’innovation de l’entreprise, la « Digital Factory » met en place une plateforme data et une démarche « Data centric ».Pour renforcer notre Pôle Data & Visualisation, nous sommes à la recherche d’une ou d’un Data Engineer confirmé qui sera contributeur de cette démarche « Data centric » (en traitant des activités d’ingestion puis de mise à disposition de ces données aux métiers), d’accès simplifié à la donnée (Self BI) et de la gouvernance associée.MissionsAu sein du Pôle Data & Visualisation (de la Digital Factory) dans le cadre d’un CDI, vous aurez la charge de la collecte et la mise à disposition des données au sein de l’entreprise ainsi que l’industrialisation et la mise en production des traitements sur les données.Par conséquent, vous interviendrez sur différentes missions comprenant :Ingestion des données :Recueillir les besoins métiers utilisateurs de solutions de collecte et stockage de la donnée.Développer (de manière industrialisée) la pipeline d’ingestion de la donnée : collecte | stockage | transformation de la donnée.Réaliser les tests unitaires et d’intégration.Mise à disposition des données aux équipes demandeuses / utilisatrices :Définir le modèle de données le plus pertinent par rapport à un cas d’usage métier.Industrialiser et automatiser le nettoyage de la donnée selon les spécifications retenues.Gérer, maintenir et documenter les bases de données (brutes & orientées vues métier).Assurer le suivi de production et la maintenance. Gouvernance de la donnée :S’intégrer dans le processus de gouvernance de données (catalogue de données | lineage | qualité de données). Supervision :Coaching | accompagnement d’un data engineer alternant. Communication et adoption : Accompagnement des équipes métiers dans leur accès à la donnée."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - service management",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": [
                "(json,",
                "xml,"
            ],
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "xml,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-service-management_nanterre_AXA_P2LW99L?q=80f6ac0930b006f8455c20e4f0d394af&o=1a14a920-79fa-4423-a3de-954099c66de0",
        "description": "Descriptif du posteEnvironnement : En tant que Service Engineer (F/H), vous intégrerez l’équipe socle de la data Factory qui fait partie intégrante de la DATA OFFICE d’AXA France.Cette data Factory a pour but d’implémenter et à industrialiser toutes les données au cœur des activités d’AXA France.La DATA Factory et ses équipes portent et contribuent au Delivery de bout en bout des projets DATA, de l’idéation à la mise en production et au monitoring des cas d’usage.Vous serez au sein d’une équipe composée de Data ops et de Data Engineers pour garantir la livraison de produits data de haute qualité, innovants.Votre rôle de service engineer est stratégique car il doit permettre à AXA d’accélérer sa transformation en utilisant la data comme un levier stratégique.Vous jouerez un rôle clé dans l'industrialisation des produits data, l’intégration des données au niveau du datalake AXA France, la mise en place d'un socle technologique pour l'innovation et le delivery de projets à forte valeur ajoutée pour AXA France. Le rôle d’un Service Engineer consiste à :Intégrer des données dans le datalake AFAIntégration des données structurées (json, csv, xml, MF…) et non structurées;Configuration de fichiers de paramétrage afin de s’assurer de la bonne intégration des fichiers;Typage des données structurées;Tests d’intégration.Créer des UCsMise à disposition des environnements de développement jusqu’à la production. Ils seront par la suite utilisés par les data engineers pour la consommation des données.Créer des LABsMise a disposition d’environnement exploratoire pour les data eng, data scientist ou BA des tribus ou coté métier.Travailler sur des taches transversesContribuer à l’innovation AXA via la veille technologique et le développement des synergies entre technologies, méthodes et pratiques;Participer à des projets transverses liés au socle big data;Contribuer à la qualité des solutions en améliorant le code produit et en réalisant régulièrement des revues de codes collectives et des Pull Requests;Mettre en place les sources de données virtualisées via Denodo. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - service management",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": [
                "(json,",
                "xml,"
            ],
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "xml,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-service-management_nanterre_AXA_P2LW99L?q=80f6ac0930b006f8455c20e4f0d394af&o=1a14a920-79fa-4423-a3de-954099c66de0",
        "description": "Descriptif du posteEnvironnement : En tant que Service Engineer (F/H), vous intégrerez l’équipe socle de la data Factory qui fait partie intégrante de la DATA OFFICE d’AXA France.Cette data Factory a pour but d’implémenter et à industrialiser toutes les données au cœur des activités d’AXA France.La DATA Factory et ses équipes portent et contribuent au Delivery de bout en bout des projets DATA, de l’idéation à la mise en production et au monitoring des cas d’usage.Vous serez au sein d’une équipe composée de Data ops et de Data Engineers pour garantir la livraison de produits data de haute qualité, innovants.Votre rôle de service engineer est stratégique car il doit permettre à AXA d’accélérer sa transformation en utilisant la data comme un levier stratégique.Vous jouerez un rôle clé dans l'industrialisation des produits data, l’intégration des données au niveau du datalake AXA France, la mise en place d'un socle technologique pour l'innovation et le delivery de projets à forte valeur ajoutée pour AXA France. Le rôle d’un Service Engineer consiste à :Intégrer des données dans le datalake AFAIntégration des données structurées (json, csv, xml, MF…) et non structurées;Configuration de fichiers de paramétrage afin de s’assurer de la bonne intégration des fichiers;Typage des données structurées;Tests d’intégration.Créer des UCsMise à disposition des environnements de développement jusqu’à la production. Ils seront par la suite utilisés par les data engineers pour la consommation des données.Créer des LABsMise a disposition d’environnement exploratoire pour les data eng, data scientist ou BA des tribus ou coté métier.Travailler sur des taches transversesContribuer à l’innovation AXA via la veille technologique et le développement des synergies entre technologies, méthodes et pratiques;Participer à des projets transverses liés au socle big data;Contribuer à la qualité des solutions en améliorant le code produit et en réalisant régulièrement des revues de codes collectives et des Pull Requests;Mettre en place les sources de données virtualisées via Denodo. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Machine Learning Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Trainline",
        "location": "London",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Mobilité, Ferroviaire, E-commerce",
            "company_size": "1000",
            "creation_date": "1997",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": [
                "pandas,",
                "pandas,",
                "numpy,",
                "numpy,"
            ],
            "BigData": [
                "spark",
                "pyspark"
            ],
            "MachineLearning": [
                "(scikit-learn,",
                "tensorflow,",
                "lightgbm,"
            ],
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": [
                "digital",
                "docker",
                "docker,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": [
                "terraform",
                "terraform,"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker",
                "docker,"
            ],
            "Collaboration": [
                "teams",
                "teams"
            ],
            "Other": [
                "devops",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml/ds",
                "mlops:",
                "mlflow",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/trainline/jobs/senior-machine-learning-engineer_london_TRAIN_oZx3QAA?q=80f6ac0930b006f8455c20e4f0d394af&o=9c6d009d-bdb4-4bf1-9415-4722d51ec7cd",
        "description": "Descriptif du poste💻 Senior Machine Learning Engineer 📍London (Hybrid, 40% in office) 💸 £Salary + Benefits Introducing Machine Learning and AI at Trainline 👋 Machine learning is at the heart of Trainline's mission to help millions of people make sustainable travel choices every day. Our ML models power critical aspects of our platform, including: Advanced search and recommendations capabilities across our mobile and web applications Pricing and routing optimisations to find the best fares for customers Personalised user experiences enhanced by generative AI Data-driven digital marketing systems AI agents improving customer support Our machine learning teams own the complete delivery lifecycle from ideation to production. We work closely with stakeholders across the business to expand the understanding and impact of machine learning and AI throughout Trainline. The RoleWe are looking for a Senior Machine Learning Engineer to join our team help shape the future of train travel. You will be part of a highly innovative AI and ML platform working alongside engineers, scientists and product managers to tackle complex challenges by combining Trainline’s rich datasets with cutting edge algorithms. What unites our team is an expertise in the field, a love of what we do and the desire to create impactful solutions to support Trainline’s goals of encouraging sustainable travel.  As a part of Trainline you will be joining an environment where learning and development is top priority. You will have the opportunity to work with fellow ML enthusiasts on large-scale production systems, delivering highly impactful products that make a difference to our millions of users.  As a Senior Machine Learning Engineer at Trainline you will... 🚄   Work in cross-functional teams combining data scientists, software, data and machine learning engineers, and product managers  Design and deliver machine learning models at scale that drive measurable impact for our business  Own the full end to end machine learning delivery lifecycle including data exploration, feature engineering, model selection and tuning, offline and online evaluation, deployments and maintenance  Partner with stakeholders to propose innovative data products that leverage Trainline’s extensive datasets and state of the art algorithms  Create the tools, frameworks and libraries that enables the acceleration of our ML products delivery and improve our workflows  Take an active part in our AI and ML community and foster a culture of rigorous learning and experimentation We'd love to hear from you if you...🔍   Have an advanced degree in Computer Science, Mathematics or a similar quantitative discipline  Are proficient with Python, including open-source data libraries (e.g Pandas, Numpy, Scikit learn etc.)    Have experience productionising machine learning models   Are an expert in one of predictive modeling, classification, regression, optimisation or recommendation systems  Have experience with Spark   Have knowledge of DevOps technologies such as Docker and Terraform and ML Ops practices and platforms like ML Flow  Have experience with agile delivery methodologies and CI/CD processes and tools  Have a broad of understanding of data extraction, data manipulation and feature engineering techniques   Are familiar with statistical methodologies.  Have good communication skills   Nice to have 😍 Experience with transport industry and/or geographical information systems (GIS)  Experience with cloud infrastructure  Understanding of NLP algorithms and techniques  and/or experience with Large Language Models (fine tuning, RAG, agents)  Experience with graph technology and/or algorithms Our technology stack 💻  Python and associated ML/DS libraries (scikit-learn, NumPy, LightGBM, Pandas, LangChain/LangGraph, TensorFlow, etc...) PySpark AWS cloud infrastructure: EMR, ECS, Athena, etc.  MLOps: Terraform, Docker, Airflow, MLFlow  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Machine Learning Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Trainline",
        "location": "London",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Mobilité, Ferroviaire, E-commerce",
            "company_size": "1000",
            "creation_date": "1997",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": [
                "pandas,",
                "pandas,",
                "numpy,",
                "numpy,"
            ],
            "BigData": [
                "spark",
                "pyspark"
            ],
            "MachineLearning": [
                "(scikit-learn,",
                "tensorflow,",
                "lightgbm,"
            ],
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": [
                "digital",
                "docker",
                "docker,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": [
                "terraform",
                "terraform,"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker",
                "docker,"
            ],
            "Collaboration": [
                "teams",
                "teams"
            ],
            "Other": [
                "devops",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml",
                "ml/ds",
                "mlops:",
                "mlflow",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/trainline/jobs/senior-machine-learning-engineer_london_TRAIN_oZx3QAA?q=80f6ac0930b006f8455c20e4f0d394af&o=9c6d009d-bdb4-4bf1-9415-4722d51ec7cd",
        "description": "Descriptif du poste💻 Senior Machine Learning Engineer 📍London (Hybrid, 40% in office) 💸 £Salary + Benefits Introducing Machine Learning and AI at Trainline 👋 Machine learning is at the heart of Trainline's mission to help millions of people make sustainable travel choices every day. Our ML models power critical aspects of our platform, including: Advanced search and recommendations capabilities across our mobile and web applications Pricing and routing optimisations to find the best fares for customers Personalised user experiences enhanced by generative AI Data-driven digital marketing systems AI agents improving customer support Our machine learning teams own the complete delivery lifecycle from ideation to production. We work closely with stakeholders across the business to expand the understanding and impact of machine learning and AI throughout Trainline. The RoleWe are looking for a Senior Machine Learning Engineer to join our team help shape the future of train travel. You will be part of a highly innovative AI and ML platform working alongside engineers, scientists and product managers to tackle complex challenges by combining Trainline’s rich datasets with cutting edge algorithms. What unites our team is an expertise in the field, a love of what we do and the desire to create impactful solutions to support Trainline’s goals of encouraging sustainable travel.  As a part of Trainline you will be joining an environment where learning and development is top priority. You will have the opportunity to work with fellow ML enthusiasts on large-scale production systems, delivering highly impactful products that make a difference to our millions of users.  As a Senior Machine Learning Engineer at Trainline you will... 🚄   Work in cross-functional teams combining data scientists, software, data and machine learning engineers, and product managers  Design and deliver machine learning models at scale that drive measurable impact for our business  Own the full end to end machine learning delivery lifecycle including data exploration, feature engineering, model selection and tuning, offline and online evaluation, deployments and maintenance  Partner with stakeholders to propose innovative data products that leverage Trainline’s extensive datasets and state of the art algorithms  Create the tools, frameworks and libraries that enables the acceleration of our ML products delivery and improve our workflows  Take an active part in our AI and ML community and foster a culture of rigorous learning and experimentation We'd love to hear from you if you...🔍   Have an advanced degree in Computer Science, Mathematics or a similar quantitative discipline  Are proficient with Python, including open-source data libraries (e.g Pandas, Numpy, Scikit learn etc.)    Have experience productionising machine learning models   Are an expert in one of predictive modeling, classification, regression, optimisation or recommendation systems  Have experience with Spark   Have knowledge of DevOps technologies such as Docker and Terraform and ML Ops practices and platforms like ML Flow  Have experience with agile delivery methodologies and CI/CD processes and tools  Have a broad of understanding of data extraction, data manipulation and feature engineering techniques   Are familiar with statistical methodologies.  Have good communication skills   Nice to have 😍 Experience with transport industry and/or geographical information systems (GIS)  Experience with cloud infrastructure  Understanding of NLP algorithms and techniques  and/or experience with Large Language Models (fine tuning, RAG, agents)  Experience with graph technology and/or algorithms Our technology stack 💻  Python and associated ML/DS libraries (scikit-learn, NumPy, LightGBM, Pandas, LangChain/LangGraph, TensorFlow, etc...) PySpark AWS cloud infrastructure: EMR, ECS, Athena, etc.  MLOps: Terraform, Docker, Airflow, MLFlow  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F) Confirmé(e)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "MP DATA",
        "location": "Boulogne-Billancourt",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "100",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-h-f-confirme_boulogne-billancourt?q=80f6ac0930b006f8455c20e4f0d394af&o=00126ea6-6a95-463f-a51a-305e54553d48",
        "description": "Descriptif du posteMP DATA recrute un(e) Data Engineer (H/F).Dans le cadre de la transformation digitale industriel, l’équipe de data engineering en charge de l’exploitation du Cluster Big Data cherche à se développer.En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse. Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F) Confirmé(e)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "MP DATA",
        "location": "Boulogne-Billancourt",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "100",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-h-f-confirme_boulogne-billancourt?q=80f6ac0930b006f8455c20e4f0d394af&o=00126ea6-6a95-463f-a51a-305e54553d48",
        "description": "Descriptif du posteMP DATA recrute un(e) Data Engineer (H/F).Dans le cadre de la transformation digitale industriel, l’équipe de data engineering en charge de l’exploitation du Cluster Big Data cherche à se développer.En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse. Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Data",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Daveo",
        "location": "Lille",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, SaaS / Cloud Services",
            "company_size": "230",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "28M",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/daveo/jobs/ingenieur-data_lille?q=80f6ac0930b006f8455c20e4f0d394af&o=2288354c-b113-4ab9-9401-b774ce6c2bef",
        "description": "Descriptif du posteDaveo est un cabinet de conseil spécialisé dans les domaines du product management, de la technologie et du cloud. Fondé en 2008, Daveo a bâti sa réputation sur une culture d’entreprise forte axée sur la réussite collective.Voici quelques points clés à propos de Daveo :Innovation et Collaboration : Daveo allie amour de l’innovation et état d’esprit collaboratif pour offrir des solutions de pointe à ses clients.Expertise : Daveo est un pure player du product management, de la tech et du cloud public AWS et GCP. L’entreprise est présente dans plusieurs villes, dont Paris, Lille, Lyon, Bordeaux et Nantes.Accompagnement à 360° : Daveo propose un accompagnement complet à ses clients, en mettant en avant ses compétences en matière d’innovation, de technologie et de gestion de produits.En somme, Daveo est un acteur dynamique qui allie expertise technique, culture de la différence et ambition de réussite collective. 🚀Rejoindre Daveo c’est Offrir une expérience collaborateur impactante : la réussite de votre projet professionnel est indissociable du développement de Daveo-———————————————————————Localisation : LilleMode de travail hybride avec 2 jours de télétravail par semaine.Fourchette salariale comprise entre 45€ - 55k€ selon expérience et niveau de compétence.Expérience requise : 3 ans sur un rôle de Data Engineer (hors stage)-———————————————————————Intégré au sein des équipes de notre client votre mission consiste à :· Collecte et stockage des données : trouver des solutions pour collecter facilement des données provenant de sources variées telles que les réseaux sociaux, les retours terrain, les sites web, les applications, etc. Il les intègre ensuite dans un lieu de stockage centralisé.· Compréhension des besoins des utilisateurs : Identifier les besoins de l’organisation en concevant une infrastructure data adaptée. Par exemple, déterminer les données pertinentes, quel format est optimal, et où stocker les données.· Garantie de l’accès aux données : Nettoyer les données en doublon, obsolètes, fausses ou erronées, et uniformise leur format pour qu’elles soient lisibles dans les différents outils de l’entreprise.Intégrer Daveo c’est aussi la possibilité de :Co-construire une innovation durableFaire rayonner l’expertise Daveo au sein de nos différents EventsÊtre acteur de la formation et de la montée en compétences de nos collaborateursS’investir sur des projets d’innovation au sein de notre LabeoPoursuivre son apprentissage et sa montée en compétence au travers de nos parcours de formations."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Data",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "Daveo",
        "location": "Lille",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, SaaS / Cloud Services",
            "company_size": "230",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "28M",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "gcp."
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/daveo/jobs/ingenieur-data_lille?q=80f6ac0930b006f8455c20e4f0d394af&o=2288354c-b113-4ab9-9401-b774ce6c2bef",
        "description": "Descriptif du posteDaveo est un cabinet de conseil spécialisé dans les domaines du product management, de la technologie et du cloud. Fondé en 2008, Daveo a bâti sa réputation sur une culture d’entreprise forte axée sur la réussite collective.Voici quelques points clés à propos de Daveo :Innovation et Collaboration : Daveo allie amour de l’innovation et état d’esprit collaboratif pour offrir des solutions de pointe à ses clients.Expertise : Daveo est un pure player du product management, de la tech et du cloud public AWS et GCP. L’entreprise est présente dans plusieurs villes, dont Paris, Lille, Lyon, Bordeaux et Nantes.Accompagnement à 360° : Daveo propose un accompagnement complet à ses clients, en mettant en avant ses compétences en matière d’innovation, de technologie et de gestion de produits.En somme, Daveo est un acteur dynamique qui allie expertise technique, culture de la différence et ambition de réussite collective. 🚀Rejoindre Daveo c’est Offrir une expérience collaborateur impactante : la réussite de votre projet professionnel est indissociable du développement de Daveo-———————————————————————Localisation : LilleMode de travail hybride avec 2 jours de télétravail par semaine.Fourchette salariale comprise entre 45€ - 55k€ selon expérience et niveau de compétence.Expérience requise : 3 ans sur un rôle de Data Engineer (hors stage)-———————————————————————Intégré au sein des équipes de notre client votre mission consiste à :· Collecte et stockage des données : trouver des solutions pour collecter facilement des données provenant de sources variées telles que les réseaux sociaux, les retours terrain, les sites web, les applications, etc. Il les intègre ensuite dans un lieu de stockage centralisé.· Compréhension des besoins des utilisateurs : Identifier les besoins de l’organisation en concevant une infrastructure data adaptée. Par exemple, déterminer les données pertinentes, quel format est optimal, et où stocker les données.· Garantie de l’accès aux données : Nettoyer les données en doublon, obsolètes, fausses ou erronées, et uniformise leur format pour qu’elles soient lisibles dans les différents outils de l’entreprise.Intégrer Daveo c’est aussi la possibilité de :Co-construire une innovation durableFaire rayonner l’expertise Daveo au sein de nos différents EventsÊtre acteur de la formation et de la montée en compétences de nos collaborateursS’investir sur des projets d’innovation au sein de notre LabeoPoursuivre son apprentissage et sa montée en compétence au travers de nos parcours de formations."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer & Innovation - Stage",
        "contract_type": "Stage(6 mois)",
        "salary": "Non spécifié",
        "company": "Removall",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Environnement / Développement durable, Stratégie, Finance",
            "company_size": "21",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/removall/jobs/ia-data-for-nature-stage_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=a0695d71-7150-442a-98e8-273524e2ef84",
        "description": "Descriptif du posteRattaché au département Innovation, le/la stagiaire Data Engineer & Innovation aura un champ d’action transverse, en collaboration avec l’ensemble des départements de l’entreprise. Ses principales responsabilités seront :-          Data Management :o  Améliorer la gestion des bases de données de manière harmonisée à l’échelle de l’entrepriseo   Concevoir des tableaux de bord de restitution de résultats des analyses et indicateurs métiers, en particulier grâce à des outils de data visualisationo   Créer des nouveaux KPIs ou jeux de données selon les demandes métiers-          Stratégie sur les outils IT dans l’entreprise :o   Etat des lieux des process et outillages des différents départements de l’entrepriseo   Identification des besoins, priorisation et quantification du retour sur investissemento   Choix de solutions innovantes et implémentation technique-          Développement d’un outil facilitant la certification de projets carbone et plastique à forts impactso   Comprendre les méthodologies de certification de projets environnementauxo   Etablir le cahier des charges de l’outil, le planning de production,et le choix de la solution technologiqueo   Implémenter l’outil et former les collaborateurs"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer & Innovation - Stage",
        "contract_type": "Stage(6 mois)",
        "salary": "Non spécifié",
        "company": "Removall",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Environnement / Développement durable, Stratégie, Finance",
            "company_size": "21",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/removall/jobs/ia-data-for-nature-stage_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=a0695d71-7150-442a-98e8-273524e2ef84",
        "description": "Descriptif du posteRattaché au département Innovation, le/la stagiaire Data Engineer & Innovation aura un champ d’action transverse, en collaboration avec l’ensemble des départements de l’entreprise. Ses principales responsabilités seront :-          Data Management :o  Améliorer la gestion des bases de données de manière harmonisée à l’échelle de l’entrepriseo   Concevoir des tableaux de bord de restitution de résultats des analyses et indicateurs métiers, en particulier grâce à des outils de data visualisationo   Créer des nouveaux KPIs ou jeux de données selon les demandes métiers-          Stratégie sur les outils IT dans l’entreprise :o   Etat des lieux des process et outillages des différents départements de l’entrepriseo   Identification des besoins, priorisation et quantification du retour sur investissemento   Choix de solutions innovantes et implémentation technique-          Développement d’un outil facilitant la certification de projets carbone et plastique à forts impactso   Comprendre les méthodologies de certification de projets environnementauxo   Etablir le cahier des charges de l’outil, le planning de production,et le choix de la solution technologiqueo   Implémenter l’outil et former les collaborateurs"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Data Engineer sur GCP (H/F)",
        "contract_type": "Stage(4 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Tata Consultancy Services",
        "location": "Suresnes",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "601000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "$ 29 milliards",
            "proportion_female": "36",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml/ai",
                "cloud.missionsnous",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/stage-data-engineer-sur-gcp-h-f_suresnes?q=80f6ac0930b006f8455c20e4f0d394af&o=b2ea7c20-7eb0-4cf4-bba9-a4b721a06c2b",
        "description": "Descriptif du postePoste basé à la Défense (92)Durée du stage : 6 moisTata Consultancy Services (TCS) est une société de services informatiques et de conseil qui s’associe depuis 55 ans à de nombreuses entreprises parmi les plus importantes au monde dans leurs parcours de transformation. En tant que membre du groupe Tata, le plus grand groupe multinational de l’Inde, TCS compte plus de 614 000 consultants parmi les mieux formés au monde dans 55 pays.TCS France est au service de plus de 80 clients (marques réputées et faisant partie du CAC40) en France depuis plus de 28 ans avec 1 500 employés et des investissements couvrant toutes les régions. Avec son centre d’innovation et plusieurs centres de service, TCS France délivre une croissance à deux chiffres depuis plus de 5 ans en accompagnant ses clients dans leur transformation digitale et leurs problématiques Data et cloud.MissionsNous te proposons d’intégrer notre DATA & AI Practice France pour travailler sur l’implémentation de solution BIG DATA & ML/AI pour un client grand compte.Au sein d’une équipe TCS, tu commenceras par une période de formation avant de commencer à travailler sous la responsabilité d’un consultant SENIOR. Tu auras au démarrage des tâches très concrètes de mise en place de data pipeline sur les solutions GOOGLE CLOUD PLATFORM. Et progressivement tu monteras en compétences pour gagner en autonomie.Ton objectif sera d’obtenir une certification GOOGLE CLOUD PLATFORM en fin de stage."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Data Engineer sur GCP (H/F)",
        "contract_type": "Stage(4 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Tata Consultancy Services",
        "location": "Suresnes",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "601000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "$ 29 milliards",
            "proportion_female": "36",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml/ai",
                "cloud.missionsnous",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/stage-data-engineer-sur-gcp-h-f_suresnes?q=80f6ac0930b006f8455c20e4f0d394af&o=b2ea7c20-7eb0-4cf4-bba9-a4b721a06c2b",
        "description": "Descriptif du postePoste basé à la Défense (92)Durée du stage : 6 moisTata Consultancy Services (TCS) est une société de services informatiques et de conseil qui s’associe depuis 55 ans à de nombreuses entreprises parmi les plus importantes au monde dans leurs parcours de transformation. En tant que membre du groupe Tata, le plus grand groupe multinational de l’Inde, TCS compte plus de 614 000 consultants parmi les mieux formés au monde dans 55 pays.TCS France est au service de plus de 80 clients (marques réputées et faisant partie du CAC40) en France depuis plus de 28 ans avec 1 500 employés et des investissements couvrant toutes les régions. Avec son centre d’innovation et plusieurs centres de service, TCS France délivre une croissance à deux chiffres depuis plus de 5 ans en accompagnant ses clients dans leur transformation digitale et leurs problématiques Data et cloud.MissionsNous te proposons d’intégrer notre DATA & AI Practice France pour travailler sur l’implémentation de solution BIG DATA & ML/AI pour un client grand compte.Au sein d’une équipe TCS, tu commenceras par une période de formation avant de commencer à travailler sous la responsabilité d’un consultant SENIOR. Tu auras au démarrage des tâches très concrètes de mise en place de data pipeline sur les solutions GOOGLE CLOUD PLATFORM. Et progressivement tu monteras en compétences pour gagner en autonomie.Ton objectif sera d’obtenir une certification GOOGLE CLOUD PLATFORM en fin de stage."
    },
    {
        "source": "welcometothejungle",
        "job_title": "[Luxe] | Cloud Data Analyst / Engineer (H/F) PARIS",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Cenova",
        "location": "Neuilly-sur-Seine",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation",
            "company_size": "70",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,"
            ],
            "DataBase": [
                "sql,",
                "sql",
                "mysql,",
                "mongodb"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux",
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure",
                "azure)",
                "gcp",
                "(gcp"
            ],
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": [
                "mysql,",
                "bigquery"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cenova/jobs/luxe-cloud-data-analyst-engineer-h-f-paris_neuilly-sur-seine?q=80f6ac0930b006f8455c20e4f0d394af&o=b22f4069-f93c-42f7-8a28-d5eb458b4426",
        "description": "Descriptif du postePour le compte de l’un de nos clients, acteur majeur du secteur du luxe, vous rejoignez une équipe projet pour contribuer à la mise en place d’une “Analytics Data Platform”. Environnement technique : Cloud : Microsoft Azure, GCP Langages : SQL, Python, Spark Base de données : SQL Server, Oracle, MySQL, MongoDB Datamanagement : Fabric, Azure Data Factory / Databricks / Synapse / BigQuery Datavisualisation : Power BI, DAX Repository : GIT, Azure DevOps En tant que Data Analyst, vos missions principales sont les suivantes : Collecter et préparer les données (Power BI) Nettoyer et structurer les données afin de garantir leur qualité Recueillir les besoins des équipes métier (marketing, finance, RH, supply, retail, etc.)  Créer des tableaux de bord visuels et dynamiques dans Power BI  Définir, améliorer et analyser les KPI’s pertinents pour le suivi des performances Effectuer des analyses descriptives, exploratoires et prédictives Identifier les tendances et les anomalies pour fournir des insights décisionnels  Contribuer à l’automatisation des flux de données  Mettre en œuvre des processus d’optimisation  Se tenir informé des nouvelles fonctionnalités des outils de data visualisation du marché Former les utilisateurs finaux à l’utilisation des tableaux de bord et rapports Power BI. Être responsable de la validation des recettes avant livraison en production Vous pouvez également apporter une expertise en data engineering sur les aspects suivants : Concevoir et mettre en œuvre des solutions de traitement de données dans un environnement Cloud (GCP / Azure) Mener des études de faisabilité et préconiser les architectures data cibles Créer, tester et déployer des pipelines de données d’extraction, de transformation et de chargement Mettre en application les concepts de CI/CD via les outils dédiés"
    },
    {
        "source": "welcometothejungle",
        "job_title": "[Luxe] | Cloud Data Analyst / Engineer (H/F) PARIS",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Cenova",
        "location": "Neuilly-sur-Seine",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation",
            "company_size": "70",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,"
            ],
            "DataBase": [
                "sql,",
                "sql",
                "mysql,",
                "mongodb"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableaux",
                "tableaux"
            ],
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure",
                "azure)",
                "gcp",
                "(gcp"
            ],
            "DevTools": [
                "git,"
            ],
            "OS": null,
            "DBMS": [
                "mysql,",
                "bigquery"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloud",
                "cloud",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cenova/jobs/luxe-cloud-data-analyst-engineer-h-f-paris_neuilly-sur-seine?q=80f6ac0930b006f8455c20e4f0d394af&o=b22f4069-f93c-42f7-8a28-d5eb458b4426",
        "description": "Descriptif du postePour le compte de l’un de nos clients, acteur majeur du secteur du luxe, vous rejoignez une équipe projet pour contribuer à la mise en place d’une “Analytics Data Platform”. Environnement technique : Cloud : Microsoft Azure, GCP Langages : SQL, Python, Spark Base de données : SQL Server, Oracle, MySQL, MongoDB Datamanagement : Fabric, Azure Data Factory / Databricks / Synapse / BigQuery Datavisualisation : Power BI, DAX Repository : GIT, Azure DevOps En tant que Data Analyst, vos missions principales sont les suivantes : Collecter et préparer les données (Power BI) Nettoyer et structurer les données afin de garantir leur qualité Recueillir les besoins des équipes métier (marketing, finance, RH, supply, retail, etc.)  Créer des tableaux de bord visuels et dynamiques dans Power BI  Définir, améliorer et analyser les KPI’s pertinents pour le suivi des performances Effectuer des analyses descriptives, exploratoires et prédictives Identifier les tendances et les anomalies pour fournir des insights décisionnels  Contribuer à l’automatisation des flux de données  Mettre en œuvre des processus d’optimisation  Se tenir informé des nouvelles fonctionnalités des outils de data visualisation du marché Former les utilisateurs finaux à l’utilisation des tableaux de bord et rapports Power BI. Être responsable de la validation des recettes avant livraison en production Vous pouvez également apporter une expertise en data engineering sur les aspects suivants : Concevoir et mettre en œuvre des solutions de traitement de données dans un environnement Cloud (GCP / Azure) Mener des études de faisabilité et préconiser les architectures data cibles Créer, tester et déployer des pipelines de données d’extraction, de transformation et de chargement Mettre en application les concepts de CI/CD via les outils dédiés"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Data Engineer AZURE & DATABRICKS (H/F)",
        "contract_type": "Stage(4 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Tata Consultancy Services",
        "location": "Suresnes",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "601000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "$ 29 milliards",
            "proportion_female": "36",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "databricks.",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure",
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml/ai",
                "cloud.missionsnous"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/stage-data-engineer-azure-databricks-h-f_puteaux?q=80f6ac0930b006f8455c20e4f0d394af&o=a00c550b-8c4f-4362-9db4-8f6ec2292a73",
        "description": "Descriptif du postePoste basé à la Défense (92)Durée du stage : 6 moisTata Consultancy Services (TCS) est une société de services informatiques et de conseil qui s’associe depuis 55 ans à de nombreuses entreprises parmi les plus importantes au monde dans leurs parcours de transformation. En tant que membre du groupe Tata, le plus grand groupe multinational de l’Inde, TCS compte plus de 614 000 consultants parmi les mieux formés au monde dans 55 pays.TCS France est au service de plus de 80 clients (marques réputées et faisant partie du CAC40) en France depuis plus de 28 ans avec 1 500 employés et des investissements couvrant toutes les régions. Avec son centre d’innovation et plusieurs centres de service, TCS France délivre une croissance à deux chiffres depuis plus de 5 ans en accompagnant ses clients dans leur transformation digitale et leurs problématiques Data et cloud.MissionsNous te proposons d’intégrer notre DATA & AI Practice France pour travailler sur l’implémentation de solution BIG DATA & ML/AI pour un client grand compte.Au sein d’une équipe TCS, tu commenceras par une période de formation avant de commencer à travailler sous la responsabilité d’un consultant SENIOR. Tu auras au démarrage des tâches très concrètes de mise en place de data pipeline sur les solutions MS AZURE & DATABRICKS. Et progressivement tu monteras en compétences pour gagner en autonomie.Ton objectif sera d’obtenir une certification MS AZURE ou DATABRICKS en fin de stage.Ceci est un stage de pré-embauche."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Data Engineer AZURE & DATABRICKS (H/F)",
        "contract_type": "Stage(4 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Tata Consultancy Services",
        "location": "Suresnes",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "601000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "$ 29 milliards",
            "proportion_female": "36",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "databricks.",
                "databricks"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure",
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml/ai",
                "cloud.missionsnous"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/tata-consultancy-services/jobs/stage-data-engineer-azure-databricks-h-f_puteaux?q=80f6ac0930b006f8455c20e4f0d394af&o=a00c550b-8c4f-4362-9db4-8f6ec2292a73",
        "description": "Descriptif du postePoste basé à la Défense (92)Durée du stage : 6 moisTata Consultancy Services (TCS) est une société de services informatiques et de conseil qui s’associe depuis 55 ans à de nombreuses entreprises parmi les plus importantes au monde dans leurs parcours de transformation. En tant que membre du groupe Tata, le plus grand groupe multinational de l’Inde, TCS compte plus de 614 000 consultants parmi les mieux formés au monde dans 55 pays.TCS France est au service de plus de 80 clients (marques réputées et faisant partie du CAC40) en France depuis plus de 28 ans avec 1 500 employés et des investissements couvrant toutes les régions. Avec son centre d’innovation et plusieurs centres de service, TCS France délivre une croissance à deux chiffres depuis plus de 5 ans en accompagnant ses clients dans leur transformation digitale et leurs problématiques Data et cloud.MissionsNous te proposons d’intégrer notre DATA & AI Practice France pour travailler sur l’implémentation de solution BIG DATA & ML/AI pour un client grand compte.Au sein d’une équipe TCS, tu commenceras par une période de formation avant de commencer à travailler sous la responsabilité d’un consultant SENIOR. Tu auras au démarrage des tâches très concrètes de mise en place de data pipeline sur les solutions MS AZURE & DATABRICKS. Et progressivement tu monteras en compétences pour gagner en autonomie.Ton objectif sera d’obtenir une certification MS AZURE ou DATABRICKS en fin de stage.Ceci est un stage de pré-embauche."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Ingénieur SI Finances F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Poste Groupe",
        "location": "Nantes",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": "Bac",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logistique",
            "company_size": "232700",
            "creation_date": "1477",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-poste-groupe/jobs/data-ingenieur-si-finances-f-h_nantes_LPG_RoAq8bo?q=80f6ac0930b006f8455c20e4f0d394af&o=472cfd2a-ef48-41fb-bd71-2b844886518d",
        "description": "Descriptif du posteEn rejoignant I-team en tant que Data Ingénieur SI Finances vous intégrerez la direction des services IT du Groupe La Poste à Nantes. I-team, c’est 1000 collaborateurs au service des systèmes d’information du Groupe et de ses filiales. Vous rejoindrez le pôle Reportings Financiers dont la mission principale correspond aux projets décisionnels impactant le Datalake groupe. Il gère en autonomie le domaine finance du Datalake, notamment la mise en œuvre des nouveaux projets : ingestion, data prep et data viz.Les projets sont nombreux ! Ils peuvent venir de normes règlementaires, par exemple pour le pilotage de la performance RSE ; Ils peuvent également être liés aux projets de transformation stratégique du groupe, ou permettre la simplification des tâches via l’intégration d’Intelligences artificielles.Vos missions :Contribuer aux projets d’évolution des reportings financiersConcevoir la solution technique répondant au besoin métier, s’intégrant dans l’architecture existante et adaptée aux contraintes techniqueRéaliser un développement optimisé, maintenable et documentéContribuer à l’évolution technique du domaine finance du datalakeContribuer au projet de migration dans le cloud du datalake sur les différentes phases (Etude, analyse, Conception, réalisation, Aide à la montée en compétence de l’équipe)Etre moteur pour l’intégration des nouvelles technologies arrivant via le métier ou le socle technique"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Ingénieur SI Finances F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Poste Groupe",
        "location": "Nantes",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": "Bac",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logistique",
            "company_size": "232700",
            "creation_date": "1477",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-poste-groupe/jobs/data-ingenieur-si-finances-f-h_nantes_LPG_RoAq8bo?q=80f6ac0930b006f8455c20e4f0d394af&o=472cfd2a-ef48-41fb-bd71-2b844886518d",
        "description": "Descriptif du posteEn rejoignant I-team en tant que Data Ingénieur SI Finances vous intégrerez la direction des services IT du Groupe La Poste à Nantes. I-team, c’est 1000 collaborateurs au service des systèmes d’information du Groupe et de ses filiales. Vous rejoindrez le pôle Reportings Financiers dont la mission principale correspond aux projets décisionnels impactant le Datalake groupe. Il gère en autonomie le domaine finance du Datalake, notamment la mise en œuvre des nouveaux projets : ingestion, data prep et data viz.Les projets sont nombreux ! Ils peuvent venir de normes règlementaires, par exemple pour le pilotage de la performance RSE ; Ils peuvent également être liés aux projets de transformation stratégique du groupe, ou permettre la simplification des tâches via l’intégration d’Intelligences artificielles.Vos missions :Contribuer aux projets d’évolution des reportings financiersConcevoir la solution technique répondant au besoin métier, s’intégrant dans l’architecture existante et adaptée aux contraintes techniqueRéaliser un développement optimisé, maintenable et documentéContribuer à l’évolution technique du domaine finance du datalakeContribuer au projet de migration dans le cloud du datalake sur les différentes phases (Etude, analyse, Conception, réalisation, Aide à la montée en compétence de l’équipe)Etre moteur pour l’intégration des nouvelles technologies arrivant via le métier ou le socle technique"
    },
    {
        "source": "welcometothejungle",
        "job_title": "ANALYTICS Engineer - Expérimenté",
        "contract_type": "CDI",
        "salary": "47K à 57K €",
        "company": "CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY",
        "location": "Toulouse, Versailles, Lyon",
        "remote": "Télétravail occasionnel",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Big Data, Cybersécurité",
            "company_size": "25",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": "1",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "hadoop)"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws,",
                "aws",
                "aws,",
                "(aws,",
                "gcp…),"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake",
                "snowflake."
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudera"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/castle-bee-data-cloud-cyber-foundry/jobs/data-analyst-senior-snowflake-tableau-aws?q=80f6ac0930b006f8455c20e4f0d394af&o=c2a5f871-b8a9-4ff3-bb31-7713c4535652",
        "description": "Descriptif du posteAu sein du pôle DataOps chez Castle Bee, vous allez intégrer les squads data de notre client, grand compte. Votre rôle sera de collecter les données de notre client, de les transformer et d’apporter de la valeur aux différents business unit du groupe. Sensible à la protection des données personnelles, à la gouvernance des données et au suivi des données, votre mission première est d’assurer une qualité optimale des données et de leurs applications. Pour la réussite de ses projets, vous serez intégr(e), au sein de l’équipe Data Engineering qui travaille les Data Product et les équipes métiers. Responsabilités : En pleine transformation vers les nouvelles fonctionnalités des environnements CLOUD (Amazon AWS, Google GCP…), vous apporterez toute votre expertise à la mise en œuvre de solutions BI, intelligence artificielle et Big Data dans un environnement industriel, étroitement lié à toutes les parties prenantes du Produit. Vous travaillerez avec différents partenaires tels que des experts data business, des data scientists, des data managers, Data Product, mais aussi des dev-ops et de la sécurité. Vous allez travailler sur un  Datalake hybride Cloudera hébergé chez AWS en pleine migration vers full AWS, de son Snowflake DatawareHouseVotre travail consiste à encadrer les acteurs du développement et de l’amélioration de cette plateforme avec l’utilisation des micro-services Amazon DWS, Hadoop, Snowflake. Responsabilités : Superviser une équipe de Data Engineers Référence technique pour le Big Data (AWS, Hadoop) Intégration des données dans le Datalake Développement de modèles de données Développement du flocon de neige DWH Extraire des données du Datalake Industrialisation des projets Data Science Industrialisation des projets Big Data"
    },
    {
        "source": "welcometothejungle",
        "job_title": "ANALYTICS Engineer - Expérimenté",
        "contract_type": "CDI",
        "salary": "47K à 57K €",
        "company": "CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY",
        "location": "Toulouse, Versailles, Lyon",
        "remote": "Télétravail occasionnel",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Big Data, Cybersécurité",
            "company_size": "25",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": "1",
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "hadoop)"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws,",
                "aws",
                "aws,",
                "(aws,",
                "gcp…),"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake",
                "snowflake."
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloudera"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/castle-bee-data-cloud-cyber-foundry/jobs/data-analyst-senior-snowflake-tableau-aws?q=80f6ac0930b006f8455c20e4f0d394af&o=c2a5f871-b8a9-4ff3-bb31-7713c4535652",
        "description": "Descriptif du posteAu sein du pôle DataOps chez Castle Bee, vous allez intégrer les squads data de notre client, grand compte. Votre rôle sera de collecter les données de notre client, de les transformer et d’apporter de la valeur aux différents business unit du groupe. Sensible à la protection des données personnelles, à la gouvernance des données et au suivi des données, votre mission première est d’assurer une qualité optimale des données et de leurs applications. Pour la réussite de ses projets, vous serez intégr(e), au sein de l’équipe Data Engineering qui travaille les Data Product et les équipes métiers. Responsabilités : En pleine transformation vers les nouvelles fonctionnalités des environnements CLOUD (Amazon AWS, Google GCP…), vous apporterez toute votre expertise à la mise en œuvre de solutions BI, intelligence artificielle et Big Data dans un environnement industriel, étroitement lié à toutes les parties prenantes du Produit. Vous travaillerez avec différents partenaires tels que des experts data business, des data scientists, des data managers, Data Product, mais aussi des dev-ops et de la sécurité. Vous allez travailler sur un  Datalake hybride Cloudera hébergé chez AWS en pleine migration vers full AWS, de son Snowflake DatawareHouseVotre travail consiste à encadrer les acteurs du développement et de l’amélioration de cette plateforme avec l’utilisation des micro-services Amazon DWS, Hadoop, Snowflake. Responsabilités : Superviser une équipe de Data Engineers Référence technique pour le Big Data (AWS, Hadoop) Intégration des données dans le Datalake Développement de modèles de données Développement du flocon de neige DWH Extraire des données du Datalake Industrialisation des projets Data Science Industrialisation des projets Big Data"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert en Intelligence Artificielle et Data Science",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Bluekango",
        "location": "Cesson-Sévigné",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",
            "company_size": "170",
            "creation_date": "2002",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/bluekango/jobs/expert-en-intelligence-artificielle-et-data-science_cesson-sevigne?q=80f6ac0930b006f8455c20e4f0d394af&o=b570c1ad-c70c-40d3-a404-c800ea039666",
        "description": "Descriptif du posteNous cherchons à renforcer notre équipe en recrutant un expert en IA capable de mener des projets complexes de traitement et d’analyse de données, tout en intégrant les dernières avancées technologiques en intelligence artificielle.Ce que vous ferez en tant qu’expert en Intelligence Artificielle et Data Science :Travailler en étroite collaboration avec des équipes pluridisciplinaires (R&D, commerce, marketing, support, etc.) afin d’identifier les besoins en IADévelopper et implémenter des modèles d’intelligence artificielle (Machine Learning, Deep Learning) pour répondre à ces besoins métiers spécifiques internes, mais aussi clientsGérer et traiter de larges volumes de données structurées et non structurées (Big Data) afin d’en extraire des insights exploitablesConcevoir et optimiser des pipelines de données pour alimenter des modèles prédictifs et de classificationCollaborer avec les équipes techniques et métier pour identifier des solutions innovantes à partir des donnéesAssurer une veille technologique active sur les nouvelles méthodes et outils en intelligence artificielle et data science"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert en Intelligence Artificielle et Data Science",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Bluekango",
        "location": "Cesson-Sévigné",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",
            "company_size": "170",
            "creation_date": "2002",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/bluekango/jobs/expert-en-intelligence-artificielle-et-data-science_cesson-sevigne?q=80f6ac0930b006f8455c20e4f0d394af&o=b570c1ad-c70c-40d3-a404-c800ea039666",
        "description": "Descriptif du posteNous cherchons à renforcer notre équipe en recrutant un expert en IA capable de mener des projets complexes de traitement et d’analyse de données, tout en intégrant les dernières avancées technologiques en intelligence artificielle.Ce que vous ferez en tant qu’expert en Intelligence Artificielle et Data Science :Travailler en étroite collaboration avec des équipes pluridisciplinaires (R&D, commerce, marketing, support, etc.) afin d’identifier les besoins en IADévelopper et implémenter des modèles d’intelligence artificielle (Machine Learning, Deep Learning) pour répondre à ces besoins métiers spécifiques internes, mais aussi clientsGérer et traiter de larges volumes de données structurées et non structurées (Big Data) afin d’en extraire des insights exploitablesConcevoir et optimiser des pipelines de données pour alimenter des modèles prédictifs et de classificationCollaborer avec les équipes techniques et métier pour identifier des solutions innovantes à partir des donnéesAssurer une veille technologique active sur les nouvelles méthodes et outils en intelligence artificielle et data science"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Architecture de streaming data H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "NEXTON",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Design, IT / Digital, Digital",
            "company_size": "450",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "31 millions",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-architecture-de-streaming-data-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=bdd44e9d-aff5-46b9-8cf5-1a8865a66a75",
        "description": "Descriptif du posteNexton recrute un Data Engineer - Architecture de streaming data H/F, en CDI, à Paris !  Ton futur environnement de travail : Tu seras au cœur du plan de transformation DATA de notre compte client, qui vise à autonomiser les métiers business (pilotage, marketing, commerce, etc.) dans l’analyse des données et des KPI grâce à des applications DATA avancées.Tes missions : En tant que Data Engineer sur des architectures de streaming data, tu seras en charge de :Concevoir et développer des pipelines de données performants.Développer des solutions en utilisant des outils comme Scala, Spark, DBT.Implémenter des architectures de Streaming Data sur AWS (Lambda, Kinesis Stream, S3, Firehose, EMR Serverless, DynamoDB, etc.).Contribuer aux initiatives FinOps pour optimiser les coûts liés aux architectures Big Data.Développer et optimiser des traitements d'intégration de données en streaming, traitant plus de 100 To de données par jour.Participer à des projets innovants tels que :Systèmes de recommandation AI ;Feature Store ;Modernisation des flux financiers ;Plateforme de traitement des données CRM et usage ;Intégration de données pour partenaires stratégiques. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Architecture de streaming data H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "NEXTON",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "Design, IT / Digital, Digital",
            "company_size": "450",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "31 millions",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/nexton-consulting/jobs/data-engineer-architecture-de-streaming-data-h-f_paris?q=80f6ac0930b006f8455c20e4f0d394af&o=bdd44e9d-aff5-46b9-8cf5-1a8865a66a75",
        "description": "Descriptif du posteNexton recrute un Data Engineer - Architecture de streaming data H/F, en CDI, à Paris !  Ton futur environnement de travail : Tu seras au cœur du plan de transformation DATA de notre compte client, qui vise à autonomiser les métiers business (pilotage, marketing, commerce, etc.) dans l’analyse des données et des KPI grâce à des applications DATA avancées.Tes missions : En tant que Data Engineer sur des architectures de streaming data, tu seras en charge de :Concevoir et développer des pipelines de données performants.Développer des solutions en utilisant des outils comme Scala, Spark, DBT.Implémenter des architectures de Streaming Data sur AWS (Lambda, Kinesis Stream, S3, Firehose, EMR Serverless, DynamoDB, etc.).Contribuer aux initiatives FinOps pour optimiser les coûts liés aux architectures Big Data.Développer et optimiser des traitements d'intégration de données en streaming, traitant plus de 100 To de données par jour.Participer à des projets innovants tels que :Systèmes de recommandation AI ;Feature Store ;Modernisation des flux financiers ;Plateforme de traitement des données CRM et usage ;Intégration de données pour partenaires stratégiques. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer @eXalt Lille",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "eXalt",
        "location": "Lille",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-lille_lille?q=a6b09c99a6a04801acff655dede1f77d&o=fc71812a-0d21-443c-831f-0d9c40a52d67",
        "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre expertise IT, recherche son/sa nouveau/elle Data Engineer pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer @eXalt Lille",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "eXalt",
        "location": "Lille",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-lille_lille?q=a6b09c99a6a04801acff655dede1f77d&o=fc71812a-0d21-443c-831f-0d9c40a52d67",
        "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre expertise IT, recherche son/sa nouveau/elle Data Engineer pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris, Caen",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java",
                "scalabilité,"
            ],
            "DataBase": [
                "postgresql)connaissance",
                "postgresqllakehouse:"
            ],
            "DataAnalytics": [
                "(pandas,"
            ],
            "BigData": [
                "spark",
                "(pyspark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "azure),",
                "gcp"
            ],
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": [
                "postgresql)connaissance",
                "postgresqllakehouse:",
                "snowflake,",
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,"
            ],
            "InfrastructureAsCode": [
                "(terraform)expérience"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,"
            ],
            "Collaboration": null,
            "Other": [
                "mle/mlops",
                "uml,",
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-senior-cdi-paris-ou-caen?q=a6b09c99a6a04801acff655dede1f77d&o=6696f7e0-63be-4373-8470-85bff272293b",
        "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu seras impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec tes pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager ton savoir-faire avec les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,Assurer une veille technologique et savoir mener à bien un projet de R&D.Tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ELT : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse: Delta LakeConnaissance message broker : RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris, Caen",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "java",
                "scalabilité,"
            ],
            "DataBase": [
                "postgresql)connaissance",
                "postgresqllakehouse:"
            ],
            "DataAnalytics": [
                "(pandas,"
            ],
            "BigData": [
                "spark",
                "(pyspark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "(aws,",
                "azure),",
                "gcp"
            ],
            "DevTools": [
                "digitales"
            ],
            "OS": null,
            "DBMS": [
                "postgresql)connaissance",
                "postgresqllakehouse:",
                "snowflake,",
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": [
                "kubernetes,"
            ],
            "InfrastructureAsCode": [
                "(terraform)expérience"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes,"
            ],
            "Collaboration": null,
            "Other": [
                "mle/mlops",
                "uml,",
                "cloud",
                "cloud",
                "cloud"
            ],
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-senior-cdi-paris-ou-caen?q=a6b09c99a6a04801acff655dede1f77d&o=6696f7e0-63be-4373-8470-85bff272293b",
        "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu seras impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec tes pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager ton savoir-faire avec les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,Assurer une veille technologique et savoir mener à bien un projet de R&D.Tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ELT : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse: Delta LakeConnaissance message broker : RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior (H/F)",
        "contract_type": "CDI",
        "salary": "50K à 65K €",
        "company": "LittleBigCode",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "fiabilité.collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer-senior-h-f_neuilly-sur-seine?q=a6b09c99a6a04801acff655dede1f77d&o=a0416a32-5a8c-407f-96cc-e5ce05cc139a",
        "description": "Descriptif du posteNous cherchons à renforcer notre équipe avec un(e) Data Engineer Senior passionné(e) par les défis techniques et prêt(e) à accompagner nos clients dans leurs ambitions Data !🔎 Ton rôle chez LittleBigCodeAuprès de nos clients :Accompagnement stratégique : Tu guideras les clients dans l’implémentation de pipelines, de plateformes de données et de processus de transformation pour soutenir la création de produits data.Choix technologiques : Tu conseilleras les clients sur les technologies les plus adaptées à leurs besoins, tout en tenant compte des solutions déjà en place.Qualité des données : Tu veilleras à la mise en place de processus de nettoyage, de transformation et d’intégration des données pour garantir leur qualité et leur fiabilité.Collaboration métier : Tu travailleras en étroite collaboration avec les équipes métiers pour comprendre leurs besoins et proposer des solutions adaptées.Meilleures pratiques : Tu promouvras les standards en matière de gouvernance, sécurité, et développement de pipelines de données.En interne :Partage d’expertise : Tu participeras à la création de contenus techniques pour encourager le partage de connaissances et la formation continue.Support commercial : Tu accompagneras nos Business Managers lors de propositions commerciales en apportant ton expertise technique.Veille technologique : Tu effectueras une veille régulière pour suivre les innovations et les tendances du domaine.Mentorat : Tu joueras un rôle clé dans l’accompagnement des Data Engineers juniors pour les aider à progresser et à atteindre leurs objectifs professionnels."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior (H/F)",
        "contract_type": "CDI",
        "salary": "50K à 65K €",
        "company": "LittleBigCode",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "fiabilité.collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-engineer-senior-h-f_neuilly-sur-seine?q=a6b09c99a6a04801acff655dede1f77d&o=a0416a32-5a8c-407f-96cc-e5ce05cc139a",
        "description": "Descriptif du posteNous cherchons à renforcer notre équipe avec un(e) Data Engineer Senior passionné(e) par les défis techniques et prêt(e) à accompagner nos clients dans leurs ambitions Data !🔎 Ton rôle chez LittleBigCodeAuprès de nos clients :Accompagnement stratégique : Tu guideras les clients dans l’implémentation de pipelines, de plateformes de données et de processus de transformation pour soutenir la création de produits data.Choix technologiques : Tu conseilleras les clients sur les technologies les plus adaptées à leurs besoins, tout en tenant compte des solutions déjà en place.Qualité des données : Tu veilleras à la mise en place de processus de nettoyage, de transformation et d’intégration des données pour garantir leur qualité et leur fiabilité.Collaboration métier : Tu travailleras en étroite collaboration avec les équipes métiers pour comprendre leurs besoins et proposer des solutions adaptées.Meilleures pratiques : Tu promouvras les standards en matière de gouvernance, sécurité, et développement de pipelines de données.En interne :Partage d’expertise : Tu participeras à la création de contenus techniques pour encourager le partage de connaissances et la formation continue.Support commercial : Tu accompagneras nos Business Managers lors de propositions commerciales en apportant ton expertise technique.Veille technologique : Tu effectueras une veille régulière pour suivre les innovations et les tendances du domaine.Mentorat : Tu joueras un rôle clé dans l’accompagnement des Data Engineers juniors pour les aider à progresser et à atteindre leurs objectifs professionnels."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (M/W)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Porto",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-03",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-m-w_porto_MERIT_x9eygyr?q=a6b09c99a6a04801acff655dede1f77d&o=6b652772-5b3e-4b83-9a84-edb1b54b4967",
        "description": "Descriptif du posteAs a Data Engineer, your missions will be to develop efficient persistence and data access services produced by pricing environments. Your tasks- Develop access and update services for various parameter reference repositories for pricing, implementing audit and historical tracking of these changes,- Participate in maintaining high-quality production by ensuring compliance with best practices (adherence to procedures, impact analysis, test coverage, business validation, etc.) and proactively managing application and infrastructure incidents by following established action plans, - Manage technical debt within your scope by encouraging remediation and continuous improvement actions in agreement with business partners."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (M/W)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Porto",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-03",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-m-w_porto_MERIT_x9eygyr?q=a6b09c99a6a04801acff655dede1f77d&o=6b652772-5b3e-4b83-9a84-edb1b54b4967",
        "description": "Descriptif du posteAs a Data Engineer, your missions will be to develop efficient persistence and data access services produced by pricing environments. Your tasks- Develop access and update services for various parameter reference repositories for pricing, implementing audit and historical tracking of these changes,- Participate in maintaining high-quality production by ensuring compliance with best practices (adherence to procedures, impact analysis, test coverage, business validation, etc.) and proactively managing application and infrastructure incidents by following established action plans, - Manage technical debt within your scope by encouraging remediation and continuous improvement actions in agreement with business partners."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead Data Engineer (F/H)",
        "contract_type": "CDI",
        "salary": "40K à 45K €",
        "company": "ASI",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-02",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "500",
            "creation_date": "1993",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "42,7 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java"
            ],
            "DataBase": [
                "sql,",
                "sql",
                "nosql",
                "nosql"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud:"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/asi/jobs/lead-data-engineer-f-h_nantes_ASI_PWKrVQL?q=a6b09c99a6a04801acff655dede1f77d&o=d6065fde-7406-4652-b5c0-61ec262df519",
        "description": "Descriptif du posteDans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin.Avec Simon GRIFFON, responsable de l’équipe Data Nantaise, nous recherchons un Lead Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une équipe dédiée, principalement en contexte agile, voici les missions qui pourront vous être confiées : Participer à la compréhension des besoins métiers et réaliser des ateliers de cadrage avec le client Participer à la rédaction des spécifications fonctionnelles et techniques des flux Maîtriser les formats de données structurés et non structurés et savoir les manipuler  Modéliser et mettre en place des systèmes décisionnels   Installer et connecter une solution ETL / ELT à une source de données en tenant compte des contraintes et de l’environnement du client Concevoir et réaliser un pipeline de transformation et de valorisation des données et ordonnancer son fonctionnement Veiller à la sécurisation des pipelines de données Concevoir et réaliser des API utilisant les données valorisées  Définir des plans de tests et d’intégration Prendre en charge la maintenance évolutive et corrective Accompagner les juniors dans leur montée en compétences  En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes : L’écosystème data notamment Microsoft Azure Les langages : SQL, Java Les bases de données SQL et NoSQL Stockage cloud: S3, Azure Blob Storage… Les ETL/ESB et autres outils : Talend, Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue...  En rejoignant ASI : Vous évoluerez au sein d’une entreprise aux modes de fonctionnement internes flexibles garantis par une politique RH attentive (accord télétravail 3J/semaine, accord congé parenthèse…)  Vous intégrerez les différentes communautés expertes d'ASI, pour partager des bonnes pratiques et participer aux actions d'amélioration continue. Vous évoluerez dans une entreprise bientôt reconnue Société à mission, Team GreenCaring et non GreenWashing porteuse d’une démarche RSE incarnée et animée, depuis plus de 10 ans. (Equipe RSE dédiée, accord forfaits mobilités durables…)  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead Data Engineer (F/H)",
        "contract_type": "CDI",
        "salary": "40K à 45K €",
        "company": "ASI",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-02",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "500",
            "creation_date": "1993",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "42,7 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java"
            ],
            "DataBase": [
                "sql,",
                "sql",
                "nosql",
                "nosql"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "airflow,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud:"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/asi/jobs/lead-data-engineer-f-h_nantes_ASI_PWKrVQL?q=a6b09c99a6a04801acff655dede1f77d&o=d6065fde-7406-4652-b5c0-61ec262df519",
        "description": "Descriptif du posteDans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin.Avec Simon GRIFFON, responsable de l’équipe Data Nantaise, nous recherchons un Lead Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une équipe dédiée, principalement en contexte agile, voici les missions qui pourront vous être confiées : Participer à la compréhension des besoins métiers et réaliser des ateliers de cadrage avec le client Participer à la rédaction des spécifications fonctionnelles et techniques des flux Maîtriser les formats de données structurés et non structurés et savoir les manipuler  Modéliser et mettre en place des systèmes décisionnels   Installer et connecter une solution ETL / ELT à une source de données en tenant compte des contraintes et de l’environnement du client Concevoir et réaliser un pipeline de transformation et de valorisation des données et ordonnancer son fonctionnement Veiller à la sécurisation des pipelines de données Concevoir et réaliser des API utilisant les données valorisées  Définir des plans de tests et d’intégration Prendre en charge la maintenance évolutive et corrective Accompagner les juniors dans leur montée en compétences  En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes : L’écosystème data notamment Microsoft Azure Les langages : SQL, Java Les bases de données SQL et NoSQL Stockage cloud: S3, Azure Blob Storage… Les ETL/ESB et autres outils : Talend, Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue...  En rejoignant ASI : Vous évoluerez au sein d’une entreprise aux modes de fonctionnement internes flexibles garantis par une politique RH attentive (accord télétravail 3J/semaine, accord congé parenthèse…)  Vous intégrerez les différentes communautés expertes d'ASI, pour partager des bonnes pratiques et participer aux actions d'amélioration continue. Vous évoluerez dans une entreprise bientôt reconnue Société à mission, Team GreenCaring et non GreenWashing porteuse d’une démarche RSE incarnée et animée, depuis plus de 10 ans. (Equipe RSE dédiée, accord forfaits mobilités durables…)  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead data engineer (F/H)",
        "contract_type": "CDI",
        "salary": "45K à 60K €",
        "company": "Groupe SII",
        "location": "Lille",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-01",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "(java,",
                "scala"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableauo"
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "aws",
                "azure),",
                "(gcp,",
                "gcpo"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,",
                "cloud",
                "cloud,",
                "cloud.",
                "cloud",
                "cloud",
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/lead-data-engineer-f-h_lille?q=a6b09c99a6a04801acff655dede1f77d&o=45c00311-1153-4439-875b-539c0ffbce79",
        "description": "Descriptif du posteSII Lille recherche un(e) : Lead data engineer (H/F)En tant que Lead data engineer, vous avez l’opportunité d’intervenir sur des missions d’expertise et de conseils auprès de nos clients grands comptes. Vous concevez, faites évoluer et gérer des plateformes Data et outils associés ainsi que des flux entre les différentes sources de données de l'entreprise.  Lors de ces missions d'expertise, vous allez :   Analyser les besoins clients: animer des ateliers, préconiser des architectures, définir des méthodologies et plans de migration,  Intégrer les futurs services et outils dans un environnement cloud provider (GCP, AWS ou Microsoft Azure), Construire des architectures de données résilients et sécurisées, mener les analyse d'impacts et diffuser les bonnes pratiques,    Concevoir, automatiser, assurer la qualité des échanges et le traitement des données (flux, streams, dataops…),    Conseiller et participer à la conception, mise en place et/ou migration de data warehouses/data lakes, Assurer le pilotage et l’optimisation des outils de transport et de traitement de la donnée.En complément de ces missions pour nos clients, nous vous proposons également d’intervenir en interne et au niveau national sur une mission d’expertise.Vos 3 principales activités sont :  Animation et encadrement de la communauté Data,    Accompagner et former nos consultants data junior, Le développement et la valorisation de l’expertise du groupe SII (publications, conférences, webinaires...),   L’appui au business : participation à des phases d’avant-vente, aide au ciblage des clients, proposition de solutions…Vous disposerez d’un jour par semaine minimum pour mener à bien cette mission.Vous bénéficierez de la dynamique de notre équipe d’experts, composée à terme d’une cinquantaine de personnes sur différents domaines d’expertise (Applicatif, Devops, Cloud, Data, IA,…)Profil : Vous justifiez d’une expérience significative d’au moins 5 ans sur un poste similaire dans un environnement cloud.  Compétences techniques :o    Maitrise d’au moins un cloud public : AWS ou GCPo    Maitrise des langages suivants : SQL, Python (Java, Scala et/ou Spark serait un plus)o    Maitrise du fonctionnement des ETL/ESBo    Maitrise des architectures big datao    Connaissance d’un outil de stockage et de gestion de données sur le cloud : Snowflake, Cloudera, Databricso    Connaissance d’un outil de data visualisation : Looker, PowerBI, Tableauo    Maitrise des processus et bonnes pratiques de développemento    Anglais techniqueAu-delà des compétences techniques, vous faîtes preuve de rigueur, d’une bonne capacité d’analyse et êtes force de proposition. Vous avez un bon relationnel et savez communiquer auprès des métiers pour recueillir leur besoin. Vous êtes à l'aise lorsque vous prenez la parole face à un large public.Vous souhaitez mettre votre expérience au service des clients et mettre votre expertise au sein d’SII pour relever des challenges techniques en apportant de la valeur sur le domaine de la data.Qui sommes-nous? Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.  Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés.Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Lead data engineer (F/H)",
        "contract_type": "CDI",
        "salary": "45K à 60K €",
        "company": "Groupe SII",
        "location": "Lille",
        "remote": "Télétravail non autorisé",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-01",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python",
                "(java,",
                "scala"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableauo"
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws",
                "aws",
                "azure),",
                "(gcp,",
                "gcpo"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,",
                "cloud",
                "cloud,",
                "cloud.",
                "cloud",
                "cloud",
                "cloudera,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/lead-data-engineer-f-h_lille?q=a6b09c99a6a04801acff655dede1f77d&o=45c00311-1153-4439-875b-539c0ffbce79",
        "description": "Descriptif du posteSII Lille recherche un(e) : Lead data engineer (H/F)En tant que Lead data engineer, vous avez l’opportunité d’intervenir sur des missions d’expertise et de conseils auprès de nos clients grands comptes. Vous concevez, faites évoluer et gérer des plateformes Data et outils associés ainsi que des flux entre les différentes sources de données de l'entreprise.  Lors de ces missions d'expertise, vous allez :   Analyser les besoins clients: animer des ateliers, préconiser des architectures, définir des méthodologies et plans de migration,  Intégrer les futurs services et outils dans un environnement cloud provider (GCP, AWS ou Microsoft Azure), Construire des architectures de données résilients et sécurisées, mener les analyse d'impacts et diffuser les bonnes pratiques,    Concevoir, automatiser, assurer la qualité des échanges et le traitement des données (flux, streams, dataops…),    Conseiller et participer à la conception, mise en place et/ou migration de data warehouses/data lakes, Assurer le pilotage et l’optimisation des outils de transport et de traitement de la donnée.En complément de ces missions pour nos clients, nous vous proposons également d’intervenir en interne et au niveau national sur une mission d’expertise.Vos 3 principales activités sont :  Animation et encadrement de la communauté Data,    Accompagner et former nos consultants data junior, Le développement et la valorisation de l’expertise du groupe SII (publications, conférences, webinaires...),   L’appui au business : participation à des phases d’avant-vente, aide au ciblage des clients, proposition de solutions…Vous disposerez d’un jour par semaine minimum pour mener à bien cette mission.Vous bénéficierez de la dynamique de notre équipe d’experts, composée à terme d’une cinquantaine de personnes sur différents domaines d’expertise (Applicatif, Devops, Cloud, Data, IA,…)Profil : Vous justifiez d’une expérience significative d’au moins 5 ans sur un poste similaire dans un environnement cloud.  Compétences techniques :o    Maitrise d’au moins un cloud public : AWS ou GCPo    Maitrise des langages suivants : SQL, Python (Java, Scala et/ou Spark serait un plus)o    Maitrise du fonctionnement des ETL/ESBo    Maitrise des architectures big datao    Connaissance d’un outil de stockage et de gestion de données sur le cloud : Snowflake, Cloudera, Databricso    Connaissance d’un outil de data visualisation : Looker, PowerBI, Tableauo    Maitrise des processus et bonnes pratiques de développemento    Anglais techniqueAu-delà des compétences techniques, vous faîtes preuve de rigueur, d’une bonne capacité d’analyse et êtes force de proposition. Vous avez un bon relationnel et savez communiquer auprès des métiers pour recueillir leur besoin. Vous êtes à l'aise lorsque vous prenez la parole face à un large public.Vous souhaitez mettre votre expérience au service des clients et mettre votre expertise au sein d’SII pour relever des challenges techniques en apportant de la valeur sur le domaine de la data.Qui sommes-nous? Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés.  Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés.Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En fonction de la mission, il est possible de réaliser jusqu’à 50 % de télétravail grâce à notre accord dédié.En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Groupe Mentor",
        "location": "Dommartemont",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": "Bac +3",
        "publication_date": "2024-12-30",
        "company_data": {
            "sector": "IT / Digital, Immobilier particulier, Finance",
            "company_size": "2400",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "164",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": [
                "nosqlassurer",
                "nosqlassurer"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-mentor/jobs/data-engineer-h-f_dommartemont_GM_rxPPV0Z?q=a6b09c99a6a04801acff655dede1f77d&o=039e2deb-ecd7-4285-af33-e92ffeb02e60",
        "description": "Descriptif du posteEn tant que Data Engineer, vous serez responsable de la conception, de la construction et de la maintenance des infrastructures de données, surtout en l'absence d'un data architect. Vous veillerez à ce que les données soient facilement accessibles, de haute qualité et bien organisées pour répondre aux besoins des équipes d'analyse, des data scientists, ainsi qu'aux exigences transversales du groupe et de ses filiales.Vos missions :1- Conception et développement des pipelines de donnéesConstruire et maintenir des pipelines ETL (Extract, Transform, Load)Intégrer des données provenant de diverses sources (BDD, API, fichiers, etc)2- Gestion des BDDConfigurer et gérer les bases de données relationnelles et NoSQLAssurer l'optimisation et la performance des systèmes de stockage de données3- Qualité et intégrité des donnéesMettre en place des processus pour garantir la qualité, la cohérence et l'intégrité des donnéesAutomatiser les processus de nettoyage et de transformation des données4- Collaboration avec les équipesTravailler en étroite collaboration avec les Data Scientist et Analyst pour comprendre leurs besoins en donnéesSupporter les équipes de développement en fournissant des solutions de gestions de données efficaces5- SupportSurveiller les flux de données et résoudre les problèmes techniquesMaintenir et documenter les flux et l'infrastructure des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Groupe Mentor",
        "location": "Dommartemont",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": "Bac +3",
        "publication_date": "2024-12-30",
        "company_data": {
            "sector": "IT / Digital, Immobilier particulier, Finance",
            "company_size": "2400",
            "creation_date": "1998",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "164",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": [
                "nosqlassurer",
                "nosqlassurer"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-mentor/jobs/data-engineer-h-f_dommartemont_GM_rxPPV0Z?q=a6b09c99a6a04801acff655dede1f77d&o=039e2deb-ecd7-4285-af33-e92ffeb02e60",
        "description": "Descriptif du posteEn tant que Data Engineer, vous serez responsable de la conception, de la construction et de la maintenance des infrastructures de données, surtout en l'absence d'un data architect. Vous veillerez à ce que les données soient facilement accessibles, de haute qualité et bien organisées pour répondre aux besoins des équipes d'analyse, des data scientists, ainsi qu'aux exigences transversales du groupe et de ses filiales.Vos missions :1- Conception et développement des pipelines de donnéesConstruire et maintenir des pipelines ETL (Extract, Transform, Load)Intégrer des données provenant de diverses sources (BDD, API, fichiers, etc)2- Gestion des BDDConfigurer et gérer les bases de données relationnelles et NoSQLAssurer l'optimisation et la performance des systèmes de stockage de données3- Qualité et intégrité des donnéesMettre en place des processus pour garantir la qualité, la cohérence et l'intégrité des donnéesAutomatiser les processus de nettoyage et de transformation des données4- Collaboration avec les équipesTravailler en étroite collaboration avec les Data Scientist et Analyst pour comprendre leurs besoins en donnéesSupporter les équipes de développement en fournissant des solutions de gestions de données efficaces5- SupportSurveiller les flux de données et résoudre les problèmes techniquesMaintenir et documenter les flux et l'infrastructure des données"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Data F/H",
        "contract_type": "CDI",
        "salary": "40K à 50K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-28",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/tech-lead-data-f-h_le-mans?q=a6b09c99a6a04801acff655dede1f77d&o=93bf99c1-fd1f-4da5-b60e-e492985e1258",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et les activités du groupe, nous recherchons un Tech Lead Data H/FRattaché à notre cellule d’expertise, vous serez intégré au sein de l’équipe structure mancelle.En tant qu’interlocuteur privilégié sur la région du Mans, vous aurez en charge l’accompagnement du développement de notre Delivery Center Data, une participation active au suivi technique des projets ainsi qu’un acteur à la veille technologique et au déploiement de méthodes ou d’environnements innovants autour de la data.Vous interviendrez sur les activités suivantes :  Participation de l’animation technique des équipes ;   Intervention sur des sujets à fortes valeurs ajoutées ou en situation de blocage ; Délivrer des missions d’expertise et de conseil auprès de nos clients ;    Support au développement des compétences internes (consolidation des plans de formation, animation technique et suivi montée en compétences) ; Capitaliser des savoirs faire sur nos projets et compléter les références pour le Groupe ; En liaison avec l’équipe commerciale et la Direction du Développement du Groupe, contribution aux réponses à des appels d’offres ; Communication et mise en avant de notre offre data (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …) ;    Veille technologique ; Animation de la communauté Big Data locale.De formation supérieure (Bac +4/5) en informatique, vous avez une expérience technique confirmée (minimum 3 ans) en contexte projets Big Data.Vous connaissez précisément l’écosystème existant (opensource/buy), Déterminé, à l'écoute et autonome, devenez un expert reconnu sur votre territoire et pour le Groupe SII!Rejoindre SII Ouest, c’est aussi :  Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …)   Une ambiance conviviale (Petit déjeuner à l’agence, Afterworks, Soirées d’Agence, …)   Jusqu’à 50% de télétravail (on privilégie l’équilibre vie pro/vie perso tout en gardant le lien avec nos collaborateurs !) Une QVT reconnue (pour la 7ème année consécutive, nous sommes certifiés Great Place to Work)Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !#LI-CM8"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Tech Lead Data F/H",
        "contract_type": "CDI",
        "salary": "40K à 50K €",
        "company": "Groupe SII",
        "location": "Le Mans",
        "remote": "Télétravail non autorisé",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-28",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "communication"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/tech-lead-data-f-h_le-mans?q=a6b09c99a6a04801acff655dede1f77d&o=93bf99c1-fd1f-4da5-b60e-e492985e1258",
        "description": "Descriptif du posteAfin d'accompagner notre croissance et les activités du groupe, nous recherchons un Tech Lead Data H/FRattaché à notre cellule d’expertise, vous serez intégré au sein de l’équipe structure mancelle.En tant qu’interlocuteur privilégié sur la région du Mans, vous aurez en charge l’accompagnement du développement de notre Delivery Center Data, une participation active au suivi technique des projets ainsi qu’un acteur à la veille technologique et au déploiement de méthodes ou d’environnements innovants autour de la data.Vous interviendrez sur les activités suivantes :  Participation de l’animation technique des équipes ;   Intervention sur des sujets à fortes valeurs ajoutées ou en situation de blocage ; Délivrer des missions d’expertise et de conseil auprès de nos clients ;    Support au développement des compétences internes (consolidation des plans de formation, animation technique et suivi montée en compétences) ; Capitaliser des savoirs faire sur nos projets et compléter les références pour le Groupe ; En liaison avec l’équipe commerciale et la Direction du Développement du Groupe, contribution aux réponses à des appels d’offres ; Communication et mise en avant de notre offre data (Events / Réseaux sociaux / Blog / Speak-up / Club-client / …) ;    Veille technologique ; Animation de la communauté Big Data locale.De formation supérieure (Bac +4/5) en informatique, vous avez une expérience technique confirmée (minimum 3 ans) en contexte projets Big Data.Vous connaissez précisément l’écosystème existant (opensource/buy), Déterminé, à l'écoute et autonome, devenez un expert reconnu sur votre territoire et pour le Groupe SII!Rejoindre SII Ouest, c’est aussi :  Un service formation au top (formations techniques, développement personnel, gestion d’équipe, management, …)  Des possibilités d’évolution pour votre carrière (devenir Lead Dev, Chef de Projet, passerelles entre les métiers techniques et fonctionnels, …)   Une vraie communauté de passionnés (participation aux événements techniques tels que le Breizh Camp, l’Agile Tour ; possibilité de partager ses connaissances à travers les Déjeuners Techniques, …)   Une ambiance conviviale (Petit déjeuner à l’agence, Afterworks, Soirées d’Agence, …)   Jusqu’à 50% de télétravail (on privilégie l’équilibre vie pro/vie perso tout en gardant le lien avec nos collaborateurs !) Une QVT reconnue (pour la 7ème année consécutive, nous sommes certifiés Great Place to Work)Le Groupe SII est une société d’ingénierie et de conseils en technologies (ICT) et une entreprise de services numériques (ESN). Nous sommes au cœur de l'innovation au service de grands comptes dans des secteurs d'ingénierie variés. Le groupe SII fait travailler plus de 16 000 personnes dans 21 pays.En 2024, pour la 7ème année consécutive, SII France a obtenu le label Great Place To Work® et s'est hissée au Palmarès Best WorkPlaces dans la catégorie des entreprises de plus de 2500 salariés. Nous sommes très fiers d’obtenir cette reconnaissance de nos salariés ! Ce succès est le reflet de notre culture basée sur notre volonté de proposer à tous nos collaborateurs un cadre de travail épanouissant pour le développement de leurs compétences et carrières. En tant que société à fortes valeurs humaines, nous sommes signataires de la Charte de la diversité, de la Charte d’engagement LGBT+ avec l’Association L'Autre Cercle et sommes une entreprise handi-accueillante. Alors si ces valeurs vous parlent, rejoignez-nous !#LI-CM8"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Biot",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-25",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop.convertir"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "cloud/azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud/azure"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-h-f_biot_MERIT_y1W2w02?q=a6b09c99a6a04801acff655dede1f77d&o=bb6ee600-9a6a-46a7-bcd5-5885ba739859",
        "description": "Descriptif du posteEn tant que Data engineer (H/F), vous intégrerez une entreprise dynamique évoluant dans un contexte international et un environnement de travail agile. Vos missions seront :Développer des logiciels au sein d'une large gamme de solutions techniques et d'environnements. En particulier : Databrick Cloud/Azure ; Étincelle, Scala, écosystème Hadoop.Convertir les spécifications fonctionnelles en nouvelles solutions logicielles grâce à l'analyse des spécifications.Concevoir des solutions techniques et réaliser des études de faisabilité.Réaliser des tests unitaires, d'emballage et de performance et assurer un haut niveau de qualité.Participer à la phase de validation du cycle du produit, peaufiner si nécessaire pour finaliser le produit."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meritis",
        "location": "Biot",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-25",
        "company_data": {
            "sector": "IT / Digital, Finance",
            "company_size": "900",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "87",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop.convertir"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "cloud/azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud/azure"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meritis/jobs/data-engineer-h-f_biot_MERIT_y1W2w02?q=a6b09c99a6a04801acff655dede1f77d&o=bb6ee600-9a6a-46a7-bcd5-5885ba739859",
        "description": "Descriptif du posteEn tant que Data engineer (H/F), vous intégrerez une entreprise dynamique évoluant dans un contexte international et un environnement de travail agile. Vos missions seront :Développer des logiciels au sein d'une large gamme de solutions techniques et d'environnements. En particulier : Databrick Cloud/Azure ; Étincelle, Scala, écosystème Hadoop.Convertir les spécifications fonctionnelles en nouvelles solutions logicielles grâce à l'analyse des spécifications.Concevoir des solutions techniques et réaliser des études de faisabilité.Réaliser des tests unitaires, d'emballage et de performance et assurer un haut niveau de qualité.Participer à la phase de validation du cycle du produit, peaufiner si nécessaire pour finaliser le produit."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Data Java/Spark (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FINAXYS",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-23",
        "company_data": {
            "sector": "Banque, Logiciels, SaaS / Cloud Services, Big Data",
            "company_size": "400",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "40 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java",
                "java",
                "scalables"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,",
                "sparkimplémenter"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "(ci/cd)"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/finaxys/jobs/data-engineer-java-spark-f-h_puteaux?q=a6b09c99a6a04801acff655dede1f77d&o=00a20454-6ee6-4b88-b978-9113e6bd441e",
        "description": "Descriptif du posteEn tant qu’Ingénieur Data Java / Spark, vous rejoindrez les équipes techniques de nos clients grands comptes pour :Concevoir et développer des pipelines de traitement des données massives (Big Data) en utilisant Apache SparkImplémenter des solutions robustes et scalables en Java pour répondre aux besoins métiersParticiper à l’architecture et au développement des plateformes de données, en garantissant leur performance et leur fiabilitéOptimiser les flux de données (ETL) pour assurer un traitement rapide et efficaceCollaborer étroitement avec les équipes Data Science, BI et métiers pour garantir l’alignement avec les objectifs businessSuperviser les processus d’intégration et de déploiement continu (CI/CD) sur des environnements Cloud ou on-premise"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur Data Java/Spark (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FINAXYS",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-23",
        "company_data": {
            "sector": "Banque, Logiciels, SaaS / Cloud Services, Big Data",
            "company_size": "400",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "40 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "java",
                "java",
                "scalables"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark,",
                "sparkimplémenter"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "(ci/cd)"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/finaxys/jobs/data-engineer-java-spark-f-h_puteaux?q=a6b09c99a6a04801acff655dede1f77d&o=00a20454-6ee6-4b88-b978-9113e6bd441e",
        "description": "Descriptif du posteEn tant qu’Ingénieur Data Java / Spark, vous rejoindrez les équipes techniques de nos clients grands comptes pour :Concevoir et développer des pipelines de traitement des données massives (Big Data) en utilisant Apache SparkImplémenter des solutions robustes et scalables en Java pour répondre aux besoins métiersParticiper à l’architecture et au développement des plateformes de données, en garantissant leur performance et leur fiabilitéOptimiser les flux de données (ETL) pour assurer un traitement rapide et efficaceCollaborer étroitement avec les équipes Data Science, BI et métiers pour garantir l’alignement avec les objectifs businessSuperviser les processus d’intégration et de déploiement continu (CI/CD) sur des environnements Cloud ou on-premise"
    },
    {
        "source": "welcometothejungle",
        "job_title": " Data Engineer - Financial Services F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera),"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-financial-services-f-h_paris_CGI_96Jppjm?q=a6b09c99a6a04801acff655dede1f77d&o=79abd149-8163-40b9-9f61-2870f7cd26bd",
        "description": "Descriptif du poste Vos responsabilités sont les suivantes :- Concevoir, développer et déployer des pipelines de transformations de données en environnement Big Data- Définir des solutions globales permettant de répondre aux besoins métiers en prenant en compte les problématiques de performances, d’industrialisation, d’exploitation et de sécurité.- Paramétrer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, …)- Faire des prototypes sur des technologies et de la veille technologique sur le Big Data- Accompagner & supporter les équipes projet en coaching et expertise- Animer et faire progresser des juniors et stagiaires- Assurer le rôle de Lead Tech dans une équipeEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Data Engineer - Financial Services F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudera),"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/data-engineer-financial-services-f-h_paris_CGI_96Jppjm?q=a6b09c99a6a04801acff655dede1f77d&o=79abd149-8163-40b9-9f61-2870f7cd26bd",
        "description": "Descriptif du poste Vos responsabilités sont les suivantes :- Concevoir, développer et déployer des pipelines de transformations de données en environnement Big Data- Définir des solutions globales permettant de répondre aux besoins métiers en prenant en compte les problématiques de performances, d’industrialisation, d’exploitation et de sécurité.- Paramétrer et maintenir des clusters Big Data (MapR, Cloudera), ou des composants connexes (Nifi, Kafka, …)- Faire des prototypes sur des technologies et de la veille technologique sur le Big Data- Accompagner & supporter les équipes projet en coaching et expertise- Animer et faire progresser des juniors et stagiaires- Assurer le rôle de Lead Tech dans une équipeEn rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail non renseigné",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-19",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/data-engineer-h-f_issy-les-moulineaux?q=a6b09c99a6a04801acff655dede1f77d&o=a83eb973-3ab3-40de-9dbf-0fedd371805d",
        "description": "Descriptif du posteData Engineer       Vos missions:   Côté hardskills, voici nos prérequis :  Concevoir, développer et maintenir des pipelines de données pour l’acquisition, le traitement et le chargement des données provenant de diverses sources. Mettre en place et optimiser des bases de données et des entrepôts de données pour le stockage et l’accès efficaces aux données. Collaborer avec les équipes métier pour comprendre les besoins en matière de données et proposer des solutions techniques adaptées. Assurer la qualité des données en mettant en place des processus de nettoyage, de validation et de normalisation. Automatiser les tâches récurrentes liées à la gestion des données pour améliorer l’efficacité opérationnelle. Effectuer la surveillance et le dépannage des pipelines de données pour garantir leur fiabilité et leur performance. Travailler en étroite collaboration avec les data scientists et les analystes pour fournir des ensembles de données fiables et prêts à l’emploi. Assurer la conformité aux normes de sécurité et aux réglementations en matière de protection des données. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail non renseigné",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-19",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/data-engineer-h-f_issy-les-moulineaux?q=a6b09c99a6a04801acff655dede1f77d&o=a83eb973-3ab3-40de-9dbf-0fedd371805d",
        "description": "Descriptif du posteData Engineer       Vos missions:   Côté hardskills, voici nos prérequis :  Concevoir, développer et maintenir des pipelines de données pour l’acquisition, le traitement et le chargement des données provenant de diverses sources. Mettre en place et optimiser des bases de données et des entrepôts de données pour le stockage et l’accès efficaces aux données. Collaborer avec les équipes métier pour comprendre les besoins en matière de données et proposer des solutions techniques adaptées. Assurer la qualité des données en mettant en place des processus de nettoyage, de validation et de normalisation. Automatiser les tâches récurrentes liées à la gestion des données pour améliorer l’efficacité opérationnelle. Effectuer la surveillance et le dépannage des pipelines de données pour garantir leur fiabilité et leur performance. Travailler en étroite collaboration avec les data scientists et les analystes pour fournir des ensembles de données fiables et prêts à l’emploi. Assurer la conformité aux normes de sécurité et aux réglementations en matière de protection des données. "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant Expérimenté & Manager en Data Engineering - Secteur Financier, H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EY",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-18",
        "company_data": {
            "sector": "Stratégie, Audit, Transaction Services, Digital, Finance",
            "company_size": "7000",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "45 Milliards",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital,",
                "digital,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultant-experimente-manager-en-data-engineering-secteur-financier-h-f_paris_EY_bwGGwOb?q=a6b09c99a6a04801acff655dede1f77d&o=e6f6f493-2bf3-4f24-b094-286e2b981142",
        "description": "Descriptif du posteL’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, architecture, robotics, analyse quantitative, datamining, big data, algorithmique, blockchain, intelligence artificielle, digital, …). Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel. Cette annonce est destinée aux candidats spécialisés en Data Engineering, mais nous recherchons des profils expérimentés et mobilisables sur le spectre élargi des métiers de la data. Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à apporter vos compétences à des équipes engagées sur des missions de conseil de différentes natures :·       Conception et mise en œuvre de solutions de valorisation de la donnée depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisation·        Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…·       Cartographie des processus de transformation de données·       Cadrage et analyse fonctionnelle de projets de transformation data·       Accompagnement au pilotage, à la coordination et à la gestion de projets data·       Définition de stratégie client en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)·       Etudes et choix de solutions et de plateformes big data, analytics…·       Veille sur l’évolution des méthodes, des pratiques, des outils… Vous pourrez continuer de développer des compétences dans les domaines de votre choix grâce à l’approche de formation EY."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant Expérimenté & Manager en Data Engineering - Secteur Financier, H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EY",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-18",
        "company_data": {
            "sector": "Stratégie, Audit, Transaction Services, Digital, Finance",
            "company_size": "7000",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "45 Milliards",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital,",
                "digital,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultant-experimente-manager-en-data-engineering-secteur-financier-h-f_paris_EY_bwGGwOb?q=a6b09c99a6a04801acff655dede1f77d&o=e6f6f493-2bf3-4f24-b094-286e2b981142",
        "description": "Descriptif du posteL’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, architecture, robotics, analyse quantitative, datamining, big data, algorithmique, blockchain, intelligence artificielle, digital, …). Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel. Cette annonce est destinée aux candidats spécialisés en Data Engineering, mais nous recherchons des profils expérimentés et mobilisables sur le spectre élargi des métiers de la data. Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à apporter vos compétences à des équipes engagées sur des missions de conseil de différentes natures :·       Conception et mise en œuvre de solutions de valorisation de la donnée depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisation·        Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…·       Cartographie des processus de transformation de données·       Cadrage et analyse fonctionnelle de projets de transformation data·       Accompagnement au pilotage, à la coordination et à la gestion de projets data·       Définition de stratégie client en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)·       Etudes et choix de solutions et de plateformes big data, analytics…·       Veille sur l’évolution des méthodes, des pratiques, des outils… Vous pourrez continuer de développer des compétences dans les domaines de votre choix grâce à l’approche de formation EY."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Data Engineer (F/H/X)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EPSILON France",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-16",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",
            "company_size": "650",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "38",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python",
                "java,",
                "scala…"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop/hdfs,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure),",
                "azure).vous",
                "(gcp,",
                "(gcp"
            ],
            "DevTools": [
                "digitales,"
            ],
            "OS": [
                "linux/unix,"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,comprendre",
                "ml).vous",
                "cloudmaintenir",
                "cloud",
                "cloud),",
                "cloudera,",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/epsilon/jobs/senior-data-engineer-f-h-x_paris_EF_8AKrre8?q=a6b09c99a6a04801acff655dede1f77d&o=993e04f1-bf8c-411f-baaf-df48b1ff55f3",
        "description": "Descriptif du posteDans le cadre du développement du pôle Data & IA (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions), nous recherchons un(e) Consultant Sénior Data Engineer qui aura pour missions :Délivrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de données, modélisation, tests, déploiements) dans un contexte de plus en plus DevOps,Comprendre les besoins des équipes digitales, principalement associées aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python, …),Être capable de faire le lien avec les contraintes techniques (IT, sécurité, accès, outils) d’une DSI,Assurer la veille technologique sur les composants d’une plateforme Datalake, CloudMaintenir les environnements techniques et partager ses connaissances (capitalisation, séminaires, formations, KM en ligne),Rédiger des documents projets (design, réalisation, déploiement, …),Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA.De formation Bac + 4/5 en informatique, vous avez au moins 5 ans d’expérience d’un projet de type Datalake en environnement HDFS et/ou cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des méthodes Agile, voire du DataOps (industrialisation de modèles de ML).Vous possédez de bonnes compétences en Linux/Unix, Java, Spark, Scala… ainsi que sur les problématiques d’intégration (fichiers, messages, data) avec la connaissance d’au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, débogage, mise en œuvre) et d’une solution cloud (GCP ou Azure).Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, …).Votre expérience dans le traitement de flux en streaming (KafKa) est un plus.Votre niveau d’Anglais est opérationnel.CHOISISSEZ…- Notre expertise reconnue dans le domaine du décisionnel et du Big Data depuis 30 ans, un cadre méthodologique et une organisation des compétences animées constamment dans un souci de veille et de progression,- Nos projets innovants et nos missions de conseil en cours de réalisation ou réalisés autour des solutions BI, Big Data et DMP,- Notre diversité de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale…),- Notre management de proximité et notre souci de développement des compétences."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Senior Data Engineer (F/H/X)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "EPSILON France",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-16",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, AdTech  / MarTech",
            "company_size": "650",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "38",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python",
                "java,",
                "scala…"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop/hdfs,",
                "spark,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure),",
                "azure).vous",
                "(gcp,",
                "(gcp"
            ],
            "DevTools": [
                "digitales,"
            ],
            "OS": [
                "linux/unix,"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops,comprendre",
                "ml).vous",
                "cloudmaintenir",
                "cloud",
                "cloud),",
                "cloudera,",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/epsilon/jobs/senior-data-engineer-f-h-x_paris_EF_8AKrre8?q=a6b09c99a6a04801acff655dede1f77d&o=993e04f1-bf8c-411f-baaf-df48b1ff55f3",
        "description": "Descriptif du posteDans le cadre du développement du pôle Data & IA (cadrage fonctionnel et technique, définition de use-cases, stratégie des moyens, accompagnement du changement, mise en œuvre, maintenance et commercialisation de solutions), nous recherchons un(e) Consultant Sénior Data Engineer qui aura pour missions :Délivrer des projets Data Lake / Big Data (ingestion de sources, pipeline de traitements de données, modélisation, tests, déploiements) dans un contexte de plus en plus DevOps,Comprendre les besoins des équipes digitales, principalement associées aux projets Data Science et leurs technologies / outils (Jupyter, Zeppelin, R, Python, …),Être capable de faire le lien avec les contraintes techniques (IT, sécurité, accès, outils) d’une DSI,Assurer la veille technologique sur les composants d’une plateforme Datalake, CloudMaintenir les environnements techniques et partager ses connaissances (capitalisation, séminaires, formations, KM en ligne),Rédiger des documents projets (design, réalisation, déploiement, …),Gérer l’évolution des solutions proposées, et possiblement en assurer la TMA.De formation Bac + 4/5 en informatique, vous avez au moins 5 ans d’expérience d’un projet de type Datalake en environnement HDFS et/ou cloud (GCP, Azure), une connaissance des DWH (sur technologie traditionnelle et/ou cloud), des méthodes Agile, voire du DataOps (industrialisation de modèles de ML).Vous possédez de bonnes compétences en Linux/Unix, Java, Spark, Scala… ainsi que sur les problématiques d’intégration (fichiers, messages, data) avec la connaissance d’au moins une plateforme Big Data Cloudera, Hortonworks (administration, configuration, monitoring, débogage, mise en œuvre) et d’une solution cloud (GCP ou Azure).Vous connaissez les technologies Hadoop/HDFS, Hive, Python et le requêtage de données (Impala, Hive, …).Votre expérience dans le traitement de flux en streaming (KafKa) est un plus.Votre niveau d’Anglais est opérationnel.CHOISISSEZ…- Notre expertise reconnue dans le domaine du décisionnel et du Big Data depuis 30 ans, un cadre méthodologique et une organisation des compétences animées constamment dans un souci de veille et de progression,- Nos projets innovants et nos missions de conseil en cours de réalisation ou réalisés autour des solutions BI, Big Data et DMP,- Notre diversité de projets et de clients (SNCF, Groupe BPCE, Fnac, La Banque Postale…),- Notre management de proximité et notre souci de développement des compétences."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Data (H/F)",
        "contract_type": "CDI",
        "salary": "57K à 75K €",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-12",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalabilité"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/architect-data-h-f?q=a6b09c99a6a04801acff655dede1f77d&o=0feaa5d1-eb8d-4bbd-899e-3b46e7b27de7",
        "description": "Descriptif du posteTu fais partie de ceux qui voient dans la donnée un trésor à exploiter ? Les projets de transformation numérique autour des données te passionnent, et tu es prêt(e) à structurer des écosystèmes de données performants et sécurisés ? Viens rejoindre la communauté Data Strategii et sois à l’avant-garde de l’innovation technologique autour de l’Architecture Data !Mais qu’est-ce que l’équipe Data Strategii adresse ?En tant qu’Architecte Data H/F, tes missions seront de :Préconiser des solutions d’architecture de données : Identifier et concevoir des architectures data robustes et évolutives, répondant aux besoins de performance et de sécurité des systèmes d’information.Assurer la scalabilité et la sécurité des infrastructures de données : Mettre en place des solutions capables de gérer de grands volumes de données tout en assurant une sécurité maximale (gestion des accès, protection des données sensibles).Optimiser les flux de données : Automatiser les processus ETL/ELT, améliorer les systèmes de stockage (Data Lakes, Data Warehouses) et garantir une intégration fluide des données en provenance de sources multiples.Gouverner la qualité des données : Mettre en œuvre des politiques de gouvernance des données afin de garantir leur intégrité, leur qualité et leur conformité aux réglementations en vigueur (RGPD, par exemple).Collaborer avec les équipes DevOps et Data Engineers : Travailler main dans la main avec les équipes de développement et d’ingénierie pour créer une infrastructure de données performante et adaptée aux besoins de l’entreprise.Optimiser les coûts : Identifier les opportunités d’optimisation des ressources et veiller à la gestion économique des infrastructures data.Documenter et standardiser les processus : Rédiger les dossiers d’architecture et formaliser les bonnes pratiques autour de la gestion des données.Ce que nous t’offrons ?Un salaire qui évolue au rythme de tes performances et de ton expertise.Une carrière à la “Sherlock Holmes” : tu es le détective des données, et ta progression est assurée sur le long terme.Prise en charge à 100 % de ta mutuelle et de ton titre de transport : plus de soucis de frais !Télétravail partiel : équilibre parfait entre pyjama et salle de réunion.Et surtout, la chance de contribuer à des projets passionnants qui feront de toi un acteur clé dans la transformation data de demain ! 🚀"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Data (H/F)",
        "contract_type": "CDI",
        "salary": "57K à 75K €",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 7",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-12",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalabilité"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/architect-data-h-f?q=a6b09c99a6a04801acff655dede1f77d&o=0feaa5d1-eb8d-4bbd-899e-3b46e7b27de7",
        "description": "Descriptif du posteTu fais partie de ceux qui voient dans la donnée un trésor à exploiter ? Les projets de transformation numérique autour des données te passionnent, et tu es prêt(e) à structurer des écosystèmes de données performants et sécurisés ? Viens rejoindre la communauté Data Strategii et sois à l’avant-garde de l’innovation technologique autour de l’Architecture Data !Mais qu’est-ce que l’équipe Data Strategii adresse ?En tant qu’Architecte Data H/F, tes missions seront de :Préconiser des solutions d’architecture de données : Identifier et concevoir des architectures data robustes et évolutives, répondant aux besoins de performance et de sécurité des systèmes d’information.Assurer la scalabilité et la sécurité des infrastructures de données : Mettre en place des solutions capables de gérer de grands volumes de données tout en assurant une sécurité maximale (gestion des accès, protection des données sensibles).Optimiser les flux de données : Automatiser les processus ETL/ELT, améliorer les systèmes de stockage (Data Lakes, Data Warehouses) et garantir une intégration fluide des données en provenance de sources multiples.Gouverner la qualité des données : Mettre en œuvre des politiques de gouvernance des données afin de garantir leur intégrité, leur qualité et leur conformité aux réglementations en vigueur (RGPD, par exemple).Collaborer avec les équipes DevOps et Data Engineers : Travailler main dans la main avec les équipes de développement et d’ingénierie pour créer une infrastructure de données performante et adaptée aux besoins de l’entreprise.Optimiser les coûts : Identifier les opportunités d’optimisation des ressources et veiller à la gestion économique des infrastructures data.Documenter et standardiser les processus : Rédiger les dossiers d’architecture et formaliser les bonnes pratiques autour de la gestion des données.Ce que nous t’offrons ?Un salaire qui évolue au rythme de tes performances et de ton expertise.Une carrière à la “Sherlock Holmes” : tu es le détective des données, et ta progression est assurée sur le long terme.Prise en charge à 100 % de ta mutuelle et de ton titre de transport : plus de soucis de frais !Télétravail partiel : équilibre parfait entre pyjama et salle de réunion.Et surtout, la chance de contribuer à des projets passionnants qui feront de toi un acteur clé dans la transformation data de demain ! 🚀"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer  (H/F) | Stage",
        "contract_type": "Stage(3 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Datascientest",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "SaaS / Cloud Services, EdTech, Formation",
            "company_size": "130",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml.application",
                "ml",
                "mlops,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-formateur-h-f-stage_puteaux?q=a6b09c99a6a04801acff655dede1f77d&o=fa32085a-d09f-45c8-8a69-4bb0fb7c4ab2",
        "description": "Descriptif du posteAu sein de l’équipe Machine Learning Engineering du pôle Data Science, vous serez amenés à intervenir sur le parcours Machine Learning Engineer (en priorité) et sur les parcours Data Scientist et Data Analyst. Le rôle s’articule autour des axes suivants :Développement : mise à jour et création de notebooks Python sur des sujets avancés de Machine & Deep Learning, notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.Application : accompagnement d’apprenants sur des projets de Machine Learning Engineering.Pédagogie : participation à l’animation de Masterclasses et d’évènements techniques autour du ML Engineering.Autoformation : recherche sur des technologies complexes et récentes en Machine Learning et MLOps, pouvant mener à la rédaction d’articles techniques."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer  (H/F) | Stage",
        "contract_type": "Stage(3 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Datascientest",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "SaaS / Cloud Services, EdTech, Formation",
            "company_size": "130",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml.application",
                "ml",
                "mlops,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-formateur-h-f-stage_puteaux?q=a6b09c99a6a04801acff655dede1f77d&o=fa32085a-d09f-45c8-8a69-4bb0fb7c4ab2",
        "description": "Descriptif du posteAu sein de l’équipe Machine Learning Engineering du pôle Data Science, vous serez amenés à intervenir sur le parcours Machine Learning Engineer (en priorité) et sur les parcours Data Scientist et Data Analyst. Le rôle s’articule autour des axes suivants :Développement : mise à jour et création de notebooks Python sur des sujets avancés de Machine & Deep Learning, notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.Application : accompagnement d’apprenants sur des projets de Machine Learning Engineering.Pédagogie : participation à l’animation de Masterclasses et d’évènements techniques autour du ML Engineering.Autoformation : recherche sur des technologies complexes et récentes en Machine Learning et MLOps, pouvant mener à la rédaction d’articles techniques."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer Junior (H/F) | CDI",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Datascientest",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 6 mois",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "SaaS / Cloud Services, EdTech, Formation",
            "company_size": "130",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops.",
                "ml.•"
            ],
            "EnSoftSkils": [
                "leadership",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-h-f-cdi_puteaux_DATAS_w1Az8r1?q=a6b09c99a6a04801acff655dede1f77d&o=21cb0944-065c-4238-bce6-8bdba1182a4f",
        "description": "Descriptif du posteRejoignez l’équipe Machine Learning Engineering au sein du pôle Data Science et jouez un rôle central dans la transformation digitale des entreprises et la formation des experts de demain.Vous interviendrez principalement sur le parcours Machine Learning Engineer, tout en apportant votre expertise dans les autres thématiques Data. Ce rôle stratégique s’articule autour de trois axes :1. Développement et Innovation :• Concevoir, mettre à jour et enrichir nos offres de formation couvrant des sujets avancés en Machine Learning et MLOps. Vous travaillerez notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.• Contribuer à positionner DataScientest comme un acteur à la pointe de l’innovation en suivant de près les évolutions du secteur et en intégrant les dernières tendances et outils dans les parcours d’apprentissage.2. Application et Coaching :• Encadrer et coacher les apprenants sur des projets pratiques de Machine Learning Engineering, en leur offrant des retours d’expérience concrets et des conseils techniques personnalisés.• Garantir que chaque projet d’entreprise est aligné avec les meilleures pratiques de l’industrie et répond aux besoins réels du marché, tout en aidant les clients à développer des compétences opérationnelles.3. Pédagogie et Leadership Technique :• Participer à l’animation des sessions de formation techniques autour du Machine Learning Engineering, où vous aurez l’occasion de partager votre expertise et d’échanger avec des professionnels et des passionnés du domaine.• Contribuer à créer un environnement d’apprentissage stimulant, favorisant la curiosité, la collaboration et l’innovation, tout en rendant accessibles des concepts complexes.Ce rôle vous place au cœur de l’innovation en Data Science, avec l’opportunité d’influencer directement l’évolution des compétences dans ce secteur. Si vous êtes passionné(e) par le Machine Learning Engineering, la pédagogie, et que vous avez envie de transmettre votre savoir tout en explorant des technologies de pointe, ce poste est fait pour vous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer Junior (H/F) | CDI",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Datascientest",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 6 mois",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "SaaS / Cloud Services, EdTech, Formation",
            "company_size": "130",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": null,
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops.",
                "ml.•"
            ],
            "EnSoftSkils": [
                "leadership",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-h-f-cdi_puteaux_DATAS_w1Az8r1?q=a6b09c99a6a04801acff655dede1f77d&o=21cb0944-065c-4238-bce6-8bdba1182a4f",
        "description": "Descriptif du posteRejoignez l’équipe Machine Learning Engineering au sein du pôle Data Science et jouez un rôle central dans la transformation digitale des entreprises et la formation des experts de demain.Vous interviendrez principalement sur le parcours Machine Learning Engineer, tout en apportant votre expertise dans les autres thématiques Data. Ce rôle stratégique s’articule autour de trois axes :1. Développement et Innovation :• Concevoir, mettre à jour et enrichir nos offres de formation couvrant des sujets avancés en Machine Learning et MLOps. Vous travaillerez notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.• Contribuer à positionner DataScientest comme un acteur à la pointe de l’innovation en suivant de près les évolutions du secteur et en intégrant les dernières tendances et outils dans les parcours d’apprentissage.2. Application et Coaching :• Encadrer et coacher les apprenants sur des projets pratiques de Machine Learning Engineering, en leur offrant des retours d’expérience concrets et des conseils techniques personnalisés.• Garantir que chaque projet d’entreprise est aligné avec les meilleures pratiques de l’industrie et répond aux besoins réels du marché, tout en aidant les clients à développer des compétences opérationnelles.3. Pédagogie et Leadership Technique :• Participer à l’animation des sessions de formation techniques autour du Machine Learning Engineering, où vous aurez l’occasion de partager votre expertise et d’échanger avec des professionnels et des passionnés du domaine.• Contribuer à créer un environnement d’apprentissage stimulant, favorisant la curiosité, la collaboration et l’innovation, tout en rendant accessibles des concepts complexes.Ce rôle vous place au cœur de l’innovation en Data Science, avec l’opportunité d’influencer directement l’évolution des compétences dans ce secteur. Si vous êtes passionné(e) par le Machine Learning Engineering, la pédagogie, et que vous avez envie de transmettre votre savoir tout en explorant des technologies de pointe, ce poste est fait pour vous !"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FEEDGY",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Intelligence artificielle / Machine Learning, Energie",
            "company_size": "93",
            "creation_date": "2014",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "24",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability,"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/feedgy/jobs/data-engineer-h-f_paris?q=a6b09c99a6a04801acff655dede1f77d&o=73310278-9e9c-4708-b3e6-e93370380f69",
        "description": "Descriptif du posteSolar PV plants convert solar energy to electricity. While operating, a large amount of data is created in the form of time series. The electrical variables describing the behavior of plants is directly influenced by the environmental variables. The electricity generated by these plants is either self-consumed or transported and distributed to the consumption points by the power grid and traded in the energy markets. In order to create services for our clients, we need to take advantage of all the data stream of the PV and electricity stakeholders and do a good usage of this data. The main goal of the Data Engineer is to contribute to expanding and optimizing our Data Platform, as well as optimizing data flow and collection for cross functional teams. Example of tasks include: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with other profiles and teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FEEDGY",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Intelligence artificielle / Machine Learning, Energie",
            "company_size": "93",
            "creation_date": "2014",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "24",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability,"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/feedgy/jobs/data-engineer-h-f_paris?q=a6b09c99a6a04801acff655dede1f77d&o=73310278-9e9c-4708-b3e6-e93370380f69",
        "description": "Descriptif du posteSolar PV plants convert solar energy to electricity. While operating, a large amount of data is created in the form of time series. The electrical variables describing the behavior of plants is directly influenced by the environmental variables. The electricity generated by these plants is either self-consumed or transported and distributed to the consumption points by the power grid and traded in the energy markets. In order to create services for our clients, we need to take advantage of all the data stream of the PV and electricity stakeholders and do a good usage of this data. The main goal of the Data Engineer is to contribute to expanding and optimizing our Data Platform, as well as optimizing data flow and collection for cross functional teams. Example of tasks include: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with other profiles and teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer @eXalt Bordeaux",
        "contract_type": "CDI",
        "salary": "40K à 48K €",
        "company": "eXalt",
        "location": "Bordeaux",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-bordeaux_bordeaux?q=a6b09c99a6a04801acff655dede1f77d&o=a7d4717c-d564-4a34-95bf-672fec635e9d",
        "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data.Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer @eXalt Bordeaux",
        "contract_type": "CDI",
        "salary": "40K à 48K €",
        "company": "eXalt",
        "location": "Bordeaux",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-bordeaux_bordeaux?q=a6b09c99a6a04801acff655dede1f77d&o=a7d4717c-d564-4a34-95bf-672fec635e9d",
        "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data.Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Analytics Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Swan",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-06",
        "company_data": {
            "sector": "Banque, IT / Digital, FinTech / InsurTech",
            "company_size": "200",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "organization."
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/swan/jobs/analytics-engineer_paris?q=a6b09c99a6a04801acff655dede1f77d&o=863cbed7-36d8-462d-9e82-329a8ef89610",
        "description": "Descriptif du posteSwan is looking for an Analytics Engineer to join its Data team. You will have a high-impact and high-exposure role within the organization. Your responsibilities will be the equivalent of a full-stack analytics professional, with emphasis on data modelling and occasional work on analysis and dashboard creation. This is an exciting opportunity to join a dynamic and growing team and make a significant impact on the future success of Swan.Responsibilities :Collaborate closely with other data team members, software engineers, and business stakeholders on a daily basisDevelop and maintain robust and production-quality SQL pipelines for 1-2 business domains, adhering to engineering best practices and making sure the models are tested, documented and easy to use for data analysts, business users and financial regulatorsBecome the data expert and main PoC for said business domains. Create reusable and scalable analytical solutions (datasets, dashboards, automations, etc) to empower your direct stakeholders and promote self-service data cultureHelp build the analytics engineering function by actively contributing to internal guidelines and best practices, suggesting process enhancement and adoption of new toolsKeep up to date with latest industry standards and emerging tools"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Analytics Engineer",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Swan",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-06",
        "company_data": {
            "sector": "Banque, IT / Digital, FinTech / InsurTech",
            "company_size": "200",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": [
                "sql"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "organization."
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/swan/jobs/analytics-engineer_paris?q=a6b09c99a6a04801acff655dede1f77d&o=863cbed7-36d8-462d-9e82-329a8ef89610",
        "description": "Descriptif du posteSwan is looking for an Analytics Engineer to join its Data team. You will have a high-impact and high-exposure role within the organization. Your responsibilities will be the equivalent of a full-stack analytics professional, with emphasis on data modelling and occasional work on analysis and dashboard creation. This is an exciting opportunity to join a dynamic and growing team and make a significant impact on the future success of Swan.Responsibilities :Collaborate closely with other data team members, software engineers, and business stakeholders on a daily basisDevelop and maintain robust and production-quality SQL pipelines for 1-2 business domains, adhering to engineering best practices and making sure the models are tested, documented and easy to use for data analysts, business users and financial regulatorsBecome the data expert and main PoC for said business domains. Create reusable and scalable analytical solutions (datasets, dashboards, automations, etc) to empower your direct stakeholders and promote self-service data cultureHelp build the analytics engineering function by actively contributing to internal guidelines and best practices, suggesting process enhancement and adoption of new toolsKeep up to date with latest industry standards and emerging tools"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer/Data Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability",
                "scalability,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "pysparko",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": [
                "seamless",
                "cloud"
            ],
            "EnSoftSkils": [
                "creativity,",
                "organization.your"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-data-analyst_paris?q=a6b09c99a6a04801acff655dede1f77d&o=b2b3bea1-f790-49c0-ab09-900affa9d826",
        "description": "Descriptif du posteNotre métier, protéger les personnes, les biens et les actifs. Notre raison d’être, agir pour le progrès humain en protégeant ce qui compte.Cela vous parle ? Alors venez rejoindre 149 000 futurs collègues qui s’engagent au quotidien auprès de nos 95 millions de clients dans 50 pays à travers le monde. Votre environnement de travailLe siège social du Groupe AXA (GIE AXA) regroupe nos activités corporate. Il assure le pilotage et le support des filiales dans le monde, afin de garantir notamment la coordination et le suivi de la stratégie globale d’AXA, l’application de ses standards, la cohérence des approches commerciales, et le partage des meilleures pratiques. Le siège est composé d’environ 1000 employés et se distingue par sa forte culture internationale (45 nationalités), ce qui en fait un espace de travail riche et stimulant.C’est autour de la diversité et de l’unité que se construit AXA, c’est pourquoi nous nous engageons à promouvoir le succès collectif par l’inclusion.Within the Group, you will join the Information Management team which is part of Group Performance Management Department within Group Finance.  Led by the Corporate Center Chief Data and AI Officer, Information Management team setup and deploy the Data strategy though (i) Data Governance and Data Quality Programs, (ii) efficient Data Architecture design, (iii) Data and AI services and (iv) Data Culture fostering.  Within this Department, you will be part of the Data and AI Operation Services team, which is responsible for (i) organizing, optimizing, and operating the collection of transversal data, either external or internal (ii) optimizing their distribution, (iii) ensuring their quality and (iv) controlling the entire data lifecycle, from collection to operational use.  You will work hand in hand with Data Governance and Data Transformation teams prioritizing and implementing use cases to create value for the overall organization.Your job and daily missions:We are looking for a Data expert able to do both data engineering and data analyses to take part in the scaling of our data platform and support the team’s and company’s growth. Within the Data and AI Operation services team, you will work with the following objectives:Optimize and maintain our Data Lake (several terabytes) that collects, stores, and processes external and internal data, focusing on scalability and reliability:o   Designing, automating, and managing data pipeline using Microsoft Azure and Databricks, to ensure seamless and efficient integration of data to meet internal client’s needs.o   Controlling and managing the data entire lifecycle, from collection to operational use considering Group Security and GDPR policieso   Ensuring the scalability, security, and availability of platform datao   Carrying out a technological watch to be at the forefront of cloud & Data solutionsDistribute data to final users ensuring expected data quality:o   Modelling and analyzing data.o   Industrialising and automating data cleansing aligned with final users’ specifications.o   Creating datasets using PySparko   Managing, maintaining, and documenting the several data baseso   Creating and automatising dashboards for final users  Explore and acquire new sources of data.  Using curiosity and creativity, this would involve using technology to automate data acquisition, ability to link new sources with internal data, and appropriate level of supporting documentation of the source and technical solution. Providing the right context of data required for a given analysis. This would require working with data analysts to understand the business problems they are trying to solve and create data structures to feed into their analysis. Build upon learnings of internal and external data to become more proactive.  This includes thinking ahead of what internal clients will anticipate with their data needs and designing structures that are intuitive to use.Ensuring quality and understanding of analytical data.  This would require hands on data experience to investigate data issues and seek to resolution or acceptance.  Create the appropriate amount of documentation, leverage standards and build upon them.  Data should be reconciled and documented at various stages for integrity.Participate in developing governance and rigor of data management practice within the Data Operation Team.  This will also include partnering with other IT groups and involvement in other data related functions.   Vous rejoignez une entreprise :-    Responsable, vis-à-vis des personnes, y compris ses employés et ses clients, et de la planète. -    Aux valeurs fortes-    Qui encourage la mobilité interne, et la formation de ses employés-    Qui vous offre de nombreux avantages (en savoir plus ici : Reward & Benefits - french | AXA Group)-    Flexible, qui permet le travail hybride, au bureau et à la maison.Les informations fournies par les candidat(e)s seront traitées de manière strictement confidentielle et utilisées uniquement à des fins de recrutement."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer/Data Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": null,
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability",
                "scalability,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "pysparko",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": [
                "seamless",
                "cloud"
            ],
            "EnSoftSkils": [
                "creativity,",
                "organization.your"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-data-analyst_paris?q=a6b09c99a6a04801acff655dede1f77d&o=b2b3bea1-f790-49c0-ab09-900affa9d826",
        "description": "Descriptif du posteNotre métier, protéger les personnes, les biens et les actifs. Notre raison d’être, agir pour le progrès humain en protégeant ce qui compte.Cela vous parle ? Alors venez rejoindre 149 000 futurs collègues qui s’engagent au quotidien auprès de nos 95 millions de clients dans 50 pays à travers le monde. Votre environnement de travailLe siège social du Groupe AXA (GIE AXA) regroupe nos activités corporate. Il assure le pilotage et le support des filiales dans le monde, afin de garantir notamment la coordination et le suivi de la stratégie globale d’AXA, l’application de ses standards, la cohérence des approches commerciales, et le partage des meilleures pratiques. Le siège est composé d’environ 1000 employés et se distingue par sa forte culture internationale (45 nationalités), ce qui en fait un espace de travail riche et stimulant.C’est autour de la diversité et de l’unité que se construit AXA, c’est pourquoi nous nous engageons à promouvoir le succès collectif par l’inclusion.Within the Group, you will join the Information Management team which is part of Group Performance Management Department within Group Finance.  Led by the Corporate Center Chief Data and AI Officer, Information Management team setup and deploy the Data strategy though (i) Data Governance and Data Quality Programs, (ii) efficient Data Architecture design, (iii) Data and AI services and (iv) Data Culture fostering.  Within this Department, you will be part of the Data and AI Operation Services team, which is responsible for (i) organizing, optimizing, and operating the collection of transversal data, either external or internal (ii) optimizing their distribution, (iii) ensuring their quality and (iv) controlling the entire data lifecycle, from collection to operational use.  You will work hand in hand with Data Governance and Data Transformation teams prioritizing and implementing use cases to create value for the overall organization.Your job and daily missions:We are looking for a Data expert able to do both data engineering and data analyses to take part in the scaling of our data platform and support the team’s and company’s growth. Within the Data and AI Operation services team, you will work with the following objectives:Optimize and maintain our Data Lake (several terabytes) that collects, stores, and processes external and internal data, focusing on scalability and reliability:o   Designing, automating, and managing data pipeline using Microsoft Azure and Databricks, to ensure seamless and efficient integration of data to meet internal client’s needs.o   Controlling and managing the data entire lifecycle, from collection to operational use considering Group Security and GDPR policieso   Ensuring the scalability, security, and availability of platform datao   Carrying out a technological watch to be at the forefront of cloud & Data solutionsDistribute data to final users ensuring expected data quality:o   Modelling and analyzing data.o   Industrialising and automating data cleansing aligned with final users’ specifications.o   Creating datasets using PySparko   Managing, maintaining, and documenting the several data baseso   Creating and automatising dashboards for final users  Explore and acquire new sources of data.  Using curiosity and creativity, this would involve using technology to automate data acquisition, ability to link new sources with internal data, and appropriate level of supporting documentation of the source and technical solution. Providing the right context of data required for a given analysis. This would require working with data analysts to understand the business problems they are trying to solve and create data structures to feed into their analysis. Build upon learnings of internal and external data to become more proactive.  This includes thinking ahead of what internal clients will anticipate with their data needs and designing structures that are intuitive to use.Ensuring quality and understanding of analytical data.  This would require hands on data experience to investigate data issues and seek to resolution or acceptance.  Create the appropriate amount of documentation, leverage standards and build upon them.  Data should be reconciled and documented at various stages for integrity.Participate in developing governance and rigor of data management practice within the Data Operation Team.  This will also include partnering with other IT groups and involvement in other data related functions.   Vous rejoignez une entreprise :-    Responsable, vis-à-vis des personnes, y compris ses employés et ses clients, et de la planète. -    Aux valeurs fortes-    Qui encourage la mobilité interne, et la formation de ses employés-    Qui vous offre de nombreux avantages (en savoir plus ici : Reward & Benefits - french | AXA Group)-    Flexible, qui permet le travail hybride, au bureau et à la maison.Les informations fournies par les candidat(e)s seront traitées de manière strictement confidentielle et utilisées uniquement à des fins de recrutement."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Spark Scala H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloudimplémenter"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-spark-scala-h-f?q=a6b09c99a6a04801acff655dede1f77d&o=174828c4-cd7a-4417-9ff8-928605072a0d",
        "description": "Descriptif du poste🪄Tu as le pouvoir de créer des pipelines capables de transformer des données en véritables trésors exploitables, alors tu es peut-être notre Super Data Ingénieur !🎯Tu es prêt à affronter des défis titanesques, à gérer des montagnes de données, à défendre la résilience des systèmes, et à affronter des flux de données massifs, l’équipe DATA Factorii t’ouvre ses portes comme un véritable repaire de super-héros !🚀En tant que Super Data Engineer - Spark Scala H/F, tes missions seront de :Définir et déployer le socle technologique d’un DatalakeConseiller et concevoir une architecture de donnéesImplémenter l’intégration des données au sein du DatalakeIdentifier, étudier et prototyper des cas d’usage stratégiquesIndustrialiser les projets Big Data en environnement cloudImplémenter les méthodologies Devops pour optimiser les processus de développementParticiper à l’estimation des besoins utilisateurs.Concevoir du code et le documenter.Collaborer étroitement au sein de l’équipe SCRUM, comprenant le Product Owner, les développeurs, Quality Analyst, et le support, pour assurer le succès des projets.🎁 Ce que nous t’offrons ?Un salaire qui évolue comme une rock star sur scène !Une carrière à la “James Bond” : à moyen et long terme, c’est toi le héros !Ta mutuelle et ton titre de transport pris en charge à 100% (bye-bye les frais) !Télétravail partiel : l’équilibre parfait entre pyjama et costume !  Et surtout, la chance de t’investir dans des projets ultra cool qui te propulseront techniquement vers l’infini et au-delà ! 🚀"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Spark Scala H/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "skiils",
        "location": "Suresnes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data",
            "company_size": "100",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "11",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "cloudimplémenter"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/data-engineer-spark-scala-h-f?q=a6b09c99a6a04801acff655dede1f77d&o=174828c4-cd7a-4417-9ff8-928605072a0d",
        "description": "Descriptif du poste🪄Tu as le pouvoir de créer des pipelines capables de transformer des données en véritables trésors exploitables, alors tu es peut-être notre Super Data Ingénieur !🎯Tu es prêt à affronter des défis titanesques, à gérer des montagnes de données, à défendre la résilience des systèmes, et à affronter des flux de données massifs, l’équipe DATA Factorii t’ouvre ses portes comme un véritable repaire de super-héros !🚀En tant que Super Data Engineer - Spark Scala H/F, tes missions seront de :Définir et déployer le socle technologique d’un DatalakeConseiller et concevoir une architecture de donnéesImplémenter l’intégration des données au sein du DatalakeIdentifier, étudier et prototyper des cas d’usage stratégiquesIndustrialiser les projets Big Data en environnement cloudImplémenter les méthodologies Devops pour optimiser les processus de développementParticiper à l’estimation des besoins utilisateurs.Concevoir du code et le documenter.Collaborer étroitement au sein de l’équipe SCRUM, comprenant le Product Owner, les développeurs, Quality Analyst, et le support, pour assurer le succès des projets.🎁 Ce que nous t’offrons ?Un salaire qui évolue comme une rock star sur scène !Une carrière à la “James Bond” : à moyen et long terme, c’est toi le héros !Ta mutuelle et ton titre de transport pris en charge à 100% (bye-bye les frais) !Télétravail partiel : l’équilibre parfait entre pyjama et costume !  Et surtout, la chance de t’investir dans des projets ultra cool qui te propulseront techniquement vers l’infini et au-delà ! 🚀"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior H/F",
        "contract_type": "CDI",
        "salary": "55K à 80K €",
        "company": "Innovela",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-03",
        "company_data": {
            "sector": "IT / Digital, SaaS / Cloud Services, Big Data",
            "company_size": "15",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "1.7",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp.effectuer"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-senior-h-f_paris?q=a6b09c99a6a04801acff655dede1f77d&o=36ad7506-380a-4236-8336-4264dbd35021",
        "description": "Descriptif du posteLe poste Au sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés à Paris.Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilitésIdentifier et conseiller les solutions appropriées pour répondre aux besoins des clients.Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.Construire et monitorer des pipeline de données sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Senior H/F",
        "contract_type": "CDI",
        "salary": "55K à 80K €",
        "company": "Innovela",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-03",
        "company_data": {
            "sector": "IT / Digital, SaaS / Cloud Services, Big Data",
            "company_size": "15",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "1.7",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp.effectuer"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-senior-h-f_paris?q=a6b09c99a6a04801acff655dede1f77d&o=36ad7506-380a-4236-8336-4264dbd35021",
        "description": "Descriptif du posteLe poste Au sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés à Paris.Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilitésIdentifier et conseiller les solutions appropriées pour répondre aux besoins des clients.Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.Construire et monitorer des pipeline de données sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer H/F",
        "contract_type": "CDI",
        "salary": "45K à 65K €",
        "company": "Innovela",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-03",
        "company_data": {
            "sector": "IT / Digital, SaaS / Cloud Services, Big Data",
            "company_size": "15",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "1.7",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp.effectuer"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-h-f_paris_INNOV_W6OajrA?q=a6b09c99a6a04801acff655dede1f77d&o=74a9aa2e-f8ea-4ca3-9d83-a46498bbd2e2",
        "description": "Descriptif du posteLe posteAu sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés dans le 11ème arrondissement de Paris.Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilitésIdentifier et conseiller les solutions appropriées pour répondre aux besoins des clients.Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.Construire et monitorer des pipeline de données sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer H/F",
        "contract_type": "CDI",
        "salary": "45K à 65K €",
        "company": "Innovela",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-03",
        "company_data": {
            "sector": "IT / Digital, SaaS / Cloud Services, Big Data",
            "company_size": "15",
            "creation_date": "2016",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "1.7",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp.effectuer"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/innovela/jobs/data-engineer-h-f_paris_INNOV_W6OajrA?q=a6b09c99a6a04801acff655dede1f77d&o=74a9aa2e-f8ea-4ca3-9d83-a46498bbd2e2",
        "description": "Descriptif du posteLe posteAu sein de l’équipe de développement d’Innovela, vous participerez à la conception et au développement de pipeline de données en utilisant les solutions de la plateforme Google principalement.Vous travaillerez en mode agile au sein d’une équipe passionnée et dynamique, et sur des technologies toujours plus innovantes.Les projets sont effectués soit chez nos clients, soit directement dans les locaux d’Innovela situés dans le 11ème arrondissement de Paris.Enfin, vous participerez également aux événements organisés par Google (Summit, formations etc..) dans le cadre du partenariat Innovela-Google.Les responsabilitésIdentifier et conseiller les solutions appropriées pour répondre aux besoins des clients.Participer aux différentes phases d’un projet (analyse, prototypage, conception, développement, déploiement, maintenance).Veiller à la gouvernance des données et mise en place de process MDM : Rapprochement de données de différentes sources non homogènes, Dédoublonnage, Normalisation, Historisation, Calcul d’indicateurs et d’agrégats.Construire et monitorer des pipeline de données sur GCP.Effectuer de la veille technologique sur les technologies web, cloud et Google."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Spark/Scala F/H",
        "contract_type": "CDI",
        "salary": "55K à 60K €",
        "company": "Size Up Consulting",
        "location": "Nanterre",
        "remote": "Télétravail occasionnel",
        "experience": "> 5",
        "education_level": "Bac +4",
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "200",
            "creation_date": "2023",
            "address": null,
            "average_age_of_employees": "38",
            "turnover_in_millions": "10 Millions",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/size-up-consulting/jobs/data-engineer-spark-scala-f-h_nanterre?q=a6b09c99a6a04801acff655dede1f77d&o=f9c9f150-e5db-405d-948d-de406292e6f9",
        "description": "Descriptif du posteAu sein du chantier concerné, travaillant en mode agile (SCRUM), la mission consistera à prendre part aux développements sur l’outil, tout en étant garant de la pérennité et la non régression de l’outillage déjà en place, sur les deux sujets ci-dessous :L’optimisation de la performance**, temps d’exécution, utilisation des ressources machines afin de tenir les délais de traitement des informations et de leurs distributions vers les consommateurs avals (Calculateurs et reporting) dans le cadre des arrêtés mais également des besoins quotidiens. Notamment afin de faire face à l’augmentation significative de la volumétrie de données sur S2 2024 et 2025 en lien avec les déploiements  GASPARDLa contribution à la mise en place des outils de monitoring technique et fonctionnelleCompétences techniques requises :- Spark / Scala : confirmé- Kafka : connaissance ++- à l’aise avec la programmation fonctionnelle (connaissance des librairies ZIO, MONIX, CATS appréciée)L’équipe est principalement localisée à Paris mais dispose de ressources à Porto. L’anglais est donc d’usage dans l’équipe."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer Spark/Scala F/H",
        "contract_type": "CDI",
        "salary": "55K à 60K €",
        "company": "Size Up Consulting",
        "location": "Nanterre",
        "remote": "Télétravail occasionnel",
        "experience": "> 5",
        "education_level": "Bac +4",
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "Logiciels, IT / Digital, Big Data",
            "company_size": "200",
            "creation_date": "2023",
            "address": null,
            "average_age_of_employees": "38",
            "turnover_in_millions": "10 Millions",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scala"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "spark"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/size-up-consulting/jobs/data-engineer-spark-scala-f-h_nanterre?q=a6b09c99a6a04801acff655dede1f77d&o=f9c9f150-e5db-405d-948d-de406292e6f9",
        "description": "Descriptif du posteAu sein du chantier concerné, travaillant en mode agile (SCRUM), la mission consistera à prendre part aux développements sur l’outil, tout en étant garant de la pérennité et la non régression de l’outillage déjà en place, sur les deux sujets ci-dessous :L’optimisation de la performance**, temps d’exécution, utilisation des ressources machines afin de tenir les délais de traitement des informations et de leurs distributions vers les consommateurs avals (Calculateurs et reporting) dans le cadre des arrêtés mais également des besoins quotidiens. Notamment afin de faire face à l’augmentation significative de la volumétrie de données sur S2 2024 et 2025 en lien avec les déploiements  GASPARDLa contribution à la mise en place des outils de monitoring technique et fonctionnelleCompétences techniques requises :- Spark / Scala : confirmé- Kafka : connaissance ++- à l’aise avec la programmation fonctionnelle (connaissance des librairies ZIO, MONIX, CATS appréciée)L’équipe est principalement localisée à Paris mais dispose de ressources à Porto. L’anglais est donc d’usage dans l’équipe."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Database Engineer (Talent Pool)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Descartes & Mauss",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Stratégie",
            "company_size": "35",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable",
                "scalability"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "sql",
                "postgresql",
                "postgresql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql"
            ],
            "DataAnalytics": null,
            "BigData": [
                "pyspark",
                "sparknlpmanage"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp",
                "gcp"
            ],
            "DevTools": [
                "github",
                "docker"
            ],
            "OS": null,
            "DBMS": [
                "postgresql",
                "postgresql"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker"
            ],
            "Collaboration": [
                "slack"
            ],
            "Other": [
                "seamless",
                "seamless",
                "cloud",
                "cloud),",
                "cloud",
                "cloud.",
                "cloud",
                "cloud",
                "(ci/cd)",
                "ci/cd"
            ],
            "EnSoftSkils": [
                "communication:",
                "initiative,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/descartes-mauss/jobs/data-database-engineer-talent-pool_paris?q=a6b09c99a6a04801acff655dede1f77d&o=fe91af80-1884-459e-a3af-80688678f771",
        "description": "Descriptif du posteAt D&M, we’re always on the lookout for exceptional talent to join our dynamic team. This posting is part of our talent pool initiative, where we invite passionate professionals interested in technology and AI to connect with us. By submitting your application, you’ll be considered for future openings that align with your skills and aspirations. Join us in shaping the future of innovation!We are seeking a skilled Data/Database Engineer to join our team and take ownership of managing, optimizing, and monitoring our data infrastructure. The ideal candidate will have experience working with both SQL and NoSQL databases, building and maintaining ETL pipelines, and ensuring seamless data operations. This role requires expertise in cloud platforms (preferably Google Cloud), containerization, and continuous integration/continuous deployment (CI/CD) practices. The engineer will also ensure data security and compliance with regulations such as GDPR/CCPA. Your responsibilities include:Data Pipeline Management: Design, implement, and maintain scalable ETL processes using PySpark and SparkNLPManage data pipelines using GCP Workflows for scheduling and orchestrating jobsEnsure seamless integration and management of data systems to maintain continuous operation. Database Management: 1/ SQL Databases: Manage and optimize PostgreSQL databases for transactional data and relational database management. Regularly optimize queries and indexes to ensure high-performance operations. Implement automated backup and recovery solutions for PostgreSQL to prevent data loss. 2/ NoSQL Databases: Manage and optimize NoSQL datasets using Delta Lake for large-scale data. Ensure NoSQL infrastructure scalability to handle increasing data volumes. Infrastructure & Deployment: Deploy data applications on cloud platforms like Google Cloud. Utilize Docker for containerized environments and ensure consistency across development, testing, and production environments. Leverage GCP services for deployment, scaling, and monitoring of data applications. Set up and manage CI/CD pipelines using GitHub Actions to automate testing, deployment, and version control. Monitoring & Performance Optimization: Monitor data processing systems for latency, throughput, and error rates to ensure optimal performance. Ensure data quality by regularly checking for consistency, completeness, and accuracy across databases and pipelines. Implement centralized logging using Google Cloud Logging to aggregate logs from multiple sources. Security & Compliance: Ensure the encryption of data both at rest and in transit. Implement role-based access control (RBAC) to secure data and model endpoints. Maintain compliance with regulations such as GDPR and CCPA, including detailed audit logging for model training and data access. Documentation & Communication: Document API endpoints and data pipelines using tools like Swagger for ease of maintenance and onboarding. Provide data flow diagrams, ETL process documentation, and data schema explanations. Set up alerts using Google Cloud Monitoring and Slack for real-time issue notifications. Generate and share performance reports to keep stakeholders informed and facilitate data-driven decision-making."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Database Engineer (Talent Pool)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Descartes & Mauss",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Stratégie",
            "company_size": "35",
            "creation_date": "2021",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable",
                "scalability"
            ],
            "DataBase": [
                "sql",
                "nosql",
                "sql",
                "postgresql",
                "postgresql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql",
                "nosql"
            ],
            "DataAnalytics": null,
            "BigData": [
                "pyspark",
                "sparknlpmanage"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "gcp",
                "gcp"
            ],
            "DevTools": [
                "github",
                "docker"
            ],
            "OS": null,
            "DBMS": [
                "postgresql",
                "postgresql"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "docker"
            ],
            "Collaboration": [
                "slack"
            ],
            "Other": [
                "seamless",
                "seamless",
                "cloud",
                "cloud),",
                "cloud",
                "cloud.",
                "cloud",
                "cloud",
                "(ci/cd)",
                "ci/cd"
            ],
            "EnSoftSkils": [
                "communication:",
                "initiative,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/descartes-mauss/jobs/data-database-engineer-talent-pool_paris?q=a6b09c99a6a04801acff655dede1f77d&o=fe91af80-1884-459e-a3af-80688678f771",
        "description": "Descriptif du posteAt D&M, we’re always on the lookout for exceptional talent to join our dynamic team. This posting is part of our talent pool initiative, where we invite passionate professionals interested in technology and AI to connect with us. By submitting your application, you’ll be considered for future openings that align with your skills and aspirations. Join us in shaping the future of innovation!We are seeking a skilled Data/Database Engineer to join our team and take ownership of managing, optimizing, and monitoring our data infrastructure. The ideal candidate will have experience working with both SQL and NoSQL databases, building and maintaining ETL pipelines, and ensuring seamless data operations. This role requires expertise in cloud platforms (preferably Google Cloud), containerization, and continuous integration/continuous deployment (CI/CD) practices. The engineer will also ensure data security and compliance with regulations such as GDPR/CCPA. Your responsibilities include:Data Pipeline Management: Design, implement, and maintain scalable ETL processes using PySpark and SparkNLPManage data pipelines using GCP Workflows for scheduling and orchestrating jobsEnsure seamless integration and management of data systems to maintain continuous operation. Database Management: 1/ SQL Databases: Manage and optimize PostgreSQL databases for transactional data and relational database management. Regularly optimize queries and indexes to ensure high-performance operations. Implement automated backup and recovery solutions for PostgreSQL to prevent data loss. 2/ NoSQL Databases: Manage and optimize NoSQL datasets using Delta Lake for large-scale data. Ensure NoSQL infrastructure scalability to handle increasing data volumes. Infrastructure & Deployment: Deploy data applications on cloud platforms like Google Cloud. Utilize Docker for containerized environments and ensure consistency across development, testing, and production environments. Leverage GCP services for deployment, scaling, and monitoring of data applications. Set up and manage CI/CD pipelines using GitHub Actions to automate testing, deployment, and version control. Monitoring & Performance Optimization: Monitor data processing systems for latency, throughput, and error rates to ensure optimal performance. Ensure data quality by regularly checking for consistency, completeness, and accuracy across databases and pipelines. Implement centralized logging using Google Cloud Logging to aggregate logs from multiple sources. Security & Compliance: Ensure the encryption of data both at rest and in transit. Implement role-based access control (RBAC) to secure data and model endpoints. Maintain compliance with regulations such as GDPR and CCPA, including detailed audit logging for model training and data access. Documentation & Communication: Document API endpoints and data pipelines using tools like Swagger for ease of maintenance and onboarding. Provide data flow diagrams, ETL process documentation, and data schema explanations. Set up alerts using Google Cloud Monitoring and Slack for real-time issue notifications. Generate and share performance reports to keep stakeholders informed and facilitate data-driven decision-making."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Consultant Data Engineer F/H",
        "contract_type": "Stage(5 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Villeurbanne",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-24",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "databricks",
                "databricksetl"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau,"
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws,",
                "aws,",
                "azure",
                "azure,"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud",
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/stage-consultant-data-engineer-f-h_villeurbanne?q=a6b09c99a6a04801acff655dede1f77d&o=11f19e43-0493-4a9a-81f6-21674458fe62",
        "description": "Descriptif du posteAu sein de Micropole, nous vous proposons de rejoindre notre entité lyonnaise où vous serez rattache(é) à l’équipe Data Analytics composée de 45 #InnovativePeople.   Nous sommes un pôle Data Analytics innovant et dynamique, spécialisé dans les solutions de Big Data et Data Engineering.   Nous accompagnons des entreprises de divers secteurs d'activité dans la mise en place de solutions analytiques performantes, basées sur des technologies Cloud de pointe, telles que Microsoft Azure (Power BI, Fabric), AWS, Databricks ...   Vos principales missions seront : Implémentation de data pipelines de données robustes et évolutifs pour transformer et structurer les données sur des cloud data plateformesData Modélisation au sein de data warehouse pour optimiser les performances et garantir l'intégrité des données Analyse et traitement de données volumineuses sur des frameworks Big Data Modélisation et création de dashboards en nous appuyant sur les outils de datavisualisation performants du marché, tels que Power BIVeille technologique sur les nouvelles solutions Cloud, Big Data et Data.Technologies : Environnements : Azure, AWS, Microsoft BI, Snowflake, DatabricksETL : Talend, Microsoft SSIS, ODI, … Datavisualisation : Power BI, QuickSight, Tableau, …"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Consultant Data Engineer F/H",
        "contract_type": "Stage(5 à 6 mois)",
        "salary": "Non spécifié",
        "company": "Micropole",
        "location": "Villeurbanne",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-24",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "1200",
            "creation_date": "1987",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "142 millions d'€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "databricks",
                "databricksetl"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau,"
            ],
            "Statistics": null,
            "CloudComputing": [
                "aws,",
                "aws,",
                "azure",
                "azure,"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": [
                "snowflake,"
            ],
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud",
                "cloud",
                "cloud,"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/stage-consultant-data-engineer-f-h_villeurbanne?q=a6b09c99a6a04801acff655dede1f77d&o=11f19e43-0493-4a9a-81f6-21674458fe62",
        "description": "Descriptif du posteAu sein de Micropole, nous vous proposons de rejoindre notre entité lyonnaise où vous serez rattache(é) à l’équipe Data Analytics composée de 45 #InnovativePeople.   Nous sommes un pôle Data Analytics innovant et dynamique, spécialisé dans les solutions de Big Data et Data Engineering.   Nous accompagnons des entreprises de divers secteurs d'activité dans la mise en place de solutions analytiques performantes, basées sur des technologies Cloud de pointe, telles que Microsoft Azure (Power BI, Fabric), AWS, Databricks ...   Vos principales missions seront : Implémentation de data pipelines de données robustes et évolutifs pour transformer et structurer les données sur des cloud data plateformesData Modélisation au sein de data warehouse pour optimiser les performances et garantir l'intégrité des données Analyse et traitement de données volumineuses sur des frameworks Big Data Modélisation et création de dashboards en nous appuyant sur les outils de datavisualisation performants du marché, tels que Power BIVeille technologique sur les nouvelles solutions Cloud, Big Data et Data.Technologies : Environnements : Azure, AWS, Microsoft BI, Snowflake, DatabricksETL : Talend, Microsoft SSIS, ODI, … Datavisualisation : Power BI, QuickSight, Tableau, …"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "eXalt",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-22",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer_paris?q=a6b09c99a6a04801acff655dede1f77d&o=d00d5d3d-d3e0-4724-8f74-dec6afd99d81",
        "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data. Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "eXalt",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-22",
        "company_data": {
            "sector": "IT / Digital",
            "company_size": "950",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "75",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer_paris?q=a6b09c99a6a04801acff655dede1f77d&o=d00d5d3d-d3e0-4724-8f74-dec6afd99d81",
        "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data. Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer/Business Analyst (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-20",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-business-analyst-f-h_nanterre?q=a6b09c99a6a04801acff655dede1f77d&o=ae5f8a80-e35f-44e7-b412-ea2dcdb4685c",
        "description": "Descriptif du posteVenez rejoindre notre tribu Data/BI au sein de la DSI IARD et Partenariats en tant que Data Engineer/Business Analyst (F/H).Vous êtes en charge de:Définir et mettre en œuvre les solutions pour nos métiers;Cadrer, macro-estimation des coûts et du planning des évolutions demandées;Identifier les compétences nécessaires au développement de ces évolutions projets;Construire en lien avec le QoS tous les outils et processus permettant d’assurer une qualité de service fiable et robuste;Travailler efficacement avec toutes les équipes DT2 concernées pour donner une visibilité  à nos métiers. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer/Business Analyst (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-20",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/data-engineer-business-analyst-f-h_nanterre?q=a6b09c99a6a04801acff655dede1f77d&o=ae5f8a80-e35f-44e7-b412-ea2dcdb4685c",
        "description": "Descriptif du posteVenez rejoindre notre tribu Data/BI au sein de la DSI IARD et Partenariats en tant que Data Engineer/Business Analyst (F/H).Vous êtes en charge de:Définir et mettre en œuvre les solutions pour nos métiers;Cadrer, macro-estimation des coûts et du planning des évolutions demandées;Identifier les compétences nécessaires au développement de ces évolutions projets;Construire en lien avec le QoS tous les outils et processus permettant d’assurer une qualité de service fiable et robuste;Travailler efficacement avec toutes les équipes DT2 concernées pour donner une visibilité  à nos métiers. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Services Financiers - Nantes",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2024-10-28",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-nantes_nantes_SS_lDDlJqW?q=a6b09c99a6a04801acff655dede1f77d&o=508d43d8-60d6-4be8-ad9b-b52506ea065d",
        "description": "Descriptif du posteVotre futur environnement de travail :La division « Services Financiers » s’est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.Si vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Nantes et les quelques 100 Data Ingénieurs qui la composent. Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.Vous êtes accompagné(e) au développement de vos connaissances à travers différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence, vous participez à :La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;La mise en œuvre de solutions d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;Le traitement de la donnée jusqu'à l'exposition au métier ;La mise en place de la chaine CI/CD et de sa supervision ;La veille technologique avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, RInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Engineer - Services Financiers - Nantes",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Nantes",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2024-10-28",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "java,",
                "scala,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": [
                "hadoop,",
                "spark,",
                "databricks,"
            ],
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure"
            ],
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud.",
                "cloud",
                "cloudera,",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/data-engineer-services-financiers-nantes_nantes_SS_lDDlJqW?q=a6b09c99a6a04801acff655dede1f77d&o=508d43d8-60d6-4be8-ad9b-b52506ea065d",
        "description": "Descriptif du posteVotre futur environnement de travail :La division « Services Financiers » s’est développée autour des métiers de la banque de détail, de la banque privée et des services financiers spécialisés. Nous participons à la révolution digitale grâce à notre expertise en automatisation des processus, Big Data, IA, Cloud. Nous accompagnons la transformation de nos clients en y associant nos compétences dans les domaines fonctionnels des Crédits, des Risques/Conformité et des Moyens de Paiement.Si vous êtes passionné(e) par la valorisation de la donnée, rejoignez notre Data Factory localisée à Nantes et les quelques 100 Data Ingénieurs qui la composent. Vous y rencontrerez des experts de la mise en œuvre de Plateforme de Données, des Data Architectes ou autres experts solution autour des problématiques de valorisation de la donnée.Vous êtes accompagné(e) au développement de vos connaissances à travers différents parcours Data que ce soit pour l'ingestion, la construction de datahub, la transformation et valorisation de la donnée, la modélisation et mise à disposition.Rejoindre la Data Factory Sopra Steria, c'est rejoindre une communauté de Data Ingénieurs fiers de partager leur savoir et ouverts aux nouvelles expériences et expérimentations de la donnée.Votre rôle et vos missions :Dans le cadre de la mise en place de plateforme Data pour nos clients et selon votre expérience et votre appétence, vous participez à :La compréhension des besoins métiers et la traduction solution de data ingénierie et ou data analysis ;La mise en œuvre de solutions d'ingestion des données quelles soit en batch et/ou en streaming dans un contexte Cloud ;La structuration du DataLake, la mise en place des processus de gouvernance et de sécurisation des données ;Le traitement de la donnée jusqu'à l'exposition au métier ;La mise en place de la chaine CI/CD et de sa supervision ;La veille technologique avec nos partenaires éditeurs et la mise en place de Prototype Design, Proof of Concept ou encore MVP dans un objectif d'idéation pour nos clients.Environnement technique : Spark, Hadoop, Hive, Kafka, Elastic, Cloudera, Azure HD Insight, Informatica, Talend, Stambia, DataStage, SAS, DataIku, DataBricks, Qlik, SAP BI (BO), Power BI, Java, Scala, Python, RInformations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer - Research Internship",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meltwater",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "IT / Digital, Marketing / Communication, Digital",
            "company_size": "2200",
            "creation_date": "2001",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "477 M",
            "proportion_female": "49",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meltwater/jobs/machine-learning-engineer-research-internship_paris_MELTW_jazNM9a?q=9535b0189e8e7cf32ba6058db50630c7&o=8c446284-90b8-4901-8849-6b93af78a568",
        "description": "Descriptif du posteMeltwater’s Consumer Intelligence AI Team is looking for a ML Research Intern who will be contributing on developing new innovative Natural Language Processing or Computer Vision features relying on the literature’s state of the art. Those features are meant to be integrated in our Consumer Intelligence platform meaning that your work will be used by our customers.We are looking for someone with a creative, proactive, collaborative, and innovation focused mindset. You will work alongside a team of passionate engineers driven by enthusiasm for new technologies and excitement about making the difference for customers using AI.Our team is organized over 3 objectives : innovation, research and production.Innovation: We leverage our AI expertise to constantly imagine new business oriented features to enhance our products.Research: To implement our algorithms, we need to stay up-to-date to the latest breakthroughs over the Machine Learning world as well as the latest frameworks.Production: We make a point of designing and developing our algorithms in a software engineering fashion. Scalability is our goal. The models that we develop are running over billions of documents (text or image) per day.You will take ownership of conducting research over a subject associated with Social Media data (billions of images and texts). Your results will help improve our products and could yield to publishing a paper. Depending on your profile and preferences, here are some examples of research subjects you might be working on:Explore Function Calling Agents with constraints on DSL and specific schemas generation tasks.Explore Large Language Models training to perform advanced data enrichments constrained to a user-defined scope and objective on text, image or multimodal.Explore multi-task Computer Vision with a single backbone (Large Vision Model) with adapters.Enhance RAG components and LLMs evaluation systems."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Machine Learning Engineer - Research Internship",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Meltwater",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-07",
        "company_data": {
            "sector": "IT / Digital, Marketing / Communication, Digital",
            "company_size": "2200",
            "creation_date": "2001",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "477 M",
            "proportion_female": "49",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalability"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "ml"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/meltwater/jobs/machine-learning-engineer-research-internship_paris_MELTW_jazNM9a?q=9535b0189e8e7cf32ba6058db50630c7&o=8c446284-90b8-4901-8849-6b93af78a568",
        "description": "Descriptif du posteMeltwater’s Consumer Intelligence AI Team is looking for a ML Research Intern who will be contributing on developing new innovative Natural Language Processing or Computer Vision features relying on the literature’s state of the art. Those features are meant to be integrated in our Consumer Intelligence platform meaning that your work will be used by our customers.We are looking for someone with a creative, proactive, collaborative, and innovation focused mindset. You will work alongside a team of passionate engineers driven by enthusiasm for new technologies and excitement about making the difference for customers using AI.Our team is organized over 3 objectives : innovation, research and production.Innovation: We leverage our AI expertise to constantly imagine new business oriented features to enhance our products.Research: To implement our algorithms, we need to stay up-to-date to the latest breakthroughs over the Machine Learning world as well as the latest frameworks.Production: We make a point of designing and developing our algorithms in a software engineering fashion. Scalability is our goal. The models that we develop are running over billions of documents (text or image) per day.You will take ownership of conducting research over a subject associated with Social Media data (billions of images and texts). Your results will help improve our products and could yield to publishing a paper. Depending on your profile and preferences, here are some examples of research subjects you might be working on:Explore Function Calling Agents with constraints on DSL and specific schemas generation tasks.Explore Large Language Models training to perform advanced data enrichments constrained to a user-defined scope and objective on text, image or multimodal.Explore multi-task Computer Vision with a single backbone (Large Vision Model) with adapters.Enhance RAG components and LLMs evaluation systems."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager Socle Data",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": "> 10",
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/engineering-manager-socle-data_nanterre?q=9535b0189e8e7cf32ba6058db50630c7&o=a7bdb6f4-fa50-4e9c-a8e2-3df7c50d2b57",
        "description": "Descriptif du posteLe contexte et l’environnementEn tant qu’Engineering Manager Socle Data (F/H), vous intégrerez la Data Factory au sein du Data Office d’AXA France. Vous reportez directement au Head of Data Factory.La Data Factory a pour mission de développer, maintenir et faire évoluer les socles technologiques Data, BI & IA (plateformes Big Data, BI, …) permettant à AXA France de stocker, gérer et valoriser son patrimoine de données. Elle définit ainsi une vision « produit » des plateformes data, au plus proche des usages et des utilisateurs, et pilote leur trajectoire d’évolution en adéquation avec les besoins et les tendances du marché. Notre Data Factory porte également les activités relatives à l’ingénierie des données au sein d’AXA France, et est en charge de gérer de bout en bout les pipelines de données comprenant la collecte, la préparation, l’intégration et la mise à disposition des produits de données auprès des Data Analysts et Data Scientists. La Data Factory garantit en outre le maintien de la plateforme en conditions opérationnelles et de sécurité.Vous allez en tant que ’Engineering Manager Socles Data (F/H),  contribuer au programme NADiA de transformation par la Data et l’IA d’AXA France en portant l’offre de service de la plateforme data.Vous ferez appliquer localement les pratiques de son métier et aurez également un rôle de facilitatrice/facilitateur du Delivery, notamment dans la prise en charge des obstacles que vos équipes ne peuvent pas traiter à leurs niveaux et dans la priorisation de leurs activités.Votre rôle et vos missions·       Participer à la définition de la stratégie data en définissant notamment la roadmap d’évolution de la plateforme data et en la mettant en œuvre. Monter et animer à cet effet les partenariats stratégiques adéquats.·       Porter l’offre de service auprès des utilisateurs.·       Anticiper les risques liés à la hausse de la criticité des systèmes applicatifs de plateforme et proposer un plan d'actions avec des solutions correctrices.·       Piloter le delivery, le staffing, et l'animation des compétences de l’équipe « Socle ». ·       Rechercher la meilleure efficacité de delivery technique des socles toute en renforçant la qualité de service. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager Socle Data",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "AXA",
        "location": "Nanterre",
        "remote": "Télétravail fréquent",
        "experience": "> 10",
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Banque, Assurance, FinTech / InsurTech",
            "company_size": "21889",
            "creation_date": "1985",
            "address": null,
            "average_age_of_employees": "43",
            "turnover_in_millions": null,
            "proportion_female": "54",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/axa/jobs/engineering-manager-socle-data_nanterre?q=9535b0189e8e7cf32ba6058db50630c7&o=a7bdb6f4-fa50-4e9c-a8e2-3df7c50d2b57",
        "description": "Descriptif du posteLe contexte et l’environnementEn tant qu’Engineering Manager Socle Data (F/H), vous intégrerez la Data Factory au sein du Data Office d’AXA France. Vous reportez directement au Head of Data Factory.La Data Factory a pour mission de développer, maintenir et faire évoluer les socles technologiques Data, BI & IA (plateformes Big Data, BI, …) permettant à AXA France de stocker, gérer et valoriser son patrimoine de données. Elle définit ainsi une vision « produit » des plateformes data, au plus proche des usages et des utilisateurs, et pilote leur trajectoire d’évolution en adéquation avec les besoins et les tendances du marché. Notre Data Factory porte également les activités relatives à l’ingénierie des données au sein d’AXA France, et est en charge de gérer de bout en bout les pipelines de données comprenant la collecte, la préparation, l’intégration et la mise à disposition des produits de données auprès des Data Analysts et Data Scientists. La Data Factory garantit en outre le maintien de la plateforme en conditions opérationnelles et de sécurité.Vous allez en tant que ’Engineering Manager Socles Data (F/H),  contribuer au programme NADiA de transformation par la Data et l’IA d’AXA France en portant l’offre de service de la plateforme data.Vous ferez appliquer localement les pratiques de son métier et aurez également un rôle de facilitatrice/facilitateur du Delivery, notamment dans la prise en charge des obstacles que vos équipes ne peuvent pas traiter à leurs niveaux et dans la priorisation de leurs activités.Votre rôle et vos missions·       Participer à la définition de la stratégie data en définissant notamment la roadmap d’évolution de la plateforme data et en la mettant en œuvre. Monter et animer à cet effet les partenariats stratégiques adéquats.·       Porter l’offre de service auprès des utilisateurs.·       Anticiper les risques liés à la hausse de la criticité des systèmes applicatifs de plateforme et proposer un plan d'actions avec des solutions correctrices.·       Piloter le delivery, le staffing, et l'animation des compétences de l’équipe « Socle ». ·       Rechercher la meilleure efficacité de delivery technique des socles toute en renforçant la qualité de service. Nous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.Nous choisir, c’est bénéficier par exemple :D’un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l’intéressement, la possibilité d’acquérir des actions AXA, ou encore des solutions d’épargne avantageuses ;D’un cadre de travail flexible jusqu’à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l’achat d’un écran ou fauteuil ergonomique ;D’une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d’absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;De la possibilité de s’engager pour une cause qui vous tient à cœur grâce à nos associations telles que AXA Atout Cœur, AXA Compétences Solidaires ou encore AXA Prévention ;Et bien plus encore ! Perspectives de développement des compétences et de carrières immenses, CE, conciergerie, offres privilèges, soutien en cas d’épreuve personnelle…On s’arrête là, la liste est longue "
    },
    {
        "source": "welcometothejungle",
        "job_title": "DevOps Engineer AWS Confirmé·e",
        "contract_type": "CDI",
        "salary": "47K à 55K €",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.participation"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                ":aws,"
            ],
            "DevTools": [
                "gitlab",
                "gitlab,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "d’ansible",
                "kubernetes"
            ],
            "InfrastructureAsCode": [
                "terraform,"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes"
            ],
            "Collaboration": null,
            "Other": [
                "devops,",
                "mle/mlops",
                "cloud,",
                "cloud",
                "cloud",
                "cloud",
                "ci/cd",
                "ci/cd,"
            ],
            "EnSoftSkils": [
                "résilience.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/devops-engineer-confirme-e_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=ef171c33-9871-475e-9488-dfb0879c70d7",
        "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.En tant qu’Ingénieur DevOps, tu joues un rôle clé dans la conception et l’optimisation des infrastructures cloud, tout en veillant à la sécurité, la performance et la résilience des solutions mises en place.A cet effet, tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Conception, déploiement et maintien d’une infrastructure cloud AWS en tenant compte des impératifs de sécurité, conformité, performance et résilience.Collaboration avec l’équipe sur la définition de l’architecture d’infrastructure pour des solutions cloud et conteneurisées.Automatisation et optimisation des processus d’infrastructure à l’aide d’Ansible et de scripts en Python.Participation à la migration d’infrastructures monolithiques vers des modèles de conteneurisation à l’aide de Kubernetes (EKS, on-premise).Développement et maintien de pipelines CI/CD autonomes à l’aide de GitLab pour permettre aux équipes de développement de gérer de façon autonome leurs opérations.Renforcement et maintien d’un modèle de surveillance robuste pour assurer une traçabilité complète des actions et des performances (99,9% de disponibilité).Apport d’expertise sur les meilleures pratiques pour la mise en œuvre d’infrastructures cloud sécurisées et performantes.Optimisation des versions et gestion de l’évolution continue des standards d’infrastructure.Stack :AWS, Terraform, Gitlab, pipelines CI/CD, SAP S/4 Hana."
    },
    {
        "source": "welcometothejungle",
        "job_title": "DevOps Engineer AWS Confirmé·e",
        "contract_type": "CDI",
        "salary": "47K à 55K €",
        "company": "JAKALA FRANCE SAS",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Digital Marketing / Data Marketing, Big Data, E-commerce",
            "company_size": "150",
            "creation_date": "2000",
            "address": null,
            "average_age_of_employees": "31",
            "turnover_in_millions": "15",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python.participation"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "aws",
                ":aws,"
            ],
            "DevTools": [
                "gitlab",
                "gitlab,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "d’ansible",
                "kubernetes"
            ],
            "InfrastructureAsCode": [
                "terraform,"
            ],
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": [
                "kubernetes"
            ],
            "Collaboration": null,
            "Other": [
                "devops,",
                "mle/mlops",
                "cloud,",
                "cloud",
                "cloud",
                "cloud",
                "ci/cd",
                "ci/cd,"
            ],
            "EnSoftSkils": [
                "résilience.collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/devops-engineer-confirme-e_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=ef171c33-9871-475e-9488-dfb0879c70d7",
        "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.En tant qu’Ingénieur DevOps, tu joues un rôle clé dans la conception et l’optimisation des infrastructures cloud, tout en veillant à la sécurité, la performance et la résilience des solutions mises en place.A cet effet, tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Conception, déploiement et maintien d’une infrastructure cloud AWS en tenant compte des impératifs de sécurité, conformité, performance et résilience.Collaboration avec l’équipe sur la définition de l’architecture d’infrastructure pour des solutions cloud et conteneurisées.Automatisation et optimisation des processus d’infrastructure à l’aide d’Ansible et de scripts en Python.Participation à la migration d’infrastructures monolithiques vers des modèles de conteneurisation à l’aide de Kubernetes (EKS, on-premise).Développement et maintien de pipelines CI/CD autonomes à l’aide de GitLab pour permettre aux équipes de développement de gérer de façon autonome leurs opérations.Renforcement et maintien d’un modèle de surveillance robuste pour assurer une traçabilité complète des actions et des performances (99,9% de disponibilité).Apport d’expertise sur les meilleures pratiques pour la mise en œuvre d’infrastructures cloud sécurisées et performantes.Optimisation des versions et gestion de l’évolution continue des standards d’infrastructure.Stack :AWS, Terraform, Gitlab, pipelines CI/CD, SAP S/4 Hana."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Analyst M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams,",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-analyst-m-f_bruxelles?q=9535b0189e8e7cf32ba6058db50630c7&o=9d92491e-281d-4adb-9a12-412fb4f02a6c",
        "description": "Descriptif du posteWhat will be your tasks with us ?You will work in Agile mode and you will support our client on their challenges related to Data and analysis.You will be working in the following areas:•   Business case study with business teams, understanding of business requirements•   Design of Data solutions•   Analysis of customer data and processes in order to study their valuation•   Elaboration of Data Analysis solutions•   Support Data Scientists & Data Engineers on deployment of AI applications•   Creation of dashboards & visualization solutions in order to bring business teams valuable & dynamic insights•   Support your customers in the use of the applications you developed•   Ensure a technological watch in order to propose innovations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Analyst M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams,",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-analyst-m-f_bruxelles?q=9535b0189e8e7cf32ba6058db50630c7&o=9d92491e-281d-4adb-9a12-412fb4f02a6c",
        "description": "Descriptif du posteWhat will be your tasks with us ?You will work in Agile mode and you will support our client on their challenges related to Data and analysis.You will be working in the following areas:•   Business case study with business teams, understanding of business requirements•   Design of Data solutions•   Analysis of customer data and processes in order to study their valuation•   Elaboration of Data Analysis solutions•   Support Data Scientists & Data Engineers on deployment of AI applications•   Creation of dashboards & visualization solutions in order to bring business teams valuable & dynamic insights•   Support your customers in the use of the applications you developed•   Ensure a technological watch in order to propose innovations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e) Cloud Data Azure",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "KPC",
        "location": "Saint-Herblain",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-17",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Big Data",
            "company_size": "450",
            "creation_date": "2010",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "50 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain_KC_xVkgQpA?q=9535b0189e8e7cf32ba6058db50630c7&o=62a29273-c974-418d-9629-ea3931011b53",
        "description": "Descriptif du posteVous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .Vos principales missions :Identifier et challenger les besoins métier de nos clients ;Veiller à la satisfaction client et la bonne communication avec les autres services ;Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;Concevoir et développer les architectures Data sous Azure ;Sourcer les données pertinentes et les collecter ;Tester les architectures et les développements ;Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;Contribuer à l analyse et préparer les données ;Déployer la solution  dans les environnements adéquats ;Effectuer une veille technologique sur les azure Data."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e) Cloud Data Azure",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "KPC",
        "location": "Saint-Herblain",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-17",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Big Data",
            "company_size": "450",
            "creation_date": "2010",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "50 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain_KC_xVkgQpA?q=9535b0189e8e7cf32ba6058db50630c7&o=62a29273-c974-418d-9629-ea3931011b53",
        "description": "Descriptif du posteVous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .Vos principales missions :Identifier et challenger les besoins métier de nos clients ;Veiller à la satisfaction client et la bonne communication avec les autres services ;Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;Concevoir et développer les architectures Data sous Azure ;Sourcer les données pertinentes et les collecter ;Tester les architectures et les développements ;Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;Contribuer à l analyse et préparer les données ;Déployer la solution  dans les environnements adéquats ;Effectuer une veille technologique sur les azure Data."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e) Cloud Data Azure",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "KPC",
        "location": "Saint-Herblain",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-17",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Big Data",
            "company_size": "450",
            "creation_date": "2010",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "50 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain?q=9535b0189e8e7cf32ba6058db50630c7&o=c58004c4-593c-4239-93a8-7564ba4b6607",
        "description": "Descriptif du posteVous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .Vos principales missions :Identifier et challenger les besoins métier de nos clients ;Veiller à la satisfaction client et la bonne communication avec les autres services ;Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;Concevoir et développer les architectures Data sous Azure ;Sourcer les données pertinentes et les collecter ;Tester les architectures et les développements ;Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;Contribuer à l analyse et préparer les données ;Déployer la solution  dans les environnements adéquats ;Effectuer une veille technologique sur les azure Data."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e) Cloud Data Azure",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "KPC",
        "location": "Saint-Herblain",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-17",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Big Data",
            "company_size": "450",
            "creation_date": "2010",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "50 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": [
                "azure,",
                "azure",
                "azure"
            ],
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "communication",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/kp-consulting/jobs/consultant-cloud-data-azure_saint-herblain?q=9535b0189e8e7cf32ba6058db50630c7&o=c58004c4-593c-4239-93a8-7564ba4b6607",
        "description": "Descriptif du posteVous avez une expérience en développement stratégique et vous êtes passionné par les nouvelles technologies et la mise en place de solutions applicatives ?Vous aimez aider les clients et partager vos connaissances ? Analyser et comprendre les besoins des utilisateurs en termes de collecte, stockage, valorisation de la donnée, mise en œuvre, teste puis déploiement ? Cette opportunité est sûrement faite pour vous !Au sein de notre agence nantaise, votre rôle sera de créer et faire évoluer des applications hébergées dans le cloud Azure, répondant aux besoins de nos clients. Pour cela vous réalisez et mettez en place des solutions applicatives sur mesure dans une démarche agile .Vos principales missions :Identifier et challenger les besoins métier de nos clients ;Veiller à la satisfaction client et la bonne communication avec les autres services ;Assurer une veille technologique permanente et à l’évolution des bonnes pratiques KPC ;Concevoir et développer les architectures Data sous Azure ;Sourcer les données pertinentes et les collecter ;Tester les architectures et les développements ;Vérifier la cohérence fonctionnelle des données en collaboration avec les métiers ;Réaliser les composants logiciels, les assembler, les mettre à disposition pour mise en production, s assurer de leur comportement et leur pertinence dans le temps ;Contribuer à l analyse et préparer les données ;Déployer la solution  dans les environnements adéquats ;Effectuer une veille technologique sur les azure Data."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e)s Stagiaires en Data & Analytics et Innovation - Secteur financier (H/F)",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "EY",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-12",
        "company_data": {
            "sector": "Stratégie, Audit, Transaction Services, Digital, Finance",
            "company_size": "7000",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "45 Milliards",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digitale",
                "digital,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultants-stagiaires-en-data-analytics-et-innovation-secteur-financier-h-f_paris_EY_GmeN9o7?q=9535b0189e8e7cf32ba6058db50630c7&o=13c23ef4-391f-4a55-98b3-0bf2e9d4691c",
        "description": "Descriptif du posteAu sein du département FSO (Financial Services Office), plus de 1000 collaborateurs en France combinent leurs expertises métiers, fonctionnelles et technologiques, afin de répondre efficacement aux besoins de nos clients en gestion d’actifs, banque ou assurance. Dans un contexte en perpétuel changement et hautement réglementé, nous apportons ainsi à nos clients des conseils pointus et de haut niveau pour les aider à gérer les incertitudes et les opportunités de ce secteurDans le cadre du développement en forte croissance de son activité Digital Enterprise Transformation, leader du marché de la transformation digitale end to end et de l’innovation dans le secteur financier (Banque, Assurance, Prévoyance, Gestion d’actifs), EY recherche des Consultants Juniors ayant une expérience dans le domaine de la Data.L’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, machine learning, NLP, architecture, , analyse quantitative, , big data, data science, algorithmique, , intelligence artificielle, , …) .Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel.Nous recherchons des profils polyvalents intéressés par l’ensemble des métiers de la data : Data Scientist, Data Engineer Consultant(e) BI pour rejoindre notre équipe d’experts Data, passionnés en charge de déployer des solutions d’IA et d’analyse des données de pointe, au sein d’un cabinet de conseil mondial de premier plan.Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à travailler sur des missions de conseil de différentes natures :Cadrage et analyse fonctionnelle de projets de transformation, de data analytics ou de data scienceAccompagnement au pilotage, à la coordination et à la gestion de projets dataDéfinition de stratégie en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)Conception et mise en œuvre de solutions d’IA depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisationConception et mise en place de solutions NLP, machine learning, deep learning…Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…Cartographie des processus de transformation de donnéesEtudes et choix de solutions et de plateformes big data, analytics…Veille sur l’évolution des méthodes, des pratiques, des outils…"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant(e)s Stagiaires en Data & Analytics et Innovation - Secteur financier (H/F)",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "EY",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-12",
        "company_data": {
            "sector": "Stratégie, Audit, Transaction Services, Digital, Finance",
            "company_size": "7000",
            "creation_date": null,
            "address": null,
            "average_age_of_employees": "30",
            "turnover_in_millions": "45 Milliards",
            "proportion_female": "50",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digitale",
                "digital,"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultants-stagiaires-en-data-analytics-et-innovation-secteur-financier-h-f_paris_EY_GmeN9o7?q=9535b0189e8e7cf32ba6058db50630c7&o=13c23ef4-391f-4a55-98b3-0bf2e9d4691c",
        "description": "Descriptif du posteAu sein du département FSO (Financial Services Office), plus de 1000 collaborateurs en France combinent leurs expertises métiers, fonctionnelles et technologiques, afin de répondre efficacement aux besoins de nos clients en gestion d’actifs, banque ou assurance. Dans un contexte en perpétuel changement et hautement réglementé, nous apportons ainsi à nos clients des conseils pointus et de haut niveau pour les aider à gérer les incertitudes et les opportunités de ce secteurDans le cadre du développement en forte croissance de son activité Digital Enterprise Transformation, leader du marché de la transformation digitale end to end et de l’innovation dans le secteur financier (Banque, Assurance, Prévoyance, Gestion d’actifs), EY recherche des Consultants Juniors ayant une expérience dans le domaine de la Data.L’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, machine learning, NLP, architecture, , analyse quantitative, , big data, data science, algorithmique, , intelligence artificielle, , …) .Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel.Nous recherchons des profils polyvalents intéressés par l’ensemble des métiers de la data : Data Scientist, Data Engineer Consultant(e) BI pour rejoindre notre équipe d’experts Data, passionnés en charge de déployer des solutions d’IA et d’analyse des données de pointe, au sein d’un cabinet de conseil mondial de premier plan.Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à travailler sur des missions de conseil de différentes natures :Cadrage et analyse fonctionnelle de projets de transformation, de data analytics ou de data scienceAccompagnement au pilotage, à la coordination et à la gestion de projets dataDéfinition de stratégie en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)Conception et mise en œuvre de solutions d’IA depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisationConception et mise en place de solutions NLP, machine learning, deep learning…Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…Cartographie des processus de transformation de donnéesEtudes et choix de solutions et de plateformes big data, analytics…Veille sur l’évolution des méthodes, des pratiques, des outils…"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant Senior/Manager - Data Gouvernance - Ile-De-France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria Next",
        "location": "Courbevoie",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Transformation",
            "company_size": "4000",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud."
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria-next/jobs/consultant-senior-manager-data-gouvernance-ile-de-france_courbevoie?q=9535b0189e8e7cf32ba6058db50630c7&o=eba5580e-acf3-4575-92e1-1d4218d1026f",
        "description": "Descriptif du posteL'équipe Au sein de notre Cabinet Sopra Steria NEXT, rejoignez le Centre d'Expertise Digital (CED) composé aujourd'hui de 160 Consultants, Directeurs et Partner sur l'ensemble de nos spécialités.Environnement de travail Le CED intervient en transverse sur l'ensemble des secteurs d'activité et combine une approche conseil de haut niveau en stratégie IT et expertises de pointes, notamment autour de l'architecture, la data et le cloud. Notre management de proximité est basé sur le savoir-faire, un gage pour vous de monter en compétences sur des missions à haute valeur ajoutée dans un environnement stimulant et avec le bon niveau d'encadrement.La missionDéfinir une feuille de route de stratégie de donnéesCadrer et mettre en oeuvre la gouvernance des donnéesOptimiser l'organisation, les méthodes et les processus DataParticiper à l'audit de l'existant Data (usages, données, capacités)Contribuer à la mise en oeuvre de cas d'usages des donnéesPiloter nos consultants data et métiers dans leurs missions clients- En interne, participer à la définition des offres et à leur rédactionParticiper au développement commercial et à la rédaction de propositions d'accompagnementPrise en charge du développement d'un vertical selon votre background (banque, retail, santé, défense et sécurité)Contribuer au développement de l'équipe par la mise en place d'un recrutement ambitieux et cohérent avec l'ADN de la tribu actuelleContribuer au rayonnement de nos activités au travers d'articles et d'événementsSuivre les missions internes des consultants de la tribu (KM, Assets)Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missionsDes nouveaux locaux inspirants et un environnement de travail agréable certifié Great Place To work à la Défense et dans plusieurs grandes villes de France.Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptationUn accompagnement individualisé avec un mentor que vous choisissezDes opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemblePlusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria AcademyDes parcours pour accélérer la progression et la promotion des femmes dans l’entreprise tous les niveauxLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi »#LI-HYBRID  #PFEmployeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Consultant Senior/Manager - Data Gouvernance - Ile-De-France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria Next",
        "location": "Courbevoie",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Transformation",
            "company_size": "4000",
            "creation_date": "2019",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud."
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria-next/jobs/consultant-senior-manager-data-gouvernance-ile-de-france_courbevoie?q=9535b0189e8e7cf32ba6058db50630c7&o=eba5580e-acf3-4575-92e1-1d4218d1026f",
        "description": "Descriptif du posteL'équipe Au sein de notre Cabinet Sopra Steria NEXT, rejoignez le Centre d'Expertise Digital (CED) composé aujourd'hui de 160 Consultants, Directeurs et Partner sur l'ensemble de nos spécialités.Environnement de travail Le CED intervient en transverse sur l'ensemble des secteurs d'activité et combine une approche conseil de haut niveau en stratégie IT et expertises de pointes, notamment autour de l'architecture, la data et le cloud. Notre management de proximité est basé sur le savoir-faire, un gage pour vous de monter en compétences sur des missions à haute valeur ajoutée dans un environnement stimulant et avec le bon niveau d'encadrement.La missionDéfinir une feuille de route de stratégie de donnéesCadrer et mettre en oeuvre la gouvernance des donnéesOptimiser l'organisation, les méthodes et les processus DataParticiper à l'audit de l'existant Data (usages, données, capacités)Contribuer à la mise en oeuvre de cas d'usages des donnéesPiloter nos consultants data et métiers dans leurs missions clients- En interne, participer à la définition des offres et à leur rédactionParticiper au développement commercial et à la rédaction de propositions d'accompagnementPrise en charge du développement d'un vertical selon votre background (banque, retail, santé, défense et sécurité)Contribuer au développement de l'équipe par la mise en place d'un recrutement ambitieux et cohérent avec l'ADN de la tribu actuelleContribuer au rayonnement de nos activités au travers d'articles et d'événementsSuivre les missions internes des consultants de la tribu (KM, Assets)Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missionsDes nouveaux locaux inspirants et un environnement de travail agréable certifié Great Place To work à la Défense et dans plusieurs grandes villes de France.Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptationUn accompagnement individualisé avec un mentor que vous choisissezDes opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemblePlusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria AcademyDes parcours pour accélérer la progression et la promotion des femmes dans l’entreprise tous les niveauxLa possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi »#LI-HYBRID  #PFEmployeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements> "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist expérimenté(e) - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CAPGEMINI INVENT",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail fréquent",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Digital, AdTech  / MarTech, Accompagnement d'entreprises",
            "company_size": "2100",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "22,5 milliards €",
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini-invent/jobs/data-scientist-experimente-nlp-llm-paris_issy-les-moulineaux?q=9535b0189e8e7cf32ba6058db50630c7&o=de2f9b66-59f4-4c10-bd25-c3e39989393d",
        "description": "Descriptif du posteVos missionsChez Capgemini Invent, notre vision est de placer l’innovation au cœur des stratégies d’entreprise grâce à la Data Science. Au sein de Capgemini Invent vous rejoignez une communauté de spécialistes de la data qui a pour mission d’accélérer la transformation de nos clients par la valorisation de la donnée et la mise en place de solutions innovantes utilisant notamment l’IA. Nous adressons l’ensemble des secteurs, de l’industrie aux secteurs financiers en passant par secteur public et la santé. En intégrant une des expertises de notre équipe – Data Science LLM/NLP, Computer Vision, Time Series, Optimisation, Trusted AI, Ontologie & Knowledge graph – relevez les défis data de nos clients, de l’idéation à l’industrialisation. Vous piloterez des projets techniques, gérerez une équipe projet et garantirez la réussite de missions variées auprès de nos clients. Quelques exemples de responsabilités : Piloter l’implémentation de plusieurs cas d’usage IA en mode agile au sein d’une Data Factory, dès la phase d’idéation jusqu’au déploiement en production et de monitoring Contribuer à l’établissement de la stratégie et de la feuille de route GenAI, en apportant votre connaissance de l’état de l’art du domaine Encadrer le développement et le déploiement d’un assistant financier pour faciliter l’analyse de milliers d’informations en temps réel Gérer une mission d’audit en anticipant ainsi la prise en compte des différentes les exigences de l’AI Act Identifier les axes de recherche prioritaires pour notre Lab R&I"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist expérimenté(e) - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CAPGEMINI INVENT",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail fréquent",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Digital, AdTech  / MarTech, Accompagnement d'entreprises",
            "company_size": "2100",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "22,5 milliards €",
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini-invent/jobs/data-scientist-experimente-nlp-llm-paris_issy-les-moulineaux?q=9535b0189e8e7cf32ba6058db50630c7&o=de2f9b66-59f4-4c10-bd25-c3e39989393d",
        "description": "Descriptif du posteVos missionsChez Capgemini Invent, notre vision est de placer l’innovation au cœur des stratégies d’entreprise grâce à la Data Science. Au sein de Capgemini Invent vous rejoignez une communauté de spécialistes de la data qui a pour mission d’accélérer la transformation de nos clients par la valorisation de la donnée et la mise en place de solutions innovantes utilisant notamment l’IA. Nous adressons l’ensemble des secteurs, de l’industrie aux secteurs financiers en passant par secteur public et la santé. En intégrant une des expertises de notre équipe – Data Science LLM/NLP, Computer Vision, Time Series, Optimisation, Trusted AI, Ontologie & Knowledge graph – relevez les défis data de nos clients, de l’idéation à l’industrialisation. Vous piloterez des projets techniques, gérerez une équipe projet et garantirez la réussite de missions variées auprès de nos clients. Quelques exemples de responsabilités : Piloter l’implémentation de plusieurs cas d’usage IA en mode agile au sein d’une Data Factory, dès la phase d’idéation jusqu’au déploiement en production et de monitoring Contribuer à l’établissement de la stratégie et de la feuille de route GenAI, en apportant votre connaissance de l’état de l’art du domaine Encadrer le développement et le déploiement d’un assistant financier pour faciliter l’analyse de milliers d’informations en temps réel Gérer une mission d’audit en anticipant ainsi la prise en compte des différentes les exigences de l’AI Act Identifier les axes de recherche prioritaires pour notre Lab R&I"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist NLP & LLM - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CAPGEMINI INVENT",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Digital, AdTech  / MarTech, Accompagnement d'entreprises",
            "company_size": "2100",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "22,5 milliards €",
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini-invent/jobs/data-scientist-nlp-llm-paris_issy-les-moulineaux?q=9535b0189e8e7cf32ba6058db50630c7&o=5a7f12b0-66ab-4b78-9f87-03f0ba2eb325",
        "description": "Descriptif du posteChez Capgemini Invent, notre vision est de placer l’innovation au cœur des stratégies d’entreprise grâce à la Data Science. En Intégrant l’expertise NLP & LLM relevez les défis data de nos clients, de l’idéation à l’industrialisation. Vous piloterez des projets techniques, gérerez une équipe projet, et garantirez la réussite de missions variées auprès de nos clients. Quelques exemples de responsabilités : Piloter l’implémentation de plusieurs cas d’usage IA en mode agile au sein d’une Data Factory, dès la phase d’idéation jusqu’au déploiement en production et de monitoring Contribuer à l’établissement de la stratégie et de la feuille de route GenAI, en apportant votre connaissance de l’état de l’art du domaine Encadrer le développement et le déploiement d’un assistant financier pour faciliter l’analyse de milliers d’informations en temps réel Gérer une mission d’audit de LLM en anticipant ainsi la prise en compte des différentes les exigences de l’AI Act Identifier les axes de recherche prioritaires pour notre Lab’ R&D concernant les protocoles d’évaluation des système basés sur des LLMs"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist NLP & LLM - Paris",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CAPGEMINI INVENT",
        "location": "Issy-les-Moulineaux",
        "remote": "Télétravail fréquent",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Digital, AdTech  / MarTech, Accompagnement d'entreprises",
            "company_size": "2100",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": "22,5 milliards €",
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini-invent/jobs/data-scientist-nlp-llm-paris_issy-les-moulineaux?q=9535b0189e8e7cf32ba6058db50630c7&o=5a7f12b0-66ab-4b78-9f87-03f0ba2eb325",
        "description": "Descriptif du posteChez Capgemini Invent, notre vision est de placer l’innovation au cœur des stratégies d’entreprise grâce à la Data Science. En Intégrant l’expertise NLP & LLM relevez les défis data de nos clients, de l’idéation à l’industrialisation. Vous piloterez des projets techniques, gérerez une équipe projet, et garantirez la réussite de missions variées auprès de nos clients. Quelques exemples de responsabilités : Piloter l’implémentation de plusieurs cas d’usage IA en mode agile au sein d’une Data Factory, dès la phase d’idéation jusqu’au déploiement en production et de monitoring Contribuer à l’établissement de la stratégie et de la feuille de route GenAI, en apportant votre connaissance de l’état de l’art du domaine Encadrer le développement et le déploiement d’un assistant financier pour faciliter l’analyse de milliers d’informations en temps réel Gérer une mission d’audit de LLM en anticipant ainsi la prise en compte des différentes les exigences de l’AI Act Identifier les axes de recherche prioritaires pour notre Lab’ R&D concernant les protocoles d’évaluation des système basés sur des LLMs"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sales Engineer France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Tellent France",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "SaaS / Cloud Services",
            "company_size": "62",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "29",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.",
                "teams",
                "teams,",
                "teams.consultative",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "skills:communication:",
                "engcollaboration:",
                "organizations"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/javelo/jobs/sales-engineer-france_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=097242c2-4a86-4914-ab4b-f60038d81446",
        "description": "Descriptif du posteThis is a hybrid role, and priority will be given to the candidates who are able to work both from home and Paris office (2-3 times per week). Your mission As our Sales Engineer for Tellent France you will be driving our commercial success by helping our sales team increase their win rate. Your job is to manage the technology evaluation and validation stages of the sales process for Recruitee, KiwiHR and Javelo products. In other words: you are in charge of getting the “technical win”.To be successful in this role we are looking for someone who combines deep product knowledge with strong consultative selling skills and can articulate their ideas clearly to any audience, regardless of their level of expertise. About The Team You will be part of Tellent France’s New Business Sales team, reporting directly to our VP of Sales for France. Your peers will be the Account Executives for France. Besides, you will work closely together with our BDR, Customer Success and Product teams. 12-month journey In the first 3 months, you’ll focus on learning everything about Recruitee, Javelo and KiwiHR: understanding the products, the technical framework of our software, the target markets, our customers, their pains, the impact they are looking for in our solutions. You will craft state-of-the-art demo pitches for each product, obsessing over each word and how we present each part of our products. After 6 months, you’ll help the sales team in discovering, articulating, and demonstrating our Tellent solutions to deliver on specific customer requirements and desired business outcomes. You will collect a library of customer use cases to illustrate how our solutions already help over 1.000 customers in France and ensure that your demos are more a customer storytelling moment rather than an explanation of features. After 12 months, you will have contributed to a substantial increase of our win rate thanks to your impactful demo preparation and delivery skills. You will be an essential part of the French commercial team and everyone will enjoy working with you. What You’ll DoYou will be helping our prospects understand the value of our products by configuring tailor-made environments, doing demo’s, and answering technical questions and RFP’s.Craft best-in-class demo scripts focused on customer stories and the impact we help our customers achieve.Partner with Sales, Legal and Finance to strategise on deal strategy & priorities and provide support for specific prospects, customers and partners.Partner with Product, Marketing and Customer Success teams to provide feedback to improve products, services and value messaging based on field experiences and feedback.Requirements:What you’ll bring to the teamTechnical skills:Product knowledge: develop deep ATS and HRIS understanding, familiarity with API & integrations, data migrationSolution engineering: understand customer pain points & impact, design tailored solutions, understand compliance requirementsData fluency: understand analytics, reporting, KPIs of HR and TA teams, ability to articulate ROI of ATS and HRIS solutionsTechnical troubleshooting: ability to address technical queries or implementation questionsInterpersonal skills:Communication: strong presentation & storytelling skills, fluency in FR and ENGCollaboration: ability to work closely with the Account Executives, providing technical support during sales cycles; cross-functional coordination with Customer Success and Implementation teams.Consultative selling: capacity to position oneself as a trusted advisor, understanding client goals and aligning them with product benefits. Skills to navigate complex buying cycles with multiple stakeholders in mid-sized companies (50–2,500 employees).Experience:3+ years working experience within a similar role (Sales Engineer, Pre-Sales, Solution Consultant), in a mid-market contextB2B SaaS experience is mandatoryHR Tech experience is a big plus, especially ATS or HRISFluency in French and EnglishWhy Tellent 💜Type of contract - Permanent contract (cadre) 💼Salary Package range between 63K et 70K (uncapped bonus !) 💸Offices located in the heart of Paris, near Pigalle, in the 9th district🗼Flexible remote work policy 🏠Alan Blue Healthcare plan ❤️‍🩹50% Pass Navigo reimbursed 🚅34 paid holidays per year + 2 wellbeing days in 20241 sophrology session per month 🧘Subscription plan to Mokacare to take care of yourself 💆International environment 🌍Tellent, a premier Talent Management Suite, enables People teams to improve the full employee lifecycle with a cutting-edge Applicant Tracking System, Human Resources Information System, and Performance Management Software – all in one place.With 300+ talented employees operating from six global locations, we've empowered over 7,000 organizations across 100+ countries with our leading HR tech solutions – Recruitee, KiwiHR, and Javelo. We have a growing network of over 300 partners, all committed to one vision: guiding all People leaders to create a better world of work.Have we caught your attention? ⚡️If you’d like to be part of this incredible journey, please apply directly - we're looking forward to speaking to you!Tellent is an Equal Opportunity Employer. We celebrate diversity and welcome applications from underrepresented groups and encourage people of all backgrounds to apply. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, neurodiversity, or status as an individual with a disability."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sales Engineer France",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Tellent France",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 2",
        "education_level": null,
        "publication_date": "2024-12-02",
        "company_data": {
            "sector": "SaaS / Cloud Services",
            "company_size": "62",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "29",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.",
                "teams",
                "teams,",
                "teams.consultative",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "skills:communication:",
                "engcollaboration:",
                "organizations"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/javelo/jobs/sales-engineer-france_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=097242c2-4a86-4914-ab4b-f60038d81446",
        "description": "Descriptif du posteThis is a hybrid role, and priority will be given to the candidates who are able to work both from home and Paris office (2-3 times per week). Your mission As our Sales Engineer for Tellent France you will be driving our commercial success by helping our sales team increase their win rate. Your job is to manage the technology evaluation and validation stages of the sales process for Recruitee, KiwiHR and Javelo products. In other words: you are in charge of getting the “technical win”.To be successful in this role we are looking for someone who combines deep product knowledge with strong consultative selling skills and can articulate their ideas clearly to any audience, regardless of their level of expertise. About The Team You will be part of Tellent France’s New Business Sales team, reporting directly to our VP of Sales for France. Your peers will be the Account Executives for France. Besides, you will work closely together with our BDR, Customer Success and Product teams. 12-month journey In the first 3 months, you’ll focus on learning everything about Recruitee, Javelo and KiwiHR: understanding the products, the technical framework of our software, the target markets, our customers, their pains, the impact they are looking for in our solutions. You will craft state-of-the-art demo pitches for each product, obsessing over each word and how we present each part of our products. After 6 months, you’ll help the sales team in discovering, articulating, and demonstrating our Tellent solutions to deliver on specific customer requirements and desired business outcomes. You will collect a library of customer use cases to illustrate how our solutions already help over 1.000 customers in France and ensure that your demos are more a customer storytelling moment rather than an explanation of features. After 12 months, you will have contributed to a substantial increase of our win rate thanks to your impactful demo preparation and delivery skills. You will be an essential part of the French commercial team and everyone will enjoy working with you. What You’ll DoYou will be helping our prospects understand the value of our products by configuring tailor-made environments, doing demo’s, and answering technical questions and RFP’s.Craft best-in-class demo scripts focused on customer stories and the impact we help our customers achieve.Partner with Sales, Legal and Finance to strategise on deal strategy & priorities and provide support for specific prospects, customers and partners.Partner with Product, Marketing and Customer Success teams to provide feedback to improve products, services and value messaging based on field experiences and feedback.Requirements:What you’ll bring to the teamTechnical skills:Product knowledge: develop deep ATS and HRIS understanding, familiarity with API & integrations, data migrationSolution engineering: understand customer pain points & impact, design tailored solutions, understand compliance requirementsData fluency: understand analytics, reporting, KPIs of HR and TA teams, ability to articulate ROI of ATS and HRIS solutionsTechnical troubleshooting: ability to address technical queries or implementation questionsInterpersonal skills:Communication: strong presentation & storytelling skills, fluency in FR and ENGCollaboration: ability to work closely with the Account Executives, providing technical support during sales cycles; cross-functional coordination with Customer Success and Implementation teams.Consultative selling: capacity to position oneself as a trusted advisor, understanding client goals and aligning them with product benefits. Skills to navigate complex buying cycles with multiple stakeholders in mid-sized companies (50–2,500 employees).Experience:3+ years working experience within a similar role (Sales Engineer, Pre-Sales, Solution Consultant), in a mid-market contextB2B SaaS experience is mandatoryHR Tech experience is a big plus, especially ATS or HRISFluency in French and EnglishWhy Tellent 💜Type of contract - Permanent contract (cadre) 💼Salary Package range between 63K et 70K (uncapped bonus !) 💸Offices located in the heart of Paris, near Pigalle, in the 9th district🗼Flexible remote work policy 🏠Alan Blue Healthcare plan ❤️‍🩹50% Pass Navigo reimbursed 🚅34 paid holidays per year + 2 wellbeing days in 20241 sophrology session per month 🧘Subscription plan to Mokacare to take care of yourself 💆International environment 🌍Tellent, a premier Talent Management Suite, enables People teams to improve the full employee lifecycle with a cutting-edge Applicant Tracking System, Human Resources Information System, and Performance Management Software – all in one place.With 300+ talented employees operating from six global locations, we've empowered over 7,000 organizations across 100+ countries with our leading HR tech solutions – Recruitee, KiwiHR, and Javelo. We have a growing network of over 300 partners, all committed to one vision: guiding all People leaders to create a better world of work.Have we caught your attention? ⚡️If you’d like to be part of this incredible journey, please apply directly - we're looking forward to speaking to you!Tellent is an Equal Opportunity Employer. We celebrate diversity and welcome applications from underrepresented groups and encourage people of all backgrounds to apply. We do not discriminate based upon race, religion, color, national origin, gender (including pregnancy, childbirth, or related medical conditions), sexual orientation, gender identity, gender expression, age, neurodiversity, or status as an individual with a disability."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Joko",
        "location": "Paris, Barcelona",
        "remote": "Télétravail total",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Application mobile, Intelligence artificielle / Machine Learning, FinTech / InsurTech",
            "company_size": "60",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams!",
                "teams",
                "teams",
                "teams,",
                "teams",
                "teams.reporting"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/joko/jobs/data-analyst_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=44526c19-4769-4cc7-a55f-2c9cda09f974",
        "description": "Descriptif du posteThis position is remote-friendly.Our Data teamThe Data team at Joko is turning mountains of data into actionable insights for all the teams! The Data team is part of our Operations department led by Quentin, our COO, and our mission is to empower the company to make informed decisions.More specifically, the team’s responsibilities are:Data for Business: We create top-notch reports and tools, making it easy for teams to dive into data and excel in their decision-making.Help our stakeholders with the best data stack: We load and transform data, automate reports, and continuously improve our data stack. This allows teams to use valuable insights built on robust and scalable foundations.Spread the data culture: At Joko, we have a strong engineering and tech culture across all teams, making it an ideal environment for our Data team to have a significant impact. We provide support and training on data tools to our stakeholders, and by closely collaborating with them, we ensure that our solutions align perfectly with their operational needs.What you will doAs a Data Analyst, you will have a cross-functional role and collaborate closely with teams to understand our data and develop insights.Deep-dive analyses: You will explore and analyse data to uncover trends, patterns, and potential issues that will help in the decision-making processes across all teams.Reporting and Data Visualization: You will participate in creating content, such as dashboards and charts, using our data visualization tool. You will be involved in defining the report’s content and constructing dashboards and charts to effectively communicate data-driven findings to stakeholders.Data loading and transformation: You will be involved in loading and transforming the data as we have a “full stack” approach in Data at Joko. Of course, you will get some help on Data Engineering parts but you will be involved in the entire lifecycle of our data.Interactions with stakeholders: You will work hand-in-hand with them to understand their needs, collect their feedback, and also evangelize data usage to help them make smarter choices.Continuous Learning and Improvement: As “never stop learning” is one of our values, you will grow along the way and learn how to use analytical methods and the different tools that we use (and will use) in our data stack."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Joko",
        "location": "Paris, Barcelona",
        "remote": "Télétravail total",
        "experience": null,
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "Application mobile, Intelligence artificielle / Machine Learning, FinTech / InsurTech",
            "company_size": "60",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": "48",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalable"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams!",
                "teams",
                "teams",
                "teams,",
                "teams",
                "teams.reporting"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/joko/jobs/data-analyst_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=44526c19-4769-4cc7-a55f-2c9cda09f974",
        "description": "Descriptif du posteThis position is remote-friendly.Our Data teamThe Data team at Joko is turning mountains of data into actionable insights for all the teams! The Data team is part of our Operations department led by Quentin, our COO, and our mission is to empower the company to make informed decisions.More specifically, the team’s responsibilities are:Data for Business: We create top-notch reports and tools, making it easy for teams to dive into data and excel in their decision-making.Help our stakeholders with the best data stack: We load and transform data, automate reports, and continuously improve our data stack. This allows teams to use valuable insights built on robust and scalable foundations.Spread the data culture: At Joko, we have a strong engineering and tech culture across all teams, making it an ideal environment for our Data team to have a significant impact. We provide support and training on data tools to our stakeholders, and by closely collaborating with them, we ensure that our solutions align perfectly with their operational needs.What you will doAs a Data Analyst, you will have a cross-functional role and collaborate closely with teams to understand our data and develop insights.Deep-dive analyses: You will explore and analyse data to uncover trends, patterns, and potential issues that will help in the decision-making processes across all teams.Reporting and Data Visualization: You will participate in creating content, such as dashboards and charts, using our data visualization tool. You will be involved in defining the report’s content and constructing dashboards and charts to effectively communicate data-driven findings to stakeholders.Data loading and transformation: You will be involved in loading and transforming the data as we have a “full stack” approach in Data at Joko. Of course, you will get some help on Data Engineering parts but you will be involved in the entire lifecycle of our data.Interactions with stakeholders: You will work hand-in-hand with them to understand their needs, collect their feedback, and also evangelize data usage to help them make smarter choices.Continuous Learning and Improvement: As “never stop learning” is one of our values, you will grow along the way and learn how to use analytical methods and the different tools that we use (and will use) in our data stack."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Principal Solutions Engineer",
        "contract_type": "CDI",
        "salary": "120K à 160K $",
        "company": "Dfns",
        "location": "New York",
        "remote": "Télétravail total",
        "experience": "> 7",
        "education_level": "Bac +3",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Blockchain, Cybersécurité, Finance",
            "company_size": "25",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": null,
            "proportion_female": "15",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "adaptability,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-solutions-engineer?q=9535b0189e8e7cf32ba6058db50630c7&o=366143be-c792-4153-a0e7-b98ae09d2f2a",
        "description": "Descriptif du posteJoin a team of exceptional leaders (CEO, CPO, CTO) and skilled experts (Software Engineers, Head of Sales) to build the leading blockchain wallet infrastructure for the next financial era. We’re seeking a driven and resourceful Principal Solutions Engineer with expertise in technical architecture, client-facing solutions, APIs, fintech and blockchains. This role requires attention to detail, adaptability, and the ability to perform under pressure with limited resources. As a Principal Solutions Engineer, you will combine technical expertise with sales skills to design, deliver, and present tailored solutions for fintechs and financial institutions. You’ll collaborate with clients and internal teams to define requirements, ensure successful integrations, and enhance technical documentation to industry-leading standards. With a deep understanding of blockchain wallet functionality and underlying technical foundations, you will provide solutions addressing client needs and guiding technical experts, from engineers to CTOs."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Principal Solutions Engineer",
        "contract_type": "CDI",
        "salary": "120K à 160K $",
        "company": "Dfns",
        "location": "New York",
        "remote": "Télétravail total",
        "experience": "> 7",
        "education_level": "Bac +3",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Blockchain, Cybersécurité, Finance",
            "company_size": "25",
            "creation_date": "2020",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": null,
            "proportion_female": "15",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "adaptability,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-solutions-engineer?q=9535b0189e8e7cf32ba6058db50630c7&o=366143be-c792-4153-a0e7-b98ae09d2f2a",
        "description": "Descriptif du posteJoin a team of exceptional leaders (CEO, CPO, CTO) and skilled experts (Software Engineers, Head of Sales) to build the leading blockchain wallet infrastructure for the next financial era. We’re seeking a driven and resourceful Principal Solutions Engineer with expertise in technical architecture, client-facing solutions, APIs, fintech and blockchains. This role requires attention to detail, adaptability, and the ability to perform under pressure with limited resources. As a Principal Solutions Engineer, you will combine technical expertise with sales skills to design, deliver, and present tailored solutions for fintechs and financial institutions. You’ll collaborate with clients and internal teams to define requirements, ensure successful integrations, and enhance technical documentation to industry-leading standards. With a deep understanding of blockchain wallet functionality and underlying technical foundations, you will provide solutions addressing client needs and guiding technical experts, from engineers to CTOs."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teamsanalysis"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-scientist_bruxelles?q=9535b0189e8e7cf32ba6058db50630c7&o=c976ba08-06cb-4c4f-b346-8e22adf55233",
        "description": "Descriptif du posteWhat will be your tasks with us ?You will work in Agile mode and you will support our client on their challenges related to Data and production.You will be working in the following areas:Business case study with business teamsAnalysis of customer data and processes in order to study their valuationElaboration of Data Science solutionsGoing into production with Data EngineersCreation of POC, model developmentEnsure a technological watch in order to propose innovations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Data Scientist M/F",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "LittleBigCode",
        "location": "Brussels",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-06",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "79",
            "creation_date": "2018",
            "address": null,
            "average_age_of_employees": "28",
            "turnover_in_millions": "5,5",
            "proportion_female": "31",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teamsanalysis"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/littlebigcode/jobs/data-scientist_bruxelles?q=9535b0189e8e7cf32ba6058db50630c7&o=c976ba08-06cb-4c4f-b346-8e22adf55233",
        "description": "Descriptif du posteWhat will be your tasks with us ?You will work in Agile mode and you will support our client on their challenges related to Data and production.You will be working in the following areas:Business case study with business teamsAnalysis of customer data and processes in order to study their valuationElaboration of Data Science solutionsGoing into production with Data EngineersCreation of POC, model developmentEnsure a technological watch in order to propose innovations"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Manager - Engineering & Construction – Strategy & Consulting – F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Accenture France",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-20",
        "company_data": {
            "sector": "IT / Digital, Digital",
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                ":digitalisation",
                "digitalisation",
                "digitaux",
                "digitales",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/accenture-france/jobs/manager-engineering-construction-strategy-consulting-f-h_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=94edb1ee-93fa-42fa-a981-2e305f5b68fc",
        "description": "Descriptif du posteImaginez, transformez et impactez le monde positivement : venez vivre au cœur du changement en tant que Manager Engineering & construction.  Vos principales missions :Digitalisation des opérations & chantiers : Vous assisterez nos clients à définir leurs plans de transformation et digitalisation des opérations et métiers afin d’améliorer la performance des chantiers, optimiser les fonctions transverses / supports grâce à des leviers digitaux (AI, GenAI, IoT, Analytics, Augmented Reality, BIM, PLM, …)Transition environnementale : Vous accompagnerez nos clients dans la définition de leur stratégie et l’exécution de leurs engagements de transition environnementale (scope 1/2/3) en:Construisant le pilotage des indicateurs environnementaux (eg. CSRD),Identifiant les leviers d’optimisation de consommation d’énergie, de l’eau et déchetIntégrant l’impact carbone dans les processus de design des architectures (sustainable by Design)Evaluant le potentiel lié à l’économie circulaire, etc.Analysant les performances environnementales des fournisseursOperating Model : Vous assisterez les directions générales pour définir et mettre en place les nouveaux modèles d’organisations pour faire face aux enjeux induits par les changements technologiques et sociétaux : mises en place d’organisations digitales types « Digital Factory / AI Hub», centres de services partagés, identification des capabilités nécessaires pour répondre aux nouveaux enjeux, etc.Développement commercial : Vous développerez notre activité auprès de nos grands comptes français et européens, sur tout ou partie de notre offre de serviceGestion d’une équipe de consultant(e)s chez un/des client(s)Un chef de projet vous accompagne dès votre arrivée et vous intégrez notre équipe Industry, Mobility et Travel (IMT) au sein des équipes Strategy & Consulting.Vous construisez une carrière agile, grâce à la formation, aux certifications et aux feedbacks reçus pour chacune de vos réalisations. Nos équipes apprennent chaque jour avec les meilleurs experts en France et à l’international. Vous évoluez dans un environnement de travail flexible qui vise à favoriser l’équilibre entre vie professionnelle et vie personnelle : le télétravail donne la possibilité d’adapter son rythme professionnel en fonction des actualités de l’équipe et du projet.Nous vous proposons de vivre l’expérience du changement auprès de nos équipes, rejoignez Accenture.#LI-EU"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Manager - Engineering & Construction – Strategy & Consulting – F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Accenture France",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-20",
        "company_data": {
            "sector": "IT / Digital, Digital",
            "company_size": null,
            "creation_date": null,
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                ":digitalisation",
                "digitalisation",
                "digitaux",
                "digitales",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chef"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/accenture-france/jobs/manager-engineering-construction-strategy-consulting-f-h_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=94edb1ee-93fa-42fa-a981-2e305f5b68fc",
        "description": "Descriptif du posteImaginez, transformez et impactez le monde positivement : venez vivre au cœur du changement en tant que Manager Engineering & construction.  Vos principales missions :Digitalisation des opérations & chantiers : Vous assisterez nos clients à définir leurs plans de transformation et digitalisation des opérations et métiers afin d’améliorer la performance des chantiers, optimiser les fonctions transverses / supports grâce à des leviers digitaux (AI, GenAI, IoT, Analytics, Augmented Reality, BIM, PLM, …)Transition environnementale : Vous accompagnerez nos clients dans la définition de leur stratégie et l’exécution de leurs engagements de transition environnementale (scope 1/2/3) en:Construisant le pilotage des indicateurs environnementaux (eg. CSRD),Identifiant les leviers d’optimisation de consommation d’énergie, de l’eau et déchetIntégrant l’impact carbone dans les processus de design des architectures (sustainable by Design)Evaluant le potentiel lié à l’économie circulaire, etc.Analysant les performances environnementales des fournisseursOperating Model : Vous assisterez les directions générales pour définir et mettre en place les nouveaux modèles d’organisations pour faire face aux enjeux induits par les changements technologiques et sociétaux : mises en place d’organisations digitales types « Digital Factory / AI Hub», centres de services partagés, identification des capabilités nécessaires pour répondre aux nouveaux enjeux, etc.Développement commercial : Vous développerez notre activité auprès de nos grands comptes français et européens, sur tout ou partie de notre offre de serviceGestion d’une équipe de consultant(e)s chez un/des client(s)Un chef de projet vous accompagne dès votre arrivée et vous intégrez notre équipe Industry, Mobility et Travel (IMT) au sein des équipes Strategy & Consulting.Vous construisez une carrière agile, grâce à la formation, aux certifications et aux feedbacks reçus pour chacune de vos réalisations. Nos équipes apprennent chaque jour avec les meilleurs experts en France et à l’international. Vous évoluez dans un environnement de travail flexible qui vise à favoriser l’équilibre entre vie professionnelle et vie personnelle : le télétravail donne la possibilité d’adapter son rythme professionnel en fonction des actualités de l’équipe et du projet.Nous vous proposons de vivre l’expérience du changement auprès de nos équipes, rejoignez Accenture.#LI-EU"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager",
        "contract_type": "CDI",
        "salary": "68K à 100K €",
        "company": "Payflows",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",
            "company_size": "25",
            "creation_date": "2022",
            "address": null,
            "average_age_of_employees": "29",
            "turnover_in_millions": null,
            "proportion_female": "25",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/payflows/jobs/engineering-manager_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=f3362911-6828-4b66-930e-9711e43fdca5",
        "description": "Descriptif du poste🌍 Our Vision & MissionAt Payflows, we’re on a mission to free finance teams from repetitive, low-value tasks so they can focus on strategic growth. Our all-in-one ERP platform powers banking connectivity, payments, AI-driven workflows, and more—enabling finance teams to truly thrive.🤝 Why Join Us?Join a team of builders who’ve been in the trenches at Airbnb, Luko, BNP Paribas, and Facebook. It’s intense and fast-paced, but you’ll see your fingerprint on a product that genuinely impacts customers. If that’s what you’re after, you’ll love it here.🚀 What You’ll DoAs an Engineering Manager, you’ll:⚙️ Guide & Inspire: Set the roadmap and help decide how we build systems that scale gracefully.🌱 Coach & Grow: Mentor engineers, provide meaningful feedback, and champion a culture of continuous learning.📅 Own Delivery: Collaborate with Product to plan and ship features. Adapt when priorities shift—because they will.🔥 Foster Quality & Autonomy: Uphold coding standards and best practices, and give your team the trust and freedom they need to innovate.🤩 What Makes You a Great Fit🗓️ 2+ years in engineering management.🛠️ Strong technical background: You can still talk shop on architecture and performance.🎯 Product-minded: You understand the impact of engineering decisions on real users.💪 Thrive under intensity: You’re energized by challenges and tight deadlines."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager",
        "contract_type": "CDI",
        "salary": "68K à 100K €",
        "company": "Payflows",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",
            "company_size": "25",
            "creation_date": "2022",
            "address": null,
            "average_age_of_employees": "29",
            "turnover_in_millions": null,
            "proportion_female": "25",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ricardo-france/jobs/engineering-manager-sophia-antipolis-france_valbonne?q=9535b0189e8e7cf32ba6058db50630c7&o=70c82c34-42bc-48bf-9a20-37646be27ec8",
        "description": null
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager",
        "contract_type": "CDI",
        "salary": "68K à 100K €",
        "company": "Payflows",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-10",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services",
            "company_size": "25",
            "creation_date": "2022",
            "address": null,
            "average_age_of_employees": "29",
            "turnover_in_millions": null,
            "proportion_female": "25",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ricardo-france/jobs/engineering-manager-sophia-antipolis-france_valbonne?q=9535b0189e8e7cf32ba6058db50630c7&o=70c82c34-42bc-48bf-9a20-37646be27ec8",
        "description": null
    },
    {
        "source": "welcometothejungle",
        "job_title": "Engineering Manager- Sophia Antipolis (France)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "SMG swiss marketplace group (ex Ricardo)",
        "location": "Valbonne",
        "remote": "Télétravail non autorisé",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-13",
        "company_data": {
            "sector": "E-commerce, Digital, SocialTech / GreenTech",
            "company_size": "31",
            "creation_date": "1999",
            "address": null,
            "average_age_of_employees": "38",
            "turnover_in_millions": "48M CHF (Ricardo)",
            "proportion_female": "20",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": [
                "seamless"
            ],
            "EnSoftSkils": [
                "communication,",
                "leadership",
                "collaboration,"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/ricardo-france/jobs/engineering-manager-sophia-antipolis-france_valbonne?q=9535b0189e8e7cf32ba6058db50630c7&o=70c82c34-42bc-48bf-9a20-37646be27ec8",
        "description": "Descriptif du posteCompany DescriptionWelcome to SMG Swiss Marketplace Group AGSMG Swiss Marketplace Group AG came together following the merger of Scout24 Switzerland and TX Markets (part of TX Group) in 2021. A union which included some of Switzerland’s most well-known leading marketplaces. We are a pioneering network of online marketplaces and a leading European digital company that simplifies people's lives with forward-looking products.Job DescriptionWhy work for General Marketplaces (GM)?Ricardo, tutti.ch & anibis.ch are services with a positive impact on the world. Reducing waste by giving unused items a new home is a cornerstone of sustainability. Today there are already over four million people using Ricardo, tutti & anibis but we are not done yet. We are working hard on making it easy for everyone to participate.We have modern tech-stack and interesting challenges ahead. We know that keeping up with technology is no easy feat, which is why we have dedicated training and conference budgets for every engineer.What you’ll doAs our Engineering Manager, you will play a pivotal role in ensuring the seamless operation of Chatty Chipmunks. Working in tandem with our Product Manager, you'll be responsible for fostering a cohesive team dynamic, fostering effective communication, and maintaining alignment within the team.You will have line management responsibility for the Chatty Chipmunks team. This will enable you to have your foot in both worlds, engineering leadership and product developmentYou will support them in building their careers, coaching them, and finding mentors when neededYou will participate in the engineering manager team, representing the needs of your engineers. We will rely on your insights for our teams processes, culture, and deliveryYou will be responsible for growing and developing the team by leading by example, creating team cohesion, encouraging mutual support and collaboration, promoting SMG valuesBe a motivating force in engineering. Positively contributing to our work environment is a big part of your mission. We want our processes, rituals, culture, and interactions to be net positive influences on our daily lives. This doesn’t just happen by chance and requires continued love, attention, and supportYou will be a process engineer and challenge our way of working every single day. Someone who has taken the step from trying to understand machines, to understanding people and how they work together. From designing algorithms for computers to designing processes for people "
    },
    {
        "source": "welcometothejungle",
        "job_title": "DataOps",
        "contract_type": "CDI",
        "salary": "50K à 60K €",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalabilité"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/dataops_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=146aa160-9eb3-46f0-ae1f-9fa97d70c102",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Data Ops (H/F). Rattaché(e) au Lead Infra, vos travaux d’innovation et de recherche en data engineering /ops permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Au cœur de la société, vous travaillerez au quotidien avec toutes les équipes impliquées (commercial, marketing, R&D, produit et finance) pour mener à bien vos missions.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Infra, vous aurez pour missions :Assurer la scalabilité de tous nos services utilisant la donnée afin de suivre une haute croissance de nos bases de données,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Travailler l’optimisation de nos services afin de les rendre moins couteux et plus efficace,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "DataOps",
        "contract_type": "CDI",
        "salary": "50K à 60K €",
        "company": "Lucky Cart",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 4",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, Grande distribution, SaaS / Cloud Services",
            "company_size": "63",
            "creation_date": "2011",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": null,
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "scalabilité"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "leadership,",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/lucky-cart/jobs/dataops_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=146aa160-9eb3-46f0-ae1f-9fa97d70c102",
        "description": "Descriptif du posteLa forte croissance que nous enregistrons et les projets de développement à l’international nous amènent à renforcer notre équipe data en recrutant un Data Ops (H/F). Rattaché(e) au Lead Infra, vos travaux d’innovation et de recherche en data engineering /ops permettront de faire évoluer les produits de Lucky Cart, d’évaluer au mieux leur performance et d’élargir la palette de services connexes.Au cœur de la société, vous travaillerez au quotidien avec toutes les équipes impliquées (commercial, marketing, R&D, produit et finance) pour mener à bien vos missions.Vos recherches pourront faire l’objet de publications, de présentation dans des séminaires ou des meetups et de dépôts de brevet.Votre leadership, votre ambition et votre engagement feront de vous une partie intégrante de la forte expansion de Lucky Cart en France et en Europe.Au cœur de la société, vous collaborerez au quotidien avec toutes les équipes impliquées (marketing, R&D, data et juridique) pour mener à bien vos missions.MISSIONSSous la responsabilité du Lead Infra, vous aurez pour missions :Assurer la scalabilité de tous nos services utilisant la donnée afin de suivre une haute croissance de nos bases de données,Assurer la fiabilité des pipelines de données, des processus ETL et de la transformation des données en réalisant et en mettant en œuvre des tests manuels et automatisés,Être force de proposition sur tous les sujets d’architecture et de modélisation,Travailler l’optimisation de nos services afin de les rendre moins couteux et plus efficace,Être force de proposition et prendre le lead sur des dispositifs innovants,Travailler en parfaite collaboration avec les autres fonctions au sein de la société (marketing, R&D, Sales, Produit),Assurer un reporting régulier de l’activité."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur BI Talend - Services Publics - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-05",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau.développer"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-bi-talend-services-publics-bordeaux_merignac?q=9535b0189e8e7cf32ba6058db50630c7&o=78246097-7d0e-4710-91d9-899dad1ff760",
        "description": "Descriptif du posteDans le cadre de votre poste et directement rattaché au vertical Services Publics, vous interviendrez auprès d’une équipe soudée et contribuerez activement à des projets stratégiques d’intégration de données.Vos missions :Participer aux ateliers fonctionnels avec les équipes métier pour comprendre leurs besoins et apporter des solutions adaptées.Animer et participer aux cérémonies agiles (daily, sprint, démonstrations) pour assurer une bonne coordination de l'équipe.Modéliser, traiter et charger les données dans l’entrepôt de données en utilisant Talend.Automatiser les différents workflows et optimiser les processus ETL sous Talend.Préparer les chaînes d'intégration continue pour assurer une mise en production fluide et sécurisée.Restituer les données de manière claire et interactive en utilisant des outils de datavisualisation tels que Power BI, Business Objects, Data Factory et Tableau.Développer des solutions sur mesure en Python pour répondre aux besoins spécifiques de l'équipe.Ce rôle nécessite une expertise en modélisation de données, traitement ETL, et restitution de données pour appuyer les prises de décisions de nos clients. Si vous avez l’esprit analytique, une bonne compréhension des métiers et êtes passionné par la data, ce poste est fait pour vous !Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur BI Talend - Services Publics - Bordeaux",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sopra Steria",
        "location": "Mérignac",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-05",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management",
            "company_size": "52000",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "5,8 Mds",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": [
                "tableau.développer"
            ],
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sopra-steria/jobs/ingenieur-bi-talend-services-publics-bordeaux_merignac?q=9535b0189e8e7cf32ba6058db50630c7&o=78246097-7d0e-4710-91d9-899dad1ff760",
        "description": "Descriptif du posteDans le cadre de votre poste et directement rattaché au vertical Services Publics, vous interviendrez auprès d’une équipe soudée et contribuerez activement à des projets stratégiques d’intégration de données.Vos missions :Participer aux ateliers fonctionnels avec les équipes métier pour comprendre leurs besoins et apporter des solutions adaptées.Animer et participer aux cérémonies agiles (daily, sprint, démonstrations) pour assurer une bonne coordination de l'équipe.Modéliser, traiter et charger les données dans l’entrepôt de données en utilisant Talend.Automatiser les différents workflows et optimiser les processus ETL sous Talend.Préparer les chaînes d'intégration continue pour assurer une mise en production fluide et sécurisée.Restituer les données de manière claire et interactive en utilisant des outils de datavisualisation tels que Power BI, Business Objects, Data Factory et Tableau.Développer des solutions sur mesure en Python pour répondre aux besoins spécifiques de l'équipe.Ce rôle nécessite une expertise en modélisation de données, traitement ETL, et restitution de données pour appuyer les prises de décisions de nos clients. Si vous avez l’esprit analytique, une bonne compréhension des métiers et êtes passionné par la data, ce poste est fait pour vous !Informations supplémentairesUn accord télétravail pour télétravailler jusqu’à 2 jours par semaine selon vos missions. Un package avantages intéressant : une mutuelle, un CSE, des titres restaurants, un accord d’intéressement, des primes vacances et cooptation.Un accompagnement individualisé avec un mentor.Des opportunités de carrières multiples : plus de 30 familles de métiers, autant de passerelles à imaginer ensemble.Plusieurs centaines de formations accessibles en toute autonomie depuis l’app mobile avec Sopra Steria Academy.La possibilité de s'engager auprès de notre fondation ou de notre partenaire « Vendredi ».L'opportunité de rejoindre le collectif Tech'Me UP (formations, conférences, veille, et bien plus encore…).Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Ingénieur.e R&D en IA Générative F/H",
        "contract_type": "Stage",
        "salary": "16,1K €",
        "company": "Groupe SII",
        "location": "Vélizy-Villacoublay",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-24",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": [
                "scikit-learn",
                "tensorflow,",
                "pytorch"
            ],
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/stage-ingenieur-e-r-d-en-ia-generative-f-h_velizy?q=9535b0189e8e7cf32ba6058db50630c7&o=0ddfd593-3417-45da-a36d-be7821f2497f",
        "description": "Descriptif du posteVous recherchez un stage stimulant dans la recherche et le développement ? Alors n’hésitez plus, ce stage est fait pour vous !SII recherche un(e) stagiair(e) pour rejoindre le pôle d’innovation IA/DATA de SII Research, dans l’équipe IA générative, situé à Vélizy. Nous nous engageons à faire progresser le domaine de l'intelligence artificielle en réalisant des avancées technologiques expérimentales dans de nombreux domaines tels que la cybersécurité, l’énergie, les assurances, l’aérospatial et la défense. Vous serez intégré à une communauté d’innovation dynamique d’une quinzaine de chercheurs pour vous accompagner dans votre apprentissage. Nous recherchons une personne motivée, ayant une forte appétence pour la Recherche et Développement (R&D) en entreprise, à l’aise en Deep Learning, spécialisée sur les technologies d’IA générative, idéalement sensibilisée aux LLMs.Objectif de la mission :Vous serez en charge de :    Effectuer un état de l’art conséquent afin de considérer le choix technique entre un fine-tunnig du LLM ou le recours à de la Retrieval Augmented Generation (RAG), puis démontrer la pertinence de la proposition    Améliorer les recherches dans l’IA Générative en analysant et optimisant les modèles déployés, notamment à travers la méthodologie MLOps    Collaborer avec les chercheurs en partageant les résultats et en intégrant les éléments trouvé dans un démonstrateur    Participer à la recherche en IA en contribuant à un article sur les résultats obtenus Profil recherché :  Vous êtes actuellement étudiant(e) ingénieur(e) en dernière année ou en master avec spécialité Data Science, vous recherchez un stage d’une durée de 6 mois ?  Vous avez des connaissances en langage de programmation python pour le Machine Learning et Deep Learning  Vous métrisez Scikit-Learn et au moins un des frameworks de Data Science tels que Tensorflow, Pytorch ou Transformers  Vous êtes à l’aise pour travailler en équipe et en autonomie et faites preuve de rigueur et de curiosité   Vous savez nouer des relations de qualité avec des interlocuteurs variés (R&D, clients...) Vous parlez un anglais courant et orienté rechercheCompétences supplémentaires :    Vous avez travaillé sur un projet en IA générative end-to-end  Vous avez déjà manipulé et êtes à l’aise sur la Big Data et l’intégration de nombreuses sources de données Vous avez une expérience sur le cloud appliqué à la Data Science ou sur un environnement GPU   Vous avez des compétences en développement Web"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage Ingénieur.e R&D en IA Générative F/H",
        "contract_type": "Stage",
        "salary": "16,1K €",
        "company": "Groupe SII",
        "location": "Vélizy-Villacoublay",
        "remote": "Télétravail non autorisé",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-24",
        "company_data": {
            "sector": "Logiciels, Intelligence artificielle / Machine Learning, IT / Digital",
            "company_size": "16000",
            "creation_date": "1979",
            "address": null,
            "average_age_of_employees": "34",
            "turnover_in_millions": "1 022.5 ",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": [
                "scikit-learn",
                "tensorflow,",
                "pytorch"
            ],
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops",
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sii/jobs/stage-ingenieur-e-r-d-en-ia-generative-f-h_velizy?q=9535b0189e8e7cf32ba6058db50630c7&o=0ddfd593-3417-45da-a36d-be7821f2497f",
        "description": "Descriptif du posteVous recherchez un stage stimulant dans la recherche et le développement ? Alors n’hésitez plus, ce stage est fait pour vous !SII recherche un(e) stagiair(e) pour rejoindre le pôle d’innovation IA/DATA de SII Research, dans l’équipe IA générative, situé à Vélizy. Nous nous engageons à faire progresser le domaine de l'intelligence artificielle en réalisant des avancées technologiques expérimentales dans de nombreux domaines tels que la cybersécurité, l’énergie, les assurances, l’aérospatial et la défense. Vous serez intégré à une communauté d’innovation dynamique d’une quinzaine de chercheurs pour vous accompagner dans votre apprentissage. Nous recherchons une personne motivée, ayant une forte appétence pour la Recherche et Développement (R&D) en entreprise, à l’aise en Deep Learning, spécialisée sur les technologies d’IA générative, idéalement sensibilisée aux LLMs.Objectif de la mission :Vous serez en charge de :    Effectuer un état de l’art conséquent afin de considérer le choix technique entre un fine-tunnig du LLM ou le recours à de la Retrieval Augmented Generation (RAG), puis démontrer la pertinence de la proposition    Améliorer les recherches dans l’IA Générative en analysant et optimisant les modèles déployés, notamment à travers la méthodologie MLOps    Collaborer avec les chercheurs en partageant les résultats et en intégrant les éléments trouvé dans un démonstrateur    Participer à la recherche en IA en contribuant à un article sur les résultats obtenus Profil recherché :  Vous êtes actuellement étudiant(e) ingénieur(e) en dernière année ou en master avec spécialité Data Science, vous recherchez un stage d’une durée de 6 mois ?  Vous avez des connaissances en langage de programmation python pour le Machine Learning et Deep Learning  Vous métrisez Scikit-Learn et au moins un des frameworks de Data Science tels que Tensorflow, Pytorch ou Transformers  Vous êtes à l’aise pour travailler en équipe et en autonomie et faites preuve de rigueur et de curiosité   Vous savez nouer des relations de qualité avec des interlocuteurs variés (R&D, clients...) Vous parlez un anglais courant et orienté rechercheCompétences supplémentaires :    Vous avez travaillé sur un projet en IA générative end-to-end  Vous avez déjà manipulé et êtes à l’aise sur la Big Data et l’intégration de nombreuses sources de données Vous avez une expérience sur le cloud appliqué à la Data Science ou sur un environnement GPU   Vous avez des compétences en développement Web"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert en Intelligence Artificielle",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "MP DATA",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 10",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "100",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams)"
            ],
            "Other": null,
            "EnSoftSkils": [
                "initiatives.identifier"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/expert-en-intelligence-artificielle_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=b3e192fd-dd42-47d6-88c4-99255cfd82e0",
        "description": "Descriptif du posteNous recherchons un Expert en Intelligence Artificielle passionné et expérimenté pour accompagner notre société dans l’exécution de sa feuille de route stratégique en IA. Vous jouerez un rôle clé dans la mise en œuvre de notre vision AI, en challengeant nos orientations stratégiques et en assurant le succès des projets prioritaires identifiés dans notre roadmap.Missions principalesChallenger la roadmap AI existanteAnalyser la feuille de route AI et les matrices de priorisation des cas d’usage.Apporter une perspective critique et des recommandations pour renforcer l’impact stratégique des initiatives.Identifier les opportunités d’optimisation ou de nouveaux cas d’usage alignés avec les objectifs de l’entreprise.Mise en œuvre de la stratégie Data et infrastructureCollaborer avec les équipes internes Infra, archi et data pour établir les bases d’une infrastructure Data solide et évolutive pour nos POC AI.Superviser la mise en place de pipelines de données, des outils de traitement et des architectures nécessaires aux projets IA.Assurer l’intégration des outils et des plateformes technologiques sélectionnés dans le cadre de la stratégie AI.Gouvernance et pilotage des projets pilotes (PoC)Superviser les Proofs of Concept pour expérimenter et valider les choix technologiques et organisationnels de la gouvernance AI.Assurer la coordination entre les parties prenantes internes (DSI, métiers, Data teams) et les partenaires externes.Évaluer les résultats des PoC et fournir des recommandations pour le passage à l’échelle (industrialisation).Accompagnement à la prise de décision stratégique (Make or Buy)Participer activement aux discussions stratégiques sur la matrice make or buy pour les solutions IA.Apporter une expertise pour évaluer les solutions externes et les capacités internes.Support opérationnel et accompagnement des équipesTransférer des compétences aux équipes internes pour garantir l’autonomie progressive dans la gestion des projets IA.Apporter un soutien technique sur la conception, l’entraînement, et le déploiement des modèles IA en production.Mettre en œuvre les bonnes pratiques en matière d’explicabilité, de robustesse et d’éthique des modèles IA.Veille technologique et innovationAssurer une veille active sur les technologies émergentes et les meilleures pratiques dans le domaine de l’IA et de la Data Science."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Expert en Intelligence Artificielle",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "MP DATA",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": "> 10",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-20",
        "company_data": {
            "sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data",
            "company_size": "100",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "27",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams)"
            ],
            "Other": null,
            "EnSoftSkils": [
                "initiatives.identifier"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/expert-en-intelligence-artificielle_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=b3e192fd-dd42-47d6-88c4-99255cfd82e0",
        "description": "Descriptif du posteNous recherchons un Expert en Intelligence Artificielle passionné et expérimenté pour accompagner notre société dans l’exécution de sa feuille de route stratégique en IA. Vous jouerez un rôle clé dans la mise en œuvre de notre vision AI, en challengeant nos orientations stratégiques et en assurant le succès des projets prioritaires identifiés dans notre roadmap.Missions principalesChallenger la roadmap AI existanteAnalyser la feuille de route AI et les matrices de priorisation des cas d’usage.Apporter une perspective critique et des recommandations pour renforcer l’impact stratégique des initiatives.Identifier les opportunités d’optimisation ou de nouveaux cas d’usage alignés avec les objectifs de l’entreprise.Mise en œuvre de la stratégie Data et infrastructureCollaborer avec les équipes internes Infra, archi et data pour établir les bases d’une infrastructure Data solide et évolutive pour nos POC AI.Superviser la mise en place de pipelines de données, des outils de traitement et des architectures nécessaires aux projets IA.Assurer l’intégration des outils et des plateformes technologiques sélectionnés dans le cadre de la stratégie AI.Gouvernance et pilotage des projets pilotes (PoC)Superviser les Proofs of Concept pour expérimenter et valider les choix technologiques et organisationnels de la gouvernance AI.Assurer la coordination entre les parties prenantes internes (DSI, métiers, Data teams) et les partenaires externes.Évaluer les résultats des PoC et fournir des recommandations pour le passage à l’échelle (industrialisation).Accompagnement à la prise de décision stratégique (Make or Buy)Participer activement aux discussions stratégiques sur la matrice make or buy pour les solutions IA.Apporter une expertise pour évaluer les solutions externes et les capacités internes.Support opérationnel et accompagnement des équipesTransférer des compétences aux équipes internes pour garantir l’autonomie progressive dans la gestion des projets IA.Apporter un soutien technique sur la conception, l’entraînement, et le déploiement des modèles IA en production.Mettre en œuvre les bonnes pratiques en matière d’explicabilité, de robustesse et d’éthique des modèles IA.Veille technologique et innovationAssurer une veille active sur les technologies émergentes et les meilleures pratiques dans le domaine de l’IA et de la Data Science."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur MLOps - Projet de Federated Learning (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Institut Imagine",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-16",
        "company_data": {
            "sector": "Pharmaceutique / Biotechnologique, Santé, ONG",
            "company_size": "550",
            "creation_date": "2014",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "30",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops"
            ],
            "EnSoftSkils": [
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/institut-imagine/jobs/ingenieur-mlops-projet-de-federated-learning-h-f_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=d983ae84-b45d-4ff7-a77f-2d8f448dd62e",
        "description": "Descriptif du posteLa plateforme data science de l'Institut Imagine recherche un Ingénieur MLOps spécialisé en Federated Learning pour rejoindre son équipe de data scientists. Vous travaillerez sur un projet innovant visant à développer des solutions de Federated Learning tout en assurant la confidentialité et la sécurité des données pour la recherche sur les maladies génétiques. Vous collaborerez étroitement avec des spécialistes en machine learning (traitement automatique du langage, Computer vision, Graph neural network), des médecins et des chercheurs en génétique, et l’équipe IT de l’Institut Imagine.https://www.institutimagine.org/fr/nicolas-garcelon-757Responsabilités :Développement et Maintenance : Développer, déployer et maintenir des modèles de Federated Learning pour les recherches en génétique en collaboration avec un spécialiste en machine learning ;Sécurité des Données : Mettre en place des mesures de sécurité robustes pour protéger les données sensibles et assurer la conformité avec les réglementations en matière de confidentialité des données (CNIL, RGPD, ISO etc.) ;Optimisation des Modèles : Collaborer avec les chercheurs et spécialistes en machine learning pour optimiser les modèles tout en minimisant les risques de fuite de données ;Documentation : Documenter et organiser les processus de mise en production des modèles de machine learning ;Coordination avec l'Équipe IT : Travailler en étroite collaboration avec l'équipe informatique qui maintiendra l'infrastructure nécessaire pour soutenir le déploiement et la maintenance des modèles de Federated Learning."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur MLOps - Projet de Federated Learning (H/F)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Institut Imagine",
        "location": "Paris",
        "remote": "Télétravail occasionnel",
        "experience": "> 3",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-16",
        "company_data": {
            "sector": "Pharmaceutique / Biotechnologique, Santé, ONG",
            "company_size": "550",
            "creation_date": "2014",
            "address": null,
            "average_age_of_employees": "35",
            "turnover_in_millions": "30",
            "proportion_female": "55",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "mlops"
            ],
            "EnSoftSkils": [
                "collaboration",
                "collaboration"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/institut-imagine/jobs/ingenieur-mlops-projet-de-federated-learning-h-f_paris?q=9535b0189e8e7cf32ba6058db50630c7&o=d983ae84-b45d-4ff7-a77f-2d8f448dd62e",
        "description": "Descriptif du posteLa plateforme data science de l'Institut Imagine recherche un Ingénieur MLOps spécialisé en Federated Learning pour rejoindre son équipe de data scientists. Vous travaillerez sur un projet innovant visant à développer des solutions de Federated Learning tout en assurant la confidentialité et la sécurité des données pour la recherche sur les maladies génétiques. Vous collaborerez étroitement avec des spécialistes en machine learning (traitement automatique du langage, Computer vision, Graph neural network), des médecins et des chercheurs en génétique, et l’équipe IT de l’Institut Imagine.https://www.institutimagine.org/fr/nicolas-garcelon-757Responsabilités :Développement et Maintenance : Développer, déployer et maintenir des modèles de Federated Learning pour les recherches en génétique en collaboration avec un spécialiste en machine learning ;Sécurité des Données : Mettre en place des mesures de sécurité robustes pour protéger les données sensibles et assurer la conformité avec les réglementations en matière de confidentialité des données (CNIL, RGPD, ISO etc.) ;Optimisation des Modèles : Collaborer avec les chercheurs et spécialistes en machine learning pour optimiser les modèles tout en minimisant les risques de fuite de données ;Documentation : Documenter et organiser les processus de mise en production des modèles de machine learning ;Coordination avec l'Équipe IT : Travailler en étroite collaboration avec l'équipe informatique qui maintiendra l'infrastructure nécessaire pour soutenir le déploiement et la maintenance des modèles de Federated Learning."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieure / Ingenieur de Production-Montpellier",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Capgemini",
        "location": "Montpellier",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Stratégie, Transformation",
            "company_size": "340000",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "22.5 Mds €",
            "proportion_female": "32",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini/jobs/ingenieure-ingenieur-de-production-montpellier_montpellier_CAPGE_Ry6e99e?q=9535b0189e8e7cf32ba6058db50630c7&o=04d76a9f-1e89-43d7-9390-a59a8d8cc9f6",
        "description": "Descriptif du posteVos missions :       Vous interviendrez pour un de nos clients stratégiques dans le secteur bancaire pour les activités suivantes :  Gérer l’administration des composants applicatifs et techniques Participer à la validation ou élaboration des Fiches de Supervision Métier, des contraintes d’ordonnancement propres à chaque application en fonction du cycle de fabrication Définir des règles d’exploitation de chaque composant à mettre en production, l’outillage à mettre en œuvre et les consignes de pilotage associées en fonction du cycle de fabrication Assurer le bon fonctionnement en termes d’incidents, problèmes et/ou changements Participer à la mise en œuvre des évolutions des SI Installer, maintenir et intégrer en recette permanente, pré-production et production des évolutions techniques et applicatives récurrentes Gérer des livraisons de matière respectant les contraintes de fonctionnement de l’exploitation ainsi que les engagements de services Participer à la VSR des mises en Production d’opérations non cataloguées.                     "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieure / Ingenieur de Production-Montpellier",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Capgemini",
        "location": "Montpellier",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-16",
        "company_data": {
            "sector": "IT / Digital, Organisation / Management, Stratégie, Transformation",
            "company_size": "340000",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": "22.5 Mds €",
            "proportion_female": "32",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/capgemini/jobs/ingenieure-ingenieur-de-production-montpellier_montpellier_CAPGE_Ry6e99e?q=9535b0189e8e7cf32ba6058db50630c7&o=04d76a9f-1e89-43d7-9390-a59a8d8cc9f6",
        "description": "Descriptif du posteVos missions :       Vous interviendrez pour un de nos clients stratégiques dans le secteur bancaire pour les activités suivantes :  Gérer l’administration des composants applicatifs et techniques Participer à la validation ou élaboration des Fiches de Supervision Métier, des contraintes d’ordonnancement propres à chaque application en fonction du cycle de fabrication Définir des règles d’exploitation de chaque composant à mettre en production, l’outillage à mettre en œuvre et les consignes de pilotage associées en fonction du cycle de fabrication Assurer le bon fonctionnement en termes d’incidents, problèmes et/ou changements Participer à la mise en œuvre des évolutions des SI Installer, maintenir et intégrer en recette permanente, pré-production et production des évolutions techniques et applicatives récurrentes Gérer des livraisons de matière respectant les contraintes de fonctionnement de l’exploitation ainsi que les engagements de services Participer à la VSR des mises en Production d’opérations non cataloguées.                     "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Référent(e) applicatif - H/F",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "France Travail DSI (Direction des Systèmes d'Information)",
        "location": "Pessac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Big Data, Administration publique, Recrutement",
            "company_size": "1600",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": "32",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/france-travail-dsi/jobs/referent-applicatif-h-f_pessac?q=9535b0189e8e7cf32ba6058db50630c7&o=9156254f-c1bd-43af-a82b-8bffb48f6d74",
        "description": "Descriptif du posteLes challenges à relever avec votre équipe 🚀Au sein de la Direction des Systèmes d'Information de France Travail, vous aurez pour mission d’accompagner les départements produits de la direction Pilotage et Support à l’Organisation, dans la définition des trajectoires d’évolutions des produits SI.La direction Pilotage et Support à l’Organisation assure la conception et le développement des produits transverses à la délivrance des services métiers.Piloter les projets SI, coordonner les équipes métiers et techniques, et suivre les plannings, budgets et ressources pour garantir leur bon déroulement.Participer à la conception de l’architecture des produits applicatifs et superviser leur intégration, en veillant à leur qualité, sécurité et performanceAnalyser les besoins métier avec les équipes et définir les évolutions des produits en alignant les priorités stratégiques.Proposer et suivre les trajectoires d’évolution des produits, en assurant leur intégration continue avec la stratégie de France Travail.Définir les exigences non fonctionnelles (sécurité, performance, etc.) pour garantir la conformité des produits aux standards.Contribuer à l’évolution de la démarche de conception, en intégrant des pratiques agiles et centrées sur l’utilisateur.Assurer le suivi et la qualité des livrables tout au long des phases de développement et de déploiement."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Référent(e) applicatif - H/F",
        "contract_type": "CDI",
        "salary": "45K à 55K €",
        "company": "France Travail DSI (Direction des Systèmes d'Information)",
        "location": "Pessac",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-15",
        "company_data": {
            "sector": "Big Data, Administration publique, Recrutement",
            "company_size": "1600",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": "32",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/france-travail-dsi/jobs/referent-applicatif-h-f_pessac?q=9535b0189e8e7cf32ba6058db50630c7&o=9156254f-c1bd-43af-a82b-8bffb48f6d74",
        "description": "Descriptif du posteLes challenges à relever avec votre équipe 🚀Au sein de la Direction des Systèmes d'Information de France Travail, vous aurez pour mission d’accompagner les départements produits de la direction Pilotage et Support à l’Organisation, dans la définition des trajectoires d’évolutions des produits SI.La direction Pilotage et Support à l’Organisation assure la conception et le développement des produits transverses à la délivrance des services métiers.Piloter les projets SI, coordonner les équipes métiers et techniques, et suivre les plannings, budgets et ressources pour garantir leur bon déroulement.Participer à la conception de l’architecture des produits applicatifs et superviser leur intégration, en veillant à leur qualité, sécurité et performanceAnalyser les besoins métier avec les équipes et définir les évolutions des produits en alignant les priorités stratégiques.Proposer et suivre les trajectoires d’évolution des produits, en assurant leur intégration continue avec la stratégie de France Travail.Définir les exigences non fonctionnelles (sécurité, performance, etc.) pour garantir la conformité des produits aux standards.Contribuer à l’évolution de la démarche de conception, en intégrant des pratiques agiles et centrées sur l’utilisateur.Assurer le suivi et la qualité des livrables tout au long des phases de développement et de déploiement."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte logiciel - Défense & Sécurité - Le Plessis Robinson",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CS",
        "location": "Le Plessis-Robinson",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale, Energie",
            "company_size": "2700",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "40",
            "turnover_in_millions": "300 000 000€",
            "proportion_female": "20",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "c/c++/java,",
                "qt/java",
                "c/c++/java,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "logiciellegit/revue"
            ],
            "OS": [
                "linuxlogiciels"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "code/devops/intégration"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cs-group/jobs/architecte-logiciel-defense-securite-le-plessis-robinson_le-plessis-robinson_CS_zr2zAKK?q=9535b0189e8e7cf32ba6058db50630c7&o=c26a8cbf-3eea-44cb-9cf3-c6283190bb3e",
        "description": "Descriptif du posteNous recrutons un/une Architecte logiciel pour renforcer notre Business Unit Défense & Sécurité au sein de l'agence Direction Technique qui accompagne la dynamique d'innovation du groupe. A ce titre, la DT prend en compte les besoins issus de réflexions projet ou marketing pour évaluer les impacts techniques de leur mise en œuvre. La DT définit les orientations technologiques et stratégiques de la BU et intervient à chaque étape de la vie des projets (internes ou externes) pour contribuer à l’application d’une politique technique. Elle met en valeur les compétences et la maitrise technologique au bénéfice des Business Lines. Vos missions : Représenter la direction technique auprès des équipes de développementContribuer aux architectures des logiciels développés au sein de la Business Unit ;Organiser des revues d’architectures logicielles et proposer des évolutions ;Participer à la définition du référentiel de développement logiciel ainsi qu’aux choix technologiques en fonction des besoins ;Contribuer à l’activité DevOps en apportant une expertise sur les règles de qualimétrie de code et autres métriques ;Contribuer activement aux synergies entre les différentes équipes de développement de la Business Unit ;Participation aux activités d’avant-vente lorsque le développement est une part importanteL'environnement technique :Langages C/C++/Java, IHM QT/Java FX/SwingSystèmes Majoritairement LinuxLogiciels utilisés dans des systèmes complexes de type C2Ingénierie et architecture logicielleGit/Revue de code/DevOps/Intégration Continue/AutomatisationInformations supplémentairesINFORMATIONS COMPLEMENTAIRESIntégrer l'Agence Direction Technique c’est aussi :Des formations dès votre arrivée & tout au long de votre carrière : la CS Academy et la Sopra Steria Academy vous propose des parcours de formations spécifiques aux métiers et à votre environnement (4400 jours de formation en 2023, 5700 jours de formation prévus sur 2024)Des espaces de travail collaboratifs modernes, lumineux, flexiblesDes facilités d’accès : lignes de bus depuis le centre-ville (transports en commun avec prise en charge à 50%), parking privé pour les automobilistes, les cyclistes et les motocyclistesDu télétravail, si le projet le permetUne mutuelle prenant en charge votre famille Un comité d’entreprise offrant des avantages culturels, sportifs et des prix sur vos hébergements et transports lors de vos vacancesUne prime vacances et de cooptationMais aussi… la promesse de se détendre entre midi et deux (babyfoot, piano, jeux, tables extérieures…).LA SUITE DES EVENEMENTS Si votre profil correspond, vous aurez un entretien technique avec un de nos Responsables opérationnels. Puis, vous rencontrerez Laura lors d’un entretien RH. Et nous nous engageons à vous faire un retour par téléphone :)#CSGROUP #hiring #architect #LI-Hybrid #LI-LM1Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte logiciel - Défense & Sécurité - Le Plessis Robinson",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CS",
        "location": "Le Plessis-Robinson",
        "remote": "Télétravail non renseigné",
        "experience": "> 5",
        "education_level": null,
        "publication_date": "2025-01-14",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale, Energie",
            "company_size": "2700",
            "creation_date": "1968",
            "address": null,
            "average_age_of_employees": "40",
            "turnover_in_millions": "300 000 000€",
            "proportion_female": "20",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "c/c++/java,",
                "qt/java",
                "c/c++/java,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "logiciellegit/revue"
            ],
            "OS": [
                "linuxlogiciels"
            ],
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "devops",
                "code/devops/intégration"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cs-group/jobs/architecte-logiciel-defense-securite-le-plessis-robinson_le-plessis-robinson_CS_zr2zAKK?q=9535b0189e8e7cf32ba6058db50630c7&o=c26a8cbf-3eea-44cb-9cf3-c6283190bb3e",
        "description": "Descriptif du posteNous recrutons un/une Architecte logiciel pour renforcer notre Business Unit Défense & Sécurité au sein de l'agence Direction Technique qui accompagne la dynamique d'innovation du groupe. A ce titre, la DT prend en compte les besoins issus de réflexions projet ou marketing pour évaluer les impacts techniques de leur mise en œuvre. La DT définit les orientations technologiques et stratégiques de la BU et intervient à chaque étape de la vie des projets (internes ou externes) pour contribuer à l’application d’une politique technique. Elle met en valeur les compétences et la maitrise technologique au bénéfice des Business Lines. Vos missions : Représenter la direction technique auprès des équipes de développementContribuer aux architectures des logiciels développés au sein de la Business Unit ;Organiser des revues d’architectures logicielles et proposer des évolutions ;Participer à la définition du référentiel de développement logiciel ainsi qu’aux choix technologiques en fonction des besoins ;Contribuer à l’activité DevOps en apportant une expertise sur les règles de qualimétrie de code et autres métriques ;Contribuer activement aux synergies entre les différentes équipes de développement de la Business Unit ;Participation aux activités d’avant-vente lorsque le développement est une part importanteL'environnement technique :Langages C/C++/Java, IHM QT/Java FX/SwingSystèmes Majoritairement LinuxLogiciels utilisés dans des systèmes complexes de type C2Ingénierie et architecture logicielleGit/Revue de code/DevOps/Intégration Continue/AutomatisationInformations supplémentairesINFORMATIONS COMPLEMENTAIRESIntégrer l'Agence Direction Technique c’est aussi :Des formations dès votre arrivée & tout au long de votre carrière : la CS Academy et la Sopra Steria Academy vous propose des parcours de formations spécifiques aux métiers et à votre environnement (4400 jours de formation en 2023, 5700 jours de formation prévus sur 2024)Des espaces de travail collaboratifs modernes, lumineux, flexiblesDes facilités d’accès : lignes de bus depuis le centre-ville (transports en commun avec prise en charge à 50%), parking privé pour les automobilistes, les cyclistes et les motocyclistesDu télétravail, si le projet le permetUne mutuelle prenant en charge votre famille Un comité d’entreprise offrant des avantages culturels, sportifs et des prix sur vos hébergements et transports lors de vos vacancesUne prime vacances et de cooptationMais aussi… la promesse de se détendre entre midi et deux (babyfoot, piano, jeux, tables extérieures…).LA SUITE DES EVENEMENTS Si votre profil correspond, vous aurez un entretien technique avec un de nos Responsables opérationnels. Puis, vous rencontrerez Laura lors d’un entretien RH. Et nous nous engageons à vous faire un retour par téléphone :)#CSGROUP #hiring #architect #LI-Hybrid #LI-LM1Employeur inclusif et engagé, notre société œuvre chaque jour pour lutter contre toute forme de discrimination et favoriser un environnement de travail respectueux. C’est pourquoi, attachés à la mixité et à la diversité, nous encourageons toutes les candidatures et tous les profils.https://www.soprasteria.fr/nous-connaitre/nos-engagements "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Implementation Internship - Monitoring Tool",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Opensee",
        "location": "Puteaux",
        "remote": "Télétravail non autorisé",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "IT / Digital, FinTech / InsurTech, Big Data",
            "company_size": "80",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                ":python",
                "python-based",
                "python,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/opensee/jobs/implementation-internship-monitoring-tool_puteaux?q=9535b0189e8e7cf32ba6058db50630c7&o=f3fa0aa8-924c-4580-a417-f85bc993cf76",
        "description": "Descriptif du posteWhat are you going to do ? You will join our dynamic team responsible for managing a critical client, a Tier 1 financial institution, for whom we provide a cutting-edge Market Risk aggregation platform.This platform is utilized daily by hundreds of Market Risk managers, executing hundreds of thousands of risk aggregation queries on terabytes of trading data.The primary objective of this internship is to enhance our monitoring capabilities to improve platform performance and, consequently, user experience. Keys internship responsibilities :Python tool development:Develop a Python-based tool to enhance the monitoring capabilities of our platformPre-Aggregated Cubes: Automate the creation of pre-aggregated cubes through a meticulous mathematical analysis of users queriesUser Usage Monitoring: Implement generic capabilities to monitor user usage patterns, including data queried, query timings, and user identitiesCollaborate with the team to integrate the tool into the existing platform infrastructureThoroughly document the tool’s functionalities and user guidelines to ensure smooth adoption and usageClient engagement:Work closely with your team and our client to understand their specific needs and tailor the tool to meet their requirementsShare the developed tool with other teams and clients to expand its utility and impact, fostering broader adoption and benefitKeywords: python, monitoring, implementation, client support, finance, big data"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Implementation Internship - Monitoring Tool",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Opensee",
        "location": "Puteaux",
        "remote": "Télétravail non autorisé",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-10",
        "company_data": {
            "sector": "IT / Digital, FinTech / InsurTech, Big Data",
            "company_size": "80",
            "creation_date": "2015",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                ":python",
                "python-based",
                "python,"
            ],
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/opensee/jobs/implementation-internship-monitoring-tool_puteaux?q=9535b0189e8e7cf32ba6058db50630c7&o=f3fa0aa8-924c-4580-a417-f85bc993cf76",
        "description": "Descriptif du posteWhat are you going to do ? You will join our dynamic team responsible for managing a critical client, a Tier 1 financial institution, for whom we provide a cutting-edge Market Risk aggregation platform.This platform is utilized daily by hundreds of Market Risk managers, executing hundreds of thousands of risk aggregation queries on terabytes of trading data.The primary objective of this internship is to enhance our monitoring capabilities to improve platform performance and, consequently, user experience. Keys internship responsibilities :Python tool development:Develop a Python-based tool to enhance the monitoring capabilities of our platformPre-Aggregated Cubes: Automate the creation of pre-aggregated cubes through a meticulous mathematical analysis of users queriesUser Usage Monitoring: Implement generic capabilities to monitor user usage patterns, including data queried, query timings, and user identitiesCollaborate with the team to integrate the tool into the existing platform infrastructureThoroughly document the tool’s functionalities and user guidelines to ensure smooth adoption and usageClient engagement:Work closely with your team and our client to understand their specific needs and tailor the tool to meet their requirementsShare the developed tool with other teams and clients to expand its utility and impact, fostering broader adoption and benefitKeywords: python, monitoring, implementation, client support, finance, big data"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieure DevOps Confirmée / Ingénieur DevOps confirmé LYON",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Lyon",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "jenkins,…)"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "ansible,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/ingenieure-devops-confirmee-ingenieur-devops-confirme-lyon_lyon_SOGET_5ZkXAqD?q=9535b0189e8e7cf32ba6058db50630c7&o=6f258e21-05a2-4b16-8822-1394d89e0390",
        "description": "Descriptif du poste      Votre mission… Une fois dans nos équipes ?   Description du profil :  Assure le déploiement d’applications, la réalisation de phases de test réalisées en amont du développement et la mise en place d’une surveillance de la qualité de la production. Activité principale :  Déploiement sur les différents environnements jusqu'à la mise en production Amélioration continue du niveau d'industrialisation/automatisation des déploiements (écriture de modules Ansible, de pipelines Jenkins,…) Développement et mise en place d’outils pour faciliter le quotidien des équipes du projet (supervision, testing, résilience, robustesse…) Résolution / Accompagnement à la résolution d’incidents de production  Activité secondaire :  Rédaction et maintien des documentations techniques Mise en œuvre des méthodes de modélisation des données et des traitements Animation de réunions          Nos engagements et priorités   Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.     À propos de Sogeti   Sogeti fait partie du groupe Capgemini et accompagne les organisations dans leur mise en œuvre de l'innovation, en tant que partenaire local à l'échelle mondiale. En combinant son agilité et sa rapidité Sogeti propose des solutions innovantes en testing, cloud et développement d'applications, toutes pilotées par l'IA, les données et l'automatisation. Plus d’informations sur Sogeti"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieure DevOps Confirmée / Ingénieur DevOps confirmé LYON",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Lyon",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-09",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "jenkins,…)"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "ansible,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": [
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/ingenieure-devops-confirmee-ingenieur-devops-confirme-lyon_lyon_SOGET_5ZkXAqD?q=9535b0189e8e7cf32ba6058db50630c7&o=6f258e21-05a2-4b16-8822-1394d89e0390",
        "description": "Descriptif du poste      Votre mission… Une fois dans nos équipes ?   Description du profil :  Assure le déploiement d’applications, la réalisation de phases de test réalisées en amont du développement et la mise en place d’une surveillance de la qualité de la production. Activité principale :  Déploiement sur les différents environnements jusqu'à la mise en production Amélioration continue du niveau d'industrialisation/automatisation des déploiements (écriture de modules Ansible, de pipelines Jenkins,…) Développement et mise en place d’outils pour faciliter le quotidien des équipes du projet (supervision, testing, résilience, robustesse…) Résolution / Accompagnement à la résolution d’incidents de production  Activité secondaire :  Rédaction et maintien des documentations techniques Mise en œuvre des méthodes de modélisation des données et des traitements Animation de réunions          Nos engagements et priorités   Le groupe Capgemini encourage une culture inclusive dans un cadre multiculturel et handi-accueillant. En nous rejoignant, vous intégrez un collectif qui valorise la diversité, développe le potentiel de ses talents, s’engage dans des initiatives solidaires avec ses partenaires, et se mobilise pour réduire son impact environnemental sur tous ses sites et auprès de ses clients.     À propos de Sogeti   Sogeti fait partie du groupe Capgemini et accompagne les organisations dans leur mise en œuvre de l'innovation, en tant que partenaire local à l'échelle mondiale. En combinant son agilité et sa rapidité Sogeti propose des solutions innovantes en testing, cloud et développement d'applications, toutes pilotées par l'IA, les données et l'automatisation. Plus d’informations sur Sogeti"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte applicatif et logiciel F/H",
        "contract_type": "CDI",
        "salary": "55K à 63K €",
        "company": "La Sécurité Sociale",
        "location": "Toulouse",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Santé, Administration publique, SocialTech / GreenTech",
            "company_size": "150000",
            "creation_date": "1945",
            "address": null,
            "average_age_of_employees": "45",
            "turnover_in_millions": null,
            "proportion_female": "80",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/securitesociale/jobs/architecte-applicatif-et-logiciel-f-h_toulouse_LSS_eQpd4gY?q=9535b0189e8e7cf32ba6058db50630c7&o=f1619452-bc64-4327-90c0-436f84a4e5d1",
        "description": "Descriptif du poste Mission/ActivitésLe secteur « Gestion des Comptes Entreprise » (GCE) a pour objectif d'intégrer les déclarations DSN et PASRAU relatives aux cotisations sociales des entreprises afin de permettre leur recouvrement. Ces déclarations sont également fiabilisées pour offrir aux partenaires de l'URSSAF des informations nécessaires à la gestion des droits de chaque salarié.Vous serez intégré·e à l'équipe « Gestion du Déclaratif » composée de chefs de projets, d'architectes solution, de référents techniques et de référents fonctionnels.Votre mission consiste à apporter votre expertise technique pour le choix des architectures et la mise en œuvre de solutions techniques en relation avec un réseau d'experts de la DSI.Vos missions :Vous participez à la conception d'architectures applicatives des systèmes d'information concernés et vous les documentez.Vous avez un rôle de conseil et d'encadrement des bonnes pratiques auprès des équipes projetVous identifiez les améliorations d'architecture applicative et de réduction de la dette technique qui pourraient donner lieu à un projet.Vous contribuez à la réception technique des projets réalisés au forfaitVous serez amené à définir/instruire les composants techniques des SI concernésVous coordonnez techniquement le projet avec tous les acteurs concernés (autres MOE, architecture d'entreprise, infrastructure, socle)Vous êtes force de proposition pour l'émergence de solutions techniques innovantes.  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte applicatif et logiciel F/H",
        "contract_type": "CDI",
        "salary": "55K à 63K €",
        "company": "La Sécurité Sociale",
        "location": "Toulouse",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Santé, Administration publique, SocialTech / GreenTech",
            "company_size": "150000",
            "creation_date": "1945",
            "address": null,
            "average_age_of_employees": "45",
            "turnover_in_millions": null,
            "proportion_female": "80",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "chefs"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/securitesociale/jobs/architecte-applicatif-et-logiciel-f-h_toulouse_LSS_eQpd4gY?q=9535b0189e8e7cf32ba6058db50630c7&o=f1619452-bc64-4327-90c0-436f84a4e5d1",
        "description": "Descriptif du poste Mission/ActivitésLe secteur « Gestion des Comptes Entreprise » (GCE) a pour objectif d'intégrer les déclarations DSN et PASRAU relatives aux cotisations sociales des entreprises afin de permettre leur recouvrement. Ces déclarations sont également fiabilisées pour offrir aux partenaires de l'URSSAF des informations nécessaires à la gestion des droits de chaque salarié.Vous serez intégré·e à l'équipe « Gestion du Déclaratif » composée de chefs de projets, d'architectes solution, de référents techniques et de référents fonctionnels.Votre mission consiste à apporter votre expertise technique pour le choix des architectures et la mise en œuvre de solutions techniques en relation avec un réseau d'experts de la DSI.Vos missions :Vous participez à la conception d'architectures applicatives des systèmes d'information concernés et vous les documentez.Vous avez un rôle de conseil et d'encadrement des bonnes pratiques auprès des équipes projetVous identifiez les améliorations d'architecture applicative et de réduction de la dette technique qui pourraient donner lieu à un projet.Vous contribuez à la réception technique des projets réalisés au forfaitVous serez amené à définir/instruire les composants techniques des SI concernésVous coordonnez techniquement le projet avec tous les acteurs concernés (autres MOE, architecture d'entreprise, infrastructure, socle)Vous êtes force de proposition pour l'émergence de solutions techniques innovantes.  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Logiciel F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Poste Groupe",
        "location": "Nantes",
        "remote": "Télétravail non renseigné",
        "experience": "> 10",
        "education_level": "Bac",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logistique",
            "company_size": "232700",
            "creation_date": "1477",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-poste-groupe/jobs/architecte-logiciel-f-h_nantes_LPG_P2J7WRx?q=9535b0189e8e7cf32ba6058db50630c7&o=6cc678d2-1554-47a3-88e3-8656f36667c0",
        "description": "Descriptif du posteEn rejoignant I-team en tant que architecte logiciel, vous intégrerez la direction des services IT du Groupe La Poste à la Direction des Architectures Solutions et Solutions Applicatives de I-Team, c’est 1000 collaborateurs au service des systèmes d’information du Groupe et de ses filiales. Vous rejoindrez le pôle Architecture Projet dont la mission principale est de définir les solutions d’architectures des applications des métiers supports et transverses du Groupe La Poste (Finance, RH, …).Vos missions si vous les acceptez :Être garant de la définition des solutions d’architectures applicatives en adéquation avec les équipes projet en vous appuyant sur le cadre de référence architecture de la direction.Être garant de la réalisation des dossiers d’architectures en lien avec les besoins métiers et les exigences de services de l’application.Accompagner les équipes projets dans la validation de l’architecture applicative lors des instances de gouvernance architecture.Garantir la conformité de l’architecture proposée avec la stratégie SI de l’entreprise.Réaliser les études permettant de définir et mettre à jour les principes directeurs et règles d’architecture dans le cadre de référence des architectures applicatives.Anticiper la pertinence de nouvelles solutions en terme d’architecture, de rester en veille vis-à-vis des nouvelles pratiques du marché afin de faire évoluer les standards d’architecture de la direction."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Architecte Logiciel F/H",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "La Poste Groupe",
        "location": "Nantes",
        "remote": "Télétravail non renseigné",
        "experience": "> 10",
        "education_level": "Bac",
        "publication_date": "2025-01-08",
        "company_data": {
            "sector": "Logistique",
            "company_size": "232700",
            "creation_date": "1477",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": null,
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/la-poste-groupe/jobs/architecte-logiciel-f-h_nantes_LPG_P2J7WRx?q=9535b0189e8e7cf32ba6058db50630c7&o=6cc678d2-1554-47a3-88e3-8656f36667c0",
        "description": "Descriptif du posteEn rejoignant I-team en tant que architecte logiciel, vous intégrerez la direction des services IT du Groupe La Poste à la Direction des Architectures Solutions et Solutions Applicatives de I-Team, c’est 1000 collaborateurs au service des systèmes d’information du Groupe et de ses filiales. Vous rejoindrez le pôle Architecture Projet dont la mission principale est de définir les solutions d’architectures des applications des métiers supports et transverses du Groupe La Poste (Finance, RH, …).Vos missions si vous les acceptez :Être garant de la définition des solutions d’architectures applicatives en adéquation avec les équipes projet en vous appuyant sur le cadre de référence architecture de la direction.Être garant de la réalisation des dossiers d’architectures en lien avec les besoins métiers et les exigences de services de l’application.Accompagner les équipes projets dans la validation de l’architecture applicative lors des instances de gouvernance architecture.Garantir la conformité de l’architecture proposée avec la stratégie SI de l’entreprise.Réaliser les études permettant de définir et mettre à jour les principes directeurs et règles d’architecture dans le cadre de référence des architectures applicatives.Anticiper la pertinence de nouvelles solutions en terme d’architecture, de rester en veille vis-à-vis des nouvelles pratiques du marché afin de faire évoluer les standards d’architecture de la direction."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur/ Ingénieure DevOps confirmé GRENOBLE",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Grenoble",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "jenkins,…)"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "ansible,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/ingenieur-ingenieure-devops-confirme-grenoble_grenoble?q=9535b0189e8e7cf32ba6058db50630c7&o=52bef12d-fb0e-45d6-905f-a0937ede0ee7",
        "description": "Descriptif du poste      Votre mission… Une fois dans nos équipes ?   Description du profil :  Assure le déploiement d’applications, la réalisation de phases de test réalisées en amont du développement et la mise en place d’une surveillance de la qualité de la production. Activité principale :  Déploiement sur les différents environnements jusqu'à la mise en production Amélioration continue du niveau d'industrialisation/automatisation des déploiements (écriture de modules Ansible, de pipelines Jenkins,…) Développement et mise en place d’outils pour faciliter le quotidien des équipes du projet (supervision, testing, résilience, robustesse…) Résolution / Accompagnement à la résolution d’incidents de production  Activité secondaire :  Rédaction et maintien des documentations techniques Mise en œuvre des méthodes de modélisation des données et des traitements Animation de réunions         "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Ingénieur/ Ingénieure DevOps confirmé GRENOBLE",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Sogeti",
        "location": "Grenoble",
        "remote": "Télétravail fréquent",
        "experience": "> 5",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-09",
        "company_data": {
            "sector": "Logiciels, IT / Digital, SaaS / Cloud Services",
            "company_size": "4300",
            "creation_date": "1967",
            "address": null,
            "average_age_of_employees": "37",
            "turnover_in_millions": null,
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "jenkins,…)"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": [
                "ansible,"
            ],
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/ingenieur-ingenieure-devops-confirme-grenoble_grenoble?q=9535b0189e8e7cf32ba6058db50630c7&o=52bef12d-fb0e-45d6-905f-a0937ede0ee7",
        "description": "Descriptif du poste      Votre mission… Une fois dans nos équipes ?   Description du profil :  Assure le déploiement d’applications, la réalisation de phases de test réalisées en amont du développement et la mise en place d’une surveillance de la qualité de la production. Activité principale :  Déploiement sur les différents environnements jusqu'à la mise en production Amélioration continue du niveau d'industrialisation/automatisation des déploiements (écriture de modules Ansible, de pipelines Jenkins,…) Développement et mise en place d’outils pour faciliter le quotidien des équipes du projet (supervision, testing, résilience, robustesse…) Résolution / Accompagnement à la résolution d’incidents de production  Activité secondaire :  Rédaction et maintien des documentations techniques Mise en œuvre des méthodes de modélisation des données et des traitements Animation de réunions         "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Développeur ou Développeuse outil informatique de partage collaboratif",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Safran Seats",
        "location": "Issoudun",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Métallurgie, Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "1738",
            "creation_date": "1944",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": null,
            "proportion_female": "25",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/safran-seats-1/jobs/stage-developpeur-ou-developpeuse-outil-informatique-de-partage-collaboratif_issoudun?q=10260718ea5f8a9d6996794c6bc69bf1&o=c6f369c6-02c1-42da-b302-46c7e778846f",
        "description": "Descriptif du posteSafran SEATS est un des leaders mondiaux des sièges d'avion pour équipages et passagers.Nos clients : les plus grandes compagnies aériennes et avionneurs.Notre produit : le siège (de la classe économique à la classe affaire en passant par l'équipage). Vous l'avez peut-être déjà testé en voyageant avec l'une de nos compagnies clientes ; plus d'un million d'entre-deux sont actuellement en vol !Notre implantation : Issoudun (36), entre Bourges et Châteauroux aux portes des Châteaux deLoire et de la Touraine (1h15 en voiture ou en train) dans la région Centre Val De Loire et à seulement 2h30 de route de Paris.Notre engagement : Conscient de ses responsabilités, Safran s'est donné pour mission de changer durablement l'aérien pour construire le monde de demain avec 4 ambitions : décarboner l'aéronautique, être un employeur exemplaire, incarner l'industrie responsable et affirmer son engagement citoyen.Vous recherchez une expérience opérationnelle découvrant le monde aéronautique ? Où vous pourrez faire preuve d'autonomie tout en étant accompagné-e par votre tuteur ou tutrice ?Dans une équipe dynamique et conviviale ? Venez rejoindre nos 120 alternant-es & stagiaires !Votre MISSION consistera à apporter un support aux activités du Pôle Projet en développant un outil de partage collaboratif sur le vecteur Amélioration."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Stage - Développeur ou Développeuse outil informatique de partage collaboratif",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "Safran Seats",
        "location": "Issoudun",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-12-05",
        "company_data": {
            "sector": "Métallurgie, Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "1738",
            "creation_date": "1944",
            "address": null,
            "average_age_of_employees": "44",
            "turnover_in_millions": null,
            "proportion_female": "25",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/safran-seats-1/jobs/stage-developpeur-ou-developpeuse-outil-informatique-de-partage-collaboratif_issoudun?q=10260718ea5f8a9d6996794c6bc69bf1&o=c6f369c6-02c1-42da-b302-46c7e778846f",
        "description": "Descriptif du posteSafran SEATS est un des leaders mondiaux des sièges d'avion pour équipages et passagers.Nos clients : les plus grandes compagnies aériennes et avionneurs.Notre produit : le siège (de la classe économique à la classe affaire en passant par l'équipage). Vous l'avez peut-être déjà testé en voyageant avec l'une de nos compagnies clientes ; plus d'un million d'entre-deux sont actuellement en vol !Notre implantation : Issoudun (36), entre Bourges et Châteauroux aux portes des Châteaux deLoire et de la Touraine (1h15 en voiture ou en train) dans la région Centre Val De Loire et à seulement 2h30 de route de Paris.Notre engagement : Conscient de ses responsabilités, Safran s'est donné pour mission de changer durablement l'aérien pour construire le monde de demain avec 4 ambitions : décarboner l'aéronautique, être un employeur exemplaire, incarner l'industrie responsable et affirmer son engagement citoyen.Vous recherchez une expérience opérationnelle découvrant le monde aéronautique ? Où vous pourrez faire preuve d'autonomie tout en étant accompagné-e par votre tuteur ou tutrice ?Dans une équipe dynamique et conviviale ? Venez rejoindre nos 120 alternant-es & stagiaires !Votre MISSION consistera à apporter un support aux activités du Pôle Projet en développant un outil de partage collaboratif sur le vecteur Amélioration."
    },
    {
        "source": "welcometothejungle",
        "job_title": "STAGE - Ingénieure / Ingénieur généraliste avec une spécialité en informatique",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "ArianeGroup",
        "location": "Les Mureaux",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-29",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "8000",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "2,4 B€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/arianegroup/jobs/stage-ingenieur-h-f-specialise-en-materiaux-et-procedes_les-mureaux?q=10260718ea5f8a9d6996794c6bc69bf1&o=17ffbbbe-5235-4eca-9ac6-a29cf710ce70",
        "description": "Descriptif du poste Job Description : Dans le cadre de sa campagne de stage, ArianeGroup recrute un(e) Ingénieure / Ingénieur généraliste avec une spécialité en informatique.Sous la responsabilité de votre maître de stage, vous participez aux missions suivantes : - Découvrir l’outil de gestion de configuration société (teamcenter) et son fonctionnement- Recenser les outils de post-traitement des données, dans teamcenter ou en dehors, et faire un état des lieux des possibilités, et des besoins non couverts ou améliorations nécessaires- Recenser les besoins des utilisateurs (configuration managers)- Développer les outils / compléments nécessaires et les déployer- Assurer la mise en place et la prise en main par les utilisateursVous souhaitez participer à l’aventure Ariane et contribuer à la réussite de la montée en cadence d’Ariane 6 en maitrisant la configuration du lanceur et du système de lancement au sein de la société Leader Européenne de l’accès à l’Espace ? Rejoignez-nous"
    },
    {
        "source": "welcometothejungle",
        "job_title": "STAGE - Ingénieure / Ingénieur généraliste avec une spécialité en informatique",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "ArianeGroup",
        "location": "Les Mureaux",
        "remote": "Télétravail non renseigné",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-29",
        "company_data": {
            "sector": "Ingénieries Spécialisées, Aéronautique / Spatiale",
            "company_size": "8000",
            "creation_date": "2017",
            "address": null,
            "average_age_of_employees": null,
            "turnover_in_millions": "2,4 B€",
            "proportion_female": null,
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/arianegroup/jobs/stage-ingenieur-h-f-specialise-en-materiaux-et-procedes_les-mureaux?q=10260718ea5f8a9d6996794c6bc69bf1&o=17ffbbbe-5235-4eca-9ac6-a29cf710ce70",
        "description": "Descriptif du poste Job Description : Dans le cadre de sa campagne de stage, ArianeGroup recrute un(e) Ingénieure / Ingénieur généraliste avec une spécialité en informatique.Sous la responsabilité de votre maître de stage, vous participez aux missions suivantes : - Découvrir l’outil de gestion de configuration société (teamcenter) et son fonctionnement- Recenser les outils de post-traitement des données, dans teamcenter ou en dehors, et faire un état des lieux des possibilités, et des besoins non couverts ou améliorations nécessaires- Recenser les besoins des utilisateurs (configuration managers)- Développer les outils / compléments nécessaires et les déployer- Assurer la mise en place et la prise en main par les utilisateursVous souhaitez participer à l’aventure Ariane et contribuer à la réussite de la montée en cadence d’Ariane 6 en maitrisant la configuration du lanceur et du système de lancement au sein de la société Leader Européenne de l’accès à l’Espace ? Rejoignez-nous"
    },
    {
        "source": "welcometothejungle",
        "job_title": " Ingénieur(e) AVEVA PI F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Pau",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/ingenieur-aveva-pi-f-h_pau?q=10260718ea5f8a9d6996794c6bc69bf1&o=1a6c1fb4-6d48-4b66-8291-41e865578abc",
        "description": "Descriptif du poste Vous accompagnerez nos clients dans la Transformation Digitale de leur SI Industriel en participant à la mise en place de solutions innovantes.Le système PI de l’éditeur AVEVA (anciennement OSISOFT) permet l'acquisition et le stockage des données chronologiques issues du réseau industriel dans le réseau d'entreprise. Ces données sont pour nos clients la porte d'entrée vers le Big Data et sont fondamentales pour le reporting de production, l'optimisation des procédés ou le monitoring en temps réel. Elles permettent également d'activer des projets innovant dans la Data Science comme la maintenance préventive des équipements industriels.En tant qu'Ingénieur PI expérimenté, vous :-travaillerez avec des clients de différents secteurs industriels, notamment l'énergie, la pharma et la manufacturing, pour fournir des solutions de traitement de données efficaces et innovantes-serez responsable de la conception et de la mise en œuvre de modèles AF (Asset Framework) pour organiser les informations sur les actifs et les processus de production dans les industries-pourrez être impliqué dans la gestion de systèmes MES (Manufacturing Execution System) utilisés pour suivre, contrôler et optimiser les processus de fabrication en temps réel.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Ingénieur(e) AVEVA PI F/H ",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Pau",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-23",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digitale"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/ingenieur-aveva-pi-f-h_pau?q=10260718ea5f8a9d6996794c6bc69bf1&o=1a6c1fb4-6d48-4b66-8291-41e865578abc",
        "description": "Descriptif du poste Vous accompagnerez nos clients dans la Transformation Digitale de leur SI Industriel en participant à la mise en place de solutions innovantes.Le système PI de l’éditeur AVEVA (anciennement OSISOFT) permet l'acquisition et le stockage des données chronologiques issues du réseau industriel dans le réseau d'entreprise. Ces données sont pour nos clients la porte d'entrée vers le Big Data et sont fondamentales pour le reporting de production, l'optimisation des procédés ou le monitoring en temps réel. Elles permettent également d'activer des projets innovant dans la Data Science comme la maintenance préventive des équipements industriels.En tant qu'Ingénieur PI expérimenté, vous :-travaillerez avec des clients de différents secteurs industriels, notamment l'énergie, la pharma et la manufacturing, pour fournir des solutions de traitement de données efficaces et innovantes-serez responsable de la conception et de la mise en œuvre de modèles AF (Asset Framework) pour organiser les informations sur les actifs et les processus de production dans les industries-pourrez être impliqué dans la gestion de systèmes MES (Manufacturing Execution System) utilisés pour suivre, contrôler et optimiser les processus de fabrication en temps réel.En rejoignant CGI, vous bénéficiez notamment d’une offre complète de formations (techniques, métiers, développement personnel,…), de flexibilité grâce à notre accord télétravail (jusqu’à 3 jours de télétravail par semaine), d’une politique de congés avantageuse (27 jours de congés payés, RTT, congés ancienneté et enfant malade,…) et d’un package d’avantages intéressant (régime d’achats d’actions, participation, CSE,…). "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Business Intelligence Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Soil Capital",
        "location": "Ottignies-Louvain-la-Neuve",
        "remote": "Télétravail occasionnel",
        "experience": "> 6 mois",
        "education_level": null,
        "publication_date": "2024-12-13",
        "company_data": {
            "sector": "Environnement / Développement durable, SaaS / Cloud Services, Agroalimentaire / Nutrition animale",
            "company_size": "48",
            "creation_date": "2013",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "4.6 ‎",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams",
                "teams",
                "teams.",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "organization."
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/soilcapital/jobs/business-intelligence-analyst_ottignies-louvain-la-neuve?q=10260718ea5f8a9d6996794c6bc69bf1&o=bfb55401-c7b7-40fe-82b8-e6ac0b991c33",
        "description": "Descriptif du posteWhy we need you?We are looking for a Junior Business Intelligence (BI) to expand our Data team. The role of the Data team is to bring more data driven insights to Soil Capital teams and the clients. To scale this effort, we are looking for someone who can bring the most interesting pieces of data to life!In this position, the Junior BI will be responsible for inspecting, transforming, visualizing and modelling data with a keen eye for data verification, validation, integration.Together with the Lead BI you will identify how to leverage available farmer data together with available open data for Soil Capital teams which include our Agronomists, Developers, Sales; and Soil Capital clients such as farmers, cooperatives, partners.Are you the perfect match?Characteristics of the role- Role: Junior Business Intelligence- Type of contract: Permanent contract- Location: Belgium (Louvain la Neuve) or France (Paris)- Remote policy: hybrid (office and remote)Your role and responsibilitiesWork closely with the Lead BI to ensure that data pulled from the database accurately reflects business realities.Work together with the Lead BI to identify and challenge the needs related to data among the diverse teams within Soil Capital.Translate these needs into insightful reports and dashboards for the other teams. Develop and maintain relevants KPIs, dashboards and reports usable by other teams in their daily routines. Communicate insights from complex data or algorithms into simple conclusions that will empower others to act based on the insights you derive.Provide analytic support by coordinating data extraction from various databases and data interpretation.Creating and maintaining documentation that includes the design, requirements and user manuals for the organization."
    },
    {
        "source": "welcometothejungle",
        "job_title": "Business Intelligence Analyst",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Soil Capital",
        "location": "Ottignies-Louvain-la-Neuve",
        "remote": "Télétravail occasionnel",
        "experience": "> 6 mois",
        "education_level": null,
        "publication_date": "2024-12-13",
        "company_data": {
            "sector": "Environnement / Développement durable, SaaS / Cloud Services, Agroalimentaire / Nutrition animale",
            "company_size": "48",
            "creation_date": "2013",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "4.6 ‎",
            "proportion_female": "30",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams",
                "teams",
                "teams",
                "teams.",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "organization."
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/soilcapital/jobs/business-intelligence-analyst_ottignies-louvain-la-neuve?q=10260718ea5f8a9d6996794c6bc69bf1&o=bfb55401-c7b7-40fe-82b8-e6ac0b991c33",
        "description": "Descriptif du posteWhy we need you?We are looking for a Junior Business Intelligence (BI) to expand our Data team. The role of the Data team is to bring more data driven insights to Soil Capital teams and the clients. To scale this effort, we are looking for someone who can bring the most interesting pieces of data to life!In this position, the Junior BI will be responsible for inspecting, transforming, visualizing and modelling data with a keen eye for data verification, validation, integration.Together with the Lead BI you will identify how to leverage available farmer data together with available open data for Soil Capital teams which include our Agronomists, Developers, Sales; and Soil Capital clients such as farmers, cooperatives, partners.Are you the perfect match?Characteristics of the role- Role: Junior Business Intelligence- Type of contract: Permanent contract- Location: Belgium (Louvain la Neuve) or France (Paris)- Remote policy: hybrid (office and remote)Your role and responsibilitiesWork closely with the Lead BI to ensure that data pulled from the database accurately reflects business realities.Work together with the Lead BI to identify and challenge the needs related to data among the diverse teams within Soil Capital.Translate these needs into insightful reports and dashboards for the other teams. Develop and maintain relevants KPIs, dashboards and reports usable by other teams in their daily routines. Communicate insights from complex data or algorithms into simple conclusions that will empower others to act based on the insights you derive.Provide analytic support by coordinating data extraction from various databases and data interpretation.Creating and maintaining documentation that includes the design, requirements and user manuals for the organization."
    },
    {
        "source": "welcometothejungle",
        "job_title": " Stage Conseil : Consultant(e) en Architecture d'entreprises F/H ",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/stage-conseil-consultant-en-architecture-data-f-h_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=8be7c6a1-4e6e-4e8d-9c91-fe22620d1815",
        "description": "Descriptif du poste Au sein de l’entité Architecture & Cloud Strategy, ton rôle est d’accompagner les directions générales, les directions métiers et les DSI dans leurs projets de transformation sur des problématiques associées à l’architecture des données. En fonction du client, tu seras amené(e) à l’accompagner sur un ou plusieurs volets de l’architecture data :- Dresser un état des lieux sur l’architecture des données (modélisation d’un modèle d’objet métier, modélisation d’un modèle physique des données, lignage d’un objet métier…) et des échanges (patterns d’intégration)- Recommander de manière étayée des propositions d’architecture et de technologies, en mettant l'accent sur les aspects d’architecture des données et des échanges- Définir une architecture cible sur les plans des données et des échanges- Réaliser des benchmarks des technologies d’intégration des données et prévoir des préconisations de choix de solution- Recommander de manière étayée une solution de catalogage des données- Mettre en place différents processus d’alimentation d’un catalogue des données- Dresser un état des lieux sur une architecture BI- Recommander de manière étayée des architectures et technologies BI- Élaborer une architecture cible BI- Réaliser des benchmarks de technologies BI et préconisation de choixRejoindre CGI Business Consulting dans le cadre de ton stage de fin d’études ou de ton alternance, c’est intervenir sur des projets d’envergure et variés en lien avec ta formation tout en bénéficiant d’un accompagnement de proximité pour construire ta carrière. C’est aussi s’investir auprès d’une entreprise responsable qui propose de nombreux avantages (prise en charge jusqu’à 100% des transports en commun) et partager des moments de convivialité pour ensuite nous rejoindre en CDI ! "
    },
    {
        "source": "welcometothejungle",
        "job_title": " Stage Conseil : Consultant(e) en Architecture d'entreprises F/H ",
        "contract_type": "Stage",
        "salary": "Non spécifié",
        "company": "CGI",
        "location": "Paris",
        "remote": "Télétravail fréquent",
        "experience": null,
        "education_level": null,
        "publication_date": "2024-11-27",
        "company_data": {
            "sector": "IT / Digital, Transformation, Big Data",
            "company_size": "14000",
            "creation_date": "1976",
            "address": null,
            "average_age_of_employees": "36",
            "turnover_in_millions": "12 Mds € en 2022",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloud"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/cgi/jobs/stage-conseil-consultant-en-architecture-data-f-h_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=8be7c6a1-4e6e-4e8d-9c91-fe22620d1815",
        "description": "Descriptif du poste Au sein de l’entité Architecture & Cloud Strategy, ton rôle est d’accompagner les directions générales, les directions métiers et les DSI dans leurs projets de transformation sur des problématiques associées à l’architecture des données. En fonction du client, tu seras amené(e) à l’accompagner sur un ou plusieurs volets de l’architecture data :- Dresser un état des lieux sur l’architecture des données (modélisation d’un modèle d’objet métier, modélisation d’un modèle physique des données, lignage d’un objet métier…) et des échanges (patterns d’intégration)- Recommander de manière étayée des propositions d’architecture et de technologies, en mettant l'accent sur les aspects d’architecture des données et des échanges- Définir une architecture cible sur les plans des données et des échanges- Réaliser des benchmarks des technologies d’intégration des données et prévoir des préconisations de choix de solution- Recommander de manière étayée une solution de catalogage des données- Mettre en place différents processus d’alimentation d’un catalogue des données- Dresser un état des lieux sur une architecture BI- Recommander de manière étayée des architectures et technologies BI- Élaborer une architecture cible BI- Réaliser des benchmarks de technologies BI et préconisation de choixRejoindre CGI Business Consulting dans le cadre de ton stage de fin d’études ou de ton alternance, c’est intervenir sur des projets d’envergure et variés en lien avec ta formation tout en bénéficiant d’un accompagnement de proximité pour construire ta carrière. C’est aussi s’investir auprès d’une entreprise responsable qui propose de nombreux avantages (prise en charge jusqu’à 100% des transports en commun) et partager des moments de convivialité pour ensuite nous rejoindre en CDI ! "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Python (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FINAXYS",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-23",
        "company_data": {
            "sector": "Banque, Logiciels, SaaS / Cloud Services, Big Data",
            "company_size": "400",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "40 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudmettre",
                "(ci/cd)collaborer",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/finaxys/jobs/developpeur-python-f-h_puteaux_FINAX_A4xP07Q?q=10260718ea5f8a9d6996794c6bc69bf1&o=ec6a553a-aeed-4959-b3a4-5adf9058f370",
        "description": "Descriptif du posteEn tant que Développeur Python, vous rejoindrez les équipes techniques de nos clients grands comptes pour :Concevoir et développer des solutions sur mesure, performantes et évolutivesParticiper à des projets innovants dans des environnements riches en données et en calculs complexesTravailler sur des frameworks tels que Django, Flask ou encore FastAPIContribuer à des architectures modernes basées sur des microservices et des environnements cloudMettre en place des pipelines d’intégration et de déploiement continu (CI/CD)Collaborer étroitement avec les équipes métier et IT dans un contexte AgileEnvironnement technique : Python, Django, Flask, FastAPI, SQL, CI/CD"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Développeur Python (F/H)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "FINAXYS",
        "location": "Puteaux",
        "remote": "Télétravail occasionnel",
        "experience": "> 2",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-12-23",
        "company_data": {
            "sector": "Banque, Logiciels, SaaS / Cloud Services, Big Data",
            "company_size": "400",
            "creation_date": "2008",
            "address": null,
            "average_age_of_employees": "32",
            "turnover_in_millions": "40 ",
            "proportion_female": "35",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": [
                "python,",
                "python,"
            ],
            "DataBase": [
                "sql,"
            ],
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": [
                "cloudmettre",
                "(ci/cd)collaborer",
                "ci/cd"
            ],
            "EnSoftSkils": null
        },
        "link": "https://www.welcometothejungle.com/fr/companies/finaxys/jobs/developpeur-python-f-h_puteaux_FINAX_A4xP07Q?q=10260718ea5f8a9d6996794c6bc69bf1&o=ec6a553a-aeed-4959-b3a4-5adf9058f370",
        "description": "Descriptif du posteEn tant que Développeur Python, vous rejoindrez les équipes techniques de nos clients grands comptes pour :Concevoir et développer des solutions sur mesure, performantes et évolutivesParticiper à des projets innovants dans des environnements riches en données et en calculs complexesTravailler sur des frameworks tels que Django, Flask ou encore FastAPIContribuer à des architectures modernes basées sur des microservices et des environnements cloudMettre en place des pipelines d’intégration et de déploiement continu (CI/CD)Collaborer étroitement avec les équipes métier et IT dans un contexte AgileEnvironnement technique : Python, Django, Flask, FastAPI, SQL, CI/CD"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sr. Product Manager – Advertising Specialist (All Genders)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Dailymotion SA",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-05",
        "company_data": {
            "sector": "Big Data, Média, Publicité",
            "company_size": "370",
            "creation_date": "2005",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "flexibility.for",
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/sr-product-manager-advertising-specialist-all-genders_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=be542feb-9765-44f4-a5bb-6522afa11b72",
        "description": "Descriptif du posteThe Product Advertising team is in charge of conceiving and optimizing innovative monetization solutions for both Dailymotion advertising and publisher partners.With a strong emphasis on data, brand safety, and privacy, the team ensures that the views operated on the platform (website, mobile apps, connected TVs) generate revenues for Dailymotion and its partners while delivering value for advertisers and agencies.Depending on their seniority, the product managers in this team are responsible for driving the product vision for the Dailymotion proprietary advertising stack, collaborating with different internal and external stakeholders to intercept market trends and needs, prioritizing features and initiatives with high business impact, and working with the engineering team to develop, deliver, and deploy new advertising products.Additional InformationWhat we offer you:• Additional opportunities as we grow and learn together.• Join our open, collaborative culture.• Exciting, dynamic projects to work on.• Flexibility.For the France offices 🏡Hybrid Work Framework Flex (1/2 days office) 💰 Saving Plan Vivendi 🍼  Paternity leave or Coparental leave extended 🕶️  Living Employee Culture (Events / Trainings / Partys / All hands / Dailymotion tradition…) 🚀  Career development support (training / internal mobility / compensation cycle / 360 quarter feedback review …)🏥  High-end Health Insurance and Personal Services Vouchers (CESU)⛱️  Paid Time off – RTT and Saving time plan (CET)✅  Meal Vouchers – Public Transport and Bike refund 🎡 European Economic and Social Committee (sport membership/cinemas vouchers/gift vouchers/discount) 🔍Want to learn more about us: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sr. Product Manager – Advertising Specialist (All Genders)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Dailymotion SA",
        "location": "Paris",
        "remote": "Télétravail non renseigné",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2025-01-05",
        "company_data": {
            "sector": "Big Data, Média, Publicité",
            "company_size": "370",
            "creation_date": "2005",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "flexibility.for",
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/sr-product-manager-advertising-specialist-all-genders_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=be542feb-9765-44f4-a5bb-6522afa11b72",
        "description": "Descriptif du posteThe Product Advertising team is in charge of conceiving and optimizing innovative monetization solutions for both Dailymotion advertising and publisher partners.With a strong emphasis on data, brand safety, and privacy, the team ensures that the views operated on the platform (website, mobile apps, connected TVs) generate revenues for Dailymotion and its partners while delivering value for advertisers and agencies.Depending on their seniority, the product managers in this team are responsible for driving the product vision for the Dailymotion proprietary advertising stack, collaborating with different internal and external stakeholders to intercept market trends and needs, prioritizing features and initiatives with high business impact, and working with the engineering team to develop, deliver, and deploy new advertising products.Additional InformationWhat we offer you:• Additional opportunities as we grow and learn together.• Join our open, collaborative culture.• Exciting, dynamic projects to work on.• Flexibility.For the France offices 🏡Hybrid Work Framework Flex (1/2 days office) 💰 Saving Plan Vivendi 🍼  Paternity leave or Coparental leave extended 🕶️  Living Employee Culture (Events / Trainings / Partys / All hands / Dailymotion tradition…) 🚀  Career development support (training / internal mobility / compensation cycle / 360 quarter feedback review …)🏥  High-end Health Insurance and Personal Services Vouchers (CESU)⛱️  Paid Time off – RTT and Saving time plan (CET)✅  Meal Vouchers – Public Transport and Bike refund 🎡 European Economic and Social Committee (sport membership/cinemas vouchers/gift vouchers/discount) 🔍Want to learn more about us: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sr. Product Manager – Advertising Products (All Genders)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Dailymotion SA",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2024-09-17",
        "company_data": {
            "sector": "Big Data, Média, Publicité",
            "company_size": "370",
            "creation_date": "2005",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "flexibility.for",
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/sr-product-manager-advertising-products-all-genders_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=6f00df5b-8dac-481a-ad46-ee1f3c228e19",
        "description": "Descriptif du posteThe Product Advertising team is in charge of conceiving and optimizing innovative monetization solutions for both Dailymotion advertising and publisher partners.With a strong emphasis on data, brand safety, and privacy, the team ensures that the views operated on the platform (website, mobile apps, connected TVs) generate revenues for Dailymotion and its partners while delivering value for advertisers and agencies.Depending on their seniority, the product managers in this team are responsible for driving the product vision for the Dailymotion proprietary advertising stack, collaborating with different internal and external stakeholders to intercept market trends and needs, prioritizing features and initiatives with high business impact, and working with the engineering team to develop, deliver, and deploy new advertising products.Additional InformationWhat we offer you:• Additional opportunities as we grow and learn together.• Join our open, collaborative culture.• Exciting, dynamic projects to work on.• Flexibility.For the France offices 🏡Hybrid Work Framework Flex (1/2 days office) 💰 Saving Plan Vivendi 🍼  Paternity leave or Coparental leave extended 🕶️  Living Employee Culture (Events / Trainings / Partys / All hands / Dailymotion tradition…) 🚀  Career development support (training / internal mobility / compensation cycle / 360 quarter feedback review …)🏥  High-end Health Insurance and Personal Services Vouchers (CESU)⛱️  Paid Time off – RTT and Saving time plan (CET)✅  Meal Vouchers – Public Transport and Bike refund 🎡 European Economic and Social Committee (sport membership/cinemas vouchers/gift vouchers/discount) 🔍Want to learn more about us: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Sr. Product Manager – Advertising Products (All Genders)",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Dailymotion SA",
        "location": "Paris",
        "remote": "Télétravail non autorisé",
        "experience": "> 4",
        "education_level": null,
        "publication_date": "2024-09-17",
        "company_data": {
            "sector": "Big Data, Média, Publicité",
            "company_size": "370",
            "creation_date": "2005",
            "address": null,
            "average_age_of_employees": "33",
            "turnover_in_millions": null,
            "proportion_female": "40",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": null,
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": null,
            "Other": null,
            "EnSoftSkils": [
                "flexibility.for",
                "initiatives"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/dailymotion/jobs/sr-product-manager-advertising-products-all-genders_paris?q=10260718ea5f8a9d6996794c6bc69bf1&o=6f00df5b-8dac-481a-ad46-ee1f3c228e19",
        "description": "Descriptif du posteThe Product Advertising team is in charge of conceiving and optimizing innovative monetization solutions for both Dailymotion advertising and publisher partners.With a strong emphasis on data, brand safety, and privacy, the team ensures that the views operated on the platform (website, mobile apps, connected TVs) generate revenues for Dailymotion and its partners while delivering value for advertisers and agencies.Depending on their seniority, the product managers in this team are responsible for driving the product vision for the Dailymotion proprietary advertising stack, collaborating with different internal and external stakeholders to intercept market trends and needs, prioritizing features and initiatives with high business impact, and working with the engineering team to develop, deliver, and deploy new advertising products.Additional InformationWhat we offer you:• Additional opportunities as we grow and learn together.• Join our open, collaborative culture.• Exciting, dynamic projects to work on.• Flexibility.For the France offices 🏡Hybrid Work Framework Flex (1/2 days office) 💰 Saving Plan Vivendi 🍼  Paternity leave or Coparental leave extended 🕶️  Living Employee Culture (Events / Trainings / Partys / All hands / Dailymotion tradition…) 🚀  Career development support (training / internal mobility / compensation cycle / 360 quarter feedback review …)🏥  High-end Health Insurance and Personal Services Vouchers (CESU)⛱️  Paid Time off – RTT and Saving time plan (CET)✅  Meal Vouchers – Public Transport and Bike refund 🎡 European Economic and Social Committee (sport membership/cinemas vouchers/gift vouchers/discount) 🔍Want to learn more about us: Dailymotion.com New-York office - BuiltIn Offices in France - Welcome to the Jungle Our articles  "
    },
    {
        "source": "welcometothejungle",
        "job_title": "Dutch or French-speaking Paid Media Account Manager",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Selectra",
        "location": "Madrid",
        "remote": "Télétravail occasionnel",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-18",
        "company_data": {
            "sector": "SaaS / Cloud Services, Electronique / Télécommunications, Energie, Immobilier particulier",
            "company_size": "2200",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "26",
            "turnover_in_millions": "93M",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digital",
                "digital",
                "digital",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.research",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "collaboration",
                "flexibility"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/selectra/jobs/paid-media-account-manager-belgium_madrid_SELEC_erw0KoL?q=10260718ea5f8a9d6996794c6bc69bf1&o=b1eda29d-b7f8-4e1e-b003-2fda15bd780a",
        "description": "Descriptif du posteContext of the positionAre you passionate about digital marketing? Do you have an entrepreneurial mindset and thrive in a fast-paced start-up environment? CPC, CPA, CPL, AOV, and other performance metrics are your second language and data and numbers don’t scare you?We are looking for you! Our International Paid Media team in Madrid is looking to hire a Paid Media Account Manager responsible for the Belgian market.Your objective? The successful candidate will be responsible for growing our Belgian Energy and Telecom verticals by driving qualified leads for our Sales team through various paid media channels, including Google Ads, Meta Ads, Microsoft Ads, TikTok Ads, etc.Your mission? Your mission is to grow our Belgian market by continuously searching for and identifying new opportunities in terms of customer acquisition through paid media.The outcomes in detailDriving qualified leads for our Sales teamYou will use your Digital Marketing expertise to drive qualified leads for our Sales team through our different acquisition channels (of which particularly Google Ads) by:Creating, executing, and managing digital marketing campaigns that present our company’s services with the objective of generating inbound traffic;Test and propose new creative ideas together with the paid acquisition team and the sales and design teams.Research and improve important aspects of campaign features: Audience research, website research, campaign structure and funnel optimization.Deliver paid media campaign optimizations, analyzing and providing recommendations for next steps based on data.Create, analyze and optimize landing pages using our CMS, online forms software and internal tools. Aid tracking and analyzing the sales funnel acquisition.Report and daily follow-up.Market research, benchmarking and assisting with special operations projects.Stay informed of best practices and relevant industry, paid media, and paid media platform trends.Performance monitoringClosely monitor campaign performance Clearly present and interpret different KPIs as well as ROIStarting and optimizing digital marketing campaigns, mainly on Google Ads (mainly on Search but also on other Discover and Youtube), and occasionally on Bing Ads, Facebook Ads and other digital marketing platforms.In collaboration with the manager of Selectra’s International SEA department, leading the definition and the update of a clear strategy on each platform, based on strong beliefs acquired through experience. Help each account manager of the department implement that strategy in the countries and markets he/she’s responsible for.Continuously test new strategies and lead technical improvements to maximize conversions and minimize costs at each stage of the funnel.Developing SEA best practises and increase leads and sales coming from paid channelsExport best practices in different verticals and marketsAs your testing progresses, you won’t hesitate to communicate results with the team and deploy winning formulas on all Selectra’s markets, with the help of the local teams and account managers.Benefits and PerksMadrid! You’ll be seduced by this city with a dreamy atmosphere and culture where everybody feels welcome.You’ll benefit from the flexibility and reactivity of a company with a start-up spirit (flat hierarchy, chill environment) A truly international company: we count more than 20 nationalities and make sure you can talk with everyone by offering free language classes! Company events: we work hard and love to celebrate once work is done! We organize monthly team events as well as 3 company-wide afterworks per year.You’ll have responsibilities within a dynamic team, here to train and assist you when neededWe care about your health and wellbeing: preferential tariffs for private health insurance (free after a year in the company) preferential tariffs on  your Gym subscription. Fresh fruits delivered every weekBut especially, a work environment where we never let unhealthy HR situations unattended.We help you settle in your new town thanks to other advantages (Diverclick, …)"
    },
    {
        "source": "welcometothejungle",
        "job_title": "Dutch or French-speaking Paid Media Account Manager",
        "contract_type": "CDI",
        "salary": "Non spécifié",
        "company": "Selectra",
        "location": "Madrid",
        "remote": "Télétravail occasionnel",
        "experience": "> 1 an",
        "education_level": "Bac +5 / Master",
        "publication_date": "2024-11-18",
        "company_data": {
            "sector": "SaaS / Cloud Services, Electronique / Télécommunications, Energie, Immobilier particulier",
            "company_size": "2200",
            "creation_date": "2007",
            "address": null,
            "average_age_of_employees": "26",
            "turnover_in_millions": "93M",
            "proportion_female": "45",
            "proportion_male": null
        },
        "skills": {
            "ProgLanguage": null,
            "DataBase": null,
            "DataAnalytics": null,
            "BigData": null,
            "MachineLearning": null,
            "DataSerialization": null,
            "DataVisualisation": null,
            "Statistics": null,
            "CloudComputing": null,
            "DevTools": [
                "digital",
                "digital",
                "digital",
                "digital",
                "digital"
            ],
            "OS": null,
            "DBMS": null,
            "SoftBigDataProcessing": null,
            "Automation": null,
            "InfrastructureAsCode": null,
            "NetworkSecurty": null,
            "Virtualisation": null,
            "Containers": null,
            "Collaboration": [
                "teams.research",
                "teams"
            ],
            "Other": null,
            "EnSoftSkils": [
                "collaboration",
                "flexibility"
            ]
        },
        "link": "https://www.welcometothejungle.com/fr/companies/selectra/jobs/paid-media-account-manager-belgium_madrid_SELEC_erw0KoL?q=10260718ea5f8a9d6996794c6bc69bf1&o=b1eda29d-b7f8-4e1e-b003-2fda15bd780a",
        "description": "Descriptif du posteContext of the positionAre you passionate about digital marketing? Do you have an entrepreneurial mindset and thrive in a fast-paced start-up environment? CPC, CPA, CPL, AOV, and other performance metrics are your second language and data and numbers don’t scare you?We are looking for you! Our International Paid Media team in Madrid is looking to hire a Paid Media Account Manager responsible for the Belgian market.Your objective? The successful candidate will be responsible for growing our Belgian Energy and Telecom verticals by driving qualified leads for our Sales team through various paid media channels, including Google Ads, Meta Ads, Microsoft Ads, TikTok Ads, etc.Your mission? Your mission is to grow our Belgian market by continuously searching for and identifying new opportunities in terms of customer acquisition through paid media.The outcomes in detailDriving qualified leads for our Sales teamYou will use your Digital Marketing expertise to drive qualified leads for our Sales team through our different acquisition channels (of which particularly Google Ads) by:Creating, executing, and managing digital marketing campaigns that present our company’s services with the objective of generating inbound traffic;Test and propose new creative ideas together with the paid acquisition team and the sales and design teams.Research and improve important aspects of campaign features: Audience research, website research, campaign structure and funnel optimization.Deliver paid media campaign optimizations, analyzing and providing recommendations for next steps based on data.Create, analyze and optimize landing pages using our CMS, online forms software and internal tools. Aid tracking and analyzing the sales funnel acquisition.Report and daily follow-up.Market research, benchmarking and assisting with special operations projects.Stay informed of best practices and relevant industry, paid media, and paid media platform trends.Performance monitoringClosely monitor campaign performance Clearly present and interpret different KPIs as well as ROIStarting and optimizing digital marketing campaigns, mainly on Google Ads (mainly on Search but also on other Discover and Youtube), and occasionally on Bing Ads, Facebook Ads and other digital marketing platforms.In collaboration with the manager of Selectra’s International SEA department, leading the definition and the update of a clear strategy on each platform, based on strong beliefs acquired through experience. Help each account manager of the department implement that strategy in the countries and markets he/she’s responsible for.Continuously test new strategies and lead technical improvements to maximize conversions and minimize costs at each stage of the funnel.Developing SEA best practises and increase leads and sales coming from paid channelsExport best practices in different verticals and marketsAs your testing progresses, you won’t hesitate to communicate results with the team and deploy winning formulas on all Selectra’s markets, with the help of the local teams and account managers.Benefits and PerksMadrid! You’ll be seduced by this city with a dreamy atmosphere and culture where everybody feels welcome.You’ll benefit from the flexibility and reactivity of a company with a start-up spirit (flat hierarchy, chill environment) A truly international company: we count more than 20 nationalities and make sure you can talk with everyone by offering free language classes! Company events: we work hard and love to celebrate once work is done! We organize monthly team events as well as 3 company-wide afterworks per year.You’ll have responsibilities within a dynamic team, here to train and assist you when neededWe care about your health and wellbeing: preferential tariffs for private health insurance (free after a year in the company) preferential tariffs on  your Gym subscription. Fresh fruits delivered every weekBut especially, a work environment where we never let unhealthy HR situations unattended.We help you settle in your new town thanks to other advantages (Diverclick, …)"
    }
]