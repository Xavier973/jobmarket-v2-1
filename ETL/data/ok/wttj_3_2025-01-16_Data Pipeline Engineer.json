[{"source": "welcometothejungle", "job_title": "Senior Data Engineer/Scientist | LLM - NLP - Pipeline", "contract_type": "CDI", "salary": "Non spécifié", "company": "Jus Mundi", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Service juridique, Justice", "company_size": "85", "creation_date": "2018", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "6 million ARR", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalable,", "scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams,"], "Other": null, "EnSoftSkils": ["leadership:", "collaboration:"]}, "link": "https://www.welcometothejungle.com/fr/companies/jus-mundi/jobs/senior-lead-data-engineer-scientist-llm-nlp-pipeline_paris?q=557bf4ac9053418863fc5982a25786ef&o=daae1f12-8d5a-4eba-b7a8-e620e28f7ae0", "description": "Descriptif du posteWe are looking for an experienced Senior Data Engineer/Scientist. This role is your chance to shape the future of our data-driven platforms and have a direct impact on global justice through technology.In this role, you will contribute to the design and development of scalable data pipelines, leveraging cutting-edge Natural Language Processing (NLP) and Large Language Models (LLM) to build solutions that push the boundaries of legal tech.At Jus Mundi, you’ll help to innovate and solve complex technical challenges. You will collaborate with cross-functional teams, including the CTO, to define and execute the technical and product roadmap.Key Responsibilities:Data Infrastructure Leadership: Implementation, optimization, and maintenance of our data pipelines, ensuring they are scalable, secure, and reliable for processing vast amounts of legal data.NLP & LLM Expertise: Architect and implement solutions involving Large Language Models (LLMs) and Natural Language Processing (NLP) to extract insights and create advanced features for our legal tech platforms.Cross-functional Collaboration: Collaborate closely with product, engineering, and legal experts to build intelligent data systems that enhance the user experience and help democratize access to legal information.Modeling & Analytics: Develop and deploy machine learning models focused on NLP, entity extraction, and text analytics, ensuring they meet performance, accuracy, and scalability standards.Data Strategy: Help drive the technical direction of a rapidly scaling legal tech company by partnering with the CTO to create and execute long-term strategies.Best Practices & Innovation: Enforce data engineering best practices while staying on top of emerging technologies, tools, and methodologies in the fields of NLP and machine learning."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer/Scientist | LLM - NLP - Pipeline", "contract_type": "CDI", "salary": "Non spécifié", "company": "Jus Mundi", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Service juridique, Justice", "company_size": "85", "creation_date": "2018", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "6 million ARR", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalable,", "scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams,"], "Other": null, "EnSoftSkils": ["leadership:", "collaboration:"]}, "link": "https://www.welcometothejungle.com/fr/companies/jus-mundi/jobs/senior-lead-data-engineer-scientist-llm-nlp-pipeline_paris?q=557bf4ac9053418863fc5982a25786ef&o=daae1f12-8d5a-4eba-b7a8-e620e28f7ae0", "description": "Descriptif du posteWe are looking for an experienced Senior Data Engineer/Scientist. This role is your chance to shape the future of our data-driven platforms and have a direct impact on global justice through technology.In this role, you will contribute to the design and development of scalable data pipelines, leveraging cutting-edge Natural Language Processing (NLP) and Large Language Models (LLM) to build solutions that push the boundaries of legal tech.At Jus Mundi, you’ll help to innovate and solve complex technical challenges. You will collaborate with cross-functional teams, including the CTO, to define and execute the technical and product roadmap.Key Responsibilities:Data Infrastructure Leadership: Implementation, optimization, and maintenance of our data pipelines, ensuring they are scalable, secure, and reliable for processing vast amounts of legal data.NLP & LLM Expertise: Architect and implement solutions involving Large Language Models (LLMs) and Natural Language Processing (NLP) to extract insights and create advanced features for our legal tech platforms.Cross-functional Collaboration: Collaborate closely with product, engineering, and legal experts to build intelligent data systems that enhance the user experience and help democratize access to legal information.Modeling & Analytics: Develop and deploy machine learning models focused on NLP, entity extraction, and text analytics, ensuring they meet performance, accuracy, and scalability standards.Data Strategy: Help drive the technical direction of a rapidly scaling legal tech company by partnering with the CTO to create and execute long-term strategies.Best Practices & Innovation: Enforce data engineering best practices while staying on top of emerging technologies, tools, and methodologies in the fields of NLP and machine learning."}, {"source": "welcometothejungle", "job_title": "Software Engineer", "contract_type": "CDI", "salary": "54K à 70K €", "company": "Captain Data", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-30", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "11", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": ["pythonyou"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": ["json,"], "DataVisualisation": null, "Statistics": null, "CloudComputing": ["gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/captaindata/jobs/software-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=f2ea3a01-5201-408e-b65e-8d6c65b2c399", "description": "Descriptif du posteAt Captain Data, most of our work is “hidden” - working on 100+ automation and 30+ data sources, which means there are 100+ products inside Captain Data.You can imagine the number of services and features required to run such an engine is quite advanced.We have three APIs:an automation API, our “framework”, that runs our 100+ automated actions on 3 different stacks between Kubernetes, micro-services, etc.an Oauth2 API to handle Oauth2 dance + working as a proxy for 3rd party integrationsour main back-end to schedule runs, handle data manipulation, etc.Front-end wise we have:An Angular (16+) clientA Chrome ExtensionThe stack: Angular + FastAPI + TypeScript (Fastify) + GCP …Your job will be to help on all fronts. This means you’ve previously worked in a high-paced environment with strong technical challenges.Please note that this job requires advanced knowledge, do not apply if you’ve never worked on the following topics :)This job has been tailored for you if… 🦄you’re proficient with TypeScript, NodeJS and Pythonyou have experience with Angular or a TypesScript front-end frameworkyou know your way with data manipulation/optimization, JSON, and databases in general (Postgres, Mongo…)you’re perfectly comfortable with code architecture, design patterns, etc.you design before you code (engineering-wise!)you have an appetite for product-engineering topics, i.e. you’re your own POyou have the mindset of a builder, you like to build & iterate fast"}, {"source": "welcometothejungle", "job_title": "Software Engineer", "contract_type": "CDI", "salary": "54K à 70K €", "company": "Captain Data", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-30", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "11", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": ["pythonyou"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": ["json,"], "DataVisualisation": null, "Statistics": null, "CloudComputing": ["gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/captaindata/jobs/software-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=f2ea3a01-5201-408e-b65e-8d6c65b2c399", "description": "Descriptif du posteAt Captain Data, most of our work is “hidden” - working on 100+ automation and 30+ data sources, which means there are 100+ products inside Captain Data.You can imagine the number of services and features required to run such an engine is quite advanced.We have three APIs:an automation API, our “framework”, that runs our 100+ automated actions on 3 different stacks between Kubernetes, micro-services, etc.an Oauth2 API to handle Oauth2 dance + working as a proxy for 3rd party integrationsour main back-end to schedule runs, handle data manipulation, etc.Front-end wise we have:An Angular (16+) clientA Chrome ExtensionThe stack: Angular + FastAPI + TypeScript (Fastify) + GCP …Your job will be to help on all fronts. This means you’ve previously worked in a high-paced environment with strong technical challenges.Please note that this job requires advanced knowledge, do not apply if you’ve never worked on the following topics :)This job has been tailored for you if… 🦄you’re proficient with TypeScript, NodeJS and Pythonyou have experience with Angular or a TypesScript front-end frameworkyou know your way with data manipulation/optimization, JSON, and databases in general (Postgres, Mongo…)you’re perfectly comfortable with code architecture, design patterns, etc.you design before you code (engineering-wise!)you have an appetite for product-engineering topics, i.e. you’re your own POyou have the mindset of a builder, you like to build & iterate fast"}, {"source": "welcometothejungle", "job_title": "Cloud Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Visian", "location": "Courbevoie", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-16", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Stratégie", "company_size": "150", "creation_date": "2017", "address": null, "average_age_of_employees": null, "turnover_in_millions": "20 Millions d'euros", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "azure,", "gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["devops,", "cloud", "cloud", "cloud", "cloud.industrialiser", "cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/visian/jobs/cloud-data-engineer_courbevoie_VISIA_eMgLxkq?q=557bf4ac9053418863fc5982a25786ef&o=17660fea-521e-43d9-9528-8795b4f28b2f", "description": "Descriptif du posteVisian, Société de conseil spécialisée en innovation, design produit, gestion de projet IT et développement Data. Recherche un Data Engineer.🎯 MissionsEn tant que Cloud Data Engineer, vous jouerez un rôle clé dans la conception, la mise en place et la gestion des solutions Cloud pour la collecte, le traitement et le stockage des données. Vous serez responsable de :Concevoir et maintenir des infrastructures Cloud sur AWS, Azure, ou GCP pour répondre aux besoins des projets data.Implémenter et optimiser des pipelines de données robustes, scalables et performants.Assurer la sécurité, la gouvernance et la disponibilité des données dans des environnements distribués.Collaborer avec des équipes multidisciplinaires (Data Scientists, DevOps, Product Owners) pour garantir une intégration fluide des solutions Cloud.Industrialiser les workflows pour rendre les données accessibles et exploitables à l’échelle.Participer à la veille technologique pour améliorer continuellement les pratiques Cloud et Data Engineering."}, {"source": "welcometothejungle", "job_title": "Cloud Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Visian", "location": "Courbevoie", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-16", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Stratégie", "company_size": "150", "creation_date": "2017", "address": null, "average_age_of_employees": null, "turnover_in_millions": "20 Millions d'euros", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "azure,", "gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["devops,", "cloud", "cloud", "cloud", "cloud.industrialiser", "cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/visian/jobs/cloud-data-engineer_courbevoie_VISIA_eMgLxkq?q=557bf4ac9053418863fc5982a25786ef&o=17660fea-521e-43d9-9528-8795b4f28b2f", "description": "Descriptif du posteVisian, Société de conseil spécialisée en innovation, design produit, gestion de projet IT et développement Data. Recherche un Data Engineer.🎯 MissionsEn tant que Cloud Data Engineer, vous jouerez un rôle clé dans la conception, la mise en place et la gestion des solutions Cloud pour la collecte, le traitement et le stockage des données. Vous serez responsable de :Concevoir et maintenir des infrastructures Cloud sur AWS, Azure, ou GCP pour répondre aux besoins des projets data.Implémenter et optimiser des pipelines de données robustes, scalables et performants.Assurer la sécurité, la gouvernance et la disponibilité des données dans des environnements distribués.Collaborer avec des équipes multidisciplinaires (Data Scientists, DevOps, Product Owners) pour garantir une intégration fluide des solutions Cloud.Industrialiser les workflows pour rendre les données accessibles et exploitables à l’échelle.Participer à la veille technologique pour améliorer continuellement les pratiques Cloud et Data Engineering."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer M/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Onepilot", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": null, "publication_date": "2025-01-15", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Accompagnement d'entreprises", "company_size": "100", "creation_date": "2021", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["awsdevelop", "gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams,"], "Other": ["mlops", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/onepilot/jobs/senior-data-engineer-m-f?q=557bf4ac9053418863fc5982a25786ef&o=a1ea8f12-eb65-4b7c-bc0b-6bcf03dd44d2", "description": "Descriptif du posteOnepilot is looking for an experienced Data Engineer with strong MLOps skills to join the Artificial Intelligence team. Reporting to the Head of AI and working in tandem with William, Phd. AI Expert, you will be involved in setting up data pipelines and AI pipelines as part of a dynamic and ambitious team. As a major link with the other technical teams, made up of more than 10 developers, the pipelines to be built will be integrated into Onepilot’s production environment. Collecting and formatting complex unstructured data is the key to the success of the AI algorithms on which Onepilot is relying to help its development.Missions:Challenge and improve our data architecture Build and manage a bidirectional integration framework to: Allow real-time retrieval of unstructured data from a range of customer toolsBack office, payment service providers, delivery tracking tools, etc.The tools may or may not be accessible via APIPerform actions in customer tools (for instance, refund a missing item, or send a prepared response)Based on AI recommendationsIn order to automate tickets processingOversee the management of data pipelines and data storage systems required for model training and inferenceCollect (thanks to the integration framework), store and standardize raw data from a multitude of sourcesEnsure data quality by implementing quality controls, tests and validation processesChallenge and improve our AI pipelineSupporting the transition from GCP to AWSDevelop and maintain CI/CD pipelines for automating the testing, integration, and deployment of AI modelsOptimize AI infrastructure for scalability and cost-effectivenessAbility to run a multitude of LLMs in a short space of timeParticipate in maintaining technical documentation within the team"}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer M/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Onepilot", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": null, "publication_date": "2025-01-15", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Accompagnement d'entreprises", "company_size": "100", "creation_date": "2021", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["awsdevelop", "gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams,"], "Other": ["mlops", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/onepilot/jobs/senior-data-engineer-m-f?q=557bf4ac9053418863fc5982a25786ef&o=a1ea8f12-eb65-4b7c-bc0b-6bcf03dd44d2", "description": "Descriptif du posteOnepilot is looking for an experienced Data Engineer with strong MLOps skills to join the Artificial Intelligence team. Reporting to the Head of AI and working in tandem with William, Phd. AI Expert, you will be involved in setting up data pipelines and AI pipelines as part of a dynamic and ambitious team. As a major link with the other technical teams, made up of more than 10 developers, the pipelines to be built will be integrated into Onepilot’s production environment. Collecting and formatting complex unstructured data is the key to the success of the AI algorithms on which Onepilot is relying to help its development.Missions:Challenge and improve our data architecture Build and manage a bidirectional integration framework to: Allow real-time retrieval of unstructured data from a range of customer toolsBack office, payment service providers, delivery tracking tools, etc.The tools may or may not be accessible via APIPerform actions in customer tools (for instance, refund a missing item, or send a prepared response)Based on AI recommendationsIn order to automate tickets processingOversee the management of data pipelines and data storage systems required for model training and inferenceCollect (thanks to the integration framework), store and standardize raw data from a multitude of sourcesEnsure data quality by implementing quality controls, tests and validation processesChallenge and improve our AI pipelineSupporting the transition from GCP to AWSDevelop and maintain CI/CD pipelines for automating the testing, integration, and deployment of AI modelsOptimize AI infrastructure for scalability and cost-effectivenessAbility to run a multitude of LLMs in a short space of timeParticipate in maintaining technical documentation within the team"}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "60K à 75K €", "company": "Lenstra", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "30", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["github"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/lenstra/jobs/data-engineer-lead-data-platforms_paris?q=557bf4ac9053418863fc5982a25786ef&o=4172ba25-0ee6-4a14-9c05-c16d71a56c2a", "description": "Descriptif du posteLenstra is currently helping multiple major companies (> 3 B$ revenue) setting up their self service Data Platforms. Our scope of work encompasses developing the Data Platform product vision taking into account our client’s strategic goals and existing technological environment, and then implementing the Data Platform including its deep integration with our client’s IT, security and legal requirements.In this context we are looking for passionate Data Engineers to join our teams (freelancers welcome), to help put in place self service tools for data practitioners working on our platforms. The scope of work includes providing as a service, data ingestions tools, orchestration tools and data transformation engines.You will have the opportunity to work on a state-of-the-art stack which includes tools such as GitHub actions, dbt, Terraform & Vault and various new open-source players such as Dagster.If you are a highly motivated individual with a passion for Data Engineering and are excited to build tools used by large teams, this is a great opportunity for you."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "60K à 75K €", "company": "Lenstra", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "30", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["github"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/lenstra/jobs/data-engineer-lead-data-platforms_paris?q=557bf4ac9053418863fc5982a25786ef&o=4172ba25-0ee6-4a14-9c05-c16d71a56c2a", "description": "Descriptif du posteLenstra is currently helping multiple major companies (> 3 B$ revenue) setting up their self service Data Platforms. Our scope of work encompasses developing the Data Platform product vision taking into account our client’s strategic goals and existing technological environment, and then implementing the Data Platform including its deep integration with our client’s IT, security and legal requirements.In this context we are looking for passionate Data Engineers to join our teams (freelancers welcome), to help put in place self service tools for data practitioners working on our platforms. The scope of work includes providing as a service, data ingestions tools, orchestration tools and data transformation engines.You will have the opportunity to work on a state-of-the-art stack which includes tools such as GitHub actions, dbt, Terraform & Vault and various new open-source players such as Dagster.If you are a highly motivated individual with a passion for Data Engineering and are excited to build tools used by large teams, this is a great opportunity for you."}, {"source": "welcometothejungle", "job_title": "Data Engineer - CDI (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Veesion", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-07", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "150", "creation_date": "2018", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "8M €", "proportion_female": "37", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalable"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["bigquery", "bigquery", "bigquery,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams:", "teams:", "teams"], "Other": ["seamlessly"], "EnSoftSkils": ["organization.as", "organization:chief"]}, "link": "https://www.welcometothejungle.com/fr/companies/veesion-1/jobs/data-engineer-cdi-h-f_paris?q=557bf4ac9053418863fc5982a25786ef&o=1ff052bc-3706-49cc-82d6-d9648c6a4192", "description": "Descriptif du postePlease apply directly on our career site right here.All applications submitted via Welcome will not be processedVeesion is at the forefront of in-store theft detection solutions, transforming how retailers protect their products and optimize their operations. Our technology combines advanced video analysis, AI-driven insights, and intuitive user experiences to deliver real-time prevention and actionable intelligence. As we expand, we’re seeking a Senior Data Engineer to play a critical role in scaling our data capabilities and empowering teams across the organization.As a Senior Data Engineer, you will play a pivotal role in shaping the future of our data ecosystem. You’ll lead the redesign of our BigQuery Data Warehouse and refine how data is leveraged across the company. This is an opportunity to rethink and elevate our existing architecture, ensuring it aligns seamlessly with evolving business needs. You’ll have the freedom to challenge current technical decisions, introduce best practices, and build scalable solutions from the ground up—making a lasting impact on our growth and success.Reporting to the Head of Data, you will collaborate with key stakeholders across the organization:Chief Executive Officer: Align on business objectives and strategic prioritiesBusiness Teams: Partnering with data analysts from finance, revenue operations, sales, customer success, and marketing to deliver actionable insights.Tech Team: Working alongside 10+ software engineers to integrate data from Veesion’s systems into our decision-making processes.TasksDesign and refine scalable data models: Ensure data models meet current and future business needs, optimizing for performance and maintainability.Maintain and scale our BigQuery Data Warehouse: Monitor and enhance warehouse performance to support growing data volumes and usage.Build and orchestrate efficient data pipelines: Use modern tools to create, schedule, and monitor data workflows that ensure timely and accurate data delivery.Collaborate with business teams: Work closely with analysts and stakeholders to identify, prioritize, and deliver datasets that drive decision-making.Foster a self-service data culture: Provide training and tools to enable teams to explore data independently while ensuring governance and consistency.Influence and evolve the tech stack: Our current stack includes BigQuery, dbt, Airbyte, Dagster, hightouch, and n8n—but we welcome your ideas to enhance and expand it."}, {"source": "welcometothejungle", "job_title": "Data Engineer - CDI (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Veesion", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-07", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "150", "creation_date": "2018", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "8M €", "proportion_female": "37", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalable"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["bigquery", "bigquery", "bigquery,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams:", "teams:", "teams"], "Other": ["seamlessly"], "EnSoftSkils": ["organization.as", "organization:chief"]}, "link": "https://www.welcometothejungle.com/fr/companies/veesion-1/jobs/data-engineer-cdi-h-f_paris?q=557bf4ac9053418863fc5982a25786ef&o=1ff052bc-3706-49cc-82d6-d9648c6a4192", "description": "Descriptif du postePlease apply directly on our career site right here.All applications submitted via Welcome will not be processedVeesion is at the forefront of in-store theft detection solutions, transforming how retailers protect their products and optimize their operations. Our technology combines advanced video analysis, AI-driven insights, and intuitive user experiences to deliver real-time prevention and actionable intelligence. As we expand, we’re seeking a Senior Data Engineer to play a critical role in scaling our data capabilities and empowering teams across the organization.As a Senior Data Engineer, you will play a pivotal role in shaping the future of our data ecosystem. You’ll lead the redesign of our BigQuery Data Warehouse and refine how data is leveraged across the company. This is an opportunity to rethink and elevate our existing architecture, ensuring it aligns seamlessly with evolving business needs. You’ll have the freedom to challenge current technical decisions, introduce best practices, and build scalable solutions from the ground up—making a lasting impact on our growth and success.Reporting to the Head of Data, you will collaborate with key stakeholders across the organization:Chief Executive Officer: Align on business objectives and strategic prioritiesBusiness Teams: Partnering with data analysts from finance, revenue operations, sales, customer success, and marketing to deliver actionable insights.Tech Team: Working alongside 10+ software engineers to integrate data from Veesion’s systems into our decision-making processes.TasksDesign and refine scalable data models: Ensure data models meet current and future business needs, optimizing for performance and maintainability.Maintain and scale our BigQuery Data Warehouse: Monitor and enhance warehouse performance to support growing data volumes and usage.Build and orchestrate efficient data pipelines: Use modern tools to create, schedule, and monitor data workflows that ensure timely and accurate data delivery.Collaborate with business teams: Work closely with analysts and stakeholders to identify, prioritize, and deliver datasets that drive decision-making.Foster a self-service data culture: Provide training and tools to enable teams to explore data independently while ensuring governance and consistency.Influence and evolve the tech stack: Our current stack includes BigQuery, dbt, Airbyte, Dagster, hightouch, and n8n—but we welcome your ideas to enhance and expand it."}, {"source": "welcometothejungle", "job_title": "Lead data engineer (f/h/n)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Hublo", "location": "Paris", "remote": "Télétravail total", "experience": null, "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "Application mobile, SaaS / Cloud Services, Santé, Recrutement", "company_size": "200", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "22 levés", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python"], "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": ["github.ton"], "OS": null, "DBMS": ["snowflake"], "SoftBigDataProcessing": null, "Automation": ["airflow"], "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["jira,"], "Other": ["ml.ton"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/hublo/jobs/lead-data-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=7d96421c-bd10-494d-8060-4a944e5bd74c", "description": "Descriptif du posteTu rejoins notre équipe data platform au sein du département Engineering, composée d’une 50aine de personnes, et organisée en équipe/squad.Tu nous rejoins dans le cadre du remplacement de notre lead data platform.La mission de ta squad: Construire et maintenir la data platform et ses pipelines de données afin de développer davantage notre approche self-service data. De l’ingestion de la donnée brute à la mise à disposition de Datamart avec de la donnée raffinée pour les utilisateurs finaux tout en les accompagnant dans leurs usages.Aujourd’hui le self-service c’est 6 datamarts composés de 53 tables permettant de parcourir toutes les données d’Hublo du CRM jusqu’à nos outils de productivité comme Jira, en passant bien sûr par les données produits.Sur l’année 2025 la squad data platform aura aussi pour mission de favoriser l’adoption de use-cases AI, au travers notamment de problématiques d’industrialisation de modèle de ML.Ton rôle : En tant que manager hands-on tu manages les data engineer de ta squad mais tu es aussi contributeur direct de ta squad.Notre Stack Technique : Airflow / Airbyte / dbt / Python / Snowflake / AWS / SQL / Hightouch / Secoda / Metabase / Terraform / Github.Ton impactTu co-construis la roadmap de ta squad en collaboration avec tes stakeholders et le Head of Data et tu es garant·e de sa livraison ;Tu participes à l’amélioration continue des processus, rituels, pratiques, et de notre stack technique;En tant que Manager, tu définis les objectifs individuels des membres de ton équipe, et t’assures de leur suivi & réalisation;Tu accompagnes et aides les membres de ton équipe à définir la meilleure solution technique;Tu accompagnes ton équipe dans leur quotidien : planification des tâches de l’équipe, aide sur remontée des problèmes, identification des blocages, et synthétisation du feedback pour assurer le succès de l’équipe;Rattaché·e à notre Head of Data, tu manages le développement professionnel, l’évolution d’expertise, et le développement des soft skills de tes équipes;Tu contribues directement à la delivery de ton équipe;Tu sensibilises et promeus les sujets liés à la qualité et à la gouvernance des données au sein de l’entreprise;"}, {"source": "welcometothejungle", "job_title": "Lead data engineer (f/h/n)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Hublo", "location": "Paris", "remote": "Télétravail total", "experience": null, "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "Application mobile, SaaS / Cloud Services, Santé, Recrutement", "company_size": "200", "creation_date": "2016", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "22 levés", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python"], "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": ["github.ton"], "OS": null, "DBMS": ["snowflake"], "SoftBigDataProcessing": null, "Automation": ["airflow"], "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["jira,"], "Other": ["ml.ton"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/hublo/jobs/lead-data-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=7d96421c-bd10-494d-8060-4a944e5bd74c", "description": "Descriptif du posteTu rejoins notre équipe data platform au sein du département Engineering, composée d’une 50aine de personnes, et organisée en équipe/squad.Tu nous rejoins dans le cadre du remplacement de notre lead data platform.La mission de ta squad: Construire et maintenir la data platform et ses pipelines de données afin de développer davantage notre approche self-service data. De l’ingestion de la donnée brute à la mise à disposition de Datamart avec de la donnée raffinée pour les utilisateurs finaux tout en les accompagnant dans leurs usages.Aujourd’hui le self-service c’est 6 datamarts composés de 53 tables permettant de parcourir toutes les données d’Hublo du CRM jusqu’à nos outils de productivité comme Jira, en passant bien sûr par les données produits.Sur l’année 2025 la squad data platform aura aussi pour mission de favoriser l’adoption de use-cases AI, au travers notamment de problématiques d’industrialisation de modèle de ML.Ton rôle : En tant que manager hands-on tu manages les data engineer de ta squad mais tu es aussi contributeur direct de ta squad.Notre Stack Technique : Airflow / Airbyte / dbt / Python / Snowflake / AWS / SQL / Hightouch / Secoda / Metabase / Terraform / Github.Ton impactTu co-construis la roadmap de ta squad en collaboration avec tes stakeholders et le Head of Data et tu es garant·e de sa livraison ;Tu participes à l’amélioration continue des processus, rituels, pratiques, et de notre stack technique;En tant que Manager, tu définis les objectifs individuels des membres de ton équipe, et t’assures de leur suivi & réalisation;Tu accompagnes et aides les membres de ton équipe à définir la meilleure solution technique;Tu accompagnes ton équipe dans leur quotidien : planification des tâches de l’équipe, aide sur remontée des problèmes, identification des blocages, et synthétisation du feedback pour assurer le succès de l’équipe;Rattaché·e à notre Head of Data, tu manages le développement professionnel, l’évolution d’expertise, et le développement des soft skills de tes équipes;Tu contribues directement à la delivery de ton équipe;Tu sensibilises et promeus les sujets liés à la qualité et à la gouvernance des données au sein de l’entreprise;"}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability", "scalable"], "DataBase": ["sql-based", "postgresql)", "mongodb,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["postgresql)"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ml"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/lead-data-engineer_nice_DORIA_V7R1Kke?q=557bf4ac9053418863fc5982a25786ef&o=da6b8be7-b271-4a39-b6ec-c7e9082ea09e", "description": "Descriptif du posteWe are looking for a Lead Data Engineer to take charge of designing and managing our data infrastructure. You will lead efforts in developing scalable and high-performance data models. You’ll oversee our ETL pipelines, data ingestion processes, and collaborate closely with data scientists to ensure their machine learning models are smoothly integrated into production. You will also play a key role in defining the infrastructure necessary for heterogeneous data ingestion, ML training processes and ML Ops, ensuring the right pipelines, monitoring, and automation are in place.Key Responsibilities:Lead the design and optimization of data models and infrastructure to support large-scale data processing.Oversee and manage the data layer architecture, currently built on Cube.dev and MongoDB, with a key objective to evaluate and potentially transition to an SQL-based system (e.g., PostgreSQL) for enhanced performance.Handle geospatial data management, ensuring efficient handling of location-based data for analysis, storage, and visualization.Build and maintain robust ETL pipelines and data ingestion streams that ensure high availability, reliability, and performance of data systems.Collaborate with the data science team to ensure the integration of machine learning models into production environments, focusing on efficient model deployment, monitoring, and iteration.Design and implement ML Ops infrastructure to support model training, experimentation, and deployment, including tracking, versioning, and scalability of training processes.Define and implement best practices for data governance, ensuring security, quality, and compliance.Evaluate and adopt new tools and technologies to improve data processing, with a focus on real-time data ingestion and scalable ML infrastructure.Provide leadership in shaping the future of our data architecture, ensuring it aligns with the company’s goals of sustainability and high-impact analytics."}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability", "scalable"], "DataBase": ["sql-based", "postgresql)", "mongodb,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["postgresql)"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ml"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/lead-data-engineer_nice_DORIA_V7R1Kke?q=557bf4ac9053418863fc5982a25786ef&o=da6b8be7-b271-4a39-b6ec-c7e9082ea09e", "description": "Descriptif du posteWe are looking for a Lead Data Engineer to take charge of designing and managing our data infrastructure. You will lead efforts in developing scalable and high-performance data models. You’ll oversee our ETL pipelines, data ingestion processes, and collaborate closely with data scientists to ensure their machine learning models are smoothly integrated into production. You will also play a key role in defining the infrastructure necessary for heterogeneous data ingestion, ML training processes and ML Ops, ensuring the right pipelines, monitoring, and automation are in place.Key Responsibilities:Lead the design and optimization of data models and infrastructure to support large-scale data processing.Oversee and manage the data layer architecture, currently built on Cube.dev and MongoDB, with a key objective to evaluate and potentially transition to an SQL-based system (e.g., PostgreSQL) for enhanced performance.Handle geospatial data management, ensuring efficient handling of location-based data for analysis, storage, and visualization.Build and maintain robust ETL pipelines and data ingestion streams that ensure high availability, reliability, and performance of data systems.Collaborate with the data science team to ensure the integration of machine learning models into production environments, focusing on efficient model deployment, monitoring, and iteration.Design and implement ML Ops infrastructure to support model training, experimentation, and deployment, including tracking, versioning, and scalability of training processes.Define and implement best practices for data governance, ensuring security, quality, and compliance.Evaluate and adopt new tools and technologies to improve data processing, with a focus on real-time data ingestion and scalable ML infrastructure.Provide leadership in shaping the future of our data architecture, ensuring it aligns with the company’s goals of sustainability and high-impact analytics."}, {"source": "welcometothejungle", "job_title": "ARCHITECTE DATA (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Hardis Group", "location": "Paris", "remote": "Télétravail non autorisé", "experience": null, "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "IT / Digital, Supply Chain, SaaS / Cloud Services", "company_size": "1500", "creation_date": "1984", "address": null, "average_age_of_employees": "38", "turnover_in_millions": "156 millions d'euros en 2022", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableau,"], "Statistics": null, "CloudComputing": ["azure,", "gcp,"], "DevTools": null, "OS": null, "DBMS": ["snowflake,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["environnementcloud.dans", "cloud", "cloud,"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/architecte-data-h-f_paris_HG_ab4OrNV?q=557bf4ac9053418863fc5982a25786ef&o=09c1d907-25ee-48c7-9878-2cb97b8ecfca", "description": "Descriptif du posteAu sein de notre Practice DATA et dans le cadre de notre forte croissance,nous recherchons un Architecte Data capable d’accompagner nos clientsdans l’élaboration et la mise en œuvre de leur stratégie data en environnementCloud.Dans ce contexte, vous serez amené(e) à réaliser des études amont visant àcollecter et cadrer les besoins, concevoir et déployer l’architecture deplates-formes Analytics / Big Data / IoT modernes en environnement Cloud tirantpartie des dernières avancées technologiques, et définir une trajectoirepermettant d’évoluer de l’architecture existante vers la cible avec le minimumd’impact sur l’activité business.Vous pourrez égalementêtre amené(e) à définir une stratégie de modernisation d’un parc deplates-formes BI / data obsolètes en les migrant sur le Cloud, ou encoreformaliser les principes d’une gouvernance Data solide pour nos clients.POURQUOI REJOINDRE NOTRE PRACTICEDATA?Être formé(e) en continu : notre Practice DATA a développé un programme solide de formations & certifications par le biais de nos partenariats : GCP, Azure, Snowflake, Talend, Tableau, DataGalaxy, etc…Intervenir sur des sujets variés et pointus : notre Practice DATA intervient dans de nombreux secteurs d’activité : Retail, Luxe, Assurances, Industrie, …) grâce à notre portefeuille de plus de 900 clients.Intégrer un groupe solide qui se donne de belles ambitions dans la DATA et participer activement à une aventure humaine passionnante avec les moyens de ces ambitionsIntégrer une équipe : notre practice, c’est avant tout une équipe à taille humaine bénéficiant de l’écosystème d’un grand groupeVotre quotidien en tant qu’ArchitecteData, vous interviendrez sur :- L’élaboration de la vision technologique de nos     clients- Le choix de solutions technologiques pertinentes     et adaptées au contexte de nos clients- Des missions de conception, d’implémentation ou     d’optimisation d’architecture data- L’industrialisation de projets Data- L’accompagnement de nos clients dans leurs     stratégies data et leur Data Gouvernance"}, {"source": "welcometothejungle", "job_title": "ARCHITECTE DATA (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Hardis Group", "location": "Paris", "remote": "Télétravail non autorisé", "experience": null, "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "IT / Digital, Supply Chain, SaaS / Cloud Services", "company_size": "1500", "creation_date": "1984", "address": null, "average_age_of_employees": "38", "turnover_in_millions": "156 millions d'euros en 2022", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableau,"], "Statistics": null, "CloudComputing": ["azure,", "gcp,"], "DevTools": null, "OS": null, "DBMS": ["snowflake,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["environnementcloud.dans", "cloud", "cloud,"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/hardis-group/jobs/architecte-data-h-f_paris_HG_ab4OrNV?q=557bf4ac9053418863fc5982a25786ef&o=09c1d907-25ee-48c7-9878-2cb97b8ecfca", "description": "Descriptif du posteAu sein de notre Practice DATA et dans le cadre de notre forte croissance,nous recherchons un Architecte Data capable d’accompagner nos clientsdans l’élaboration et la mise en œuvre de leur stratégie data en environnementCloud.Dans ce contexte, vous serez amené(e) à réaliser des études amont visant àcollecter et cadrer les besoins, concevoir et déployer l’architecture deplates-formes Analytics / Big Data / IoT modernes en environnement Cloud tirantpartie des dernières avancées technologiques, et définir une trajectoirepermettant d’évoluer de l’architecture existante vers la cible avec le minimumd’impact sur l’activité business.Vous pourrez égalementêtre amené(e) à définir une stratégie de modernisation d’un parc deplates-formes BI / data obsolètes en les migrant sur le Cloud, ou encoreformaliser les principes d’une gouvernance Data solide pour nos clients.POURQUOI REJOINDRE NOTRE PRACTICEDATA?Être formé(e) en continu : notre Practice DATA a développé un programme solide de formations & certifications par le biais de nos partenariats : GCP, Azure, Snowflake, Talend, Tableau, DataGalaxy, etc…Intervenir sur des sujets variés et pointus : notre Practice DATA intervient dans de nombreux secteurs d’activité : Retail, Luxe, Assurances, Industrie, …) grâce à notre portefeuille de plus de 900 clients.Intégrer un groupe solide qui se donne de belles ambitions dans la DATA et participer activement à une aventure humaine passionnante avec les moyens de ces ambitionsIntégrer une équipe : notre practice, c’est avant tout une équipe à taille humaine bénéficiant de l’écosystème d’un grand groupeVotre quotidien en tant qu’ArchitecteData, vous interviendrez sur :- L’élaboration de la vision technologique de nos     clients- Le choix de solutions technologiques pertinentes     et adaptées au contexte de nos clients- Des missions de conception, d’implémentation ou     d’optimisation d’architecture data- L’industrialisation de projets Data- L’accompagnement de nos clients dans leurs     stratégies data et leur Data Gouvernance"}, {"source": "welcometothejungle", "job_title": "Data Engineer (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "FEEDGY", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": null, "publication_date": "2024-12-09", "company_data": {"sector": "Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Intelligence artificielle / Machine Learning, Energie", "company_size": "93", "creation_date": "2014", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "24", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalability,"], "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams.", "teams"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/feedgy/jobs/data-engineer-h-f_paris?q=557bf4ac9053418863fc5982a25786ef&o=73310278-9e9c-4708-b3e6-e93370380f69", "description": "Descriptif du posteSolar PV plants convert solar energy to electricity. While operating, a large amount of data is created in the form of time series. The electrical variables describing the behavior of plants is directly influenced by the environmental variables. The electricity generated by these plants is either self-consumed or transported and distributed to the consumption points by the power grid and traded in the energy markets. In order to create services for our clients, we need to take advantage of all the data stream of the PV and electricity stakeholders and do a good usage of this data. The main goal of the Data Engineer is to contribute to expanding and optimizing our Data Platform, as well as optimizing data flow and collection for cross functional teams. Example of tasks include: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with other profiles and teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader."}, {"source": "welcometothejungle", "job_title": "Data Engineer (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "FEEDGY", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": null, "publication_date": "2024-12-09", "company_data": {"sector": "Bureau d'études et d'ingénierie, Ingénieries Spécialisées, Intelligence artificielle / Machine Learning, Energie", "company_size": "93", "creation_date": "2014", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "24", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalability,"], "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams.", "teams"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/feedgy/jobs/data-engineer-h-f_paris?q=557bf4ac9053418863fc5982a25786ef&o=73310278-9e9c-4708-b3e6-e93370380f69", "description": "Descriptif du posteSolar PV plants convert solar energy to electricity. While operating, a large amount of data is created in the form of time series. The electrical variables describing the behavior of plants is directly influenced by the environmental variables. The electricity generated by these plants is either self-consumed or transported and distributed to the consumption points by the power grid and traded in the energy markets. In order to create services for our clients, we need to take advantage of all the data stream of the PV and electricity stakeholders and do a good usage of this data. The main goal of the Data Engineer is to contribute to expanding and optimizing our Data Platform, as well as optimizing data flow and collection for cross functional teams. Example of tasks include: Create and maintain optimal data pipeline architecture Assemble large, complex data sets that meet functional / non-functional business requirements. Identify, design, and implement internal process improvements: automating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc. Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and AWS ‘big data’ technologies. Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics. Work with other profiles and teams to assist with data-related technical issues and support their data infrastructure needs. Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader."}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F", "contract_type": "CDI", "salary": "42K à 48K €", "company": "Infolegale", "location": "Lyon", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-12-04", "company_data": {"sector": "SaaS / Cloud Services, Big Data, Accompagnement d'entreprises", "company_size": "180", "creation_date": "2008", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "≈ 14 000 000 €", "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["python,"], "DataBase": ["sqldata", "mysql", "postgresql", "mongodb", "neo4jutilisation", "elasticsearch"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableaubases"], "Statistics": null, "CloudComputing": null, "DevTools": ["gitlabculture", "docker,"], "OS": null, "DBMS": ["mysql", "postgresql"], "SoftBigDataProcessing": null, "Automation": ["airflow,", "airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,"], "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/infolegale/jobs/data-engineer-h-f_lyon_INFOL_oxewe1p?q=557bf4ac9053418863fc5982a25786ef&o=b4ded576-4d8e-43f0-9cee-46c9f7229b24", "description": "Descriptif du posteAu sein de l’équipe IT, vous aurez pour missions la conception et le développement de pipelines de données, le maintien en conditions opérationnelles des flux existants, mais aussi de contribuer activement à l’optimisation de nos processus et solutions technologiques.A ce titre, vos tâches principales incluront :1. La conception de pipelines de données :Concevoir des pipelines de données robustes pour l’ingestion, le stockage, la transformation et l’orchestration de grandes quantités de données depuis diverses sources (sources internes et externes).Documenter la pipeline (processus, les flux de travail et les architectures des systèmes de données)2. Le développement de pipelines de données :Intégrer les données provenant de diverses sources internes et externes.Implémenter ou développer les opérations de transformation, enrichissement, normalisation, mise en qualité des données3. L’automatisation des flux, avec pour principes directeurs : la fiabilité, la performance, l’intégrité des données4. La surveillance et maintenance des flux :Mettre en place les dispositifs d’observabilité pour surveiller les pipelines de données et identifier les problèmes potentiels.Effectuer des opérations de maintenance préventive et corrective.5. La contribution à l’amélioration de notre mode de fonctionnementContribuer à la définition des architectures techniques cibles et à la mise en place des nouvelles briques de notre data stack (DLTHUB, DBT, Airflow, etc.)Collaborer avec l’équipe Data pour améliorer nos processus de fonctionnementNotre environnement :Culture Data importante (la Data est au cœur de nos produits)Langages de programmation : Python, SQLData Stack : DLTHub, DBT, Airflow, etc.Outils de visualisation et monitoring : Kibana, Grafana, TableauBases de données : MySQL / PostgreSQL / ElasticSearch / MongoDB / RedShift / Neo4jUtilisation de Docker, GITLABCulture du travail en équipe"}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F", "contract_type": "CDI", "salary": "42K à 48K €", "company": "Infolegale", "location": "Lyon", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-12-04", "company_data": {"sector": "SaaS / Cloud Services, Big Data, Accompagnement d'entreprises", "company_size": "180", "creation_date": "2008", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "≈ 14 000 000 €", "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["python,"], "DataBase": ["sqldata", "mysql", "postgresql", "mongodb", "neo4jutilisation", "elasticsearch"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableaubases"], "Statistics": null, "CloudComputing": null, "DevTools": ["gitlabculture", "docker,"], "OS": null, "DBMS": ["mysql", "postgresql"], "SoftBigDataProcessing": null, "Automation": ["airflow,", "airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,"], "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/infolegale/jobs/data-engineer-h-f_lyon_INFOL_oxewe1p?q=557bf4ac9053418863fc5982a25786ef&o=b4ded576-4d8e-43f0-9cee-46c9f7229b24", "description": "Descriptif du posteAu sein de l’équipe IT, vous aurez pour missions la conception et le développement de pipelines de données, le maintien en conditions opérationnelles des flux existants, mais aussi de contribuer activement à l’optimisation de nos processus et solutions technologiques.A ce titre, vos tâches principales incluront :1. La conception de pipelines de données :Concevoir des pipelines de données robustes pour l’ingestion, le stockage, la transformation et l’orchestration de grandes quantités de données depuis diverses sources (sources internes et externes).Documenter la pipeline (processus, les flux de travail et les architectures des systèmes de données)2. Le développement de pipelines de données :Intégrer les données provenant de diverses sources internes et externes.Implémenter ou développer les opérations de transformation, enrichissement, normalisation, mise en qualité des données3. L’automatisation des flux, avec pour principes directeurs : la fiabilité, la performance, l’intégrité des données4. La surveillance et maintenance des flux :Mettre en place les dispositifs d’observabilité pour surveiller les pipelines de données et identifier les problèmes potentiels.Effectuer des opérations de maintenance préventive et corrective.5. La contribution à l’amélioration de notre mode de fonctionnementContribuer à la définition des architectures techniques cibles et à la mise en place des nouvelles briques de notre data stack (DLTHUB, DBT, Airflow, etc.)Collaborer avec l’équipe Data pour améliorer nos processus de fonctionnementNotre environnement :Culture Data importante (la Data est au cœur de nos produits)Langages de programmation : Python, SQLData Stack : DLTHub, DBT, Airflow, etc.Outils de visualisation et monitoring : Kibana, Grafana, TableauBases de données : MySQL / PostgreSQL / ElasticSearch / MongoDB / RedShift / Neo4jUtilisation de Docker, GITLABCulture du travail en équipe"}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer/Architect", "contract_type": "CDI", "salary": "Non spécifié", "company": "ThreatMark", "location": "Brno", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2024-12-04", "company_data": {"sector": "FinTech / InsurTech", "company_size": "90", "creation_date": "2015", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": ["mlops"], "EnSoftSkils": ["information.collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/threatmark/jobs/senior-data-engineer_brno-stred?q=557bf4ac9053418863fc5982a25786ef&o=16433dfc-1e02-4a7e-aea3-00129bb503fa", "description": "Descriptif du posteThe MissionAs a Senior Data Engineer at ThreatMark, your primary mission will be to architect and maintain robust data infrastructure and pipelines that support our data-driven decision-making and advanced analytics. You will collaborate closely with our data analysts, data scientists, and engineering teams to ensure our data is precise, accessible, and meaningful, ultimately enhancing the quality of our products. Your work will enable ThreatMark to achieve its business objectives with confidence, backed by reliable and insightful data analysis.GeneralSeniority: Senior (5+ years of experience)Hire: Employee or ContractorEmployment Type: Full-time, Employee or ContractorPlace of work: Offices in Brno, Bratislava or Prague; Full Remote PossibleResponsibilitiesIn this role, you will:Data Lake Development:Build and maintain infrastructure for storage of structured and semi-structured multitenant data in Data Lake.Maintain and develop configuration of Data Lake-related AWS infrastructure and services.Develop and automate data ingestion, ETL processes and maintenance jobs.Create a layer of consolidated data to be used for data analysis and reporting.Data Quality and Integrity:Ensure high levels of data quality and integrity across all data sources and pipelines.Implement monitoring and alerting mechanisms to detect and address data issues promptly.Performance Optimization:Optimize data processing workflows for performance and efficiency.Address bottlenecks and ensure data pipelines can scale with increasing data volumes.Data Security and Compliance:Ensure compliance with relevant data protection regulations and standards.Implement data security measures to safeguard sensitive information.Collaboration and Support:Work closely with data analysts and data scientists to understand their data needs and ensure data availability.Provide support and guidance on best practices for writing ETL and data engineering tasks within the AWS environment and used technologies.Aid in MLOps processes.Automate data reports.Participation in data analysis and research welcomed.Product’s solution design and development (out of Data Lake scope)Participating on solution design and development of product’s components for streaming, processing and storing data."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer/Architect", "contract_type": "CDI", "salary": "Non spécifié", "company": "ThreatMark", "location": "Brno", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2024-12-04", "company_data": {"sector": "FinTech / InsurTech", "company_size": "90", "creation_date": "2015", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": ["mlops"], "EnSoftSkils": ["information.collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/threatmark/jobs/senior-data-engineer_brno-stred?q=557bf4ac9053418863fc5982a25786ef&o=16433dfc-1e02-4a7e-aea3-00129bb503fa", "description": "Descriptif du posteThe MissionAs a Senior Data Engineer at ThreatMark, your primary mission will be to architect and maintain robust data infrastructure and pipelines that support our data-driven decision-making and advanced analytics. You will collaborate closely with our data analysts, data scientists, and engineering teams to ensure our data is precise, accessible, and meaningful, ultimately enhancing the quality of our products. Your work will enable ThreatMark to achieve its business objectives with confidence, backed by reliable and insightful data analysis.GeneralSeniority: Senior (5+ years of experience)Hire: Employee or ContractorEmployment Type: Full-time, Employee or ContractorPlace of work: Offices in Brno, Bratislava or Prague; Full Remote PossibleResponsibilitiesIn this role, you will:Data Lake Development:Build and maintain infrastructure for storage of structured and semi-structured multitenant data in Data Lake.Maintain and develop configuration of Data Lake-related AWS infrastructure and services.Develop and automate data ingestion, ETL processes and maintenance jobs.Create a layer of consolidated data to be used for data analysis and reporting.Data Quality and Integrity:Ensure high levels of data quality and integrity across all data sources and pipelines.Implement monitoring and alerting mechanisms to detect and address data issues promptly.Performance Optimization:Optimize data processing workflows for performance and efficiency.Address bottlenecks and ensure data pipelines can scale with increasing data volumes.Data Security and Compliance:Ensure compliance with relevant data protection regulations and standards.Implement data security measures to safeguard sensitive information.Collaboration and Support:Work closely with data analysts and data scientists to understand their data needs and ensure data availability.Provide support and guidance on best practices for writing ETL and data engineering tasks within the AWS environment and used technologies.Aid in MLOps processes.Automate data reports.Participation in data analysis and research welcomed.Product’s solution design and development (out of Data Lake scope)Participating on solution design and development of product’s components for streaming, processing and storing data."}, {"source": "welcometothejungle", "job_title": "Database Engineer (Talent Pool)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Descartes & Mauss", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2024-11-27", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Stratégie", "company_size": "35", "creation_date": "2021", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["sql", "nosql", "sql", "postgresql", "postgresql", "nosql", "nosql", "nosql", "nosql", "nosql", "nosql", "nosql"], "DataAnalytics": null, "BigData": ["pyspark", "sparknlpmanage"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["gcp", "gcp"], "DevTools": ["github", "docker"], "OS": null, "DBMS": ["postgresql", "postgresql"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker"], "Collaboration": ["slack"], "Other": ["seamless", "seamless", "cloud", "cloud),", "cloud", "cloud.", "cloud", "cloud", "(ci/cd)", "ci/cd"], "EnSoftSkils": ["communication:", "initiative,"]}, "link": "https://www.welcometothejungle.com/fr/companies/descartes-mauss/jobs/data-database-engineer-talent-pool_paris?q=557bf4ac9053418863fc5982a25786ef&o=fe91af80-1884-459e-a3af-80688678f771", "description": "Descriptif du posteAt D&M, we’re always on the lookout for exceptional talent to join our dynamic team. This posting is part of our talent pool initiative, where we invite passionate professionals interested in technology and AI to connect with us. By submitting your application, you’ll be considered for future openings that align with your skills and aspirations. Join us in shaping the future of innovation!We are seeking a skilled Data/Database Engineer to join our team and take ownership of managing, optimizing, and monitoring our data infrastructure. The ideal candidate will have experience working with both SQL and NoSQL databases, building and maintaining ETL pipelines, and ensuring seamless data operations. This role requires expertise in cloud platforms (preferably Google Cloud), containerization, and continuous integration/continuous deployment (CI/CD) practices. The engineer will also ensure data security and compliance with regulations such as GDPR/CCPA. Your responsibilities include:Data Pipeline Management: Design, implement, and maintain scalable ETL processes using PySpark and SparkNLPManage data pipelines using GCP Workflows for scheduling and orchestrating jobsEnsure seamless integration and management of data systems to maintain continuous operation. Database Management: 1/ SQL Databases: Manage and optimize PostgreSQL databases for transactional data and relational database management. Regularly optimize queries and indexes to ensure high-performance operations. Implement automated backup and recovery solutions for PostgreSQL to prevent data loss. 2/ NoSQL Databases: Manage and optimize NoSQL datasets using Delta Lake for large-scale data. Ensure NoSQL infrastructure scalability to handle increasing data volumes. Infrastructure & Deployment: Deploy data applications on cloud platforms like Google Cloud. Utilize Docker for containerized environments and ensure consistency across development, testing, and production environments. Leverage GCP services for deployment, scaling, and monitoring of data applications. Set up and manage CI/CD pipelines using GitHub Actions to automate testing, deployment, and version control. Monitoring & Performance Optimization: Monitor data processing systems for latency, throughput, and error rates to ensure optimal performance. Ensure data quality by regularly checking for consistency, completeness, and accuracy across databases and pipelines. Implement centralized logging using Google Cloud Logging to aggregate logs from multiple sources. Security & Compliance: Ensure the encryption of data both at rest and in transit. Implement role-based access control (RBAC) to secure data and model endpoints. Maintain compliance with regulations such as GDPR and CCPA, including detailed audit logging for model training and data access. Documentation & Communication: Document API endpoints and data pipelines using tools like Swagger for ease of maintenance and onboarding. Provide data flow diagrams, ETL process documentation, and data schema explanations. Set up alerts using Google Cloud Monitoring and Slack for real-time issue notifications. Generate and share performance reports to keep stakeholders informed and facilitate data-driven decision-making."}, {"source": "welcometothejungle", "job_title": "Database Engineer (Talent Pool)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Descartes & Mauss", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2024-11-27", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Digital Marketing / Data Marketing, Stratégie", "company_size": "35", "creation_date": "2021", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["sql", "nosql", "sql", "postgresql", "postgresql", "nosql", "nosql", "nosql", "nosql", "nosql", "nosql", "nosql"], "DataAnalytics": null, "BigData": ["pyspark", "sparknlpmanage"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["gcp", "gcp"], "DevTools": ["github", "docker"], "OS": null, "DBMS": ["postgresql", "postgresql"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker"], "Collaboration": ["slack"], "Other": ["seamless", "seamless", "cloud", "cloud),", "cloud", "cloud.", "cloud", "cloud", "(ci/cd)", "ci/cd"], "EnSoftSkils": ["communication:", "initiative,"]}, "link": "https://www.welcometothejungle.com/fr/companies/descartes-mauss/jobs/data-database-engineer-talent-pool_paris?q=557bf4ac9053418863fc5982a25786ef&o=fe91af80-1884-459e-a3af-80688678f771", "description": "Descriptif du posteAt D&M, we’re always on the lookout for exceptional talent to join our dynamic team. This posting is part of our talent pool initiative, where we invite passionate professionals interested in technology and AI to connect with us. By submitting your application, you’ll be considered for future openings that align with your skills and aspirations. Join us in shaping the future of innovation!We are seeking a skilled Data/Database Engineer to join our team and take ownership of managing, optimizing, and monitoring our data infrastructure. The ideal candidate will have experience working with both SQL and NoSQL databases, building and maintaining ETL pipelines, and ensuring seamless data operations. This role requires expertise in cloud platforms (preferably Google Cloud), containerization, and continuous integration/continuous deployment (CI/CD) practices. The engineer will also ensure data security and compliance with regulations such as GDPR/CCPA. Your responsibilities include:Data Pipeline Management: Design, implement, and maintain scalable ETL processes using PySpark and SparkNLPManage data pipelines using GCP Workflows for scheduling and orchestrating jobsEnsure seamless integration and management of data systems to maintain continuous operation. Database Management: 1/ SQL Databases: Manage and optimize PostgreSQL databases for transactional data and relational database management. Regularly optimize queries and indexes to ensure high-performance operations. Implement automated backup and recovery solutions for PostgreSQL to prevent data loss. 2/ NoSQL Databases: Manage and optimize NoSQL datasets using Delta Lake for large-scale data. Ensure NoSQL infrastructure scalability to handle increasing data volumes. Infrastructure & Deployment: Deploy data applications on cloud platforms like Google Cloud. Utilize Docker for containerized environments and ensure consistency across development, testing, and production environments. Leverage GCP services for deployment, scaling, and monitoring of data applications. Set up and manage CI/CD pipelines using GitHub Actions to automate testing, deployment, and version control. Monitoring & Performance Optimization: Monitor data processing systems for latency, throughput, and error rates to ensure optimal performance. Ensure data quality by regularly checking for consistency, completeness, and accuracy across databases and pipelines. Implement centralized logging using Google Cloud Logging to aggregate logs from multiple sources. Security & Compliance: Ensure the encryption of data both at rest and in transit. Implement role-based access control (RBAC) to secure data and model endpoints. Maintain compliance with regulations such as GDPR and CCPA, including detailed audit logging for model training and data access. Documentation & Communication: Document API endpoints and data pipelines using tools like Swagger for ease of maintenance and onboarding. Provide data flow diagrams, ETL process documentation, and data schema explanations. Set up alerts using Google Cloud Monitoring and Slack for real-time issue notifications. Generate and share performance reports to keep stakeholders informed and facilitate data-driven decision-making."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "PayXpert", "location": "Barcelona", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +3", "publication_date": "2024-11-26", "company_data": {"sector": "Transaction Services, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "109", "creation_date": "2010", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams", "teams"], "Other": ["seamlessly"], "EnSoftSkils": ["processes.leadership", "collaboration", "projects.collaboration:"]}, "link": "https://www.welcometothejungle.com/fr/companies/payxpert/jobs/senior-data-engineer_barcelona?q=557bf4ac9053418863fc5982a25786ef&o=167e6db3-6990-48fb-bb20-1fed7d930a74", "description": "Descriptif du posteAbout the roleOur Senior Data Engineer develops and maintains scalable data systems that enable real-time information for reporting, analytics, and actionable insights. This role focuses on building secure and efficient data infrastructure capable of managing high transaction volumes while collaborating with cross-functional teams to foster efficiency and elevate professionalism within the team.Essential Duties & ResponsibilitiesData Infrastructure Development: Design, develop, and maintain robust data pipelines and ETL processes to handle large-scale structured and unstructured data.Data Scraping and Extraction: Create and optimize data scraping solutions to collect high-quality job data from multiple sources, ensuring scalability and accuracy.Data Quality Assurance: Implement validation and monitoring mechanisms to uphold data integrity, accuracy, and reliability.Performance Optimization: Analyse system performance, resolve bottlenecks, and address scaling challenges within the data infrastructure.Integration and Deployment: Collaborate with cross-functional teams to deploy automation models efficiently and seamlessly into production environments.Technology Evaluation: Stay up-to-date with emerging technologies and best practices, recommending and implementing tools and methodologies to enhance our processes.Leadership Role: Act as a key reference within the team to support the professional growth of data analysts, enhancing their skills through collaboration on assigned projects.Collaboration: Partner closely with Treasury, Accounting, Operations and BI teams to understand data requirements and deliver tailored technical solutions.Documentation and Standards: Develop and maintain comprehensive documentation for data pipelines, systems architecture, and processes, ensuring compliance with industry standards."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "PayXpert", "location": "Barcelona", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +3", "publication_date": "2024-11-26", "company_data": {"sector": "Transaction Services, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "109", "creation_date": "2010", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams", "teams"], "Other": ["seamlessly"], "EnSoftSkils": ["processes.leadership", "collaboration", "projects.collaboration:"]}, "link": "https://www.welcometothejungle.com/fr/companies/payxpert/jobs/senior-data-engineer_barcelona?q=557bf4ac9053418863fc5982a25786ef&o=167e6db3-6990-48fb-bb20-1fed7d930a74", "description": "Descriptif du posteAbout the roleOur Senior Data Engineer develops and maintains scalable data systems that enable real-time information for reporting, analytics, and actionable insights. This role focuses on building secure and efficient data infrastructure capable of managing high transaction volumes while collaborating with cross-functional teams to foster efficiency and elevate professionalism within the team.Essential Duties & ResponsibilitiesData Infrastructure Development: Design, develop, and maintain robust data pipelines and ETL processes to handle large-scale structured and unstructured data.Data Scraping and Extraction: Create and optimize data scraping solutions to collect high-quality job data from multiple sources, ensuring scalability and accuracy.Data Quality Assurance: Implement validation and monitoring mechanisms to uphold data integrity, accuracy, and reliability.Performance Optimization: Analyse system performance, resolve bottlenecks, and address scaling challenges within the data infrastructure.Integration and Deployment: Collaborate with cross-functional teams to deploy automation models efficiently and seamlessly into production environments.Technology Evaluation: Stay up-to-date with emerging technologies and best practices, recommending and implementing tools and methodologies to enhance our processes.Leadership Role: Act as a key reference within the team to support the professional growth of data analysts, enhancing their skills through collaboration on assigned projects.Collaboration: Partner closely with Treasury, Accounting, Operations and BI teams to understand data requirements and deliver tailored technical solutions.Documentation and Standards: Develop and maintain comprehensive documentation for data pipelines, systems architecture, and processes, ensuring compliance with industry standards."}, {"source": "welcometothejungle", "job_title": "Data Engineer confirmé H/F/X", "contract_type": "CDI", "salary": "Non spécifié", "company": "Eleven Labs", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-14", "company_data": {"sector": "Logiciels, IT / Digital, Audit", "company_size": "100", "creation_date": "2011", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f-x_paris_EL_xw9jjMm?q=557bf4ac9053418863fc5982a25786ef&o=17e1d47d-cbc7-40a9-b398-469df0250c86", "description": "Descriptif du posteSeras-tu notre furtur.e Data Engineer !Un peu de contexte☝️ De plus en plus de nos consultants s’intéressent de près au sujet de la Data, ce qui nous a poussé à explorer ces problématiques chez nos clients et de constater un besoin fort d’accompagnement de leur part.Nous recherchons donc la personne qui rejoindra notre escouade Data, qui dispose de 5 ans d’expérience sur du data Engineering."}, {"source": "welcometothejungle", "job_title": "Data Engineer confirmé H/F/X", "contract_type": "CDI", "salary": "Non spécifié", "company": "Eleven Labs", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-14", "company_data": {"sector": "Logiciels, IT / Digital, Audit", "company_size": "100", "creation_date": "2011", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/eleven-labs/jobs/data-engineer-h-f-x_paris_EL_xw9jjMm?q=557bf4ac9053418863fc5982a25786ef&o=17e1d47d-cbc7-40a9-b398-469df0250c86", "description": "Descriptif du posteSeras-tu notre furtur.e Data Engineer !Un peu de contexte☝️ De plus en plus de nos consultants s’intéressent de près au sujet de la Data, ce qui nous a poussé à explorer ces problématiques chez nos clients et de constater un besoin fort d’accompagnement de leur part.Nous recherchons donc la personne qui rejoindra notre escouade Data, qui dispose de 5 ans d’expérience sur du data Engineering."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer / Azure (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Micropole", "location": "Villeurbanne", "remote": "Télétravail non renseigné", "experience": "> 7", "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "IT / Digital", "company_size": "1200", "creation_date": "1987", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "142 millions d'€", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["azure", "azure"], "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/senior-data-engineer-azure-h-f_villeurbanne?q=557bf4ac9053418863fc5982a25786ef&o=69a0033e-ae60-40d9-a751-d691b061e8e3", "description": "Descriptif du posteEn résumé :  Poste : Senior Data Engineer / Azure F/HSecteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l’IndustrieLocalité : LyonType de contrat : CDINiveau d’expérience : au moins 3 ans    Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez Senior Data Engineer / Azure pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !    Dans vos missions quotidiennes, vous serez amené(e) à :     Apporter      votre expertise à nos clients pour garantir une valeur ajoutée rigoureuse      et innovante  Participer      activement à la réalisation technique des projets de nos clients  Accompagner      et conseiller les clients sur les meilleures pratiques, les technologies      et outils les plus adaptés au contexte.  Réaliser      des présentations, démonstrations, POC ou Pilotes pour mettre en lumière      les recommandations technologiques.  Être      constamment en veille technologique  Transférer      des compétences spécifiques aux équipes techniques de nos clients "}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer / Azure (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Micropole", "location": "Villeurbanne", "remote": "Télétravail non renseigné", "experience": "> 7", "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "IT / Digital", "company_size": "1200", "creation_date": "1987", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "142 millions d'€", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["azure", "azure"], "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/senior-data-engineer-azure-h-f_villeurbanne?q=557bf4ac9053418863fc5982a25786ef&o=69a0033e-ae60-40d9-a751-d691b061e8e3", "description": "Descriptif du posteEn résumé :  Poste : Senior Data Engineer / Azure F/HSecteur de l'entreprise : experts conseil dans les secteurs de la banque-assurance, le luxe-retail et l’IndustrieLocalité : LyonType de contrat : CDINiveau d’expérience : au moins 3 ans    Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data driven et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez Senior Data Engineer / Azure pour nos clients grands-comptes dans les secteurs de le luxe/retail, la banque/assurance et l’industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !    Dans vos missions quotidiennes, vous serez amené(e) à :     Apporter      votre expertise à nos clients pour garantir une valeur ajoutée rigoureuse      et innovante  Participer      activement à la réalisation technique des projets de nos clients  Accompagner      et conseiller les clients sur les meilleures pratiques, les technologies      et outils les plus adaptés au contexte.  Réaliser      des présentations, démonstrations, POC ou Pilotes pour mettre en lumière      les recommandations technologiques.  Être      constamment en veille technologique  Transférer      des compétences spécifiques aux équipes techniques de nos clients "}, {"source": "welcometothejungle", "job_title": "Data Engineer expérimenté·e", "contract_type": "CDI", "salary": "50K à 60K €", "company": "Modeo", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-31", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "20", "creation_date": "2019", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "1 500 000", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/modeo/jobs/data-engineer-experimente-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=7f779ec4-9c90-4b43-9633-ccdf502caf03", "description": "Descriptif du posteModeo est un groupement d’experts en Data Engineering, animé par une mission : “Master The Data Engineering Landscape”.Le Data Engineering est devenu un véritable défi pour les entreprises : un domaine complexe, évolutif et marqué par des pratiques encore disparates.Quelques problématiques récurrentes :Quels sont les outils les plus pertinents pour chaque brique d’une Data Platform (ingestion, orchestration, transformation, stockage, activation, observabilité) ?Quelles pratiques DataOps mettre en place pour faciliter la self-BI dans une organisation DataMesh ?Quelles sont les bonnes pratiques à respecter en déployant une nouvelle solution (compliance, code quality, FinOps / GreenOps…)Nous nous appuyons principalement sur la Modern Data Stack pour relever ces défis. En complément, voici comment nous concrétisons notre mission ambitieuse :Nous plongeons au cœur des problématiques de nos clients – startups, scaleups, grands comptes, PME – pour comprendre ce qui fonctionne… et ce qui échoue.Nous développons des outils sur-mesure, comme des modules d’observabilité pour le GreenOps ou des assistants GenAI spécifiques aux Data Engineers.Nous collaborons avec les éditeurs de solutions.Nous animons des formations et des retours d’expérience, favorisant la montée en compétences des équipes et la diffusion des meilleures pratiques.Dans cette optique, nous souhaitons accueillir un·e Data Engineer expérimenté·e pour intervenir chez nos clients et contribuer au développement de Modeo.En rejoignant une équipe d’experts passionnés en pleine croissance, vous participerez à des projets variés et stimulants, offrant l’opportunité de relever des défis techniques majeurs, d’explorer de nouvelles solutions, et de monter en compétences tout en prenant des responsabilités.En tant que Senior Data Engineer, vous travaillerez sur l’ensemble des outils de la Modern Data Stack, sur une grande variété de projets comprenant la mise en place de Data Platforms, le développement d’applications data avancées et la mise en place de stratégie DataOps. Au cours de ces projets, vous serez régulièrement amené·e à travailler avec des équipes métier et à présenter et vulgariser votre travail à des décisionnaires.En plus de cela, vous serez en charge de piloter des missions et de manager des équipes.Vos responsabilités seront les suivantes :Mettre en place des infrastructures de données pour des clients ou des projets de Modeo, en collaboration avec d’autres membres de l’équipeDévelopper et optimiser les flux de données depuis l’extraction de données brutes jusqu’à leur activationDéployer des solutions data chez nos clientsTravailler avec des équipes métier pour comprendre et définir leurs besoins puis leur mettre à disposition des solutions adaptéesMettre en place les bonnes pratiques de DataOps au sein des entreprisesEncadrer des projets internes et accompagner nos Data Engineers dans leur montée en compétencesGérer des projets Data, de leur planification à leur livraison"}, {"source": "welcometothejungle", "job_title": "Data Engineer expérimenté·e", "contract_type": "CDI", "salary": "50K à 60K €", "company": "Modeo", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-31", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "20", "creation_date": "2019", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "1 500 000", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/modeo/jobs/data-engineer-experimente-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=7f779ec4-9c90-4b43-9633-ccdf502caf03", "description": "Descriptif du posteModeo est un groupement d’experts en Data Engineering, animé par une mission : “Master The Data Engineering Landscape”.Le Data Engineering est devenu un véritable défi pour les entreprises : un domaine complexe, évolutif et marqué par des pratiques encore disparates.Quelques problématiques récurrentes :Quels sont les outils les plus pertinents pour chaque brique d’une Data Platform (ingestion, orchestration, transformation, stockage, activation, observabilité) ?Quelles pratiques DataOps mettre en place pour faciliter la self-BI dans une organisation DataMesh ?Quelles sont les bonnes pratiques à respecter en déployant une nouvelle solution (compliance, code quality, FinOps / GreenOps…)Nous nous appuyons principalement sur la Modern Data Stack pour relever ces défis. En complément, voici comment nous concrétisons notre mission ambitieuse :Nous plongeons au cœur des problématiques de nos clients – startups, scaleups, grands comptes, PME – pour comprendre ce qui fonctionne… et ce qui échoue.Nous développons des outils sur-mesure, comme des modules d’observabilité pour le GreenOps ou des assistants GenAI spécifiques aux Data Engineers.Nous collaborons avec les éditeurs de solutions.Nous animons des formations et des retours d’expérience, favorisant la montée en compétences des équipes et la diffusion des meilleures pratiques.Dans cette optique, nous souhaitons accueillir un·e Data Engineer expérimenté·e pour intervenir chez nos clients et contribuer au développement de Modeo.En rejoignant une équipe d’experts passionnés en pleine croissance, vous participerez à des projets variés et stimulants, offrant l’opportunité de relever des défis techniques majeurs, d’explorer de nouvelles solutions, et de monter en compétences tout en prenant des responsabilités.En tant que Senior Data Engineer, vous travaillerez sur l’ensemble des outils de la Modern Data Stack, sur une grande variété de projets comprenant la mise en place de Data Platforms, le développement d’applications data avancées et la mise en place de stratégie DataOps. Au cours de ces projets, vous serez régulièrement amené·e à travailler avec des équipes métier et à présenter et vulgariser votre travail à des décisionnaires.En plus de cela, vous serez en charge de piloter des missions et de manager des équipes.Vos responsabilités seront les suivantes :Mettre en place des infrastructures de données pour des clients ou des projets de Modeo, en collaboration avec d’autres membres de l’équipeDévelopper et optimiser les flux de données depuis l’extraction de données brutes jusqu’à leur activationDéployer des solutions data chez nos clientsTravailler avec des équipes métier pour comprendre et définir leurs besoins puis leur mettre à disposition des solutions adaptéesMettre en place les bonnes pratiques de DataOps au sein des entreprisesEncadrer des projets internes et accompagner nos Data Engineers dans leur montée en compétencesGérer des projets Data, de leur planification à leur livraison"}, {"source": "welcometothejungle", "job_title": "Analytics Engineer H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Wewyse", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-15", "company_data": {"sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation", "company_size": "90", "creation_date": "2019", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/wewyse/jobs/analytics-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=d1af7033-e8e9-4581-85ec-c984078f603e", "description": "Descriptif du posteWewyse est un cabinet de conseil spécialisé en Data et en Intelligence Artificielle. C’est aussi et surtout une communauté de passionnés partageant l’ambition de grandir ensemble et d’ouvrir le champ des possibles dans leurs domaines.Si vous pensez que la Data et l’Intelligence Artificielle ont beaucoup à offrir au monde de demain, et si vous souhaitez apporter votre contribution à ce monde, avec humilité et enthousiasme, alors vous êtes un Wyser en puissance.Être Analytics Engineer chez Wewyse, c’est :Intégrer une communauté d’experts Data passionnés, toujours en quête de nouvelles solutions innovantes.Recevoir et partager des connaissances, lors de nombreux événements internes, tout en acquérant constamment de nouvelles compétences.Travailler sur des projets techniques et business à forte valeur ajoutée, souvent dans un contexte international, avec des enjeux stratégiques importants dans des secteurs variés (retail, énergie, médias, transports, banque, assurance…).Allier les compétences d’un Data Engineer et d’un Data Analyst : construire et automatiser des pipelines de données tout en collaborant avec les équipes analytiques pour fournir des insights pertinents et exploitables.Transformer des données brutes en modèles analytiques réutilisables, en utilisant des outils comme SQL et DBT.Optimiser les processus de transformation des données pour garantir la qualité, la fiabilité et l’accessibilité des données à travers des pipelines automatisés.Collaborer avec des Data Analysts pour comprendre les besoins business, anticiper les enjeux et fournir des données prêtes à l’emploi.Participer à des projets innovants et impactants au sein de notre Datalab, avec d’autres Wysers, des partenaires académiques et des startups, pour exprimer vos idées et valeurs.S’impliquer dans le développement de Wewyse, en participant à des initiatives internes : recrutement, formations, masterclasses, avant-vente business, développement de partenariats…Être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles, avec un budget dédié.Faire partie de la famille Wemanity, bénéficier d’événements réguliers (voyage annuel, talks, afterworks…) et accéder à de nombreuses opportunités de carrière au sein du groupe."}, {"source": "welcometothejungle", "job_title": "Analytics Engineer H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Wewyse", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-15", "company_data": {"sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation", "company_size": "90", "creation_date": "2019", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["sql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/wewyse/jobs/analytics-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=d1af7033-e8e9-4581-85ec-c984078f603e", "description": "Descriptif du posteWewyse est un cabinet de conseil spécialisé en Data et en Intelligence Artificielle. C’est aussi et surtout une communauté de passionnés partageant l’ambition de grandir ensemble et d’ouvrir le champ des possibles dans leurs domaines.Si vous pensez que la Data et l’Intelligence Artificielle ont beaucoup à offrir au monde de demain, et si vous souhaitez apporter votre contribution à ce monde, avec humilité et enthousiasme, alors vous êtes un Wyser en puissance.Être Analytics Engineer chez Wewyse, c’est :Intégrer une communauté d’experts Data passionnés, toujours en quête de nouvelles solutions innovantes.Recevoir et partager des connaissances, lors de nombreux événements internes, tout en acquérant constamment de nouvelles compétences.Travailler sur des projets techniques et business à forte valeur ajoutée, souvent dans un contexte international, avec des enjeux stratégiques importants dans des secteurs variés (retail, énergie, médias, transports, banque, assurance…).Allier les compétences d’un Data Engineer et d’un Data Analyst : construire et automatiser des pipelines de données tout en collaborant avec les équipes analytiques pour fournir des insights pertinents et exploitables.Transformer des données brutes en modèles analytiques réutilisables, en utilisant des outils comme SQL et DBT.Optimiser les processus de transformation des données pour garantir la qualité, la fiabilité et l’accessibilité des données à travers des pipelines automatisés.Collaborer avec des Data Analysts pour comprendre les besoins business, anticiper les enjeux et fournir des données prêtes à l’emploi.Participer à des projets innovants et impactants au sein de notre Datalab, avec d’autres Wysers, des partenaires académiques et des startups, pour exprimer vos idées et valeurs.S’impliquer dans le développement de Wewyse, en participant à des initiatives internes : recrutement, formations, masterclasses, avant-vente business, développement de partenariats…Être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles, avec un budget dédié.Faire partie de la famille Wemanity, bénéficier d’événements réguliers (voyage annuel, talks, afterworks…) et accéder à de nombreuses opportunités de carrière au sein du groupe."}, {"source": "welcometothejungle", "job_title": "Senior Machine Learning Engineer", "contract_type": "CDI", "salary": "65K à 70K €", "company": "OCUS", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-14", "company_data": {"sector": "Intelligence artificielle / Machine Learning", "company_size": "45", "creation_date": "2016", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["(mlops)", "ai/ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ocus/jobs/senior-machine-learning-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=38d06b38-a1b4-4352-ab16-3834bb93eb8d", "description": "Descriptif du posteWe are seeking a highly skilled AI Engineer with deep expertise in Machine Learning Operations (MLOps) to join our innovative technology team.The ideal candidate will combine advanced technical skills in AI/ML with robust infrastructure and deployment capabilities."}, {"source": "welcometothejungle", "job_title": "Senior Machine Learning Engineer", "contract_type": "CDI", "salary": "65K à 70K €", "company": "OCUS", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-14", "company_data": {"sector": "Intelligence artificielle / Machine Learning", "company_size": "45", "creation_date": "2016", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["(mlops)", "ai/ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ocus/jobs/senior-machine-learning-engineer_paris?q=557bf4ac9053418863fc5982a25786ef&o=38d06b38-a1b4-4352-ab16-3834bb93eb8d", "description": "Descriptif du posteWe are seeking a highly skilled AI Engineer with deep expertise in Machine Learning Operations (MLOps) to join our innovative technology team.The ideal candidate will combine advanced technical skills in AI/ML with robust infrastructure and deployment capabilities."}, {"source": "welcometothejungle", "job_title": "Data Engineer Confirmé.e", "contract_type": "CDI", "salary": "Non spécifié", "company": "JAKALA FRANCE SAS", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "Digital Marketing / Data Marketing, Big Data, E-commerce", "company_size": "150", "creation_date": "2000", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "15", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scalabilité,"], "DataBase": ["postgresql)connaissance", "postgresqllakehouse"], "DataAnalytics": ["(pandas,"], "BigData": ["spark", "(pyspark,", "databricks,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure),", "gcp"], "DevTools": ["digitales"], "OS": null, "DBMS": ["postgresql)connaissance", "postgresqllakehouse", "snowflake,", "snowflake,"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": ["(terraform)expérience"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": ["mle/mlops", "uml,", "cloud", "cloud", "cloud"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-confirme-cdi-paris_paris?q=557bf4ac9053418863fc5982a25786ef&o=5289e6f3-19c2-40cc-b99a-d2671d6eff50", "description": "Descriptif du posteAu sein de notre DataLab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à son évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec vos pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager votre savoir-faire entre les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big DataAssurer une veille technologique et savoir mener à bien un projet de R&DTu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement: :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ETL : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse : Delta LakeConnaissance message broker, RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"}, {"source": "welcometothejungle", "job_title": "Data Engineer Confirmé.e", "contract_type": "CDI", "salary": "Non spécifié", "company": "JAKALA FRANCE SAS", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "Digital Marketing / Data Marketing, Big Data, E-commerce", "company_size": "150", "creation_date": "2000", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "15", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scalabilité,"], "DataBase": ["postgresql)connaissance", "postgresqllakehouse"], "DataAnalytics": ["(pandas,"], "BigData": ["spark", "(pyspark,", "databricks,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure),", "gcp"], "DevTools": ["digitales"], "OS": null, "DBMS": ["postgresql)connaissance", "postgresqllakehouse", "snowflake,", "snowflake,"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": ["(terraform)expérience"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": ["mle/mlops", "uml,", "cloud", "cloud", "cloud"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-confirme-cdi-paris_paris?q=557bf4ac9053418863fc5982a25786ef&o=5289e6f3-19c2-40cc-b99a-d2671d6eff50", "description": "Descriptif du posteAu sein de notre DataLab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu es impliqué.e dans la prise de décisions liée aux solutions Data et à son évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec vos pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager votre savoir-faire entre les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big DataAssurer une veille technologique et savoir mener à bien un projet de R&DTu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement: :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ETL : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse : Delta LakeConnaissance message broker, RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"}, {"source": "welcometothejungle", "job_title": "CDI - Data Engineer Senior - PARIS/LYON", "contract_type": "CDI", "salary": "Non spécifié", "company": "advizeo", "location": "Paris, Lyon", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "Logiciels, Big Data, Energie, SocialTech / GreenTech", "company_size": "120", "creation_date": "2015", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "13 ", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml"], "EnSoftSkils": ["production.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/advizeo/jobs/cdi-data-engineer-senior-paris-lyon?q=557bf4ac9053418863fc5982a25786ef&o=d56a6cd6-cd42-48e0-a4db-be48247dc490", "description": "Descriptif du posteEn tant que Data Engineer Senior, vous jouerez un rôle clé dans la conception et la mise en œuvre de solutions data avancées. Vos responsabilités incluront :Industrialisation et déploiement : Assurer l’industrialisation et le déploiement des modèles de machine learning développés par les data scientists.Pipelines data : Concevoir, maintenir et optimiser des pipelines de données robustes, scalables et performants.Production ML : Améliorer les pratiques d’intégration et de monitoring des modèles de machine learning, avec une forte orientation production.Collaboration : Travailler en étroite collaboration avec les développeurs full stack pour intégrer les outils data dans notre solution SaaS Savee, garantissant leur visibilité et leur utilité pour les utilisateurs finaux.Innovation technique : Proposer des solutions techniques innovantes pour résoudre des problématiques complexes d’analyse et de traitement des données."}, {"source": "welcometothejungle", "job_title": "CDI - Data Engineer Senior - PARIS/LYON", "contract_type": "CDI", "salary": "Non spécifié", "company": "advizeo", "location": "Paris, Lyon", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "Logiciels, Big Data, Energie, SocialTech / GreenTech", "company_size": "120", "creation_date": "2015", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "13 ", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml"], "EnSoftSkils": ["production.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/advizeo/jobs/cdi-data-engineer-senior-paris-lyon?q=557bf4ac9053418863fc5982a25786ef&o=d56a6cd6-cd42-48e0-a4db-be48247dc490", "description": "Descriptif du posteEn tant que Data Engineer Senior, vous jouerez un rôle clé dans la conception et la mise en œuvre de solutions data avancées. Vos responsabilités incluront :Industrialisation et déploiement : Assurer l’industrialisation et le déploiement des modèles de machine learning développés par les data scientists.Pipelines data : Concevoir, maintenir et optimiser des pipelines de données robustes, scalables et performants.Production ML : Améliorer les pratiques d’intégration et de monitoring des modèles de machine learning, avec une forte orientation production.Collaboration : Travailler en étroite collaboration avec les développeurs full stack pour intégrer les outils data dans notre solution SaaS Savee, garantissant leur visibilité et leur utilité pour les utilisateurs finaux.Innovation technique : Proposer des solutions techniques innovantes pour résoudre des problématiques complexes d’analyse et de traitement des données."}, {"source": "welcometothejungle", "job_title": "Data Engineer | LLM - ETL", "contract_type": "CDI", "salary": "40K à 45K €", "company": "Aimigo", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +3", "publication_date": "2025-01-13", "company_data": {"sector": "Education, EdTech, Formation", "company_size": "37", "creation_date": "2004", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": "52", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": ["json"], "DataVisualisation": ["tableaux"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/gymglish/jobs/data-engineer-llm-etl_paris?q=557bf4ac9053418863fc5982a25786ef&o=338a0487-8030-4965-a088-5c3268144e36", "description": "Descriptif du posteVous rejoindrez notre équipe Technique afin de nous aider à développer nos produits futurs et existants : spécification, architecture, développement, test et déploiement. Vous travaillerez sous la responsabilité de Bogdan, notre Directeur Technique, au sein d’une équipe de 10 personnes et près de notre équipe d’IA composée de 4 personnes.🌻 Sur ce poste à mi-chemin entre l’analyse de données, le Data Engineering (Extract, Transform, Load - ETL) et le Prompt Engineering, tes responsabilités seront les suivantes :Collecter, stocker et standardiser des données brutes issues de multiples sources (textes, tableaux et images notamment)Mettre en forme et nettoyer ces données afin de les rendre exploitables par des algorithmes d’IAAssurer la qualité des données en implémentant des contrôles, des tests et des processus de validationMaintenir, tester et améliorer une architecture de pipeline de données optimaleDévelopper et maintenir des pipelines de données intégrant des modèles de langage via des API (ex. OpenAI, Anthropic)Contribuer à l’ingénierie des prompts pour optimiser l’utilisation de ces modèlesIdentifier et évaluer des opportunités de gains de productivité grâce à l’automatisation des processus🌱 L’environnement technique :Notre stack ETL actuel assure l’extraction de texte, de graphiques et d’images à partir de fichiers PDF, LaTex etc. Nous transformons ces documents en plusieurs étapes, en utilisant le format JSON pour structurer les données. Nous procédons notamment à des classifications d’images, à la génération de contenu via des modèles de langage (LLM multimodaux ou texte uniquement) et déployons une importante ingénierie à chaque étape du processus.Pour en savoir plus sur notre équipe technique : “How to handle a technical crisis at Gymglish (and live to tell the tale)”.💡 Autres informations :Type de contrat : CDI 39h - statut cadreLieu de travail : ParisDisponibilité : ASAPRémunération : 40-45k€ annuel + PEE & prime de vacancesCongés payés : 5 semaines de vacances + 5 jours supplémentaires🫶 Pourquoi postuler :Rejoignez le secteur de l’éducation, des langues et de la culture, favorisant l’ouverture aux autres et l’apprentissage continu. 📚Intégrez une équipe diversifiée de 40 personnes, représentant 14 nationalités et parlant 13 langues. 🌍Travaillez dans notre bureau ‘cosy’ à Paris 12, un ancien lavoir entièrement rénové, à proximité des lignes 1, 8 et du RER A, ou en télétravail, de manière hebdomadaire. 😉Nous acceptons occasionnellement les enfants 🧒 et les animaux 😻 au bureau !Profitez de notre mutuelle Alan 🩺 et de titres-restaurant Swile 🍽️ pris en charge à 60% (au lieu des 50% légaux !).Aimigo subventionne un abonnement avec un réseau de salle de sport partenaire : Les Cercles de la Forme 🏋️‍♂️Bénéficiez du remboursement de 50% de vos frais de transport. 🚆"}, {"source": "welcometothejungle", "job_title": "Data Engineer | LLM - ETL", "contract_type": "CDI", "salary": "40K à 45K €", "company": "Aimigo", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +3", "publication_date": "2025-01-13", "company_data": {"sector": "Education, EdTech, Formation", "company_size": "37", "creation_date": "2004", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": "52", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": ["json"], "DataVisualisation": ["tableaux"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/gymglish/jobs/data-engineer-llm-etl_paris?q=557bf4ac9053418863fc5982a25786ef&o=338a0487-8030-4965-a088-5c3268144e36", "description": "Descriptif du posteVous rejoindrez notre équipe Technique afin de nous aider à développer nos produits futurs et existants : spécification, architecture, développement, test et déploiement. Vous travaillerez sous la responsabilité de Bogdan, notre Directeur Technique, au sein d’une équipe de 10 personnes et près de notre équipe d’IA composée de 4 personnes.🌻 Sur ce poste à mi-chemin entre l’analyse de données, le Data Engineering (Extract, Transform, Load - ETL) et le Prompt Engineering, tes responsabilités seront les suivantes :Collecter, stocker et standardiser des données brutes issues de multiples sources (textes, tableaux et images notamment)Mettre en forme et nettoyer ces données afin de les rendre exploitables par des algorithmes d’IAAssurer la qualité des données en implémentant des contrôles, des tests et des processus de validationMaintenir, tester et améliorer une architecture de pipeline de données optimaleDévelopper et maintenir des pipelines de données intégrant des modèles de langage via des API (ex. OpenAI, Anthropic)Contribuer à l’ingénierie des prompts pour optimiser l’utilisation de ces modèlesIdentifier et évaluer des opportunités de gains de productivité grâce à l’automatisation des processus🌱 L’environnement technique :Notre stack ETL actuel assure l’extraction de texte, de graphiques et d’images à partir de fichiers PDF, LaTex etc. Nous transformons ces documents en plusieurs étapes, en utilisant le format JSON pour structurer les données. Nous procédons notamment à des classifications d’images, à la génération de contenu via des modèles de langage (LLM multimodaux ou texte uniquement) et déployons une importante ingénierie à chaque étape du processus.Pour en savoir plus sur notre équipe technique : “How to handle a technical crisis at Gymglish (and live to tell the tale)”.💡 Autres informations :Type de contrat : CDI 39h - statut cadreLieu de travail : ParisDisponibilité : ASAPRémunération : 40-45k€ annuel + PEE & prime de vacancesCongés payés : 5 semaines de vacances + 5 jours supplémentaires🫶 Pourquoi postuler :Rejoignez le secteur de l’éducation, des langues et de la culture, favorisant l’ouverture aux autres et l’apprentissage continu. 📚Intégrez une équipe diversifiée de 40 personnes, représentant 14 nationalités et parlant 13 langues. 🌍Travaillez dans notre bureau ‘cosy’ à Paris 12, un ancien lavoir entièrement rénové, à proximité des lignes 1, 8 et du RER A, ou en télétravail, de manière hebdomadaire. 😉Nous acceptons occasionnellement les enfants 🧒 et les animaux 😻 au bureau !Profitez de notre mutuelle Alan 🩺 et de titres-restaurant Swile 🍽️ pris en charge à 60% (au lieu des 50% légaux !).Aimigo subventionne un abonnement avec un réseau de salle de sport partenaire : Les Cercles de la Forme 🏋️‍♂️Bénéficiez du remboursement de 50% de vos frais de transport. 🚆"}, {"source": "welcometothejungle", "job_title": "Consultant.e Data engineer confirmé.e", "contract_type": "CDI", "salary": "Non spécifié", "company": "Kanbios", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "IT / Digital", "company_size": "55", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5,5 ", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-data-engineer-confirme-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=822f1d34-7d14-4ebf-a698-b69aa8498ae2", "description": "Descriptif du poste🎯 Nous recherchons un(e) Data Engineer confirmé(e) pour rejoindre notre pôle Data ! 🎯Vous serez en charge de la conception et de la maintenance de pipelines de données robustes, garantissant la qualité et l’intégrité des données.Vos missions si vous nous rejoignez : 🚀 Chez le client :Participer à l’analyse des besoins des clients et à la définition des solutions techniques adaptées.Concevoir, développer et maintenir des pipelines de données.Collaborer avec les équipes clientes pour améliorer et optimiser les infrastructures de données.Développer des solutions de traitement et de transformation de données. Veiller à la qualité́, l’intégrité́ et la sécurité́ des données.  Participer à l’intégration de nouveaux outils et technologies selon les projets.Assurer un suivi et un reporting régulier auprès des clients. 🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de template de code pour accélérer nos projets et mettre en place les bonnes pratiques.Effectuer une veille technologique pour rester à jour sur les dernières avancées en matière Data science.Participer à la construction de propositions commerciales et de présentations stratégiques."}, {"source": "welcometothejungle", "job_title": "Consultant.e Data engineer confirmé.e", "contract_type": "CDI", "salary": "Non spécifié", "company": "Kanbios", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "IT / Digital", "company_size": "55", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5,5 ", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-data-engineer-confirme-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=822f1d34-7d14-4ebf-a698-b69aa8498ae2", "description": "Descriptif du poste🎯 Nous recherchons un(e) Data Engineer confirmé(e) pour rejoindre notre pôle Data ! 🎯Vous serez en charge de la conception et de la maintenance de pipelines de données robustes, garantissant la qualité et l’intégrité des données.Vos missions si vous nous rejoignez : 🚀 Chez le client :Participer à l’analyse des besoins des clients et à la définition des solutions techniques adaptées.Concevoir, développer et maintenir des pipelines de données.Collaborer avec les équipes clientes pour améliorer et optimiser les infrastructures de données.Développer des solutions de traitement et de transformation de données. Veiller à la qualité́, l’intégrité́ et la sécurité́ des données.  Participer à l’intégration de nouveaux outils et technologies selon les projets.Assurer un suivi et un reporting régulier auprès des clients. 🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de template de code pour accélérer nos projets et mettre en place les bonnes pratiques.Effectuer une veille technologique pour rester à jour sur les dernières avancées en matière Data science.Participer à la construction de propositions commerciales et de présentations stratégiques."}, {"source": "welcometothejungle", "job_title": "Consultant.e Machine Learning engineer Senior", "contract_type": "CDI", "salary": "Non spécifié", "company": "Kanbios", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "IT / Digital", "company_size": "55", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5,5 ", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops.vos"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-machine-learning-engineer-confirme-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=06b93420-4eed-4278-9de0-0e219b8e43da", "description": "Descriptif du poste🎯 Nous sommes à la recherche d’un(e) Machine Learning Engineer Senior pour renforcer notre équipe Data ! 🎯Vous travaillerez en collaboration avec des équipes pluridisciplinaires pour intégrer des modèles de Machine Learning en production et en assurer la maintenance continue. Vous participerez également à la mise place d’un environnement MLOps.Vos missions si vous nous rejoignez :🚀 Chez le client :Analyser les besoins des clients et définir des solutions basées sur le Machine Learning.Concevoir, développer et déployer des modèles de Machine Learning et d’apprentissage automatique.Collaborer avec les équipes clients pour intégrer les modèles dans leurs systèmes existants.Effectuer des tests, valider et optimiser les modèles de Machine Learning.Assurer la qualité, l’intégrité et la sécurité des données utilisées dans les modèles.Surveiller les performances des modèles en production et les améliorer en continu.Documenter les processus et les résultats pour les clients et les parties prenantes.🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de Template de code pour accélérer nos projets et mettre en place les bonnes pratiquesEffectuer une veille technique pour rester à jour sur les dernières avancées en matière de Machine Learning.Participer à la construction de propositions commerciales et de présentations stratégiques."}, {"source": "welcometothejungle", "job_title": "Consultant.e Machine Learning engineer Senior", "contract_type": "CDI", "salary": "Non spécifié", "company": "Kanbios", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 4", "education_level": "Bac +5 / Master", "publication_date": "2025-01-13", "company_data": {"sector": "IT / Digital", "company_size": "55", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5,5 ", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops.vos"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/kanbios/jobs/consultant-e-machine-learning-engineer-confirme-e_paris?q=557bf4ac9053418863fc5982a25786ef&o=06b93420-4eed-4278-9de0-0e219b8e43da", "description": "Descriptif du poste🎯 Nous sommes à la recherche d’un(e) Machine Learning Engineer Senior pour renforcer notre équipe Data ! 🎯Vous travaillerez en collaboration avec des équipes pluridisciplinaires pour intégrer des modèles de Machine Learning en production et en assurer la maintenance continue. Vous participerez également à la mise place d’un environnement MLOps.Vos missions si vous nous rejoignez :🚀 Chez le client :Analyser les besoins des clients et définir des solutions basées sur le Machine Learning.Concevoir, développer et déployer des modèles de Machine Learning et d’apprentissage automatique.Collaborer avec les équipes clients pour intégrer les modèles dans leurs systèmes existants.Effectuer des tests, valider et optimiser les modèles de Machine Learning.Assurer la qualité, l’intégrité et la sécurité des données utilisées dans les modèles.Surveiller les performances des modèles en production et les améliorer en continu.Documenter les processus et les résultats pour les clients et les parties prenantes.🚀 En interne :Produire des contenus de partage d’expertise et de formation continue pour l’équipe.Production de Template de code pour accélérer nos projets et mettre en place les bonnes pratiquesEffectuer une veille technique pour rester à jour sur les dernières avancées en matière de Machine Learning.Participer à la construction de propositions commerciales et de présentations stratégiques."}, {"source": "welcometothejungle", "job_title": "Data Engineer Snowflake (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Micropole", "location": "Levallois-Perret", "remote": "Télétravail non renseigné", "experience": "> 4", "education_level": null, "publication_date": "2025-01-12", "company_data": {"sector": "IT / Digital", "company_size": "1200", "creation_date": "1987", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "142 millions d'€", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": ["snowflake", "snowflake", "snowflake", "snowflake"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-snowflake-h-f_levallois-perret?q=557bf4ac9053418863fc5982a25786ef&o=46f8b2bd-d294-40fb-aca5-7966e0a3929e", "description": "Descriptif du posteEn résumé :  Poste : Data Engineer Snowflake (H/F)  Localité : Levallois-Perret   Type de contrat : CDI  Niveau d’expérience : au moins 2 ans  Rythme d’emploi : Hybride     Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez \" Data Engineer Snowflake (H/F)\"   pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !  En tant qu'Ingénieur de Données Snowflake chez Micropole, vous jouerez un rôle clé dans la conception, la mise en œuvre et l'optimisation des infrastructure de données sur la plateforme Snowflake de nos clients. Vous collaborerez étroitement avec les data scientists, les analystes et d'autres parties prenantes pour soutenir la prise de décision basée sur les données dans l'ensemble des organisations de nos clients.  Responsabilités Clés    Concevoir, construire,      installer, tester et maintenir des systèmes de gestion de données hautement      évolutifs.  Assurer que les systèmes      répondent aux exigences métiers et aux pratiques de l'industrie.  Construire des      algorithmes de haute performance, des prototypes, des modèles prédictifs      et des preuves de concept.  Intégrer de nouvelles      technologies de gestion de données et outils d'ingénierie logicielle dans      les structures existantes.  Créer des outils de      données pour les équipes d'analytique et de science des données afin de      les aider à construire et optimiser notre produit.  Utiliser une variété de      langues et d'outils pour assembler les systèmes ensemble.  Recommander des moyens      d'améliorer la fiabilité, l'efficacité et la qualité des données.  Collaborer avec les      architectes de données, les modélisateurs et les membres de l'équipe IT      sur les objectifs des projets. "}, {"source": "welcometothejungle", "job_title": "Data Engineer Snowflake (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Micropole", "location": "Levallois-Perret", "remote": "Télétravail non renseigné", "experience": "> 4", "education_level": null, "publication_date": "2025-01-12", "company_data": {"sector": "IT / Digital", "company_size": "1200", "creation_date": "1987", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "142 millions d'€", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": ["snowflake", "snowflake", "snowflake", "snowflake"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/groupe-micropole/jobs/data-engineer-snowflake-h-f_levallois-perret?q=557bf4ac9053418863fc5982a25786ef&o=46f8b2bd-d294-40fb-aca5-7966e0a3929e", "description": "Descriptif du posteEn résumé :  Poste : Data Engineer Snowflake (H/F)  Localité : Levallois-Perret   Type de contrat : CDI  Niveau d’expérience : au moins 2 ans  Rythme d’emploi : Hybride     Vous êtes passionné(e)s par la data ? Vous êtes convaincus que l’optimisation du patrimoine data des entreprises est la clé de leur performance ? Vous voulez rendre les entreprises data intelligentes et les aider à se transformer pour préparer dès à présent leur futur ? Vous êtes au fait des dernières tendances et prêt à explorer de nouveaux territoires ?  Vous souhaitez rejoindre un groupe pionnier des grandes innovations data et digitale ?  Si vous avez répondu « Oui » à chacune de ces questions alors devenez \" Data Engineer Snowflake (H/F)\"   pour nos clients grands-comptes dans les secteurs du luxe/retail, banque/assurance et industrie/ services.  Alors, prêt à rejoindre l’aventure Micropole ? N’attendez plus !  En tant qu'Ingénieur de Données Snowflake chez Micropole, vous jouerez un rôle clé dans la conception, la mise en œuvre et l'optimisation des infrastructure de données sur la plateforme Snowflake de nos clients. Vous collaborerez étroitement avec les data scientists, les analystes et d'autres parties prenantes pour soutenir la prise de décision basée sur les données dans l'ensemble des organisations de nos clients.  Responsabilités Clés    Concevoir, construire,      installer, tester et maintenir des systèmes de gestion de données hautement      évolutifs.  Assurer que les systèmes      répondent aux exigences métiers et aux pratiques de l'industrie.  Construire des      algorithmes de haute performance, des prototypes, des modèles prédictifs      et des preuves de concept.  Intégrer de nouvelles      technologies de gestion de données et outils d'ingénierie logicielle dans      les structures existantes.  Créer des outils de      données pour les équipes d'analytique et de science des données afin de      les aider à construire et optimiser notre produit.  Utiliser une variété de      langues et d'outils pour assembler les systèmes ensemble.  Recommander des moyens      d'améliorer la fiabilité, l'efficacité et la qualité des données.  Collaborer avec les      architectes de données, les modélisateurs et les membres de l'équipe IT      sur les objectifs des projets. "}, {"source": "welcometothejungle", "job_title": "Développeur (Car Data) F/H", "contract_type": "CDI", "salary": "Non spécifié", "company": "Renault Digital", "location": "Boulogne-Billancourt", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "267", "creation_date": "2017", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "32", "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digital,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/renault-digital/jobs/developpeur-f-h_boulogne-billancourt_RD_19r6eXO?q=557bf4ac9053418863fc5982a25786ef&o=13899bd3-a9e3-43f5-a69b-bd13862bbec4", "description": "Descriptif du posteRejoignez Renault Digital, filiale du Groupe Renault, un leader mondial de l’industrie automobile, en tant que Développeur(se) et propulsez votre carrière vers de nouveaux horizons !Nous recherchons un(e) Développeur(se) talentueux(se) pour créer des applications performantes et sécurisées pour nos véhicules connectés. Si vous maîtrisez la conception d’architectures microservices, le développement en Java (version 17 et plus) et l’utilisation de Spring Boot, nous voulons vous rencontrer !Votre rôle :Améliorer les services proposés aux utilisateurs et faciliter les actions à distance sur nos véhicules.Contribuer à l’évolution des solutions de mobilité en participant au développement de systèmes de plus en plus intelligents et interconnectés.Ce que nous offrons :L’opportunité de travailler sur des projets d’envergure.Participer à l’innovation technologique dans le secteur automobile.Façonner l’avenir de la mobilité connectée."}, {"source": "welcometothejungle", "job_title": "Développeur (Car Data) F/H", "contract_type": "CDI", "salary": "Non spécifié", "company": "Renault Digital", "location": "Boulogne-Billancourt", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "267", "creation_date": "2017", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "32", "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digital,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/renault-digital/jobs/developpeur-f-h_boulogne-billancourt_RD_19r6eXO?q=557bf4ac9053418863fc5982a25786ef&o=13899bd3-a9e3-43f5-a69b-bd13862bbec4", "description": "Descriptif du posteRejoignez Renault Digital, filiale du Groupe Renault, un leader mondial de l’industrie automobile, en tant que Développeur(se) et propulsez votre carrière vers de nouveaux horizons !Nous recherchons un(e) Développeur(se) talentueux(se) pour créer des applications performantes et sécurisées pour nos véhicules connectés. Si vous maîtrisez la conception d’architectures microservices, le développement en Java (version 17 et plus) et l’utilisation de Spring Boot, nous voulons vous rencontrer !Votre rôle :Améliorer les services proposés aux utilisateurs et faciliter les actions à distance sur nos véhicules.Contribuer à l’évolution des solutions de mobilité en participant au développement de systèmes de plus en plus intelligents et interconnectés.Ce que nous offrons :L’opportunité de travailler sur des projets d’envergure.Participer à l’innovation technologique dans le secteur automobile.Façonner l’avenir de la mobilité connectée."}, {"source": "welcometothejungle", "job_title": "Data Engineer Expérimenté ", "contract_type": "CDI", "salary": "Non spécifié", "company": "MP DATA", "location": "Boulogne-Billancourt", "remote": "Télétravail occasionnel", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["docker)."], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker)."], "Collaboration": null, "Other": ["devops", "cloud", "(ci/cd,"], "EnSoftSkils": ["clients.collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-experimente_boulogne-billancourt_MD_b17A9kw?q=557bf4ac9053418863fc5982a25786ef&o=01b15357-1e53-499a-876f-86eceb9403b6", "description": "Descriptif du posteMP DATA est à la recherche d’un(e) Data Engineer passionné(e), curieux(se) et orienté(e) solutions, pour rejoindre son équipe dynamique et participer à des projets à fort impact. Si vous avez une véritable passion pour les données et souhaitez faire la différence en contribuant à des solutions innovantes, nous avons hâte de découvrir votre profil et d’échanger avec vous !Depuis 2015, MP DATA accompagne des entreprises industrielles dans leur transformation numérique, en plaçant les données et l’Intelligence Artificielle au cœur de leurs projets. En tant que Data Engineer, vous jouerez un rôle clé dans cette aventure en devenant un expert en gestion des données : transformer les données brutes en les valorisant, maintenir et améliorer la performance des infrastructure de données et automatiser les flux.En tant que Data Engineer chez MP Data , voici ce que vous serez amenez à réaliser au quotidien :Conception et gestion des pipelines de données : Vous serez responsable de l’élaboration et de l’optimisation des pipelines ETL (Extraction, Transformation, Chargement) qui alimentent les bases de données et les systèmes décisionnels. Vous devrez garantir la qualité, la performance et la fiabilité des flux de données.Création de solutions de stockage et de modélisation : Vous participerez à la mise en place de solutions de stockage des données (data lakes, entrepôts de données) et à la conception de modèles de données adaptés aux besoins métiers de nos clients.Collaboration étroite avec les équipes métiers et Data Scientists : Vous comprendrez les enjeux des équipes métiers, et vous les aiderez à définir des solutions techniques qui répondent à leurs besoins spécifiques en matière de données.Optimisation continue des systèmes : Vous aurez un rôle clé dans l’optimisation des systèmes existants, en analysant les processus de traitement des données, en proposant des améliorations et en intégrant de nouvelles technologies.Exploration de technologies innovantes : Vous serez en première ligne pour tester, évaluer et intégrer des technologies émergentes dans nos projets, notamment le Cloud et les outils DevOps (CI/CD, Docker)."}, {"source": "welcometothejungle", "job_title": "Data Engineer Expérimenté ", "contract_type": "CDI", "salary": "Non spécifié", "company": "MP DATA", "location": "Boulogne-Billancourt", "remote": "Télétravail occasionnel", "experience": null, "education_level": null, "publication_date": "2025-01-10", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["docker)."], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker)."], "Collaboration": null, "Other": ["devops", "cloud", "(ci/cd,"], "EnSoftSkils": ["clients.collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-experimente_boulogne-billancourt_MD_b17A9kw?q=557bf4ac9053418863fc5982a25786ef&o=01b15357-1e53-499a-876f-86eceb9403b6", "description": "Descriptif du posteMP DATA est à la recherche d’un(e) Data Engineer passionné(e), curieux(se) et orienté(e) solutions, pour rejoindre son équipe dynamique et participer à des projets à fort impact. Si vous avez une véritable passion pour les données et souhaitez faire la différence en contribuant à des solutions innovantes, nous avons hâte de découvrir votre profil et d’échanger avec vous !Depuis 2015, MP DATA accompagne des entreprises industrielles dans leur transformation numérique, en plaçant les données et l’Intelligence Artificielle au cœur de leurs projets. En tant que Data Engineer, vous jouerez un rôle clé dans cette aventure en devenant un expert en gestion des données : transformer les données brutes en les valorisant, maintenir et améliorer la performance des infrastructure de données et automatiser les flux.En tant que Data Engineer chez MP Data , voici ce que vous serez amenez à réaliser au quotidien :Conception et gestion des pipelines de données : Vous serez responsable de l’élaboration et de l’optimisation des pipelines ETL (Extraction, Transformation, Chargement) qui alimentent les bases de données et les systèmes décisionnels. Vous devrez garantir la qualité, la performance et la fiabilité des flux de données.Création de solutions de stockage et de modélisation : Vous participerez à la mise en place de solutions de stockage des données (data lakes, entrepôts de données) et à la conception de modèles de données adaptés aux besoins métiers de nos clients.Collaboration étroite avec les équipes métiers et Data Scientists : Vous comprendrez les enjeux des équipes métiers, et vous les aiderez à définir des solutions techniques qui répondent à leurs besoins spécifiques en matière de données.Optimisation continue des systèmes : Vous aurez un rôle clé dans l’optimisation des systèmes existants, en analysant les processus de traitement des données, en proposant des améliorations et en intégrant de nouvelles technologies.Exploration de technologies innovantes : Vous serez en première ligne pour tester, évaluer et intégrer des technologies émergentes dans nos projets, notamment le Cloud et les outils DevOps (CI/CD, Docker)."}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Ultra Premium Direct", "location": "Bordeaux", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-09", "company_data": {"sector": "Agroalimentaire / Nutrition animale, E-commerce, FoodTech", "company_size": "170", "creation_date": "2014", "address": null, "average_age_of_employees": "33", "turnover_in_millions": " 55.6", "proportion_female": "52", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ultra-premium-direct/jobs/data-engineer-h-f_bordeaux_UPD_JG18j04?q=557bf4ac9053418863fc5982a25786ef&o=4693ef18-71e8-4a4c-9623-e52d5237fc05", "description": "Descriptif du posteNous recherchons un(e) Data Engineer talentueux(se) et expérimenté(e) pour rejoindre notre pôle Data. En tant que responsable de la conception, du développement et de la maintenance de pipelines de données robustes, vous serez un acteur clé dans l’optimisation et la fiabilité de nos systèmes de données. Vous collaborerez étroitement avec les équipes Data Science, Analyse/BI et Produit pour garantir la qualité et la disponibilité des données au sein de l'entreprise.✨Vous aurez à cœur de réaliser les missions suivantes :Concevoir, construire et maintenir des pipelines de données fiables et évolutifs en utilisant des technologies modernes.Collecter, organiser et analyser des données provenant de différentes sources (bases de données relationnelles, API, fichiers log, etc.).Assurer la qualité des données via des processus de validation, nettoyage et enrichissement.Optimiser les performances des systèmes de stockage et de traitement de données sur l'ensemble des applicatifs de la sociétéCollaborer avec les équipes internes pour comprendre les besoins métier et assurer une bonne gouvernance des données.Implémenter des solutions de monitoring et d'alerting pour les flux de données en production.Participer à la maintenance des environnements cloud (GCP notamment).Assurer la sécurité et la confidentialité des données en conformité avec les régulations (RGPD)."}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Ultra Premium Direct", "location": "Bordeaux", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-09", "company_data": {"sector": "Agroalimentaire / Nutrition animale, E-commerce, FoodTech", "company_size": "170", "creation_date": "2014", "address": null, "average_age_of_employees": "33", "turnover_in_millions": " 55.6", "proportion_female": "52", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(gcp"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ultra-premium-direct/jobs/data-engineer-h-f_bordeaux_UPD_JG18j04?q=557bf4ac9053418863fc5982a25786ef&o=4693ef18-71e8-4a4c-9623-e52d5237fc05", "description": "Descriptif du posteNous recherchons un(e) Data Engineer talentueux(se) et expérimenté(e) pour rejoindre notre pôle Data. En tant que responsable de la conception, du développement et de la maintenance de pipelines de données robustes, vous serez un acteur clé dans l’optimisation et la fiabilité de nos systèmes de données. Vous collaborerez étroitement avec les équipes Data Science, Analyse/BI et Produit pour garantir la qualité et la disponibilité des données au sein de l'entreprise.✨Vous aurez à cœur de réaliser les missions suivantes :Concevoir, construire et maintenir des pipelines de données fiables et évolutifs en utilisant des technologies modernes.Collecter, organiser et analyser des données provenant de différentes sources (bases de données relationnelles, API, fichiers log, etc.).Assurer la qualité des données via des processus de validation, nettoyage et enrichissement.Optimiser les performances des systèmes de stockage et de traitement de données sur l'ensemble des applicatifs de la sociétéCollaborer avec les équipes internes pour comprendre les besoins métier et assurer une bonne gouvernance des données.Implémenter des solutions de monitoring et d'alerting pour les flux de données en production.Participer à la maintenance des environnements cloud (GCP notamment).Assurer la sécurité et la confidentialité des données en conformité avec les régulations (RGPD)."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Pictarine", "location": "Toulouse", "remote": "Télétravail occasionnel", "experience": null, "education_level": null, "publication_date": "2025-01-09", "company_data": {"sector": "Application mobile, Logiciels, E-commerce", "company_size": "71", "creation_date": "2009", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "14M$", "proportion_female": "44", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/pictarine/jobs/senior-data-engineer_toulouse_PICTA_3lK4mmm?q=557bf4ac9053418863fc5982a25786ef&o=b5723031-6573-4225-bbfa-c99833762283", "description": "Descriptif du posteMission and challenges 🎯Si tu es enthousiaste à embarquer dans la nouvelle équipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c’est l’aventure qu’il te faut! 🏔️Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les équipes de Pictarine ne sont jamais à court d’idées pour explorer de nouveaux horizons. 🚀En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta créativité pour garantir la qualité de la data, accompagner et challenger les besoins data.Tu évolueras au sein de l’équipe Engineering, composée des pôles dev & data. Tu rejoindras une équipe data déjà composée d'une data analyste, Romane, et de la data manager, Marie !Ton rôle comprendra les aspects suivants 👇🏻Tu es garant de la qualité de la data !En simplifiant la structure de la data et réduisant le nombre de tablesEn transformant les données pour les rendre facilement utilisablesEn orchestrant le flux des données de manière continue et automatiqueTu accompagnes et challenges les équipes de Pictarine !En co-construisant des solutions data appropriéesEn élevant le niveau de jeu des méthodes data existantesEn faisant rayonner la data autour de bonnes pratiques et d’outillages adéquates"}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Pictarine", "location": "Toulouse", "remote": "Télétravail occasionnel", "experience": null, "education_level": null, "publication_date": "2025-01-09", "company_data": {"sector": "Application mobile, Logiciels, E-commerce", "company_size": "71", "creation_date": "2009", "address": null, "average_age_of_employees": "32", "turnover_in_millions": "14M$", "proportion_female": "44", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/pictarine/jobs/senior-data-engineer_toulouse_PICTA_3lK4mmm?q=557bf4ac9053418863fc5982a25786ef&o=b5723031-6573-4225-bbfa-c99833762283", "description": "Descriptif du posteMission and challenges 🎯Si tu es enthousiaste à embarquer dans la nouvelle équipe data de Pictarine pour la faire rayonner avec tout ton savoir-faire, alors c’est l’aventure qu’il te faut! 🏔️Avec plus de 1K tables, 2M de clients et 4M de commandes en 2022, les équipes de Pictarine ne sont jamais à court d’idées pour explorer de nouveaux horizons. 🚀En tant que Data Engineer chez Pictarine tu vas pouvoir utiliser toute ta créativité pour garantir la qualité de la data, accompagner et challenger les besoins data.Tu évolueras au sein de l’équipe Engineering, composée des pôles dev & data. Tu rejoindras une équipe data déjà composée d'une data analyste, Romane, et de la data manager, Marie !Ton rôle comprendra les aspects suivants 👇🏻Tu es garant de la qualité de la data !En simplifiant la structure de la data et réduisant le nombre de tablesEn transformant les données pour les rendre facilement utilisablesEn orchestrant le flux des données de manière continue et automatiqueTu accompagnes et challenges les équipes de Pictarine !En co-construisant des solutions data appropriéesEn élevant le niveau de jeu des méthodes data existantesEn faisant rayonner la data autour de bonnes pratiques et d’outillages adéquates"}, {"source": "welcometothejungle", "job_title": "Data Engineer (H/F) Confirmé(e)", "contract_type": "CDI", "salary": "Non spécifié", "company": "MP DATA", "location": "Boulogne-Billancourt", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-09", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-h-f-confirme_boulogne-billancourt?q=557bf4ac9053418863fc5982a25786ef&o=00126ea6-6a95-463f-a51a-305e54553d48", "description": "Descriptif du posteMP DATA recrute un(e) Data Engineer (H/F).Dans le cadre de la transformation digitale industriel, l’équipe de data engineering en charge de l’exploitation du Cluster Big Data cherche à se développer.En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse. Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel."}, {"source": "welcometothejungle", "job_title": "Data Engineer (H/F) Confirmé(e)", "contract_type": "CDI", "salary": "Non spécifié", "company": "MP DATA", "location": "Boulogne-Billancourt", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2025-01-09", "company_data": {"sector": "Intelligence artificielle / Machine Learning, IT / Digital, Big Data", "company_size": "100", "creation_date": "2015", "address": null, "average_age_of_employees": "27", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/mp-data/jobs/data-engineer-h-f-confirme_boulogne-billancourt?q=557bf4ac9053418863fc5982a25786ef&o=00126ea6-6a95-463f-a51a-305e54553d48", "description": "Descriptif du posteMP DATA recrute un(e) Data Engineer (H/F).Dans le cadre de la transformation digitale industriel, l’équipe de data engineering en charge de l’exploitation du Cluster Big Data cherche à se développer.En tant que Data Engineer, vous serez responsable de la collecte, du traitement et de la gestion des données, en veillant à ce qu’elles soient prêtes pour l’analyse. Votre expertise dans la conception de pipelines ETL et la sécurisation des données sera essentielle pour soutenir les activités d’analyse et de prise de décision de l’entreprise. Votre rôle contribuera à créer une base de données solide et sécurisée pour des insights pertinents et en temps réel."}, {"source": "welcometothejungle", "job_title": "Cloud Data Engineer  ", "contract_type": "CDI", "salary": "Non spécifié", "company": "CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY", "location": "Toulouse, Versailles, Lyon", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Big Data, Cybersécurité", "company_size": "25", "creation_date": "2021", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "1", "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/castle-bee-data-cloud-cyber-foundry/jobs/data-engineer-confirme-senior?q=9c8fb74493503277e2004b746ca42534&o=2c3aa6e9-18b5-4898-abd3-05fbfe2f8ba7", "description": "Descriptif du posteAu sein du pôle DataOps chez Castle Bee, vous interviendrez en tant Data Engineer et collaborerez étroitement avec les équipes métiers pour garantir la mise en place de solutions data de nos clients. Votre expertise sera essentielle pour assurer les meilleures pratiques en matière de développement, de déploiement et de gouvernance des données."}, {"source": "welcometothejungle", "job_title": "Cloud Data Engineer  ", "contract_type": "CDI", "salary": "Non spécifié", "company": "CASTLE BEE - DATA, CLOUD & CYBER FOUNDRY", "location": "Toulouse, Versailles, Lyon", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Big Data, Cybersécurité", "company_size": "25", "creation_date": "2021", "address": null, "average_age_of_employees": "27", "turnover_in_millions": "1", "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/castle-bee-data-cloud-cyber-foundry/jobs/data-engineer-confirme-senior?q=9c8fb74493503277e2004b746ca42534&o=2c3aa6e9-18b5-4898-abd3-05fbfe2f8ba7", "description": "Descriptif du posteAu sein du pôle DataOps chez Castle Bee, vous interviendrez en tant Data Engineer et collaborerez étroitement avec les équipes métiers pour garantir la mise en place de solutions data de nos clients. Votre expertise sera essentielle pour assurer les meilleures pratiques en matière de développement, de déploiement et de gouvernance des données."}, {"source": "welcometothejungle", "job_title": "Data Engineer / Analytics Engineer SENIOR", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Lille", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-analytics-engineer-senior_lille?q=9c8fb74493503277e2004b746ca42534&o=866ad313-e07b-4f5d-92b6-cf79e643796d", "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre nouvelle expertise Tech, recherche son/sa nouveau/elle Data Engineer / Analytics Engineer Senior pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !"}, {"source": "welcometothejungle", "job_title": "Data Engineer / Analytics Engineer SENIOR", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Lille", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-analytics-engineer-senior_lille?q=9c8fb74493503277e2004b746ca42534&o=866ad313-e07b-4f5d-92b6-cf79e643796d", "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre nouvelle expertise Tech, recherche son/sa nouveau/elle Data Engineer / Analytics Engineer Senior pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !"}, {"source": "welcometothejungle", "job_title": "Data Engineer @eXalt Lille", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Lille", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-lille_lille?q=9c8fb74493503277e2004b746ca42534&o=fc71812a-0d21-443c-831f-0d9c40a52d67", "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre expertise IT, recherche son/sa nouveau/elle Data Engineer pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Data Engineer @eXalt Lille", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Lille", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-lille_lille?q=9c8fb74493503277e2004b746ca42534&o=fc71812a-0d21-443c-831f-0d9c40a52d67", "description": "Descriptif du posteeXalt Lille, filiale du groupe spécialisé sur les métiers du Product & Project Management et notre expertise IT, recherche son/sa nouveau/elle Data Engineer pour aller à la conquête de nouveaux projets techniques ! Vous évoluerez dans un contexte multi sociétés et challengeant.Vous serez rattaché(e) à notre bureau lillois.Nous recherchons des talents du test aimant le challenge, avec une vraie soif d’apprendre, passionnés par le software craftmanship, prêts à collaborer avec les différentes équipes de nos clients !Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Data Engineer Senior", "contract_type": "CDI", "salary": "Non spécifié", "company": "JAKALA FRANCE SAS", "location": "Paris, Caen", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Digital Marketing / Data Marketing, Big Data, E-commerce", "company_size": "150", "creation_date": "2000", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "15", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scalabilité,"], "DataBase": ["postgresql)connaissance", "postgresqllakehouse:"], "DataAnalytics": ["(pandas,"], "BigData": ["spark", "(pyspark,", "databricks,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure),", "gcp"], "DevTools": ["digitales"], "OS": null, "DBMS": ["postgresql)connaissance", "postgresqllakehouse:", "snowflake,", "snowflake,"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": ["(terraform)expérience"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": ["mle/mlops", "uml,", "cloud", "cloud", "cloud"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-senior-cdi-paris-ou-caen?q=9c8fb74493503277e2004b746ca42534&o=6696f7e0-63be-4373-8470-85bff272293b", "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu seras impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec tes pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager ton savoir-faire avec les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,Assurer une veille technologique et savoir mener à bien un projet de R&D.Tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ELT : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse: Delta LakeConnaissance message broker : RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"}, {"source": "welcometothejungle", "job_title": "Data Engineer Senior", "contract_type": "CDI", "salary": "Non spécifié", "company": "JAKALA FRANCE SAS", "location": "Paris, Caen", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Digital Marketing / Data Marketing, Big Data, E-commerce", "company_size": "150", "creation_date": "2000", "address": null, "average_age_of_employees": "31", "turnover_in_millions": "15", "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scalabilité,"], "DataBase": ["postgresql)connaissance", "postgresqllakehouse:"], "DataAnalytics": ["(pandas,"], "BigData": ["spark", "(pyspark,", "databricks,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure),", "gcp"], "DevTools": ["digitales"], "OS": null, "DBMS": ["postgresql)connaissance", "postgresqllakehouse:", "snowflake,", "snowflake,"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,"], "InfrastructureAsCode": ["(terraform)expérience"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["kubernetes,"], "Collaboration": null, "Other": ["mle/mlops", "uml,", "cloud", "cloud", "cloud"], "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/jakala/jobs/data-engineer-senior-cdi-paris-ou-caen?q=9c8fb74493503277e2004b746ca42534&o=6696f7e0-63be-4373-8470-85bff272293b", "description": "Descriptif du posteAu sein de notre Data Lab, tu travailles conjointement avec les Data Scientists, Data Engineers, MLE/MLOps engineer déjà en poste et tu seras impliqué.e dans la prise de décisions liée aux solutions Data et à leur évolution.A cet effet, tu es en charge de :Contribuer au développement de notre offre Data et à l’industrialisation de plateformes data pour nos clientsComprendre, analyser et proposer des solutions techniques répondant aux besoins des Plateformes digitales et des projets internesDéfinir l’architecture logiciel ETL / ELT en collaboration avec tes pairsTravailler la donnée sous toutes ses formes (stockage, élaboration de modèles, structuration, nettoyage)Rédiger de la documentation technique (diagrammes UML, documentation d’API, …)Partager ton savoir-faire avec les différents membres de l’équipeConcevoir et développer des connecteurs entre les sources de données (internes et/ou externes) et la plateformeConcevoir et développer des pipelines de traitements de données (batch et/ou temps réel) dans un environnement Big Data,Assurer une veille technologique et savoir mener à bien un projet de R&D.Tu assures en autonomie les missions suivantes en interne ou auprès de nos clients grands comptes :Cartographier des données et des flux de donnéesImplémenter des algorithmes d’analyse de données pour l’industrialisationCollecter, consolider et modéliser de gros volumes de données (Big Data, Data Warehouses, Data Lakes)Développer et automatiser des flux de données et leurs visualisations en dashboards, reportingS’assurer de la scalabilité, sécurité, stabilité et disponibilité des données de la plateformeAnalyser les données web pour répondre aux questions métiers et participer à la construction de l’architecture Big DataMettre en place du séquencement et de la supervision des flux précitées en gérant les cas limitesCompétences attendues :Bon niveau en développement :De script ETL : Python (Pandas, API Rest, FaaS), Java (ex Kafka Connect, SOAP), Spark (PySpark, Databricks, Delta Lake)De script ELT : DBT (ex. Snowflake, PostgreSQL)Connaissance conception et administration d’entrepôt de données : Snowflake, Big Query, PostgreSQLLakeHouse: Delta LakeConnaissance message broker : RabbitMQ, KafkaCompétences cloud : Kubernetes, Conteneurisation, Fournisseur cloud (AWS, GCP ou Azure), Infrastructure As Code (Terraform)Expérience d’architecture et de dimensionnement d’une architecture cloud via des services managésCartographie des données"}, {"source": "welcometothejungle", "job_title": "Lead AI Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Tomorro", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Logiciels, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "60", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "38", "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalables.en"], "DataBase": ["mysql,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,"], "DevTools": ["github,"], "OS": null, "DBMS": ["mysql,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraformdatabase:"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["responsabilitésleadership", "collaboration", "intelligente.collaboration", "collaboration", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/tomorro/jobs/lead-ai-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=426f617c-c93f-46c0-8cfc-141c9880e997", "description": "Descriptif du posteTa missionTu es Software Engineer, Data Scientist ou Machine Learning Engineer avec une expérience significative en IA générative et en développement d’agents IA ?En tant que Lead Technique dans notre équipe spécialisée en Intelligence Artificielle, ton rôle sera déterminant pour piloter des initiatives stratégiques et construire une architecture robuste au sein de notre solution SaaS de Contract Lifecycle Management (CLM).Ton rôle sera clé pour développer des solutions innovantes, optimiser notre architecture et automatiser le traitement des contrats juridiques. Ton expertise en IA et en développement d’agents te permettra d’enrichir l’expérience utilisateur en créant des fonctionnalités performantes et scalables.En collaboration avec le CTO, tu assureras une vision technique cohérente et encadreras une équipe talentueuse pour relever des défis ambitieux dans le domaine de la gestion contractuelle.Tes responsabilitésLeadership technique : Être un point de référence pour l’équipe et garantir la qualité des livrables en supervisant les revues de code et en définissant les standards techniques.Recrutement et mentoring : Participer activement à la construction de l’équipe en recrutant des talents et en accompagnant leur montée en compétences.Architecture : Concevoir et optimiser l’architecture technique pour garantir l’évolutivité et la performance de notre solution, tout en intégrant des technologies de pointe comme les LLM et l’OCR.Innovation IA : Développer et intégrer des agents IA pour automatiser les processus et offrir une expérience utilisateur fluide et intelligente.Collaboration inter-équipes : Travailler en étroite collaboration avec les équipes produit, UX/UI et business pour aligner les priorités techniques sur les objectifs stratégiques.Responsabilité produit : S’assurer que les fonctionnalités IA livrées répondent aux exigences en termes de fiabilité, de sécurité et de performance.Stack techniqueBack-end applicatif: Node.js, Typescript, NestJSBack-end IA: Python, FastAPI, LangGraphInfrastructure: AWS, Cdk, TerraformDatabase: Mysql, OpenSearch, RedisCI / CD: Github, CircleCI"}, {"source": "welcometothejungle", "job_title": "Lead AI Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Tomorro", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Logiciels, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "60", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "38", "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalables.en"], "DataBase": ["mysql,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,"], "DevTools": ["github,"], "OS": null, "DBMS": ["mysql,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraformdatabase:"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["responsabilitésleadership", "collaboration", "intelligente.collaboration", "collaboration", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/tomorro/jobs/lead-ai-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=426f617c-c93f-46c0-8cfc-141c9880e997", "description": "Descriptif du posteTa missionTu es Software Engineer, Data Scientist ou Machine Learning Engineer avec une expérience significative en IA générative et en développement d’agents IA ?En tant que Lead Technique dans notre équipe spécialisée en Intelligence Artificielle, ton rôle sera déterminant pour piloter des initiatives stratégiques et construire une architecture robuste au sein de notre solution SaaS de Contract Lifecycle Management (CLM).Ton rôle sera clé pour développer des solutions innovantes, optimiser notre architecture et automatiser le traitement des contrats juridiques. Ton expertise en IA et en développement d’agents te permettra d’enrichir l’expérience utilisateur en créant des fonctionnalités performantes et scalables.En collaboration avec le CTO, tu assureras une vision technique cohérente et encadreras une équipe talentueuse pour relever des défis ambitieux dans le domaine de la gestion contractuelle.Tes responsabilitésLeadership technique : Être un point de référence pour l’équipe et garantir la qualité des livrables en supervisant les revues de code et en définissant les standards techniques.Recrutement et mentoring : Participer activement à la construction de l’équipe en recrutant des talents et en accompagnant leur montée en compétences.Architecture : Concevoir et optimiser l’architecture technique pour garantir l’évolutivité et la performance de notre solution, tout en intégrant des technologies de pointe comme les LLM et l’OCR.Innovation IA : Développer et intégrer des agents IA pour automatiser les processus et offrir une expérience utilisateur fluide et intelligente.Collaboration inter-équipes : Travailler en étroite collaboration avec les équipes produit, UX/UI et business pour aligner les priorités techniques sur les objectifs stratégiques.Responsabilité produit : S’assurer que les fonctionnalités IA livrées répondent aux exigences en termes de fiabilité, de sécurité et de performance.Stack techniqueBack-end applicatif: Node.js, Typescript, NestJSBack-end IA: Python, FastAPI, LangGraphInfrastructure: AWS, Cdk, TerraformDatabase: Mysql, OpenSearch, RedisCI / CD: Github, CircleCI"}, {"source": "welcometothejungle", "job_title": "AI Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Tomorro", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Logiciels, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "60", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "38", "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalables.tes", "scalabilité"], "DataBase": ["mysql,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,"], "DevTools": ["github,"], "OS": null, "DBMS": ["mysql,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraformdatabase:"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ia/ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/tomorro/jobs/ai-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=010baf38-e22b-4548-9a0e-869939d13b96", "description": "Descriptif du posteTa missionTu es Software Engineer, Data Scientist ou Machine Learning Engineer avec une expérience significative en IA générative et en développement d’agents IA ? Nous recherchons un talent technique pour rejoindre notre équipe spécialisée en Intelligence Artificielle au sein de notre solution SaaS de Contract Lifecycle Management (CLM).Ton rôle sera clé pour développer des solutions innovantes, optimiser notre architecture et automatiser le traitement des contrats juridiques. Ton expertise en IA et en développement d’agents te permettra d’enrichir l’expérience utilisateur en créant des fonctionnalités performantes et scalables.Tes responsabilitésParticiper activement à l’architecture de la solution pour maximiser l’efficacité et la scalabilité des fonctionnalités IAIntégrer des solutions IA génératives (LLM) et des technologies OCR dans notre produit pour automatiser le traitement et l’analyse des documents juridiquesTravailler sur des applications d’agents pour offrir une interaction intelligente et fluide avec les données des contratsConcevoir et maintenir des API performantes pour faciliter l’accès aux services et modèles, en garantissant la performance et la fiabilitéAssurer une intégration efficace des pipelines de données avec des contrôles de qualité rigoureux, afin de garantir l’intégrité et l’efficacité des flux d’information dans le systèmeCollaborer étroitement avec les autres équipes pour contribuer aux choix techniques et apporter des solutions pragmatiques et innovantes en réponse aux besoins de nos utilisateursAssurer une veille constante dans le domaine IA/ML pour identifier et intégrer les meilleures pratiques et technologies émergentesStack techniqueBack-end applicatif: Node.js, Typescript, NestJSBack-end IA: Python, FastAPI, LangGraphInfrastructure: AWS, Cdk, TerraformDatabase: Mysql, OpenSearch, RedisCI / CD: Github, CircleCI"}, {"source": "welcometothejungle", "job_title": "AI Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Tomorro", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Logiciels, FinTech / InsurTech, SaaS / Cloud Services", "company_size": "60", "creation_date": "2020", "address": null, "average_age_of_employees": "30", "turnover_in_millions": null, "proportion_female": "38", "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalables.tes", "scalabilité"], "DataBase": ["mysql,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,"], "DevTools": ["github,"], "OS": null, "DBMS": ["mysql,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": ["terraformdatabase:"], "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ia/ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/tomorro/jobs/ai-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=010baf38-e22b-4548-9a0e-869939d13b96", "description": "Descriptif du posteTa missionTu es Software Engineer, Data Scientist ou Machine Learning Engineer avec une expérience significative en IA générative et en développement d’agents IA ? Nous recherchons un talent technique pour rejoindre notre équipe spécialisée en Intelligence Artificielle au sein de notre solution SaaS de Contract Lifecycle Management (CLM).Ton rôle sera clé pour développer des solutions innovantes, optimiser notre architecture et automatiser le traitement des contrats juridiques. Ton expertise en IA et en développement d’agents te permettra d’enrichir l’expérience utilisateur en créant des fonctionnalités performantes et scalables.Tes responsabilitésParticiper activement à l’architecture de la solution pour maximiser l’efficacité et la scalabilité des fonctionnalités IAIntégrer des solutions IA génératives (LLM) et des technologies OCR dans notre produit pour automatiser le traitement et l’analyse des documents juridiquesTravailler sur des applications d’agents pour offrir une interaction intelligente et fluide avec les données des contratsConcevoir et maintenir des API performantes pour faciliter l’accès aux services et modèles, en garantissant la performance et la fiabilitéAssurer une intégration efficace des pipelines de données avec des contrôles de qualité rigoureux, afin de garantir l’intégrité et l’efficacité des flux d’information dans le systèmeCollaborer étroitement avec les autres équipes pour contribuer aux choix techniques et apporter des solutions pragmatiques et innovantes en réponse aux besoins de nos utilisateursAssurer une veille constante dans le domaine IA/ML pour identifier et intégrer les meilleures pratiques et technologies émergentesStack techniqueBack-end applicatif: Node.js, Typescript, NestJSBack-end IA: Python, FastAPI, LangGraphInfrastructure: AWS, Cdk, TerraformDatabase: Mysql, OpenSearch, RedisCI / CD: Github, CircleCI"}, {"source": "welcometothejungle", "job_title": "GenAI Engineer (H/F)", "contract_type": "CDI", "salary": "50K à 65K €", "company": "ComptaSecure", "location": "Paris", "remote": "Télétravail total", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-05", "company_data": {"sector": "Expertise comptable, IT / Digital, SaaS / Cloud Services", "company_size": "10", "creation_date": "2023", "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/comptasecure/jobs/data-scientist-llm_paris?q=9c8fb74493503277e2004b746ca42534&o=80fa80e7-54d0-4dbb-9829-6a4ed4fb7890", "description": "Descriptif du posteAprès sa première levée de fonds en octobre 2024, ComptaSecure recherche un développeur Python spécialisé LLM-IA Générative pour rejoindre l’équipe Produit composé actuellement de 4 personnes (8 personnes en 2025). Nous avons été les premiers à proposer en 2023 un ChatBot reposant sur l’IA générative et spécialisé pour les professionnels du chiffre. Nous voulons aller encore plus loin en 2025 en améliorant ses performances. Sous l’encadrement de notre CTO :Tu feras evoluer le pipeline RAG existant vers des techniques avancéesTu étudieras des solutions de fine tuningTu seras en veille permanente sur les différents LLM, techniques de prompting, évolution des RAG/RIGTu développeras un framework de benchmarking des évolutions proposéesNos locaux sont basés à Paris, mais le poste est disponible en full-remote avec une venue à Paris 2 jours par mois."}, {"source": "welcometothejungle", "job_title": "GenAI Engineer (H/F)", "contract_type": "CDI", "salary": "50K à 65K €", "company": "ComptaSecure", "location": "Paris", "remote": "Télétravail total", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-05", "company_data": {"sector": "Expertise comptable, IT / Digital, SaaS / Cloud Services", "company_size": "10", "creation_date": "2023", "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/comptasecure/jobs/data-scientist-llm_paris?q=9c8fb74493503277e2004b746ca42534&o=80fa80e7-54d0-4dbb-9829-6a4ed4fb7890", "description": "Descriptif du posteAprès sa première levée de fonds en octobre 2024, ComptaSecure recherche un développeur Python spécialisé LLM-IA Générative pour rejoindre l’équipe Produit composé actuellement de 4 personnes (8 personnes en 2025). Nous avons été les premiers à proposer en 2023 un ChatBot reposant sur l’IA générative et spécialisé pour les professionnels du chiffre. Nous voulons aller encore plus loin en 2025 en améliorant ses performances. Sous l’encadrement de notre CTO :Tu feras evoluer le pipeline RAG existant vers des techniques avancéesTu étudieras des solutions de fine tuningTu seras en veille permanente sur les différents LLM, techniques de prompting, évolution des RAG/RIGTu développeras un framework de benchmarking des évolutions proposéesNos locaux sont basés à Paris, mais le poste est disponible en full-remote avec une venue à Paris 2 jours par mois."}, {"source": "welcometothejungle", "job_title": "Senior Data Analytics Engineer (H/F/NB)", "contract_type": "CDI", "salary": "Non spécifié", "company": "lesfurets", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-03", "company_data": {"sector": "Logiciels, FinTech / InsurTech, E-commerce", "company_size": "102", "creation_date": "2012", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["cloudsql", "nosql", "nosql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["bigquery"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloudsql"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/lesfurets/jobs/senior-data-analytics-engineer-h-f-nb_paris?q=9c8fb74493503277e2004b746ca42534&o=2702e955-173c-426a-81d6-58355fdc6022", "description": "Descriptif du posteVous pensez que la Data peut rendre le monde meilleur ? Vous aimeriez travailler pour une entreprise qui a la data au cœur de ses décisions business ?Vous aimez voir comment votre travail aide à améliorer un site utilisé chaque jour par des milliers d’internautes ?Venez participer à l’aventure de lesfurets où se mêlent travail et bonne humeur !Nous recherchons un Senior Data Analytics Engineer motivé, curieux avec un vrai esprit d’équipe pour rejoindre notre équipe data.Missions :En tant que Data Analytics Engineer vous allez mener des chantiers pour traiter des données hétérogènes venant des sources différentes (analytics, funnel, tracking, etc) pour aider à améliorer l’activité d’une dizaine de produits (assurance, banque, prêt, énergie…) fédérant des données venant d’une centaine de partenaires.Vous serez aussi amené à travailler sur l’ensemble des aspects de modélisation de données ainsi que sur la qualité de celle-ci, permettant ainsi à l’ensemble de l’entreprise de prendre les bonnes décisions.Quel sera votre quotidien ?Modéliser les données au sein de notre Datalake.Concevoir et challenger la modélisation des données (dans des systèmes relationnels - CloudSQL mais aussi NoSQL : Firestore, BigQuery ou X).Participer à la définition et mise en place de la modélisation de la donnée pour l’ensemble de l’entreprise.Faciliter l’accès aux données à l’ensemble des équipes de l’entreprises et réaliserez des chantiers avec eux : modélisation de données, conception des pipelines, suivi en production.Participer à la mise en place de la Data Gouvernance et des outils liés (Data Catalog).Mettre en place les bonnes pratiques au sein des équipes Data permettant de s’assurer de la qualité des livrables.Exemples de sujets sur lesquels vous pourriez être amené à travailler :valorisation de la datamise en place d’un Référentiel Client UniqueRebuild de la data-plateformeMise en place d’un data management à l’échelle de l’entreprise (Data Gouvernance, Data Catalog, etc…)Vous participerez à nos processus d’amélioration continue, au partage de connaissances dans le cadre de l’équipe data et plus globalement au sein de l’IT"}, {"source": "welcometothejungle", "job_title": "Senior Data Analytics Engineer (H/F/NB)", "contract_type": "CDI", "salary": "Non spécifié", "company": "lesfurets", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-03", "company_data": {"sector": "Logiciels, FinTech / InsurTech, E-commerce", "company_size": "102", "creation_date": "2012", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["cloudsql", "nosql", "nosql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["bigquery"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloudsql"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/lesfurets/jobs/senior-data-analytics-engineer-h-f-nb_paris?q=9c8fb74493503277e2004b746ca42534&o=2702e955-173c-426a-81d6-58355fdc6022", "description": "Descriptif du posteVous pensez que la Data peut rendre le monde meilleur ? Vous aimeriez travailler pour une entreprise qui a la data au cœur de ses décisions business ?Vous aimez voir comment votre travail aide à améliorer un site utilisé chaque jour par des milliers d’internautes ?Venez participer à l’aventure de lesfurets où se mêlent travail et bonne humeur !Nous recherchons un Senior Data Analytics Engineer motivé, curieux avec un vrai esprit d’équipe pour rejoindre notre équipe data.Missions :En tant que Data Analytics Engineer vous allez mener des chantiers pour traiter des données hétérogènes venant des sources différentes (analytics, funnel, tracking, etc) pour aider à améliorer l’activité d’une dizaine de produits (assurance, banque, prêt, énergie…) fédérant des données venant d’une centaine de partenaires.Vous serez aussi amené à travailler sur l’ensemble des aspects de modélisation de données ainsi que sur la qualité de celle-ci, permettant ainsi à l’ensemble de l’entreprise de prendre les bonnes décisions.Quel sera votre quotidien ?Modéliser les données au sein de notre Datalake.Concevoir et challenger la modélisation des données (dans des systèmes relationnels - CloudSQL mais aussi NoSQL : Firestore, BigQuery ou X).Participer à la définition et mise en place de la modélisation de la donnée pour l’ensemble de l’entreprise.Faciliter l’accès aux données à l’ensemble des équipes de l’entreprises et réaliserez des chantiers avec eux : modélisation de données, conception des pipelines, suivi en production.Participer à la mise en place de la Data Gouvernance et des outils liés (Data Catalog).Mettre en place les bonnes pratiques au sein des équipes Data permettant de s’assurer de la qualité des livrables.Exemples de sujets sur lesquels vous pourriez être amené à travailler :valorisation de la datamise en place d’un Référentiel Client UniqueRebuild de la data-plateformeMise en place d’un data management à l’échelle de l’entreprise (Data Gouvernance, Data Catalog, etc…)Vous participerez à nos processus d’amélioration continue, au partage de connaissances dans le cadre de l’équipe data et plus globalement au sein de l’IT"}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer (F/H/N)", "contract_type": "CDI", "salary": "55K à 65K €", "company": "Vizcab", "location": "Lyon", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-03", "company_data": {"sector": "SaaS / Cloud Services, Bâtiment / Travaux publics, SocialTech / GreenTech", "company_size": "55", "creation_date": "2015", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["postgresql-", "elasticsearch-", "elasticsearch"], "DataAnalytics": null, "BigData": ["pyspark", "databricks", "databricks.définir", "databricks"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(azure)"], "DevTools": ["git-"], "OS": null, "DBMS": ["postgresql-"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ci/cd.migrer"], "EnSoftSkils": ["collaboration", "collaboration", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/vizcab/jobs/product-manager-f-h-n_lyon?q=9c8fb74493503277e2004b746ca42534&o=349012e0-b409-412f-bc5e-fe36d3f1a4d3", "description": "Descriptif du posteDans le cadre de notre croissance et de la structuration de notre équipe Data, nous recherchons un·e Senior Data Engineer basé·e à Lyon pour assurer la pérennité, le développement de nos solutions d’intégration de données, de traitement et de reporting.🤝 Tu travailleras en étroite collaboration avec :Nicolas, Team Lead Data, ton managerL’équipe Produit & DéveloppementGuillaume, ML / Data EngineerStack :- Data Platform → Databricks (Azure) + PySpark + Git- Backend → Django + PostgreSQL- Search Engine → Elasticsearch- Reporting → Power BI- Volumétrie Quotidienne → De l’ordre du Go (Gigaoctets)Tes missions :1. Contribuer au traitement des données Vizcab pour alimenter nos fonctionnalités produits et soutenir notre croissance (60 %) :Maintenir et améliorer nos pipelines batch traitant les Déclarations Environnementales de Produits (EPD) pour renforcer la satisfaction client (NPS) sur les marchés français et internationaux.Développer de nouveaux pipelines BI (basés sur des Data Warehouses) pour les marchés internationaux et concevoir des rapports utilisateurs intégrés à nos solutions Vizcab.Maintenir et développer des pipelines qui alimentent notre Elasticsearch (Documents et Search applications).2. Optimiser et enrichir notre stack data (30 %) :Assurer le bon fonctionnement des pipelines en production tout en maximisant le ratio coût/performances.Contribuer à des initiatives techniques alignées avec la roadmap produit en proposant des idées innovantes sur l’architecture, les librairies ou les process CI/CD.Migrer du code depuis les systèmes legacy vers Databricks.Définir et ajuster les bonnes pratiques de gouvernance pour intégrer nos équipes internes à Databricks (Product Managers, Experts, Data Analysts, Ingénieurs).3. Améliorer notre moteur de recherche (10 %) :Contribuer à la conception d’algorithmes complexes.Exploiter des solutions ML et/ou GenAI en collaboration avec notre ML Engineer pour répondre aux besoins produit."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer (F/H/N)", "contract_type": "CDI", "salary": "55K à 65K €", "company": "Vizcab", "location": "Lyon", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2025-01-03", "company_data": {"sector": "SaaS / Cloud Services, Bâtiment / Travaux publics, SocialTech / GreenTech", "company_size": "55", "creation_date": "2015", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["postgresql-", "elasticsearch-", "elasticsearch"], "DataAnalytics": null, "BigData": ["pyspark", "databricks", "databricks.définir", "databricks"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(azure)"], "DevTools": ["git-"], "OS": null, "DBMS": ["postgresql-"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ci/cd.migrer"], "EnSoftSkils": ["collaboration", "collaboration", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/vizcab/jobs/product-manager-f-h-n_lyon?q=9c8fb74493503277e2004b746ca42534&o=349012e0-b409-412f-bc5e-fe36d3f1a4d3", "description": "Descriptif du posteDans le cadre de notre croissance et de la structuration de notre équipe Data, nous recherchons un·e Senior Data Engineer basé·e à Lyon pour assurer la pérennité, le développement de nos solutions d’intégration de données, de traitement et de reporting.🤝 Tu travailleras en étroite collaboration avec :Nicolas, Team Lead Data, ton managerL’équipe Produit & DéveloppementGuillaume, ML / Data EngineerStack :- Data Platform → Databricks (Azure) + PySpark + Git- Backend → Django + PostgreSQL- Search Engine → Elasticsearch- Reporting → Power BI- Volumétrie Quotidienne → De l’ordre du Go (Gigaoctets)Tes missions :1. Contribuer au traitement des données Vizcab pour alimenter nos fonctionnalités produits et soutenir notre croissance (60 %) :Maintenir et améliorer nos pipelines batch traitant les Déclarations Environnementales de Produits (EPD) pour renforcer la satisfaction client (NPS) sur les marchés français et internationaux.Développer de nouveaux pipelines BI (basés sur des Data Warehouses) pour les marchés internationaux et concevoir des rapports utilisateurs intégrés à nos solutions Vizcab.Maintenir et développer des pipelines qui alimentent notre Elasticsearch (Documents et Search applications).2. Optimiser et enrichir notre stack data (30 %) :Assurer le bon fonctionnement des pipelines en production tout en maximisant le ratio coût/performances.Contribuer à des initiatives techniques alignées avec la roadmap produit en proposant des idées innovantes sur l’architecture, les librairies ou les process CI/CD.Migrer du code depuis les systèmes legacy vers Databricks.Définir et ajuster les bonnes pratiques de gouvernance pour intégrer nos équipes internes à Databricks (Product Managers, Experts, Data Analysts, Ingénieurs).3. Améliorer notre moteur de recherche (10 %) :Contribuer à la conception d’algorithmes complexes.Exploiter des solutions ML et/ou GenAI en collaboration avec notre ML Engineer pour répondre aux besoins produit."}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer (F/H)", "contract_type": "CDI", "salary": "40K à 45K €", "company": "ASI", "location": "Nantes", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-02", "company_data": {"sector": "IT / Digital, Transformation, Big Data", "company_size": "500", "creation_date": "1993", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "42,7 ", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": ["sql,", "sql", "nosql", "nosql"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["azure", "azure"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud:"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/asi/jobs/lead-data-engineer-f-h_nantes_ASI_PWKrVQL?q=9c8fb74493503277e2004b746ca42534&o=d6065fde-7406-4652-b5c0-61ec262df519", "description": "Descriptif du posteDans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin.Avec Simon GRIFFON, responsable de l’équipe Data Nantaise, nous recherchons un Lead Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une équipe dédiée, principalement en contexte agile, voici les missions qui pourront vous être confiées : Participer à la compréhension des besoins métiers et réaliser des ateliers de cadrage avec le client Participer à la rédaction des spécifications fonctionnelles et techniques des flux Maîtriser les formats de données structurés et non structurés et savoir les manipuler  Modéliser et mettre en place des systèmes décisionnels   Installer et connecter une solution ETL / ELT à une source de données en tenant compte des contraintes et de l’environnement du client Concevoir et réaliser un pipeline de transformation et de valorisation des données et ordonnancer son fonctionnement Veiller à la sécurisation des pipelines de données Concevoir et réaliser des API utilisant les données valorisées  Définir des plans de tests et d’intégration Prendre en charge la maintenance évolutive et corrective Accompagner les juniors dans leur montée en compétences  En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes : L’écosystème data notamment Microsoft Azure Les langages : SQL, Java Les bases de données SQL et NoSQL Stockage cloud: S3, Azure Blob Storage… Les ETL/ESB et autres outils : Talend, Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue...  En rejoignant ASI : Vous évoluerez au sein d’une entreprise aux modes de fonctionnement internes flexibles garantis par une politique RH attentive (accord télétravail 3J/semaine, accord congé parenthèse…)  Vous intégrerez les différentes communautés expertes d'ASI, pour partager des bonnes pratiques et participer aux actions d'amélioration continue. Vous évoluerez dans une entreprise bientôt reconnue Société à mission, Team GreenCaring et non GreenWashing porteuse d’une démarche RSE incarnée et animée, depuis plus de 10 ans. (Equipe RSE dédiée, accord forfaits mobilités durables…)  "}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer (F/H)", "contract_type": "CDI", "salary": "40K à 45K €", "company": "ASI", "location": "Nantes", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-02", "company_data": {"sector": "IT / Digital, Transformation, Big Data", "company_size": "500", "creation_date": "1993", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "42,7 ", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": ["sql,", "sql", "nosql", "nosql"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["azure", "azure"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud:"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/asi/jobs/lead-data-engineer-f-h_nantes_ASI_PWKrVQL?q=9c8fb74493503277e2004b746ca42534&o=d6065fde-7406-4652-b5c0-61ec262df519", "description": "Descriptif du posteDans un souci d’accessibilité et de clarté, les termes employés au masculin se réfèrent aussi bien au genre féminin que masculin.Avec Simon GRIFFON, responsable de l’équipe Data Nantaise, nous recherchons un Lead Data Engineer pour mettre en place, intégrer, développer et optimiser des solutions de pipeline sur des environnements Cloud et On Premise pour nos projets clients. Au sein d'une équipe dédiée, principalement en contexte agile, voici les missions qui pourront vous être confiées : Participer à la compréhension des besoins métiers et réaliser des ateliers de cadrage avec le client Participer à la rédaction des spécifications fonctionnelles et techniques des flux Maîtriser les formats de données structurés et non structurés et savoir les manipuler  Modéliser et mettre en place des systèmes décisionnels   Installer et connecter une solution ETL / ELT à une source de données en tenant compte des contraintes et de l’environnement du client Concevoir et réaliser un pipeline de transformation et de valorisation des données et ordonnancer son fonctionnement Veiller à la sécurisation des pipelines de données Concevoir et réaliser des API utilisant les données valorisées  Définir des plans de tests et d’intégration Prendre en charge la maintenance évolutive et corrective Accompagner les juniors dans leur montée en compétences  En fonction de vos compétences et appétences, vous intervenez sur l’une ou plusieurs des technologies suivantes : L’écosystème data notamment Microsoft Azure Les langages : SQL, Java Les bases de données SQL et NoSQL Stockage cloud: S3, Azure Blob Storage… Les ETL/ESB et autres outils : Talend, Spark, Kafka NIFI, Matillion, Airflow, Datafactory, Glue...  En rejoignant ASI : Vous évoluerez au sein d’une entreprise aux modes de fonctionnement internes flexibles garantis par une politique RH attentive (accord télétravail 3J/semaine, accord congé parenthèse…)  Vous intégrerez les différentes communautés expertes d'ASI, pour partager des bonnes pratiques et participer aux actions d'amélioration continue. Vous évoluerez dans une entreprise bientôt reconnue Société à mission, Team GreenCaring et non GreenWashing porteuse d’une démarche RSE incarnée et animée, depuis plus de 10 ans. (Equipe RSE dédiée, accord forfaits mobilités durables…)  "}, {"source": "welcometothejungle", "job_title": "Product Engineer", "contract_type": "CDI", "salary": "54K à 70K €", "company": "Captain Data", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-30", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "11", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilityyou"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/captaindata/jobs/product-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=03b2e6ad-b054-4a7a-9974-92acb033cd88", "description": "Descriptif du posteAt Captain Data, we believe in empowering engineers to take ownership of both technical challenges and product decisions. As a Product Engineer, you’ll have a direct impact on the design, development, and vision of our platform, helping shape the next generation of automation and data-driven tools.You’ll work closely with our engineering and product teams to build new features, iterate on existing ones, and ensure that what we deliver is aligned with user needs. You’re not just here to code – you’ll be part of the product development cycle, from ideation to deployment.With our stack ranging from APIs to data pipelines, you’ll find yourself working on a variety of systems, always keeping the end-user experience in mind.The tools you’ll work with include:• TypeScript (NodeJS) for backend services• FastAPI & Fastify for APIs• Angular for the front-end• Google Cloud Platform for deployment and infrastructure managementYour role is to bridge the gap between product and engineering, so expect to work on both code and product strategy in equal measure.To give you a rough idea, it’ll be 20/30% product management and 70%+ time spent on coding.This job has been tailored for you if… 🦄you have strong technical skills in TypeScript, NodeJS, and API designyou love contributing to product decisions and thinking beyond just the codeyou’re passionate about building features that solve real problems for usersyou’re comfortable with collaborative product development: UX/UI, engineering, and business needsyou know how to balance rapid development with code quality and scalabilityyou think like a builder: taking ideas from concept to delivery with speed and precisionyou’re not just coding for the sake of it – you’re shaping the product"}, {"source": "welcometothejungle", "job_title": "Product Engineer", "contract_type": "CDI", "salary": "54K à 70K €", "company": "Captain Data", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-30", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Big Data", "company_size": "11", "creation_date": "2018", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "35", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilityyou"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/captaindata/jobs/product-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=03b2e6ad-b054-4a7a-9974-92acb033cd88", "description": "Descriptif du posteAt Captain Data, we believe in empowering engineers to take ownership of both technical challenges and product decisions. As a Product Engineer, you’ll have a direct impact on the design, development, and vision of our platform, helping shape the next generation of automation and data-driven tools.You’ll work closely with our engineering and product teams to build new features, iterate on existing ones, and ensure that what we deliver is aligned with user needs. You’re not just here to code – you’ll be part of the product development cycle, from ideation to deployment.With our stack ranging from APIs to data pipelines, you’ll find yourself working on a variety of systems, always keeping the end-user experience in mind.The tools you’ll work with include:• TypeScript (NodeJS) for backend services• FastAPI & Fastify for APIs• Angular for the front-end• Google Cloud Platform for deployment and infrastructure managementYour role is to bridge the gap between product and engineering, so expect to work on both code and product strategy in equal measure.To give you a rough idea, it’ll be 20/30% product management and 70%+ time spent on coding.This job has been tailored for you if… 🦄you have strong technical skills in TypeScript, NodeJS, and API designyou love contributing to product decisions and thinking beyond just the codeyou’re passionate about building features that solve real problems for usersyou’re comfortable with collaborative product development: UX/UI, engineering, and business needsyou know how to balance rapid development with code quality and scalabilityyou think like a builder: taking ideas from concept to delivery with speed and precisionyou’re not just coding for the sake of it – you’re shaping the product"}, {"source": "welcometothejungle", "job_title": "Data Engineer (F/H)", "contract_type": "CDI", "salary": "45K à 70K €", "company": "Stack Labs", "location": "Toulouse, Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-23", "company_data": {"sector": "Application mobile, IT / Digital, SaaS / Cloud Services", "company_size": "40", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "5", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "java…", "scalabilité", "scalable"], "DataBase": ["cloudsql,", "mongodb,", "mongodbcontainers"], "DataAnalytics": null, "BigData": ["spark,", "spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(gcp/aws)la", "aws,", "(gcp/aws)la", "gcp", "gcp,"], "DevTools": ["gitops)la", "gitlab,", "github,…public", "docker,"], "OS": null, "DBMS": ["bigquery,", "bigquery,"], "SoftBigDataProcessing": null, "Automation": ["ansible,", "kubernetes,", "airflow,"], "InfrastructureAsCode": ["terraform,", "cloudformation,"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kubernetes,"], "Collaboration": null, "Other": ["devops.la", "cloud.de", "cloud", "cloud", "cloud", "cloud", "cloudsql,", "cloud", "cloudformation,", "cloud", "(ci/cd,"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/stack-labs/jobs/data-engineer-f-h_toulouse?q=9c8fb74493503277e2004b746ca42534&o=3141ea44-2b7d-442a-9640-f2962666ec45", "description": "Descriptif du postePour renforcer notre équipe Data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une appétence pour les solutions Cloud.De part votre métier, vous serez amené(e) à intervenir dès les phases amont de projets de migration cloud pour des clients à forts enjeux de scalabilité sur du conseil technique et sur les fondamentaux du cloud public (sécurité, observabilité, réseau, billing, automatisation) jusqu’à la mise en service des solutions.Reconnu(e) pour votre polyvalence au sein des équipes, vous êtes orienté(e) aussi bien vers la sphère technique que vers l’Humain. Vous participez notamment à :L’audit de configuration cloud de client et des préconisations d’amélioration.Proposition d’architectures data cloud native (GCP/AWS)La mise en place d’entrepôts de données massivement scalable avec BigQuery, Redshift, MongoDB, Athena, CloudSQL, Firestore…Le développement de pipelines de traitement de données avec Spark, Dataflow, PubSub, SQS…L’analyse des données et leur mise à disposition de processus de Data science (Machine Learning)L’onboarding de clients sur les bonnes pratiques et la philosophie cloud et devops.La mise en place des bonnes pratiques d’automatisation (CI/CD, GitOps)La conduite du déploiement, de l’intégration et du passage en opération de la solutionNotre écosystème technique (indicatif, variable en fonction des missions) :Architecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP WorkflowsBig Data: BigQuery, Firestore, Redshift, Athena, MongoDBContainers & microservices : Docker, Kubernetes, Istio,…Architectures orientées messages : Kafka, PubSub,..Automatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,…Public Cloud : AWS, GCP, …Langages de développement : Python, Go, Java…"}, {"source": "welcometothejungle", "job_title": "Data Engineer (F/H)", "contract_type": "CDI", "salary": "45K à 70K €", "company": "Stack Labs", "location": "Toulouse, Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-23", "company_data": {"sector": "Application mobile, IT / Digital, SaaS / Cloud Services", "company_size": "40", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": "5", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "java…", "scalabilité", "scalable"], "DataBase": ["cloudsql,", "mongodb,", "mongodbcontainers"], "DataAnalytics": null, "BigData": ["spark,", "spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(gcp/aws)la", "aws,", "(gcp/aws)la", "gcp", "gcp,"], "DevTools": ["gitops)la", "gitlab,", "github,…public", "docker,"], "OS": null, "DBMS": ["bigquery,", "bigquery,"], "SoftBigDataProcessing": null, "Automation": ["ansible,", "kubernetes,", "airflow,"], "InfrastructureAsCode": ["terraform,", "cloudformation,"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kubernetes,"], "Collaboration": null, "Other": ["devops.la", "cloud.de", "cloud", "cloud", "cloud", "cloud", "cloudsql,", "cloud", "cloudformation,", "cloud", "(ci/cd,"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/stack-labs/jobs/data-engineer-f-h_toulouse?q=9c8fb74493503277e2004b746ca42534&o=3141ea44-2b7d-442a-9640-f2962666ec45", "description": "Descriptif du postePour renforcer notre équipe Data et accompagner notre croissance, nous recherchons actuellement un Data Engineer, avec une appétence pour les solutions Cloud.De part votre métier, vous serez amené(e) à intervenir dès les phases amont de projets de migration cloud pour des clients à forts enjeux de scalabilité sur du conseil technique et sur les fondamentaux du cloud public (sécurité, observabilité, réseau, billing, automatisation) jusqu’à la mise en service des solutions.Reconnu(e) pour votre polyvalence au sein des équipes, vous êtes orienté(e) aussi bien vers la sphère technique que vers l’Humain. Vous participez notamment à :L’audit de configuration cloud de client et des préconisations d’amélioration.Proposition d’architectures data cloud native (GCP/AWS)La mise en place d’entrepôts de données massivement scalable avec BigQuery, Redshift, MongoDB, Athena, CloudSQL, Firestore…Le développement de pipelines de traitement de données avec Spark, Dataflow, PubSub, SQS…L’analyse des données et leur mise à disposition de processus de Data science (Machine Learning)L’onboarding de clients sur les bonnes pratiques et la philosophie cloud et devops.La mise en place des bonnes pratiques d’automatisation (CI/CD, GitOps)La conduite du déploiement, de l’intégration et du passage en opération de la solutionNotre écosystème technique (indicatif, variable en fonction des missions) :Architecture Data : ETL, ELT, Dataflow, Spark, Airflow, GCP WorkflowsBig Data: BigQuery, Firestore, Redshift, Athena, MongoDBContainers & microservices : Docker, Kubernetes, Istio,…Architectures orientées messages : Kafka, PubSub,..Automatisation & Infrastructure as Code (IaC) : Terraform, CloudFormation, Ansible, GitLab, GitHub,…Public Cloud : AWS, GCP, …Langages de développement : Python, Go, Java…"}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F - ST MALO", "contract_type": "CDI", "salary": "45K à 60K €", "company": "AISPRID", "location": "Saint-Malo", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Robotique", "company_size": "27", "creation_date": "2020", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": "20", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableaux"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/aisprid/jobs/data-engineer-h-f-st-malo_saint-malo_AISPR_KxAJA50?q=9c8fb74493503277e2004b746ca42534&o=18868ea2-df0d-4b74-8826-622234be3f9b", "description": "Descriptif du posteNotre start up c’est AISPRID : créée en 2020, elle est aujourd’hui pionnière dans son domaine avec le robot d’effeuillage autonome le plus avancé au monde !Notre solution robotique de pointe, combine l’intelligence artificielle, la vision par ordinateur, et la planification de mouvement. Et notre ambition, c’est aussi d’aller plus loin et de l’adapter demain à d’autres cultures telles que la fraise, le concombre, ou d’autres tâches comme la récolte pour aider et accompagner les producteurs face à la pénurie de main d’œuvre.Dans le cadre de notre croissance, nous recherchons un Data Engineer ayant une expertise en plateformes de données et une affinité pour l’analyse de données, pour optimiser et rendre nos systèmes plus intelligents grâce à l’exploitation des données.Missions principales :En tant que Data Engineer, vous jouerez un rôle clé dans la création et la gestion d’une infrastructure robuste pour la collecte, le traitement et l’analyse des données. Vos responsabilités incluront :le développement de la plateforme de données : concevoir, implémenter et optimiser une plateforme de données centralisée et évolutive, garantissant des flux de données fiables et en temps réel pour nos systèmes robotiques.l’architecture et l’intégration des données : collaborer avec les équipes R&D et produit pour intégrer les données nécessaires à l’amélioration des performances de nos robots.la Data pipeline et l’orchestration : mettre en place des pipelines de données (ETL/ELT), s’assurant que les données brutes soient transformées et disponibles pour l’analyse.l’observabilité et le monitoring des données : créer des systèmes d’observabilité (logs, métriques, alertes) pour assurer la qualité, la traçabilité et la performance des flux de données.l’analyse de données : participer à l’analyse des données opérationnelles et business pour identifier des tendances, améliorer les performances des robots et formuler des recommandations stratégiques.l’amélioration continue : développer des outils pour faciliter l’exploration des données par les data analysts et data scientists, et travailler à l’amélioration continue de la plateforme.la collaboration multi-équipes : Travailler étroitement avec les équipes R&D et produit pour développer des tableaux de bord et des rapports permettant un suivi pertinent des performances."}, {"source": "welcometothejungle", "job_title": "Data Engineer H/F - ST MALO", "contract_type": "CDI", "salary": "45K à 60K €", "company": "AISPRID", "location": "Saint-Malo", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Robotique", "company_size": "27", "creation_date": "2020", "address": null, "average_age_of_employees": "34", "turnover_in_millions": null, "proportion_female": "20", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableaux"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/aisprid/jobs/data-engineer-h-f-st-malo_saint-malo_AISPR_KxAJA50?q=9c8fb74493503277e2004b746ca42534&o=18868ea2-df0d-4b74-8826-622234be3f9b", "description": "Descriptif du posteNotre start up c’est AISPRID : créée en 2020, elle est aujourd’hui pionnière dans son domaine avec le robot d’effeuillage autonome le plus avancé au monde !Notre solution robotique de pointe, combine l’intelligence artificielle, la vision par ordinateur, et la planification de mouvement. Et notre ambition, c’est aussi d’aller plus loin et de l’adapter demain à d’autres cultures telles que la fraise, le concombre, ou d’autres tâches comme la récolte pour aider et accompagner les producteurs face à la pénurie de main d’œuvre.Dans le cadre de notre croissance, nous recherchons un Data Engineer ayant une expertise en plateformes de données et une affinité pour l’analyse de données, pour optimiser et rendre nos systèmes plus intelligents grâce à l’exploitation des données.Missions principales :En tant que Data Engineer, vous jouerez un rôle clé dans la création et la gestion d’une infrastructure robuste pour la collecte, le traitement et l’analyse des données. Vos responsabilités incluront :le développement de la plateforme de données : concevoir, implémenter et optimiser une plateforme de données centralisée et évolutive, garantissant des flux de données fiables et en temps réel pour nos systèmes robotiques.l’architecture et l’intégration des données : collaborer avec les équipes R&D et produit pour intégrer les données nécessaires à l’amélioration des performances de nos robots.la Data pipeline et l’orchestration : mettre en place des pipelines de données (ETL/ELT), s’assurant que les données brutes soient transformées et disponibles pour l’analyse.l’observabilité et le monitoring des données : créer des systèmes d’observabilité (logs, métriques, alertes) pour assurer la qualité, la traçabilité et la performance des flux de données.l’analyse de données : participer à l’analyse des données opérationnelles et business pour identifier des tendances, améliorer les performances des robots et formuler des recommandations stratégiques.l’amélioration continue : développer des outils pour faciliter l’exploration des données par les data analysts et data scientists, et travailler à l’amélioration continue de la plateforme.la collaboration multi-équipes : Travailler étroitement avec les équipes R&D et produit pour développer des tableaux de bord et des rapports permettant un suivi pertinent des performances."}, {"source": "welcometothejungle", "job_title": "Data Engineer - Paris", "contract_type": "CDI", "salary": "Non spécifié", "company": "Sogeti", "location": "Issy-les-Moulineaux", "remote": "Télétravail non renseigné", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, IT / Digital, SaaS / Cloud Services", "company_size": "4300", "creation_date": "1967", "address": null, "average_age_of_employees": "37", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/data-engineer-h-f_issy-les-moulineaux?q=9c8fb74493503277e2004b746ca42534&o=a83eb973-3ab3-40de-9dbf-0fedd371805d", "description": "Descriptif du posteData Engineer       Vos missions:   Côté hardskills, voici nos prérequis :  Concevoir, développer et maintenir des pipelines de données pour l’acquisition, le traitement et le chargement des données provenant de diverses sources. Mettre en place et optimiser des bases de données et des entrepôts de données pour le stockage et l’accès efficaces aux données. Collaborer avec les équipes métier pour comprendre les besoins en matière de données et proposer des solutions techniques adaptées. Assurer la qualité des données en mettant en place des processus de nettoyage, de validation et de normalisation. Automatiser les tâches récurrentes liées à la gestion des données pour améliorer l’efficacité opérationnelle. Effectuer la surveillance et le dépannage des pipelines de données pour garantir leur fiabilité et leur performance. Travailler en étroite collaboration avec les data scientists et les analystes pour fournir des ensembles de données fiables et prêts à l’emploi. Assurer la conformité aux normes de sécurité et aux réglementations en matière de protection des données. "}, {"source": "welcometothejungle", "job_title": "Data Engineer - Paris", "contract_type": "CDI", "salary": "Non spécifié", "company": "Sogeti", "location": "Issy-les-Moulineaux", "remote": "Télétravail non renseigné", "experience": "> 7", "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, IT / Digital, SaaS / Cloud Services", "company_size": "4300", "creation_date": "1967", "address": null, "average_age_of_employees": "37", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/sogeti/jobs/data-engineer-h-f_issy-les-moulineaux?q=9c8fb74493503277e2004b746ca42534&o=a83eb973-3ab3-40de-9dbf-0fedd371805d", "description": "Descriptif du posteData Engineer       Vos missions:   Côté hardskills, voici nos prérequis :  Concevoir, développer et maintenir des pipelines de données pour l’acquisition, le traitement et le chargement des données provenant de diverses sources. Mettre en place et optimiser des bases de données et des entrepôts de données pour le stockage et l’accès efficaces aux données. Collaborer avec les équipes métier pour comprendre les besoins en matière de données et proposer des solutions techniques adaptées. Assurer la qualité des données en mettant en place des processus de nettoyage, de validation et de normalisation. Automatiser les tâches récurrentes liées à la gestion des données pour améliorer l’efficacité opérationnelle. Effectuer la surveillance et le dépannage des pipelines de données pour garantir leur fiabilité et leur performance. Travailler en étroite collaboration avec les data scientists et les analystes pour fournir des ensembles de données fiables et prêts à l’emploi. Assurer la conformité aux normes de sécurité et aux réglementations en matière de protection des données. "}, {"source": "welcometothejungle", "job_title": "Consultant Expérimenté & Manager en Data Engineering - Secteur Financier, H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "EY", "location": "Paris", "remote": "Télétravail non autorisé", "experience": null, "education_level": null, "publication_date": "2024-12-18", "company_data": {"sector": "Stratégie, Audit, Transaction Services, Digital, Finance", "company_size": "7000", "creation_date": null, "address": null, "average_age_of_employees": "30", "turnover_in_millions": "45 Milliards", "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digital,", "digital,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultant-experimente-manager-en-data-engineering-secteur-financier-h-f_paris_EY_bwGGwOb?q=9c8fb74493503277e2004b746ca42534&o=e6f6f493-2bf3-4f24-b094-286e2b981142", "description": "Descriptif du posteL’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, architecture, robotics, analyse quantitative, datamining, big data, algorithmique, blockchain, intelligence artificielle, digital, …). Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel. Cette annonce est destinée aux candidats spécialisés en Data Engineering, mais nous recherchons des profils expérimentés et mobilisables sur le spectre élargi des métiers de la data. Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à apporter vos compétences à des équipes engagées sur des missions de conseil de différentes natures :·       Conception et mise en œuvre de solutions de valorisation de la donnée depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisation·        Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…·       Cartographie des processus de transformation de données·       Cadrage et analyse fonctionnelle de projets de transformation data·       Accompagnement au pilotage, à la coordination et à la gestion de projets data·       Définition de stratégie client en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)·       Etudes et choix de solutions et de plateformes big data, analytics…·       Veille sur l’évolution des méthodes, des pratiques, des outils… Vous pourrez continuer de développer des compétences dans les domaines de votre choix grâce à l’approche de formation EY."}, {"source": "welcometothejungle", "job_title": "Consultant Expérimenté & Manager en Data Engineering - Secteur Financier, H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "EY", "location": "Paris", "remote": "Télétravail non autorisé", "experience": null, "education_level": null, "publication_date": "2024-12-18", "company_data": {"sector": "Stratégie, Audit, Transaction Services, Digital, Finance", "company_size": "7000", "creation_date": null, "address": null, "average_age_of_employees": "30", "turnover_in_millions": "45 Milliards", "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digital,", "digital,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/ey/jobs/consultant-experimente-manager-en-data-engineering-secteur-financier-h-f_paris_EY_bwGGwOb?q=9c8fb74493503277e2004b746ca42534&o=e6f6f493-2bf3-4f24-b094-286e2b981142", "description": "Descriptif du posteL’opportunitéEn travaillant dans une équipe en croissance sur les différents métiers Data & Analytics et Innovation, vous participez au développement des missions à forte valeur ajoutée auprès de nos clients (gestion de la donnée, processus de transformation, définition de moyen, architecture, robotics, analyse quantitative, datamining, big data, algorithmique, blockchain, intelligence artificielle, digital, …). Votre champ d’intervention s’étendra véritablement au niveau mondial et vous pourrez acquérir une expérience précieuse, bénéficiant de vastes possibilités de développement professionnel, tout en disposant de tout le soutien dont vous avez besoin pour atteindre votre potentiel. Cette annonce est destinée aux candidats spécialisés en Data Engineering, mais nous recherchons des profils expérimentés et mobilisables sur le spectre élargi des métiers de la data. Vos missionsSelon votre parcours, vos expériences et votre expertise, vous serez amené(e) à apporter vos compétences à des équipes engagées sur des missions de conseil de différentes natures :·       Conception et mise en œuvre de solutions de valorisation de la donnée depuis l’idéation jusqu’à l’industrialisation en passant par les études de faisabilité, la préparation des données et la modélisation·        Conception, développement et implémentation d’outils ou de solutions de reporting, d’aide à la décision, de visualisations de données dans les domaines du customer, du digital, de la conformité…·       Cartographie des processus de transformation de données·       Cadrage et analyse fonctionnelle de projets de transformation data·       Accompagnement au pilotage, à la coordination et à la gestion de projets data·       Définition de stratégie client en matière d’intelligence artificielle (use cases, trajectoires, roadmap…)·       Etudes et choix de solutions et de plateformes big data, analytics…·       Veille sur l’évolution des méthodes, des pratiques, des outils… Vous pourrez continuer de développer des compétences dans les domaines de votre choix grâce à l’approche de formation EY."}, {"source": "welcometothejungle", "job_title": "Data Engineer Senior (Paris, Fr & Remote)", "contract_type": "CDI", "salary": "60K à 70K €", "company": "Hiboo Systems SAS", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "SaaS / Cloud Services", "company_size": "50", "creation_date": "2018", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/hiboo/jobs/data-engineer-senior-paris-fr-remote?q=9c8fb74493503277e2004b746ca42534&o=8ee7cc0a-6822-4e21-8635-a0dfbcf11b2a", "description": "Descriptif du posteEn tant que Data Engineer, tu seras en charge de la conception, du développement, de la maintenance et de l’optimisation des infrastructures de données. Cela implique :Le développement des outils et des traitements permettant la migration de l’ingestion de nos différentes sources de données vers une architecture orientée big dataLa construction de pipeline de données (batch et temps réel) permettant d’alimenter notre application, nos APIs, nos analytics et nos projets de data-scienceAu quotidien, tu interviendras donc sur le déploiement et le monitoring des briques techniques nécessaires à l’infrastructure data d’Hiboo (plateforme d’ingestion, datalake, calcul distribué) mais également du code de collecte, structuration, mise en qualité, documentation et mise à disposition de la donnée. Tu contribueras également activement aux décisions concernant les choix produit et techniques, en lien avec le reste de l’équipe."}, {"source": "welcometothejungle", "job_title": "Data Engineer Senior (Paris, Fr & Remote)", "contract_type": "CDI", "salary": "60K à 70K €", "company": "Hiboo Systems SAS", "location": "Paris", "remote": "Télétravail total", "experience": "> 5", "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "SaaS / Cloud Services", "company_size": "50", "creation_date": "2018", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/hiboo/jobs/data-engineer-senior-paris-fr-remote?q=9c8fb74493503277e2004b746ca42534&o=8ee7cc0a-6822-4e21-8635-a0dfbcf11b2a", "description": "Descriptif du posteEn tant que Data Engineer, tu seras en charge de la conception, du développement, de la maintenance et de l’optimisation des infrastructures de données. Cela implique :Le développement des outils et des traitements permettant la migration de l’ingestion de nos différentes sources de données vers une architecture orientée big dataLa construction de pipeline de données (batch et temps réel) permettant d’alimenter notre application, nos APIs, nos analytics et nos projets de data-scienceAu quotidien, tu interviendras donc sur le déploiement et le monitoring des briques techniques nécessaires à l’infrastructure data d’Hiboo (plateforme d’ingestion, datalake, calcul distribué) mais également du code de collecte, structuration, mise en qualité, documentation et mise à disposition de la donnée. Tu contribueras également activement aux décisions concernant les choix produit et techniques, en lien avec le reste de l’équipe."}, {"source": "welcometothejungle", "job_title": "Lead ingénieur data", "contract_type": "CDI", "salary": "65K à 80K €", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-16", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["sql", "postgresql)", "mongodb,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["postgresql)"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ml"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/lead-ingenieur-data_nice?q=9c8fb74493503277e2004b746ca42534&o=596b2524-c6fb-4a30-a614-cc61f0a0924c", "description": "Descriptif du posteNous recherchons un(e) Lead Data Engineer pour prendre en charge la conception et la gestion de notre infrastructure de données. Vous serez responsable du développement de modèles de données évolutifs et performants. Vous superviserez nos pipelines ETL, les processus d’ingestion de données et collaborerez étroitement avec les data scientists pour garantir une intégration fluide de leurs modèles d’apprentissage automatique en production. Vous jouerez également un rôle clé dans la définition de l’infrastructure nécessaire à l’ingestion de données hétérogènes, aux processus d’entraînement des modèles ML et aux pratiques de ML Ops, en veillant à ce que les pipelines, le monitoring et l’automatisation soient en place.Responsabilités clés :Diriger la conception et l’optimisation des modèles de données et de l’infrastructure pour prendre en charge le traitement de données à grande échelle.Superviser et gérer l’architecture de la couche de données, actuellement basée sur Cube.dev et MongoDB, avec pour objectif d’évaluer et de potentiellement migrer vers un système basé sur SQL (par ex. PostgreSQL) pour améliorer les performances.Gérer les données géospatiales, en garantissant une gestion efficace des données basées sur la localisation pour l’analyse, le stockage et la visualisation.Construire et maintenir des pipelines ETL robustes et des flux d’ingestion de données qui assurent une haute disponibilité, fiabilité et performance des systèmes de données.Collaborer avec l’équipe de data science pour intégrer les modèles d’apprentissage automatique dans les environnements de production, en mettant l’accent sur le déploiement efficace des modèles, leur surveillance et leur itération.Concevoir et implémenter une infrastructure ML Ops pour prendre en charge l’entraînement, l’expérimentation et le déploiement des modèles, incluant le suivi, la versioning et l’évolutivité des processus d’entraînement.Définir et appliquer les meilleures pratiques en matière de gouvernance des données, en garantissant leur sécurité, leur qualité et leur conformité.Évaluer et adopter de nouveaux outils et technologies pour améliorer le traitement des données, en mettant l’accent sur l’ingestion en temps réel et une infrastructure ML évolutive.Fournir un leadership stratégique pour façonner l’avenir de notre architecture de données, en veillant à ce qu’elle s’aligne avec les objectifs de durabilité et d’analyses à fort impact de l’entreprise."}, {"source": "welcometothejungle", "job_title": "Lead ingénieur data", "contract_type": "CDI", "salary": "65K à 80K €", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-16", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": ["sql", "postgresql)", "mongodb,"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["postgresql)"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml", "ml", "ml", "ml"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/lead-ingenieur-data_nice?q=9c8fb74493503277e2004b746ca42534&o=596b2524-c6fb-4a30-a614-cc61f0a0924c", "description": "Descriptif du posteNous recherchons un(e) Lead Data Engineer pour prendre en charge la conception et la gestion de notre infrastructure de données. Vous serez responsable du développement de modèles de données évolutifs et performants. Vous superviserez nos pipelines ETL, les processus d’ingestion de données et collaborerez étroitement avec les data scientists pour garantir une intégration fluide de leurs modèles d’apprentissage automatique en production. Vous jouerez également un rôle clé dans la définition de l’infrastructure nécessaire à l’ingestion de données hétérogènes, aux processus d’entraînement des modèles ML et aux pratiques de ML Ops, en veillant à ce que les pipelines, le monitoring et l’automatisation soient en place.Responsabilités clés :Diriger la conception et l’optimisation des modèles de données et de l’infrastructure pour prendre en charge le traitement de données à grande échelle.Superviser et gérer l’architecture de la couche de données, actuellement basée sur Cube.dev et MongoDB, avec pour objectif d’évaluer et de potentiellement migrer vers un système basé sur SQL (par ex. PostgreSQL) pour améliorer les performances.Gérer les données géospatiales, en garantissant une gestion efficace des données basées sur la localisation pour l’analyse, le stockage et la visualisation.Construire et maintenir des pipelines ETL robustes et des flux d’ingestion de données qui assurent une haute disponibilité, fiabilité et performance des systèmes de données.Collaborer avec l’équipe de data science pour intégrer les modèles d’apprentissage automatique dans les environnements de production, en mettant l’accent sur le déploiement efficace des modèles, leur surveillance et leur itération.Concevoir et implémenter une infrastructure ML Ops pour prendre en charge l’entraînement, l’expérimentation et le déploiement des modèles, incluant le suivi, la versioning et l’évolutivité des processus d’entraînement.Définir et appliquer les meilleures pratiques en matière de gouvernance des données, en garantissant leur sécurité, leur qualité et leur conformité.Évaluer et adopter de nouveaux outils et technologies pour améliorer le traitement des données, en mettant l’accent sur l’ingestion en temps réel et une infrastructure ML évolutive.Fournir un leadership stratégique pour façonner l’avenir de notre architecture de données, en veillant à ce qu’elle s’aligne avec les objectifs de durabilité et d’analyses à fort impact de l’entreprise."}, {"source": "welcometothejungle", "job_title": "Consultant Confirmé Data Engineer on Cloud Data Platforms  - F/H/N", "contract_type": "CDI", "salary": "Non spécifié", "company": "OCTO Technology", "location": "Paris", "remote": "Télétravail non renseigné", "experience": "> 5", "education_level": null, "publication_date": "2024-12-15", "company_data": {"sector": "IT / Digital, Organisation / Management, Transformation", "company_size": null, "creation_date": "1998", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/octo-technology/jobs/consultant-confirme-data-engineer-on-cloud-data-platforms-f-h-n_paris_OT_Yge3z11?q=9c8fb74493503277e2004b746ca42534&o=d2e21dcb-7d27-4282-855d-e66be6b63880", "description": "Descriptif du posteVous faites partie de celles et ceux qui pensent que même avec plusieurs années d’expérience, on continue à apprendre ? Alors nous sommes sur la même longueur d'onde ! Et si on en parlait ?Au sein de l’Atelier Data & AI, on retrouve des communautés de pratique organisées par tribus. L’idée, c’est de se retrouver et de partager des expertises communes, de développer ses compétences en équipes à taille humaine. Vous aurez donc pour missions de faire du conseil, du delivery et de la R&D.Être Data Engineer on Cloud Data Platforms chez OCTO, c’est : 1- Faire du conseil autant que du delivery : accompagner nos clients dans la mise en œuvre de solutions autour de la gestion et transformation de leur Data. Participer au développement agile et à l’implémentation d’applications dans le respect des bonnes pratiques. Et bien sûr, qui dit conseil, dit convictions : proposer la solution la plus adaptée, c’est aussi savoir et oser challenger nos clients (et c’est dans notre ADN !) 2- Participer aux réponses aux appels d’offres et avant-ventes3- Participer activement à la R&D “Data & IA” : au programme, veille technologique & bonnes pratiques. Quelques sujets “chauds” du moment ? Le Green AI , Green Data et AI4Green 🌱4- Former & mentorer : le partage de connaissances et la montée en compétences des collaborateurs vous importent ? Nous sommes convaincus et prônons haut et fort la valeur de transmission. Mentoring et gestion de votre carrière seront donc à l’honneur. Et oui, chez OCTO le savoir n’est pas chasse gardée !"}, {"source": "welcometothejungle", "job_title": "Consultant Confirmé Data Engineer on Cloud Data Platforms  - F/H/N", "contract_type": "CDI", "salary": "Non spécifié", "company": "OCTO Technology", "location": "Paris", "remote": "Télétravail non renseigné", "experience": "> 5", "education_level": null, "publication_date": "2024-12-15", "company_data": {"sector": "IT / Digital, Organisation / Management, Transformation", "company_size": null, "creation_date": "1998", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/octo-technology/jobs/consultant-confirme-data-engineer-on-cloud-data-platforms-f-h-n_paris_OT_Yge3z11?q=9c8fb74493503277e2004b746ca42534&o=d2e21dcb-7d27-4282-855d-e66be6b63880", "description": "Descriptif du posteVous faites partie de celles et ceux qui pensent que même avec plusieurs années d’expérience, on continue à apprendre ? Alors nous sommes sur la même longueur d'onde ! Et si on en parlait ?Au sein de l’Atelier Data & AI, on retrouve des communautés de pratique organisées par tribus. L’idée, c’est de se retrouver et de partager des expertises communes, de développer ses compétences en équipes à taille humaine. Vous aurez donc pour missions de faire du conseil, du delivery et de la R&D.Être Data Engineer on Cloud Data Platforms chez OCTO, c’est : 1- Faire du conseil autant que du delivery : accompagner nos clients dans la mise en œuvre de solutions autour de la gestion et transformation de leur Data. Participer au développement agile et à l’implémentation d’applications dans le respect des bonnes pratiques. Et bien sûr, qui dit conseil, dit convictions : proposer la solution la plus adaptée, c’est aussi savoir et oser challenger nos clients (et c’est dans notre ADN !) 2- Participer aux réponses aux appels d’offres et avant-ventes3- Participer activement à la R&D “Data & IA” : au programme, veille technologique & bonnes pratiques. Quelques sujets “chauds” du moment ? Le Green AI , Green Data et AI4Green 🌱4- Former & mentorer : le partage de connaissances et la montée en compétences des collaborateurs vous importent ? Nous sommes convaincus et prônons haut et fort la valeur de transmission. Mentoring et gestion de votre carrière seront donc à l’honneur. Et oui, chez OCTO le savoir n’est pas chasse gardée !"}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer H/F", "contract_type": "CDI", "salary": "55K à 75K €", "company": "skiils", "location": "Suresnes", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-12", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data", "company_size": "100", "creation_date": "2020", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "11", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables,", "scalabilité"], "DataBase": null, "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["(airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/lead-data-engineer-h-f?q=9c8fb74493503277e2004b746ca42534&o=999719ea-7110-4fad-a0b8-e54d20ddaeea", "description": "Descriptif du posteTu es passionné(e) par les données et tu maîtrises l’art de concevoir des pipelines de données robustes et performants ? Construire des architectures de données scalables, automatiser les flux et guider des équipes techniques t’enthousiasme ? Rejoins Data Factorii en tant que Lead Data Engineer et prends la tête des projets de transformation data les plus ambitieux !Mais qu’est-ce que l’équipe Data Factorii adresse ?En tant que Lead Data Engineer H/F, tes missions seront de :Concevoir et superviser les architectures de données : Créer des pipelines ETL/ELT performants et évolutifs, adaptés aux besoins des équipes Data Science et Business, en optimisant les flux de données.Guider une équipe d’ingénieurs data : Encadrer et accompagner les Data Engineers dans la mise en œuvre des solutions, assurer la répartition des tâches et garantir le respect des bonnes pratiques.Automatiser les processus de traitement des données : Mettre en place des solutions d’automatisation des pipelines, en utilisant les meilleurs outils et technologies (Airflow, Spark, Kafka, etc.).Optimiser les performances des plateformes de données : Améliorer la scalabilité des systèmes et optimiser les coûts liés aux infrastructures de stockage et de traitement des données dans le cloud ou on-premise.Collaborer avec les équipes Data Science et BI : Travailler main dans la main avec les Data Scientists, les analystes et les Product Owners pour assurer que les besoins métiers sont pris en compte et que les pipelines de données sont efficaces.Rester à la pointe des innovations technologiques : Veiller à l’évolution des outils et technologies utilisés et recommander de nouvelles solutions pour améliorer continuellement les architectures de données.Ce que nous t’offrons ?Un salaire attractif qui évolue en fonction de tes compétences et de ton impact sur les projets.Une carrière stimulante, avec des projets de data engineering d’envergure et des opportunités de leadership technique.Une mutuelle et un titre de transport pris en charge à 100 %, pour plus de tranquillité.Télétravail partiel, pour un équilibre parfait entre travail d’équipe et flexibilité.Et surtout, des projets passionnants qui te permettront de construire des solutions data innovantes et de contribuer à la transformation numérique des entreprises ! 🚀"}, {"source": "welcometothejungle", "job_title": "Lead Data Engineer H/F", "contract_type": "CDI", "salary": "55K à 75K €", "company": "skiils", "location": "Suresnes", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-12", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Transformation, Big Data", "company_size": "100", "creation_date": "2020", "address": null, "average_age_of_employees": "34", "turnover_in_millions": "11", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalables,", "scalabilité"], "DataBase": null, "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["(airflow,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/skiils/jobs/lead-data-engineer-h-f?q=9c8fb74493503277e2004b746ca42534&o=999719ea-7110-4fad-a0b8-e54d20ddaeea", "description": "Descriptif du posteTu es passionné(e) par les données et tu maîtrises l’art de concevoir des pipelines de données robustes et performants ? Construire des architectures de données scalables, automatiser les flux et guider des équipes techniques t’enthousiasme ? Rejoins Data Factorii en tant que Lead Data Engineer et prends la tête des projets de transformation data les plus ambitieux !Mais qu’est-ce que l’équipe Data Factorii adresse ?En tant que Lead Data Engineer H/F, tes missions seront de :Concevoir et superviser les architectures de données : Créer des pipelines ETL/ELT performants et évolutifs, adaptés aux besoins des équipes Data Science et Business, en optimisant les flux de données.Guider une équipe d’ingénieurs data : Encadrer et accompagner les Data Engineers dans la mise en œuvre des solutions, assurer la répartition des tâches et garantir le respect des bonnes pratiques.Automatiser les processus de traitement des données : Mettre en place des solutions d’automatisation des pipelines, en utilisant les meilleurs outils et technologies (Airflow, Spark, Kafka, etc.).Optimiser les performances des plateformes de données : Améliorer la scalabilité des systèmes et optimiser les coûts liés aux infrastructures de stockage et de traitement des données dans le cloud ou on-premise.Collaborer avec les équipes Data Science et BI : Travailler main dans la main avec les Data Scientists, les analystes et les Product Owners pour assurer que les besoins métiers sont pris en compte et que les pipelines de données sont efficaces.Rester à la pointe des innovations technologiques : Veiller à l’évolution des outils et technologies utilisés et recommander de nouvelles solutions pour améliorer continuellement les architectures de données.Ce que nous t’offrons ?Un salaire attractif qui évolue en fonction de tes compétences et de ton impact sur les projets.Une carrière stimulante, avec des projets de data engineering d’envergure et des opportunités de leadership technique.Une mutuelle et un titre de transport pris en charge à 100 %, pour plus de tranquillité.Télétravail partiel, pour un équilibre parfait entre travail d’équipe et flexibilité.Et surtout, des projets passionnants qui te permettront de construire des solutions data innovantes et de contribuer à la transformation numérique des entreprises ! 🚀"}, {"source": "welcometothejungle", "job_title": "Machine Learning Engineer Junior (H/F) | CDI", "contract_type": "CDI", "salary": "Non spécifié", "company": "Datascientest", "location": "Puteaux", "remote": "Télétravail occasionnel", "experience": "> 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "SaaS / Cloud Services, EdTech, Formation", "company_size": "130", "creation_date": "2016", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops.", "ml.•"], "EnSoftSkils": ["leadership", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-h-f-cdi_puteaux_DATAS_w1Az8r1?q=9c8fb74493503277e2004b746ca42534&o=21cb0944-065c-4238-bce6-8bdba1182a4f", "description": "Descriptif du posteRejoignez l’équipe Machine Learning Engineering au sein du pôle Data Science et jouez un rôle central dans la transformation digitale des entreprises et la formation des experts de demain.Vous interviendrez principalement sur le parcours Machine Learning Engineer, tout en apportant votre expertise dans les autres thématiques Data. Ce rôle stratégique s’articule autour de trois axes :1. Développement et Innovation :• Concevoir, mettre à jour et enrichir nos offres de formation couvrant des sujets avancés en Machine Learning et MLOps. Vous travaillerez notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.• Contribuer à positionner DataScientest comme un acteur à la pointe de l’innovation en suivant de près les évolutions du secteur et en intégrant les dernières tendances et outils dans les parcours d’apprentissage.2. Application et Coaching :• Encadrer et coacher les apprenants sur des projets pratiques de Machine Learning Engineering, en leur offrant des retours d’expérience concrets et des conseils techniques personnalisés.• Garantir que chaque projet d’entreprise est aligné avec les meilleures pratiques de l’industrie et répond aux besoins réels du marché, tout en aidant les clients à développer des compétences opérationnelles.3. Pédagogie et Leadership Technique :• Participer à l’animation des sessions de formation techniques autour du Machine Learning Engineering, où vous aurez l’occasion de partager votre expertise et d’échanger avec des professionnels et des passionnés du domaine.• Contribuer à créer un environnement d’apprentissage stimulant, favorisant la curiosité, la collaboration et l’innovation, tout en rendant accessibles des concepts complexes.Ce rôle vous place au cœur de l’innovation en Data Science, avec l’opportunité d’influencer directement l’évolution des compétences dans ce secteur. Si vous êtes passionné(e) par le Machine Learning Engineering, la pédagogie, et que vous avez envie de transmettre votre savoir tout en explorant des technologies de pointe, ce poste est fait pour vous !"}, {"source": "welcometothejungle", "job_title": "Machine Learning Engineer Junior (H/F) | CDI", "contract_type": "CDI", "salary": "Non spécifié", "company": "Datascientest", "location": "Puteaux", "remote": "Télétravail occasionnel", "experience": "> 6 mois", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "SaaS / Cloud Services, EdTech, Formation", "company_size": "130", "creation_date": "2016", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["digitale"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops.", "ml.•"], "EnSoftSkils": ["leadership", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/machine-learning-engineer-h-f-cdi_puteaux_DATAS_w1Az8r1?q=9c8fb74493503277e2004b746ca42534&o=21cb0944-065c-4238-bce6-8bdba1182a4f", "description": "Descriptif du posteRejoignez l’équipe Machine Learning Engineering au sein du pôle Data Science et jouez un rôle central dans la transformation digitale des entreprises et la formation des experts de demain.Vous interviendrez principalement sur le parcours Machine Learning Engineer, tout en apportant votre expertise dans les autres thématiques Data. Ce rôle stratégique s’articule autour de trois axes :1. Développement et Innovation :• Concevoir, mettre à jour et enrichir nos offres de formation couvrant des sujets avancés en Machine Learning et MLOps. Vous travaillerez notamment sur le déploiement de modèles, l’optimisation des performances et l’automatisation des pipelines ML.• Contribuer à positionner DataScientest comme un acteur à la pointe de l’innovation en suivant de près les évolutions du secteur et en intégrant les dernières tendances et outils dans les parcours d’apprentissage.2. Application et Coaching :• Encadrer et coacher les apprenants sur des projets pratiques de Machine Learning Engineering, en leur offrant des retours d’expérience concrets et des conseils techniques personnalisés.• Garantir que chaque projet d’entreprise est aligné avec les meilleures pratiques de l’industrie et répond aux besoins réels du marché, tout en aidant les clients à développer des compétences opérationnelles.3. Pédagogie et Leadership Technique :• Participer à l’animation des sessions de formation techniques autour du Machine Learning Engineering, où vous aurez l’occasion de partager votre expertise et d’échanger avec des professionnels et des passionnés du domaine.• Contribuer à créer un environnement d’apprentissage stimulant, favorisant la curiosité, la collaboration et l’innovation, tout en rendant accessibles des concepts complexes.Ce rôle vous place au cœur de l’innovation en Data Science, avec l’opportunité d’influencer directement l’évolution des compétences dans ce secteur. Si vous êtes passionné(e) par le Machine Learning Engineering, la pédagogie, et que vous avez envie de transmettre votre savoir tout en explorant des technologies de pointe, ce poste est fait pour vous !"}, {"source": "welcometothejungle", "job_title": "Data Engineer Confirmé(H/F) | CDI", "contract_type": "CDI", "salary": "Non spécifié", "company": "Datascientest", "location": "Puteaux", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "SaaS / Cloud Services, EdTech, Formation", "company_size": "130", "creation_date": "2016", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scala"], "DataBase": ["sql.", "bddnosql", "bddnosql", "(cassandra,", "neo4j,", "hbase,"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure)compréhension", "gcp,"], "DevTools": ["(github", "gitlab", "docker,", "jenkins,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": ["hbase,", "(cassandra,"], "Automation": ["ansible,", "kubernetes,"], "InfrastructureAsCode": ["terraform,"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kubernetes,"], "Collaboration": null, "Other": ["devops,", "devops,", "cloud", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-confirmed-h-f-cdi_puteaux_DATAS_bZYl8W?q=9c8fb74493503277e2004b746ca42534&o=0854f04c-1a08-4431-82bc-ad1a1c307c32", "description": "Descriptif du posteLe Data Engineer répondra aux besoins d’ingénierie des membres de DataScientest et garantira la qualité pédagogique du cursus.Ses objectifs sont fixés en termes de quantité et qualité de contenu développé, ainsi qu’en traitement des demandes liées au stockage, création de pipelines et déploiement des équipes.Il s’occupe d’exploiter les données internes pour améliorer le suivi des apprenants.MissionsAu sein de l’équipe Data Engineering, vos missions s’articulent autour des axes suivants :Développer les contenus de cours en Data Engineering et gérer les cohortesDiffuser son savoir aux apprenants et aux collaborateurs de DataScientestPousser les projets de R&D à un niveau engineering.Coordonner la roadmap de développer en coordination avec le head of contentRevue du contenu actuelVeille technologique sur le Big Data, le DevOps, etc.Compétences requises :Aisance orale et pédagogiqueMaîtrise de Python et SQL. La connaissance de Java et / ou Scala serait un plus.Maîtrise d’au moins 4 technos parmi : Docker, Kubernetes, Spark, ETL, Terraform, Ansible, Kafka, BDDNoSQL (Cassandra, Hbase, Neo4J, …). CI/CD (GitHub Actions, Gitlab CI, Circle CI, Jenkins, …).Bonne connaissance d’un ou plusieurs fournisseurs Cloud (AWS, GCP, Azure)Compréhension des principes de modélisation des données.Notions d’architecture Big Data.Attrait pour l’actualité relative au data engineering, DevOps, machine learning, deep learning, etintelligence artificielle.Bon niveau en Anglais."}, {"source": "welcometothejungle", "job_title": "Data Engineer Confirmé(H/F) | CDI", "contract_type": "CDI", "salary": "Non spécifié", "company": "Datascientest", "location": "Puteaux", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "SaaS / Cloud Services, EdTech, Formation", "company_size": "130", "creation_date": "2016", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": ["python", "java", "scala"], "DataBase": ["sql.", "bddnosql", "bddnosql", "(cassandra,", "neo4j,", "hbase,"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["(aws,", "azure)compréhension", "gcp,"], "DevTools": ["(github", "gitlab", "docker,", "jenkins,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": ["hbase,", "(cassandra,"], "Automation": ["ansible,", "kubernetes,"], "InfrastructureAsCode": ["terraform,"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kubernetes,"], "Collaboration": null, "Other": ["devops,", "devops,", "cloud", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/datascientest/jobs/data-engineer-confirmed-h-f-cdi_puteaux_DATAS_bZYl8W?q=9c8fb74493503277e2004b746ca42534&o=0854f04c-1a08-4431-82bc-ad1a1c307c32", "description": "Descriptif du posteLe Data Engineer répondra aux besoins d’ingénierie des membres de DataScientest et garantira la qualité pédagogique du cursus.Ses objectifs sont fixés en termes de quantité et qualité de contenu développé, ainsi qu’en traitement des demandes liées au stockage, création de pipelines et déploiement des équipes.Il s’occupe d’exploiter les données internes pour améliorer le suivi des apprenants.MissionsAu sein de l’équipe Data Engineering, vos missions s’articulent autour des axes suivants :Développer les contenus de cours en Data Engineering et gérer les cohortesDiffuser son savoir aux apprenants et aux collaborateurs de DataScientestPousser les projets de R&D à un niveau engineering.Coordonner la roadmap de développer en coordination avec le head of contentRevue du contenu actuelVeille technologique sur le Big Data, le DevOps, etc.Compétences requises :Aisance orale et pédagogiqueMaîtrise de Python et SQL. La connaissance de Java et / ou Scala serait un plus.Maîtrise d’au moins 4 technos parmi : Docker, Kubernetes, Spark, ETL, Terraform, Ansible, Kafka, BDDNoSQL (Cassandra, Hbase, Neo4J, …). CI/CD (GitHub Actions, Gitlab CI, Circle CI, Jenkins, …).Bonne connaissance d’un ou plusieurs fournisseurs Cloud (AWS, GCP, Azure)Compréhension des principes de modélisation des données.Notions d’architecture Big Data.Attrait pour l’actualité relative au data engineering, DevOps, machine learning, deep learning, etintelligence artificielle.Bon niveau en Anglais."}, {"source": "welcometothejungle", "job_title": "Data Engineer @eXalt Bordeaux", "contract_type": "CDI", "salary": "40K à 48K €", "company": "eXalt", "location": "Bordeaux", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-09", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-bordeaux_bordeaux?q=9c8fb74493503277e2004b746ca42534&o=a7d4717c-d564-4a34-95bf-672fec635e9d", "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data.Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Data Engineer @eXalt Bordeaux", "contract_type": "CDI", "salary": "40K à 48K €", "company": "eXalt", "location": "Bordeaux", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-09", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer-exalt-bordeaux_bordeaux?q=9c8fb74493503277e2004b746ca42534&o=a7d4717c-d564-4a34-95bf-672fec635e9d", "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data.Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer (F/H)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Qwant", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-11-26", "company_data": {"sector": "Big Data", "company_size": "84", "creation_date": "2013", "address": null, "average_age_of_employees": "37", "turnover_in_millions": null, "proportion_female": "25", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilité.en", "scalabilité"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/qwant/jobs/senior-data-engineer-f-h_paris?q=9c8fb74493503277e2004b746ca42534&o=e5961270-f33e-48ab-8ed2-678117318b67", "description": "Descriptif du posteNous recherchons un(e) Senior Data Engineer pour jouer un rôle clé dans l’amélioration des capacités de notre moteur de recherche. Vos missions incluront le développement et l’intégration de signaux extraits de documents web, afin de renforcer la pertinence et la performance de nos résultats.Vous serez responsable de la conception, de l’optimisation et du déploiement de pipelines robustes capables de traiter de grands volumes de données, tout en garantissant leur efficacité et leur scalabilité.En collaborant avec une équipe pluridisciplinaire, vous contribuerez à résoudre des problématiques complexes liées aux graphes, à la qualité des données, à la popularité des contenus, ainsi qu’à leur représentation structurée.De plus, vous serez amené(e) à :Vous contribuez au développement de nouveaux signaux pour enrichir notre moteur de recherche, en utilisant principalement Rust pour des solutions performantes et évolutives.Vous intégrez des signaux dans nos pipelines de données, en garantissant leur fiabilité, leur scalabilité et leur performance.Vous collaborez avec des ML Engineers pour intégrer les signaux dans les modèles d’apprentissage et optimiser leur impact sur les résultats du moteur de recherche.Vous optimisez l’utilisation des bases de données relationnelles pour stocker et gérer efficacement les données extraites.Vous êtes force de proposition sur des problématiques d’architecture technique et participez à la définition des meilleures pratiques en ingénierie des données."}, {"source": "welcometothejungle", "job_title": "Senior Data Engineer (F/H)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Qwant", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-11-26", "company_data": {"sector": "Big Data", "company_size": "84", "creation_date": "2013", "address": null, "average_age_of_employees": "37", "turnover_in_millions": null, "proportion_female": "25", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilité.en", "scalabilité"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["ml"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/qwant/jobs/senior-data-engineer-f-h_paris?q=9c8fb74493503277e2004b746ca42534&o=e5961270-f33e-48ab-8ed2-678117318b67", "description": "Descriptif du posteNous recherchons un(e) Senior Data Engineer pour jouer un rôle clé dans l’amélioration des capacités de notre moteur de recherche. Vos missions incluront le développement et l’intégration de signaux extraits de documents web, afin de renforcer la pertinence et la performance de nos résultats.Vous serez responsable de la conception, de l’optimisation et du déploiement de pipelines robustes capables de traiter de grands volumes de données, tout en garantissant leur efficacité et leur scalabilité.En collaborant avec une équipe pluridisciplinaire, vous contribuerez à résoudre des problématiques complexes liées aux graphes, à la qualité des données, à la popularité des contenus, ainsi qu’à leur représentation structurée.De plus, vous serez amené(e) à :Vous contribuez au développement de nouveaux signaux pour enrichir notre moteur de recherche, en utilisant principalement Rust pour des solutions performantes et évolutives.Vous intégrez des signaux dans nos pipelines de données, en garantissant leur fiabilité, leur scalabilité et leur performance.Vous collaborez avec des ML Engineers pour intégrer les signaux dans les modèles d’apprentissage et optimiser leur impact sur les résultats du moteur de recherche.Vous optimisez l’utilisation des bases de données relationnelles pour stocker et gérer efficacement les données extraites.Vous êtes force de proposition sur des problématiques d’architecture technique et participez à la définition des meilleures pratiques en ingénierie des données."}, {"source": "welcometothejungle", "job_title": "Data Engineer ", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-11-22", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=d00d5d3d-d3e0-4724-8f74-dec6afd99d81", "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data. Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Data Engineer ", "contract_type": "CDI", "salary": "Non spécifié", "company": "eXalt", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-11-22", "company_data": {"sector": "IT / Digital", "company_size": "950", "creation_date": "2018", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "75", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/exalt/jobs/data-engineer_paris?q=9c8fb74493503277e2004b746ca42534&o=d00d5d3d-d3e0-4724-8f74-dec6afd99d81", "description": "Descriptif du posteNous recherchons un Data Engineer Confirmé H/F (minimum 4 ans d’expérience dans la fonction) pour rejoindre notre communauté sur le pilier Data Engineering & Big Data. Vos missions:Concevoir et développer des pipelines et des flux de données.Intégrer et transformer des données provenant de différentes sources.Développer et mettre en œuvre des algorithmes de traitement de données avancés.Collaborer étroitement avec les équipes clients pour comprendre leurs besoins et fournir des solutions adaptées.Assurer la qualité et la fiabilité des solutions développées.Conseiller les équipes clients sur les solutions à mettre en place."}, {"source": "welcometothejungle", "job_title": "Analytics/BI Engineer", "contract_type": "CDI", "salary": "45K à 50K €", "company": "52 Entertainment", "location": "Boulogne-Billancourt", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-11-19", "company_data": {"sector": "Jeux vidéo", "company_size": "300", "creation_date": "2016", "address": null, "average_age_of_employees": "35", "turnover_in_millions": "71", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["sql", "sql", "sql"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["github,"], "OS": null, "DBMS": ["bigquery,", "bigquery,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["jirathe", "confluence,", "slack,", "teams,"], "Other": null, "EnSoftSkils": ["flexibility."]}, "link": "https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/analytics-bi-engineer_boulogne-billancourt?q=9c8fb74493503277e2004b746ca42534&o=e60bae30-678c-4d4a-b3e5-31db73a77cb3", "description": "Descriptif du posteJob descriptionWe are looking for an intermediate Analytics Engineer (or “BI Engineer”) -he/she/they- to join our Data Team . You will be responsible for designing, developing, and maintaining SQL models and data pipelines that enable data analysis, reporting, and visualization, empowering stakeholders to gain valuable insights and make data-driven decisions.. You will work inside the Product/Marketing squad inside the Data Team and you will report to the VP of Growth.This position is hybrid (4 days per week at the office) and located in Paris.Team descriptionThe Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia).Some are geeks, some are not, apply as you are, we’re a diversity-friendly team 🧕 👧🏽 🥷 👨🏿 👩 🦾. In our team everyone is to be treated equally regardless of sex, race, gender identification, disability, age, religion, …StackModern Data Stack: Prefect, Spark, Google BigQuery, dbt, Github, VSCode, Deepnote & LookerProject Management: Slack, Google Drive, Confluence, JiraThe Analytics Engineering activities will focus on Google BigQuery, dbt and Looker.MissionsTalk to Product/Marketing stackholders to understand their needsIdentify and implement models for key data sources (first-party or third party)Write SQL queries for various purposes (data cleaning, KPI modeling, …)Architecture a clean and scalable transformation pipeline using dbtDocument database models (comments in code, wiki pages)Audit raw and transformed data and create data quality testsConnect the created databases into Looker, our BI toolMaintain and configure Looker (user access/permissions)We’re excited about you because…You have hands-on experience building and optimizing dbt pipelines for B2C applications, ideally in the gaming industry, and know how to structure them for scalability and efficiency.You are skilled at setting up and maintaining self-service BI environments, particularly with Looker, enabling stakeholders to independently retrieve insights with ease.You excel at simplifying complex systems, creating data models that are intuitive, well-documented, and built for long-term maintainability.You have a strong understanding of SQL and know how to transform raw data into actionable metrics while ensuring data quality and reliability.You enjoy collaborating with diverse teams, translating business questions from Product and Marketing stakeholders into technical solutions.BenefitsWork in a start-up with exceptional growthHighly interesting work environment with flat hierarchy, fast pace and funYou’ll have a real impact on people’s lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development.Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best.Extreme autonomy. No micro-managing here. After onboarding, you’ll be given high-level direction and then left to solve it the way you feel is best.Amazingly friendly Data team."}, {"source": "welcometothejungle", "job_title": "Analytics/BI Engineer", "contract_type": "CDI", "salary": "45K à 50K €", "company": "52 Entertainment", "location": "Boulogne-Billancourt", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-11-19", "company_data": {"sector": "Jeux vidéo", "company_size": "300", "creation_date": "2016", "address": null, "average_age_of_employees": "35", "turnover_in_millions": "71", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["sql", "sql", "sql"], "DataAnalytics": null, "BigData": ["spark,"], "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": ["github,"], "OS": null, "DBMS": ["bigquery,", "bigquery,"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["jirathe", "confluence,", "slack,", "teams,"], "Other": null, "EnSoftSkils": ["flexibility."]}, "link": "https://www.welcometothejungle.com/fr/companies/52-entertainment/jobs/analytics-bi-engineer_boulogne-billancourt?q=9c8fb74493503277e2004b746ca42534&o=e60bae30-678c-4d4a-b3e5-31db73a77cb3", "description": "Descriptif du posteJob descriptionWe are looking for an intermediate Analytics Engineer (or “BI Engineer”) -he/she/they- to join our Data Team . You will be responsible for designing, developing, and maintaining SQL models and data pipelines that enable data analysis, reporting, and visualization, empowering stakeholders to gain valuable insights and make data-driven decisions.. You will work inside the Product/Marketing squad inside the Data Team and you will report to the VP of Growth.This position is hybrid (4 days per week at the office) and located in Paris.Team descriptionThe Data team at 52 entertainment is full of talents working on Business & Financial, Product and Marketing KPIs. It is a cross-functional team that connects with all business units (US, Europe, Asia).Some are geeks, some are not, apply as you are, we’re a diversity-friendly team 🧕 👧🏽 🥷 👨🏿 👩 🦾. In our team everyone is to be treated equally regardless of sex, race, gender identification, disability, age, religion, …StackModern Data Stack: Prefect, Spark, Google BigQuery, dbt, Github, VSCode, Deepnote & LookerProject Management: Slack, Google Drive, Confluence, JiraThe Analytics Engineering activities will focus on Google BigQuery, dbt and Looker.MissionsTalk to Product/Marketing stackholders to understand their needsIdentify and implement models for key data sources (first-party or third party)Write SQL queries for various purposes (data cleaning, KPI modeling, …)Architecture a clean and scalable transformation pipeline using dbtDocument database models (comments in code, wiki pages)Audit raw and transformed data and create data quality testsConnect the created databases into Looker, our BI toolMaintain and configure Looker (user access/permissions)We’re excited about you because…You have hands-on experience building and optimizing dbt pipelines for B2C applications, ideally in the gaming industry, and know how to structure them for scalability and efficiency.You are skilled at setting up and maintaining self-service BI environments, particularly with Looker, enabling stakeholders to independently retrieve insights with ease.You excel at simplifying complex systems, creating data models that are intuitive, well-documented, and built for long-term maintainability.You have a strong understanding of SQL and know how to transform raw data into actionable metrics while ensuring data quality and reliability.You enjoy collaborating with diverse teams, translating business questions from Product and Marketing stakeholders into technical solutions.BenefitsWork in a start-up with exceptional growthHighly interesting work environment with flat hierarchy, fast pace and funYou’ll have a real impact on people’s lives! If you have the potential, we will do everything to help you to achieve the highest level of personal and professional development.Ultimate flexibility. we try to have team overlap every day, but outside that work whenever and wherever you work best.Extreme autonomy. No micro-managing here. After onboarding, you’ll be given high-level direction and then left to solve it the way you feel is best.Amazingly friendly Data team."}, {"source": "welcometothejungle", "job_title": "Product Owner Data H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Wewyse", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2025-01-15", "company_data": {"sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation", "company_size": "90", "creation_date": "2019", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/wewyse/jobs/product-owner-data_paris_WEWYS_gomwlmz?q=9c8fb74493503277e2004b746ca42534&o=55ce1699-6e8b-434d-9aa2-dfad617e914c", "description": "Descriptif du posteÊtre Product Owner Data chez Wewyse c’est : intégrer une communauté d’experts Data passionnés,recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements,participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up,bénéficier des outils et du support de la communauté Wewyse pour mener à bien tous les projets,être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles,faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière,combiner expertise Data et méthodes agiles pour un maximum d’impact,intervenir sur des projets aux enjeux sans cesse renouvelés (diversité de secteur, de métier, de maturité Data, …),mettre la Data au cœur des processus de création de valeur de nos clients,maximiser la valeur des données de nos clients,renforcer la confiance des utilisateurs dans la donnée."}, {"source": "welcometothejungle", "job_title": "Product Owner Data H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Wewyse", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2025-01-15", "company_data": {"sector": "Digital Marketing / Data Marketing, IT / Digital, Transformation", "company_size": "90", "creation_date": "2019", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/wewyse/jobs/product-owner-data_paris_WEWYS_gomwlmz?q=9c8fb74493503277e2004b746ca42534&o=55ce1699-6e8b-434d-9aa2-dfad617e914c", "description": "Descriptif du posteÊtre Product Owner Data chez Wewyse c’est : intégrer une communauté d’experts Data passionnés,recevoir et partager de la connaissance et des savoirs-faire lors de nombreux évènements,participer à des projets innovants au sein de notre Datalab, avec des Wysers mais aussi avec des partenaires académiques et des start up,bénéficier des outils et du support de la communauté Wewyse pour mener à bien tous les projets,être encouragé, conseillé et accompagné dans un parcours de formation adapté à vos ambitions professionnelles,faire partie de la famille Wemanity avec ses évènements et ses multiples opportunités de carrière,combiner expertise Data et méthodes agiles pour un maximum d’impact,intervenir sur des projets aux enjeux sans cesse renouvelés (diversité de secteur, de métier, de maturité Data, …),mettre la Data au cœur des processus de création de valeur de nos clients,maximiser la valeur des données de nos clients,renforcer la confiance des utilisateurs dans la donnée."}, {"source": "welcometothejungle", "job_title": "VP/Head of Data  | LLM - NLP", "contract_type": "CDI", "salary": "Non spécifié", "company": "Jus Mundi", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 10", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Service juridique, Justice", "company_size": "85", "creation_date": "2018", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "6 million ARR", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability,"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership:", "leadership", "leadership:", "collaboration:", "organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/jus-mundi/jobs/vp-head-of-data-llm-nlp_paris?q=9c8fb74493503277e2004b746ca42534&o=098ca4bf-407f-4ba1-82a7-3102b9fd47f4", "description": "Descriptif du poste📌 Jus Mundi is looking for a VP/Head of Data | LLM - NLPAll our services are based on our global legal database, which is unique in the world! We collect and structure the world’s legal data and make it available to the legal community.LLM & NLP are at the heart of our model!We’re looking for an outstanding data leader to accompany us on our journey of making global legal information easily accessible worldwide.Your main responsibility will be to translate our vision of a global open legal world into a technical and scientific reality by designing and developing scalable data pipelines and leveraging cutting-edge Natural Language Processing (NLP) and large language models (LLM) to build solutions that push the boundaries of legal tech.📌 Key Responsibilities:Data Infrastructure Leadership: Provide technical and people leadership over the design, architecture, and development of data infrastructure to ensure scalability, reliability, and performance.Team Building & Leadership: Attract, retain, and grow top talent. Build a diverse team and provide guidance, mentorship, and career development opportunities to team members.Innovation & Continuous Improvement: Cultivate a culture of excellence and innovation. Continuously assess and improve the data science toolkit, adopting new methodologies to drive state-of-the-art performance.Cross-functional Collaboration: Collaborate with other departments such as Product, Engineering, Customer Success, Sales, and Marketing to align technical efforts with organizational goals. Attend the Board of Directors meetings and contribute to overall strategic decision-making.LLM & NLP Expertise: Lead your team in implementing solutions involving large language models (LLMs) and Natural Language Processing (NLP) to extract insights and create advanced features for our legal tech platforms.Data Extraction & Automation: Automate and improve data extraction processes, including Metadata Extraction, Concept Identification, and Citation Extraction. Innovate to automate the Data Structuring processes and enhance our existing citation extraction methods.Strategic Vision: Translate our vision of a global, open legal world into technical and scientific reality, ensuring the continued development of our platform and products."}, {"source": "welcometothejungle", "job_title": "VP/Head of Data  | LLM - NLP", "contract_type": "CDI", "salary": "Non spécifié", "company": "Jus Mundi", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 10", "education_level": "Bac +5 / Master", "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, Service juridique, Justice", "company_size": "85", "creation_date": "2018", "address": null, "average_age_of_employees": "36", "turnover_in_millions": "6 million ARR", "proportion_female": "55", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability,"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership:", "leadership", "leadership:", "collaboration:", "organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/jus-mundi/jobs/vp-head-of-data-llm-nlp_paris?q=9c8fb74493503277e2004b746ca42534&o=098ca4bf-407f-4ba1-82a7-3102b9fd47f4", "description": "Descriptif du poste📌 Jus Mundi is looking for a VP/Head of Data | LLM - NLPAll our services are based on our global legal database, which is unique in the world! We collect and structure the world’s legal data and make it available to the legal community.LLM & NLP are at the heart of our model!We’re looking for an outstanding data leader to accompany us on our journey of making global legal information easily accessible worldwide.Your main responsibility will be to translate our vision of a global open legal world into a technical and scientific reality by designing and developing scalable data pipelines and leveraging cutting-edge Natural Language Processing (NLP) and large language models (LLM) to build solutions that push the boundaries of legal tech.📌 Key Responsibilities:Data Infrastructure Leadership: Provide technical and people leadership over the design, architecture, and development of data infrastructure to ensure scalability, reliability, and performance.Team Building & Leadership: Attract, retain, and grow top talent. Build a diverse team and provide guidance, mentorship, and career development opportunities to team members.Innovation & Continuous Improvement: Cultivate a culture of excellence and innovation. Continuously assess and improve the data science toolkit, adopting new methodologies to drive state-of-the-art performance.Cross-functional Collaboration: Collaborate with other departments such as Product, Engineering, Customer Success, Sales, and Marketing to align technical efforts with organizational goals. Attend the Board of Directors meetings and contribute to overall strategic decision-making.LLM & NLP Expertise: Lead your team in implementing solutions involving large language models (LLMs) and Natural Language Processing (NLP) to extract insights and create advanced features for our legal tech platforms.Data Extraction & Automation: Automate and improve data extraction processes, including Metadata Extraction, Concept Identification, and Citation Extraction. Innovate to automate the Data Structuring processes and enhance our existing citation extraction methods.Strategic Vision: Translate our vision of a global, open legal world into technical and scientific reality, ensuring the continued development of our platform and products."}, {"source": "welcometothejungle", "job_title": "Principal Data Product Manager – Insight & Analytics", "contract_type": "CDI", "salary": "Non spécifié", "company": "Trainline", "location": "London", "remote": "Télétravail non renseigné", "experience": "> 5", "education_level": null, "publication_date": "2024-12-19", "company_data": {"sector": "Mobilité, Ferroviaire, E-commerce", "company_size": "1000", "creation_date": "1997", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,"], "Other": ["streamlining"], "EnSoftSkils": ["communication", "communication", "leadership", "leadership", "leadership.", "collaboration:", "collaboration,", "collaborations", "initiatives", "initiatives.", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/trainline/jobs/principal-data-product-manager-insight-analytics_london?q=9c8fb74493503277e2004b746ca42534&o=808a5f04-4d9c-4faa-a721-762f1ed20e12", "description": "Descriptif du poste🎄 Most of our Talent team are currently on leave for the holiday period, so your application is likely to be reviewed in January. Enjoy the break, we’ll get back to you in the new year! 🎄💻 Principal Data Product Manager 📍 London (Hybrid, 40% in office) 💸 £Salary + Bonus + Shares + Benefits  Introducing the Data team at Trainline 👋 At Trainline, data is at the heart of our operations. Our vision is to empower a data-driven environment where every business decision is backed by easily accessible insights, leveraging the latest in BI tooling and advanced analytics techniques. Through value-driven Data Insight and Analytics products, we enable smarter, faster, and more strategic decision-making across the company. Our Data team is equipped with extensive experience and a broad spectrum of skills, covering areas such as Data Platform management, Data Engineering, Business Intelligence, and Data Science, all crucial for our data enabled value delivery. Our operating model embeds data delivery teams within each strategic theme at the company level. This integration ensures data is central to achieving our objectives and outcomes. As a Principal Data Product Manager – Data Insight and Analytics, you will lead the development of impactful insight products, including a robust suite of BI dashboards and a cross-functional metric mart that delivers consistent, actionable metrics across all business domains. You will shape the vision for BI products, tooling, and accessibility, streamlining the time, cost, and expertise needed to generate insights. Central to this vision, the metric mart will enhance data team velocity and minimise risk through reusability, delivering greater cost and time efficiency across the organisation. Partnering closely with leaders in Product, Engineering, Data Science and Analytics, you will define a strategic roadmap for data insights that aligns with Trainline’s business objectives, advocating for high-impact initiatives and fostering continuous improvement. You will play a critical role in implementing agile methodologies to maximise the impact and value of our data products. Working closely with the delivery leads and data delivery teams, you will manage significant projects, deeply exploring solution options to maximising customer impact through Insight. Together with your team, you'll devise and implement detailed plans with clear milestones for monitoring progress and adapting strategies as necessary. In our autonomous environment, as a Principal Data Product Manager, your influence and impact will be substantial. Your leadership will be crucial in pioneering innovations and integrating high-value Insight Data Products, thus playing a vital role in our growth strategy, guiding execution, and promoting a culture of continuous learning in data products.  As a Principal Data Product Manager at Trainline, you will... 🚝Strategic Vision: Develop and champion a strategic vision for Insight and Analytics products that aligns with Trainline’s mission to drive efficient, data-driven decisions. Guided by industry trends, competitive insights, and company growth objectives, implement tooling solutions and data products that reduce cost, time-to-insight and enable actionable insights across all levels.  Stakeholder collaboration: Lead on stakeholder collaboration, guiding strategic discussions and decisions to assess data value opportunities, focusing on effort estimation, capacity planning, and prioritization to align with organisational goals.   Metric Mart Implementation: Oversee the design, deployment, and actualisation of a cross-domain metric mart that spans all business domains, ensuring comprehensive, consistent, and accessible data insights to support decision-making across the company. This includes establishing table design, selecting and defining key metrics, and implementing governance frameworks to maintain accuracy and consistency across data insights assets. Value Proposition Development: Partner with business stakeholders to craft compelling value propositions for insight and analytics initiatives. Clearly identify commercial, growth, and strategic benefits, with a focus on optimising data insight products and tools to support all areas of the business. Investment Advocacy: Advocate for and prioritise key investments within the Insight and Analytics domain, playing a central role in data planning cycles. Influence the strategic direction of Data Engineering, Business Intelligence, and Analytics to maximise resource allocation and impact.  Project Leadership and Execution: As a leader, you will deliver data initiatives through efficient project execution, guided by a clear and visible execution roadmap that emphasises agile value delivery milestones. Lead cross-functional collaborations beyond your immediate scope, thereby strengthening stakeholder trust through effective leadership. Stakeholder Communication and Engagement: Ensure continuous, transparent communication across all stakeholder levels, aligning on roadmaps, strategy, and project execution. Manage tactical adjustments and strategic decisions effectively throughout delivery phases. Outcome Ownership: Own and evaluate the performance of Insight and Analytics products, using frameworks such as OKRs and product scorecards. Analyse the real-world impact of deliverables, providing data-driven guidance for future prioritization and enhancements. Continuous Improvement: Conduct periodic retrospectives on key deliverables to extract learnings for future planning.  "}, {"source": "welcometothejungle", "job_title": "Principal Data Product Manager – Insight & Analytics", "contract_type": "CDI", "salary": "Non spécifié", "company": "Trainline", "location": "London", "remote": "Télétravail non renseigné", "experience": "> 5", "education_level": null, "publication_date": "2024-12-19", "company_data": {"sector": "Mobilité, Ferroviaire, E-commerce", "company_size": "1000", "creation_date": "1997", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,"], "Other": ["streamlining"], "EnSoftSkils": ["communication", "communication", "leadership", "leadership", "leadership.", "collaboration:", "collaboration,", "collaborations", "initiatives", "initiatives.", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/trainline/jobs/principal-data-product-manager-insight-analytics_london?q=9c8fb74493503277e2004b746ca42534&o=808a5f04-4d9c-4faa-a721-762f1ed20e12", "description": "Descriptif du poste🎄 Most of our Talent team are currently on leave for the holiday period, so your application is likely to be reviewed in January. Enjoy the break, we’ll get back to you in the new year! 🎄💻 Principal Data Product Manager 📍 London (Hybrid, 40% in office) 💸 £Salary + Bonus + Shares + Benefits  Introducing the Data team at Trainline 👋 At Trainline, data is at the heart of our operations. Our vision is to empower a data-driven environment where every business decision is backed by easily accessible insights, leveraging the latest in BI tooling and advanced analytics techniques. Through value-driven Data Insight and Analytics products, we enable smarter, faster, and more strategic decision-making across the company. Our Data team is equipped with extensive experience and a broad spectrum of skills, covering areas such as Data Platform management, Data Engineering, Business Intelligence, and Data Science, all crucial for our data enabled value delivery. Our operating model embeds data delivery teams within each strategic theme at the company level. This integration ensures data is central to achieving our objectives and outcomes. As a Principal Data Product Manager – Data Insight and Analytics, you will lead the development of impactful insight products, including a robust suite of BI dashboards and a cross-functional metric mart that delivers consistent, actionable metrics across all business domains. You will shape the vision for BI products, tooling, and accessibility, streamlining the time, cost, and expertise needed to generate insights. Central to this vision, the metric mart will enhance data team velocity and minimise risk through reusability, delivering greater cost and time efficiency across the organisation. Partnering closely with leaders in Product, Engineering, Data Science and Analytics, you will define a strategic roadmap for data insights that aligns with Trainline’s business objectives, advocating for high-impact initiatives and fostering continuous improvement. You will play a critical role in implementing agile methodologies to maximise the impact and value of our data products. Working closely with the delivery leads and data delivery teams, you will manage significant projects, deeply exploring solution options to maximising customer impact through Insight. Together with your team, you'll devise and implement detailed plans with clear milestones for monitoring progress and adapting strategies as necessary. In our autonomous environment, as a Principal Data Product Manager, your influence and impact will be substantial. Your leadership will be crucial in pioneering innovations and integrating high-value Insight Data Products, thus playing a vital role in our growth strategy, guiding execution, and promoting a culture of continuous learning in data products.  As a Principal Data Product Manager at Trainline, you will... 🚝Strategic Vision: Develop and champion a strategic vision for Insight and Analytics products that aligns with Trainline’s mission to drive efficient, data-driven decisions. Guided by industry trends, competitive insights, and company growth objectives, implement tooling solutions and data products that reduce cost, time-to-insight and enable actionable insights across all levels.  Stakeholder collaboration: Lead on stakeholder collaboration, guiding strategic discussions and decisions to assess data value opportunities, focusing on effort estimation, capacity planning, and prioritization to align with organisational goals.   Metric Mart Implementation: Oversee the design, deployment, and actualisation of a cross-domain metric mart that spans all business domains, ensuring comprehensive, consistent, and accessible data insights to support decision-making across the company. This includes establishing table design, selecting and defining key metrics, and implementing governance frameworks to maintain accuracy and consistency across data insights assets. Value Proposition Development: Partner with business stakeholders to craft compelling value propositions for insight and analytics initiatives. Clearly identify commercial, growth, and strategic benefits, with a focus on optimising data insight products and tools to support all areas of the business. Investment Advocacy: Advocate for and prioritise key investments within the Insight and Analytics domain, playing a central role in data planning cycles. Influence the strategic direction of Data Engineering, Business Intelligence, and Analytics to maximise resource allocation and impact.  Project Leadership and Execution: As a leader, you will deliver data initiatives through efficient project execution, guided by a clear and visible execution roadmap that emphasises agile value delivery milestones. Lead cross-functional collaborations beyond your immediate scope, thereby strengthening stakeholder trust through effective leadership. Stakeholder Communication and Engagement: Ensure continuous, transparent communication across all stakeholder levels, aligning on roadmaps, strategy, and project execution. Manage tactical adjustments and strategic decisions effectively throughout delivery phases. Outcome Ownership: Own and evaluate the performance of Insight and Analytics products, using frameworks such as OKRs and product scorecards. Analyse the real-world impact of deliverables, providing data-driven guidance for future prioritization and enhancements. Continuous Improvement: Conduct periodic retrospectives on key deliverables to extract learnings for future planning.  "}, {"source": "welcometothejungle", "job_title": "Full stack Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["mongodb,", "mongodb"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud-based"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/full-stack-engineer_nice?q=9c8fb74493503277e2004b746ca42534&o=eb4d45c8-3c5b-44b6-a237-eae5fbf5b63d", "description": "Descriptif du posteThe Role:We are looking for a Full Stack Engineer who is passionate about solving real-world problems and eager to work in an environment where your contributions will have a direct impact. You’ll join a collaborative team of 6 developers, 2 designers, and 2 product owners, and be involved in every stage of development, from design to production. You’ll work on our core technologies: AWS, CDK, MongoDB, TypeScript, NestJS, React, React-Native, and CubeJS for building a semantic data layer. You will operate in a “You build it, you run it” mode, owning your code end-to-end in a Serverless architecture.Key Responsibilities:Develop and maintain full-stack applications using TypeScript, NestJS, React, React-Native, and CubeJS for semantic data layers.Collaborate with product owners, designers, and developers to deliver intuitive and scalable applications.Work with AWS services and deploy infrastructure using the Cloud Development Kit (CDK).Manage and improve backend services, databases, and APIs using MongoDB and cloud-based architectures.Support the collection and processing of field data, providing valuable insights to seeders through our analytics platform.Own the lifecycle of the products you build—deploy, monitor, and maintain high-performance, secure systems.Contribute to improving the quality and scalability of our codebase and participate in code reviews."}, {"source": "welcometothejungle", "job_title": "Full stack Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": null, "education_level": "Bac +5 / Master", "publication_date": "2024-12-19", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable", "scalability"], "DataBase": ["mongodb,", "mongodb"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud-based"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/full-stack-engineer_nice?q=9c8fb74493503277e2004b746ca42534&o=eb4d45c8-3c5b-44b6-a237-eae5fbf5b63d", "description": "Descriptif du posteThe Role:We are looking for a Full Stack Engineer who is passionate about solving real-world problems and eager to work in an environment where your contributions will have a direct impact. You’ll join a collaborative team of 6 developers, 2 designers, and 2 product owners, and be involved in every stage of development, from design to production. You’ll work on our core technologies: AWS, CDK, MongoDB, TypeScript, NestJS, React, React-Native, and CubeJS for building a semantic data layer. You will operate in a “You build it, you run it” mode, owning your code end-to-end in a Serverless architecture.Key Responsibilities:Develop and maintain full-stack applications using TypeScript, NestJS, React, React-Native, and CubeJS for semantic data layers.Collaborate with product owners, designers, and developers to deliver intuitive and scalable applications.Work with AWS services and deploy infrastructure using the Cloud Development Kit (CDK).Manage and improve backend services, databases, and APIs using MongoDB and cloud-based architectures.Support the collection and processing of field data, providing valuable insights to seeders through our analytics platform.Own the lifecycle of the products you build—deploy, monitor, and maintain high-performance, secure systems.Contribute to improving the quality and scalability of our codebase and participate in code reviews."}, {"source": "welcometothejungle", "job_title": "Engineering Manager Data - Paris", "contract_type": "CDI", "salary": "Non spécifié", "company": "Swile", "location": "Paris, Montpellier", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "Application mobile, Restauration, FoodTech", "company_size": "1000", "creation_date": "2017", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": "48", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/swile/jobs/engineering-manager-montpellier-f-m-n_montpellier?q=9c8fb74493503277e2004b746ca42534&o=d7ad28eb-fd0a-43b6-80bc-2a08076ebc48", "description": "Descriptif du posteAt Swile, we believe that good products can help reduce friction in daily professional life and boost employee satisfaction. Today, we provide innovative solutions in various areas such as Fintech, Travel, HR, and Employee Benefits to more than 5.5 million users in 85,000 companies in France and Brazil.As an Engineering Manager Data, your primary role is to lead a team of software engineers in creating impactful software data products. This involves guiding the team’s technical direction, helping them do better, and making sure they meet their goals and roadmaps. Additionally, you’ll help build a sustainable engineering environment that supports long-term growth and innovation.Key ResponsibilitiesBalance strong technical skills with effective people management abilities.Drive the creation and execution of roadmaps.Lead teams in delivering multiple data projects.Engage in technical discussions, contribute to software architecture, and facilitate problem-solving.Measure team impact, establish clear expectations and goals.Oversee the software development lifecycle, implementing best-in-class engineering practices.Collaborate effectively with cross-functional partners and stakeholders to achieve optimal outcomes.Mentor and support the professional development of team members, fostering a culture of excellence and continuous improvement.Encourage innovation and innovative thinking among team members.Communicate effectively with team members, peers, and stakeholders, translating complex technical concepts into clear terms as necessary.Lead by example, establishing a positive work environment and promoting team cohesion."}, {"source": "welcometothejungle", "job_title": "Engineering Manager Data - Paris", "contract_type": "CDI", "salary": "Non spécifié", "company": "Swile", "location": "Paris, Montpellier", "remote": "Télétravail fréquent", "experience": null, "education_level": null, "publication_date": "2024-12-16", "company_data": {"sector": "Application mobile, Restauration, FoodTech", "company_size": "1000", "creation_date": "2017", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": "48", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams"], "Other": null, "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/swile/jobs/engineering-manager-montpellier-f-m-n_montpellier?q=9c8fb74493503277e2004b746ca42534&o=d7ad28eb-fd0a-43b6-80bc-2a08076ebc48", "description": "Descriptif du posteAt Swile, we believe that good products can help reduce friction in daily professional life and boost employee satisfaction. Today, we provide innovative solutions in various areas such as Fintech, Travel, HR, and Employee Benefits to more than 5.5 million users in 85,000 companies in France and Brazil.As an Engineering Manager Data, your primary role is to lead a team of software engineers in creating impactful software data products. This involves guiding the team’s technical direction, helping them do better, and making sure they meet their goals and roadmaps. Additionally, you’ll help build a sustainable engineering environment that supports long-term growth and innovation.Key ResponsibilitiesBalance strong technical skills with effective people management abilities.Drive the creation and execution of roadmaps.Lead teams in delivering multiple data projects.Engage in technical discussions, contribute to software architecture, and facilitate problem-solving.Measure team impact, establish clear expectations and goals.Oversee the software development lifecycle, implementing best-in-class engineering practices.Collaborate effectively with cross-functional partners and stakeholders to achieve optimal outcomes.Mentor and support the professional development of team members, fostering a culture of excellence and continuous improvement.Encourage innovation and innovative thinking among team members.Communicate effectively with team members, peers, and stakeholders, translating complex technical concepts into clear terms as necessary.Lead by example, establishing a positive work environment and promoting team cohesion."}, {"source": "welcometothejungle", "job_title": "Senior Lead Back End Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "AODocs", "location": "Paris", "remote": "Télétravail total", "experience": null, "education_level": null, "publication_date": "2024-12-10", "company_data": {"sector": "Logiciels, SaaS / Cloud Services", "company_size": "120", "creation_date": "2012", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "78", "proportion_male": null}, "skills": {"ProgLanguage": ["java", "javascript"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,", "teams,"], "Other": ["cloud"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/aodocs/jobs/principal-back-end-engineer_paris?q=bfc932583df57bd893f063f71af02e74&o=967d58fc-db26-4490-84f6-d509be76d0cf", "description": "Descriptif du posteIn a period of growth, Aodocs’ R&D department continues to structure itself. You will collaborate with Aodocs’ R&D and Services teams (each team consisting of multiple developers (backend and frontend) a QA specialist, a Product Owner, and a Site Reliability Engineer) to realize the technical vision of the Aodocs product and find innovative technical solutions suitable for Aodocs’ ambitious goals. Under the direct responsibility of the CTO, you will participate in the development of the operational and technical backend strategy.Our infrastructure is entirely based on the Google Cloud Platform. We primarily code in Java and to some extent in Javascript and Go.Your ResponsibilitiesEnsure the technical and technological alignment of the backend platform according to Aodocs’ business objectives.Work alongside the CTO, R&D teams, and services teams, to realize the technical vision of our products.Manage the Backend technical team, which includes the back end developers in R&D, defining methods, processes, best practices, tools, architecture, and more.Foster a team spirit to unite and empower backend engineers in addressing technical challenges related to Aodocs’ business.Ensure the operational continuity of the platform (backend).Define and follow an architectural roadmap that addresses business challenges (functional and technical).Promote a culture of innovation within the technical team (recruitment, onboarding, training, and technical leadership for backend engineers)."}, {"source": "welcometothejungle", "job_title": "Senior Lead Back End Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "AODocs", "location": "Paris", "remote": "Télétravail total", "experience": null, "education_level": null, "publication_date": "2024-12-10", "company_data": {"sector": "Logiciels, SaaS / Cloud Services", "company_size": "120", "creation_date": "2012", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "78", "proportion_male": null}, "skills": {"ProgLanguage": ["java", "javascript"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams,", "teams,"], "Other": ["cloud"], "EnSoftSkils": ["leadership"]}, "link": "https://www.welcometothejungle.com/fr/companies/aodocs/jobs/principal-back-end-engineer_paris?q=bfc932583df57bd893f063f71af02e74&o=967d58fc-db26-4490-84f6-d509be76d0cf", "description": "Descriptif du posteIn a period of growth, Aodocs’ R&D department continues to structure itself. You will collaborate with Aodocs’ R&D and Services teams (each team consisting of multiple developers (backend and frontend) a QA specialist, a Product Owner, and a Site Reliability Engineer) to realize the technical vision of the Aodocs product and find innovative technical solutions suitable for Aodocs’ ambitious goals. Under the direct responsibility of the CTO, you will participate in the development of the operational and technical backend strategy.Our infrastructure is entirely based on the Google Cloud Platform. We primarily code in Java and to some extent in Javascript and Go.Your ResponsibilitiesEnsure the technical and technological alignment of the backend platform according to Aodocs’ business objectives.Work alongside the CTO, R&D teams, and services teams, to realize the technical vision of our products.Manage the Backend technical team, which includes the back end developers in R&D, defining methods, processes, best practices, tools, architecture, and more.Foster a team spirit to unite and empower backend engineers in addressing technical challenges related to Aodocs’ business.Ensure the operational continuity of the platform (backend).Define and follow an architectural roadmap that addresses business challenges (functional and technical).Promote a culture of innovation within the technical team (recruitment, onboarding, training, and technical leadership for backend engineers)."}, {"source": "welcometothejungle", "job_title": "Senior Software Engineer Java/Spring (H/F/NB) ", "contract_type": "CDI", "salary": "Non spécifié", "company": "lesfurets", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-16", "company_data": {"sector": "Logiciels, FinTech / InsurTech, E-commerce", "company_size": "102", "creation_date": "2012", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership", "d’initiatives,"]}, "link": "https://www.welcometothejungle.com/fr/companies/lesfurets/jobs/senior-software-engineer-java-spring-h-f-nb_paris?q=bfc932583df57bd893f063f71af02e74&o=a5575640-26c0-427b-89f0-6891b2d92461", "description": "Descriptif du posteContexteDans un contexte métier où les exigences réglementaires et les attentes des clients se durcissent, lesfurets reste leader de son marché. Répondre à ces attentes nécessite une évolution perpétuelle de nos outils.  Notre monolithe Java amorce une refonte modulaire, pour gagner en agilité, isoler nos déploiements et surtout améliorer la délivrabilité de nos projets B2B. Nous devons assurer cette refonte tout en conservant séniorité et efficacité sur notre chaine de production B2B, ce qui motive cette ouverture de poste. MissionsAu sein de notre plus grande Team (7 développeurs, un Tech Lead, accompagnés par 2 Technical Account Managers, vous : Contribuez au pilotage et à l’orientation stratégique de notre offre commerciale, notamment en exploitant des WebServices, en mettant en place des mappings avancés. Prenez un rôle de leadership technique dans le développement et l’amélioration de nos outils B2B et internes en mode Self Service (remontée des ventes, plateformes de partage documentaires, configurations dynamiques…). Évaluez et influencez nos futures solutions technologiques (participation aux Comités d’Architecture, encadrement de mob programming, animation d’ateliers de conception). Supervisez le monitoring et l’optimisation du code en production, ainsi que les déploiements. Définissez et améliorez continuellement nos politiques de tests, checklists d’intégration, et conventions de code. Dans notre contexte de transformation, avec une refonte technique majeure en cours et le déploiement d’une team offShore, nous devons plus que jamais renforcer nos critères de qualité, en gardant hautes nos exigences de Code Review, tout en accompagnant les plus jeunes à prendre part à l’innovation essentiel à la transformation de nos outils. Au quotidien :Nous vous proposons une gestion du temps avec davantage d’autonomie et d’initiatives, en réservant une part importante à l’innovation et à la qualité. En tant que Senior Software Engineer, vous organiserez votre temps avec une grande autonomie afin de : Proposer et implémenter des solutions techniques innovantes et évolutives, en garantissant le respect de nos standards. Encadrer et faire progresser les normes de sécurité et les standards de code pour qu’ils soient solides, fiables, et constamment mis à jour. Participer activement aux revues de code et aider à la montée en compétence des autres membres de l’équipe. Participer activement aux rituels optimisés autour d’un Kanban, avec un fort accent sur l’Amélioration Continue. Tester de manière extensive : tests unitaires, d’intégration, jeux de données de test, profils automatisés… Votre commit passera-t-il la CI et vous conduira-t-il sans impair au Showcase des TAM ? Mais la Tech chez lesfurets, c’est aussi : Des opportunités accrues de mobilité interne et de développement de carrière, avec un suivi individualisé. Une politique de télétravail avantageuse (2 jours de présence au bureau par semaine). Une forte culture de la documentation, garantissant que tout le monde est bien informé à chaque étape du processus. Une équipe qui maitrise ses sujets Métier (opportunité de se former aux domaines de l’assurance) Un process d’on-boarding parsemé de rendez-vous d’induction avec nos différents services, et un on-boarding Tech cadré et structuré"}, {"source": "welcometothejungle", "job_title": "Senior Software Engineer Java/Spring (H/F/NB) ", "contract_type": "CDI", "salary": "Non spécifié", "company": "lesfurets", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": null, "publication_date": "2025-01-16", "company_data": {"sector": "Logiciels, FinTech / InsurTech, E-commerce", "company_size": "102", "creation_date": "2012", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "50", "proportion_male": null}, "skills": {"ProgLanguage": ["java"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership", "d’initiatives,"]}, "link": "https://www.welcometothejungle.com/fr/companies/lesfurets/jobs/senior-software-engineer-java-spring-h-f-nb_paris?q=bfc932583df57bd893f063f71af02e74&o=a5575640-26c0-427b-89f0-6891b2d92461", "description": "Descriptif du posteContexteDans un contexte métier où les exigences réglementaires et les attentes des clients se durcissent, lesfurets reste leader de son marché. Répondre à ces attentes nécessite une évolution perpétuelle de nos outils.  Notre monolithe Java amorce une refonte modulaire, pour gagner en agilité, isoler nos déploiements et surtout améliorer la délivrabilité de nos projets B2B. Nous devons assurer cette refonte tout en conservant séniorité et efficacité sur notre chaine de production B2B, ce qui motive cette ouverture de poste. MissionsAu sein de notre plus grande Team (7 développeurs, un Tech Lead, accompagnés par 2 Technical Account Managers, vous : Contribuez au pilotage et à l’orientation stratégique de notre offre commerciale, notamment en exploitant des WebServices, en mettant en place des mappings avancés. Prenez un rôle de leadership technique dans le développement et l’amélioration de nos outils B2B et internes en mode Self Service (remontée des ventes, plateformes de partage documentaires, configurations dynamiques…). Évaluez et influencez nos futures solutions technologiques (participation aux Comités d’Architecture, encadrement de mob programming, animation d’ateliers de conception). Supervisez le monitoring et l’optimisation du code en production, ainsi que les déploiements. Définissez et améliorez continuellement nos politiques de tests, checklists d’intégration, et conventions de code. Dans notre contexte de transformation, avec une refonte technique majeure en cours et le déploiement d’une team offShore, nous devons plus que jamais renforcer nos critères de qualité, en gardant hautes nos exigences de Code Review, tout en accompagnant les plus jeunes à prendre part à l’innovation essentiel à la transformation de nos outils. Au quotidien :Nous vous proposons une gestion du temps avec davantage d’autonomie et d’initiatives, en réservant une part importante à l’innovation et à la qualité. En tant que Senior Software Engineer, vous organiserez votre temps avec une grande autonomie afin de : Proposer et implémenter des solutions techniques innovantes et évolutives, en garantissant le respect de nos standards. Encadrer et faire progresser les normes de sécurité et les standards de code pour qu’ils soient solides, fiables, et constamment mis à jour. Participer activement aux revues de code et aider à la montée en compétence des autres membres de l’équipe. Participer activement aux rituels optimisés autour d’un Kanban, avec un fort accent sur l’Amélioration Continue. Tester de manière extensive : tests unitaires, d’intégration, jeux de données de test, profils automatisés… Votre commit passera-t-il la CI et vous conduira-t-il sans impair au Showcase des TAM ? Mais la Tech chez lesfurets, c’est aussi : Des opportunités accrues de mobilité interne et de développement de carrière, avec un suivi individualisé. Une politique de télétravail avantageuse (2 jours de présence au bureau par semaine). Une forte culture de la documentation, garantissant que tout le monde est bien informé à chaque étape du processus. Une équipe qui maitrise ses sujets Métier (opportunité de se former aux domaines de l’assurance) Un process d’on-boarding parsemé de rendez-vous d’induction avec nos différents services, et un on-boarding Tech cadré et structuré"}, {"source": "welcometothejungle", "job_title": "Data Analyst H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Dayuse.com", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-14", "company_data": {"sector": "Application mobile, SaaS / Cloud Services, Hôtellerie", "company_size": "100", "creation_date": "2010", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableau-", "tableaux", "tableau.-"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["snowflake-"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration", "collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/dayuse-com/jobs/data-analyst-h-f_paris_DAYUS_76al48l?q=bfc932583df57bd893f063f71af02e74&o=6f00b13a-f37f-4290-9ab9-a82dc9987bdd", "description": "Descriptif du posteQui sommes-nous ?  Dayuse est le leader mondial de la réservation d’expériences à l’hôtel en journée.  Tes missions : Dans le cadre de sa forte croissance et de son internationalisation, Dayuse.com recherche un(e) Data Analyst confirmé(e) pour renforcer l’équipe data. La mission principale sera de mettre en place une chaîne décisionnelle complète, et d’assurer son évolution et son maintien opérationnel.L’équipe data, transverse à toute l’entreprise, est directement rattachée au COO.  Outils- Tableau- Snowflake- Fivetran- Dbt- Hightouch  Responsabilités :l’équipe data a pour missions principales :- Analyse de données : Fournir des analyses approfondies sur les performances, les problématiques métiers et l’optimisation des processus internes pour guider la stratégie de Dayuse.- Tableaux de bord sur mesure : Créer et maintenir des dashboard performant pour les divers métiers sur Tableau.- Modélisation des données avec dbt : Construire et maintenir des modèles de données structurés pour des analyses fiables et robustes.- Automatisation des pipelines avec Fivetran : Assurer la qualité et la fiabilité des données en automatisant les flux d’ingestion.- Collaboration interne : Travailler en étroite collaboration avec les équipes business pour comprendre leurs besoins en données et proposer des solutions sur mesure.- Amélioration continue : Participer activement à l’évolution de notre infrastructure data en collaboration avec les équipes techniques pour soutenir la croissance de Dayuse."}, {"source": "welcometothejungle", "job_title": "Data Analyst H/F", "contract_type": "CDI", "salary": "Non spécifié", "company": "Dayuse.com", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-14", "company_data": {"sector": "Application mobile, SaaS / Cloud Services, Hôtellerie", "company_size": "100", "creation_date": "2010", "address": null, "average_age_of_employees": "32", "turnover_in_millions": null, "proportion_female": "45", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": ["tableau-", "tableaux", "tableau.-"], "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": ["snowflake-"], "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration", "collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/dayuse-com/jobs/data-analyst-h-f_paris_DAYUS_76al48l?q=bfc932583df57bd893f063f71af02e74&o=6f00b13a-f37f-4290-9ab9-a82dc9987bdd", "description": "Descriptif du posteQui sommes-nous ?  Dayuse est le leader mondial de la réservation d’expériences à l’hôtel en journée.  Tes missions : Dans le cadre de sa forte croissance et de son internationalisation, Dayuse.com recherche un(e) Data Analyst confirmé(e) pour renforcer l’équipe data. La mission principale sera de mettre en place une chaîne décisionnelle complète, et d’assurer son évolution et son maintien opérationnel.L’équipe data, transverse à toute l’entreprise, est directement rattachée au COO.  Outils- Tableau- Snowflake- Fivetran- Dbt- Hightouch  Responsabilités :l’équipe data a pour missions principales :- Analyse de données : Fournir des analyses approfondies sur les performances, les problématiques métiers et l’optimisation des processus internes pour guider la stratégie de Dayuse.- Tableaux de bord sur mesure : Créer et maintenir des dashboard performant pour les divers métiers sur Tableau.- Modélisation des données avec dbt : Construire et maintenir des modèles de données structurés pour des analyses fiables et robustes.- Automatisation des pipelines avec Fivetran : Assurer la qualité et la fiabilité des données en automatisant les flux d’ingestion.- Collaboration interne : Travailler en étroite collaboration avec les équipes business pour comprendre leurs besoins en données et proposer des solutions sur mesure.- Amélioration continue : Participer activement à l’évolution de notre infrastructure data en collaboration avec les équipes techniques pour soutenir la croissance de Dayuse."}, {"source": "welcometothejungle", "job_title": "Solutions Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Opendatasoft", "location": "Paris, Nantes", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-10", "company_data": {"sector": "Logiciels, SaaS / Cloud Services, Big Data", "company_size": "90", "creation_date": "2011", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": "44", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration", "plateforme.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/opendatasoft/jobs/solution-engineer?q=bfc932583df57bd893f063f71af02e74&o=a86a00ef-8e40-4f5e-995a-d40a71b1be63", "description": "Descriptif du posteVotre rôle : concevoir des Data Experiences impactantes et innovantesEn tant que Solutions Engineer chez Opendatasoft, vous serez au cœur de projets stratégiques pour nos clients. Vous jouerez un rôle clé dans la conception et la livraison d’expériences de données innovantes et impactantes.Votre mission : associer expertise technique, créativité et sens du service pour maximiser la valeur des données.Vos missions1. Délivrer des Data Experiences à impactAnalyse et cadrage : travailler avec les clients pour recueillir leurs besoins, rédiger des spécifications techniques et contribuer au chiffrage des devis.Traitement des données : identifier les modèles de données pertinents et configurer des pipelines de traitement.Design et développement :Participer à la conception de maquettes fonctionnelles prenant en compte les besoins du client et les capacités de la plateforme Opendatasoft.Développer des Data Experiences en exploitant les fonctionnalités no-code et low-code de la plateforme Opendatasoft ou en créant des applications full-custom.Documentation : rédiger une documentation claire pour permettre la maintenance des pages par les équipes clientes.Avant-vente : intervenir en phase d’avant-vente pour soutenir les équipes commerciales sur les aspects techniques.2. Soutenir les profils Customer Facing dans leurs missions techniquesSoutien technique : appuyer les Customer Success Managers (CSMs), Onboarding Managers et Technical Project Managers dans les cas complexes ou les interactions directes avec les clients.Ateliers techniques : animer des ateliers avancés (au-delà des formations de base) avec les clients, en collaboration avec l’Onboarding Manager.Mentorat : former et accompagner les profils Customer Facing sur des aspects techniques tels que les API, widgets ou processeurs avancés de la plateforme.3. Contribuer à l’amélioration des composants de la plateformeSDK et composants : apporter des retours d’expérience pour améliorer le SDK et les composants associés à la plateforme.Collaboration inter-squads : participer, lorsque la charge de travail le permet, à des projets transverses en collaboration avec l’équipe R&D d’Opendatasoft.Pourquoi nous rejoindre ?Un rôle stratégique : Participez à des projets impactants, visibles à haut niveau et clés pour nos clients.Une mission valorisante : Mettez en valeur vos compétences en aidant nos clients à transformer leurs données en leviers de croissance.Un environnement innovant : Travaillez au sein d’une équipe collaborative et dynamique, dans une entreprise en pleine expansion.Une opportunité d’évolution : Devenez un(e) expert(e) des technologies SaaS et contribuez activement à l’évolution de notre plateforme."}, {"source": "welcometothejungle", "job_title": "Solutions Engineer", "contract_type": "CDI", "salary": "Non spécifié", "company": "Opendatasoft", "location": "Paris, Nantes", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-10", "company_data": {"sector": "Logiciels, SaaS / Cloud Services, Big Data", "company_size": "90", "creation_date": "2011", "address": null, "average_age_of_employees": "35", "turnover_in_millions": null, "proportion_female": "44", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["collaboration", "plateforme.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/opendatasoft/jobs/solution-engineer?q=bfc932583df57bd893f063f71af02e74&o=a86a00ef-8e40-4f5e-995a-d40a71b1be63", "description": "Descriptif du posteVotre rôle : concevoir des Data Experiences impactantes et innovantesEn tant que Solutions Engineer chez Opendatasoft, vous serez au cœur de projets stratégiques pour nos clients. Vous jouerez un rôle clé dans la conception et la livraison d’expériences de données innovantes et impactantes.Votre mission : associer expertise technique, créativité et sens du service pour maximiser la valeur des données.Vos missions1. Délivrer des Data Experiences à impactAnalyse et cadrage : travailler avec les clients pour recueillir leurs besoins, rédiger des spécifications techniques et contribuer au chiffrage des devis.Traitement des données : identifier les modèles de données pertinents et configurer des pipelines de traitement.Design et développement :Participer à la conception de maquettes fonctionnelles prenant en compte les besoins du client et les capacités de la plateforme Opendatasoft.Développer des Data Experiences en exploitant les fonctionnalités no-code et low-code de la plateforme Opendatasoft ou en créant des applications full-custom.Documentation : rédiger une documentation claire pour permettre la maintenance des pages par les équipes clientes.Avant-vente : intervenir en phase d’avant-vente pour soutenir les équipes commerciales sur les aspects techniques.2. Soutenir les profils Customer Facing dans leurs missions techniquesSoutien technique : appuyer les Customer Success Managers (CSMs), Onboarding Managers et Technical Project Managers dans les cas complexes ou les interactions directes avec les clients.Ateliers techniques : animer des ateliers avancés (au-delà des formations de base) avec les clients, en collaboration avec l’Onboarding Manager.Mentorat : former et accompagner les profils Customer Facing sur des aspects techniques tels que les API, widgets ou processeurs avancés de la plateforme.3. Contribuer à l’amélioration des composants de la plateformeSDK et composants : apporter des retours d’expérience pour améliorer le SDK et les composants associés à la plateforme.Collaboration inter-squads : participer, lorsque la charge de travail le permet, à des projets transverses en collaboration avec l’équipe R&D d’Opendatasoft.Pourquoi nous rejoindre ?Un rôle stratégique : Participez à des projets impactants, visibles à haut niveau et clés pour nos clients.Une mission valorisante : Mettez en valeur vos compétences en aidant nos clients à transformer leurs données en leviers de croissance.Un environnement innovant : Travaillez au sein d’une équipe collaborative et dynamique, dans une entreprise en pleine expansion.Une opportunité d’évolution : Devenez un(e) expert(e) des technologies SaaS et contribuez activement à l’évolution de notre plateforme."}, {"source": "welcometothejungle", "job_title": "Principal Software Engineer", "contract_type": "CDI", "salary": "200K à 250K $", "company": "Dfns", "location": "New York", "remote": "Télétravail total", "experience": "> 7", "education_level": "Bac +3", "publication_date": "2025-01-08", "company_data": {"sector": "Blockchain, Cybersécurité, Finance", "company_size": "25", "creation_date": "2020", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "15", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-software-engineer_new-york?q=bfc932583df57bd893f063f71af02e74&o=43664b5c-0ff1-4a29-b2d3-8c49a60e4205", "description": "Descriptif du posteJoin an exceptional team of leaders (CTO, CPO, Head of Research) and experts (Cryptography, Infrastructure, Security Engineers) to build the leading blockchain wallet infrastructure for the next financial era. We are hiring a Principal Software Engineer to develop and deliver high-quality software solutions. In this role, you will work with senior management to define requirements and lead key operational and technical projects. You will take ownership of critical projects and bring strong organizational and problem-solving skills to the team. As a Principal Software Engineer, you will also lead software change and release management, helping improve the software development process. Your goal will be to ensure software meets high-quality standards and is delivered on time."}, {"source": "welcometothejungle", "job_title": "Principal Software Engineer", "contract_type": "CDI", "salary": "200K à 250K $", "company": "Dfns", "location": "New York", "remote": "Télétravail total", "experience": "> 7", "education_level": "Bac +3", "publication_date": "2025-01-08", "company_data": {"sector": "Blockchain, Cybersécurité, Finance", "company_size": "25", "creation_date": "2020", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "15", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-software-engineer_new-york?q=bfc932583df57bd893f063f71af02e74&o=43664b5c-0ff1-4a29-b2d3-8c49a60e4205", "description": "Descriptif du posteJoin an exceptional team of leaders (CTO, CPO, Head of Research) and experts (Cryptography, Infrastructure, Security Engineers) to build the leading blockchain wallet infrastructure for the next financial era. We are hiring a Principal Software Engineer to develop and deliver high-quality software solutions. In this role, you will work with senior management to define requirements and lead key operational and technical projects. You will take ownership of critical projects and bring strong organizational and problem-solving skills to the team. As a Principal Software Engineer, you will also lead software change and release management, helping improve the software development process. Your goal will be to ensure software meets high-quality standards and is delivered on time."}, {"source": "welcometothejungle", "job_title": "Principal Software Engineer", "contract_type": "CDI", "salary": "120K à 140K €", "company": "Dfns", "location": "Paris", "remote": "Télétravail total", "experience": "> 7", "education_level": "Bac +3", "publication_date": "2025-01-08", "company_data": {"sector": "Blockchain, Cybersécurité, Finance", "company_size": "25", "creation_date": "2020", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "15", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-software-engineer_paris_DFNS_MjbKVyR?q=bfc932583df57bd893f063f71af02e74&o=df9e928c-a884-432e-b7e2-a3a40c6a1e8a", "description": "Descriptif du posteJoin an exceptional team of leaders (CTO, CPO, Head of Research) and experts (Cryptography, Infrastructure, Security Engineers) to build the leading blockchain wallet infrastructure for the next financial era. We are hiring a Principal Software Engineer to develop and deliver high-quality software solutions. In this role, you will work with senior management to define requirements and lead key operational and technical projects. You will take ownership of critical projects and bring strong organizational and problem-solving skills to the team. As a Principal Software Engineer, you will also lead software change and release management, helping improve the software development process. Your goal will be to ensure software meets high-quality standards and is delivered on time."}, {"source": "welcometothejungle", "job_title": "Principal Software Engineer", "contract_type": "CDI", "salary": "120K à 140K €", "company": "Dfns", "location": "Paris", "remote": "Télétravail total", "experience": "> 7", "education_level": "Bac +3", "publication_date": "2025-01-08", "company_data": {"sector": "Blockchain, Cybersécurité, Finance", "company_size": "25", "creation_date": "2020", "address": null, "average_age_of_employees": "36", "turnover_in_millions": null, "proportion_female": "15", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["organizational"]}, "link": "https://www.welcometothejungle.com/fr/companies/dfns/jobs/principal-software-engineer_paris_DFNS_MjbKVyR?q=bfc932583df57bd893f063f71af02e74&o=df9e928c-a884-432e-b7e2-a3a40c6a1e8a", "description": "Descriptif du posteJoin an exceptional team of leaders (CTO, CPO, Head of Research) and experts (Cryptography, Infrastructure, Security Engineers) to build the leading blockchain wallet infrastructure for the next financial era. We are hiring a Principal Software Engineer to develop and deliver high-quality software solutions. In this role, you will work with senior management to define requirements and lead key operational and technical projects. You will take ownership of critical projects and bring strong organizational and problem-solving skills to the team. As a Principal Software Engineer, you will also lead software change and release management, helping improve the software development process. Your goal will be to ensure software meets high-quality standards and is delivered on time."}, {"source": "welcometothejungle", "job_title": "Data Scientist (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Veesion", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "150", "creation_date": "2018", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "8M €", "proportion_female": "37", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops", "seamlessly", "cloud"], "EnSoftSkils": ["organization:chief"]}, "link": "https://www.welcometothejungle.com/fr/companies/veesion-1/jobs/data-scientist_paris?q=bfc932583df57bd893f063f71af02e74&o=fbf65633-4910-46ec-85c9-fc0deb8f058a", "description": "Descriptif du postePlease apply directly on our career site right here.All applications submitted via Welcome will not be processedVeesion is at the forefront of in-store theft detection solutions, transforming how retailers protect their products and optimize their operations. Our technology combines advanced video analysis, AI-driven insights, and intuitive user experiences to deliver real-time prevention and actionable intelligence. As we continue to scale, we’re looking for a Senior Data Scientist to empower Veesion’AI.You will join our growing Data team currently consisting of three experts in MLOps and Data Science. While the team tackles multiple missions, your focus will be on optimizing the use of our AI models to maximize client satisfaction.This involves exploring innovative ways to reduce missed thefts and irrelevant alerts by building on top of Veesion’s Deep Learning models.Reporting to the Head of Data, you will collaborate with key stakeholders across the organization:Chief Executive Officer: Align on business objectives and strategic prioritiesChief Scientific Officer: Refine problem definitions and methodologiesTech Team: Work closely with a team of over 10 software engineers to integrate AI capabilities seamlessly into Veesion’s systemsTasksOptimize success criteria for each camera by selecting appropriate models, fine-tuning hyperparameters, and adjusting sensitivity thresholds.Lead cross-functional projects with a strong Data Science focus, driving innovation and impact.Curate and manage datasets to enhance metrics relevance and support meaningful theoretical evaluations.Analyze production datato guide development priorities and inform high-level strategic decisions.Run video AI models for training and inference on diverse cloud infrastructures.Conduct large-scale A/B testing on premises to evaluate and refine AI solutions."}, {"source": "welcometothejungle", "job_title": "Data Scientist (H/F)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Veesion", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2025-01-07", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SaaS / Cloud Services", "company_size": "150", "creation_date": "2018", "address": null, "average_age_of_employees": "29", "turnover_in_millions": "8M €", "proportion_female": "37", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["mlops", "seamlessly", "cloud"], "EnSoftSkils": ["organization:chief"]}, "link": "https://www.welcometothejungle.com/fr/companies/veesion-1/jobs/data-scientist_paris?q=bfc932583df57bd893f063f71af02e74&o=fbf65633-4910-46ec-85c9-fc0deb8f058a", "description": "Descriptif du postePlease apply directly on our career site right here.All applications submitted via Welcome will not be processedVeesion is at the forefront of in-store theft detection solutions, transforming how retailers protect their products and optimize their operations. Our technology combines advanced video analysis, AI-driven insights, and intuitive user experiences to deliver real-time prevention and actionable intelligence. As we continue to scale, we’re looking for a Senior Data Scientist to empower Veesion’AI.You will join our growing Data team currently consisting of three experts in MLOps and Data Science. While the team tackles multiple missions, your focus will be on optimizing the use of our AI models to maximize client satisfaction.This involves exploring innovative ways to reduce missed thefts and irrelevant alerts by building on top of Veesion’s Deep Learning models.Reporting to the Head of Data, you will collaborate with key stakeholders across the organization:Chief Executive Officer: Align on business objectives and strategic prioritiesChief Scientific Officer: Refine problem definitions and methodologiesTech Team: Work closely with a team of over 10 software engineers to integrate AI capabilities seamlessly into Veesion’s systemsTasksOptimize success criteria for each camera by selecting appropriate models, fine-tuning hyperparameters, and adjusting sensitivity thresholds.Lead cross-functional projects with a strong Data Science focus, driving innovation and impact.Curate and manage datasets to enhance metrics relevance and support meaningful theoretical evaluations.Analyze production datato guide development priorities and inform high-level strategic decisions.Run video AI models for training and inference on diverse cloud infrastructures.Conduct large-scale A/B testing on premises to evaluate and refine AI solutions."}, {"source": "welcometothejungle", "job_title": "Backend Engineer", "contract_type": "CDI", "salary": "55K à 65K €", "company": "Escape", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Cybersécurité", "company_size": "23", "creation_date": "2020", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "21", "proportion_male": null}, "skills": {"ProgLanguage": ["python.event-based", "tech:python", "scalable.codebase", "scalable", "scalability.devsecops:aws"], "DataBase": ["postgresql", "architecture.postgresql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws.deployment:", "scalability.devsecops:aws", "aws"], "DevTools": ["standards.gitlab", "docker"], "OS": null, "DBMS": ["postgresql", "architecture.postgresql"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,", "kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker", "kubernetes,", "kubernetes,"], "Collaboration": ["teams"], "Other": ["seamless", "streamlined,", "gymlib📚", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/escape/jobs/backend-engineer_paris_ESCAP_KWpP6Z2?q=bfc932583df57bd893f063f71af02e74&o=b4c2f365-e742-408a-9ac8-c503742209ad", "description": "Descriptif du posteWe are seeking a driven and talented Backend Engineer to join Escape and play a crucial role in advancing our core algorithms and technology. This is a unique opportunity to be part of a fast-growing AI-driven cybersecurity company, progressively take on significant technical responsibilities, and directly contribute to our mission of securing applications at scale. As a member of one of our technical teams you will be responsible for maintaining and evolving our core AI algorithms and technology that form the backbone of our platform, driving the innovation that will shape the future of cybersecurity.ContextLocation: Paris (75002), 2 days remote/weekCompany: Escape – Leading AI Cybersecurity StartupCofounders: CEO (Tristan Kalos) and CTO (Antoine Carossio)Engineering Team: 1 Head of Engineering and 13 Engineers (including 5 Interns), 2 Technical Leads, 1 DesignerYou’ll be working in a close-knit team of 4 outstanding engineers under supervision of a technical leadKey Responsibilities:Core Algorithm Development: Implementing and maintaining key features within our R&D products, with a focus on our AI-driven cybersecurity algorithms, using Golang and Python.Event-Based System: Developing and enhancing our event-based system that ingests data from R&D products into a PostgreSQL database, ensuring seamless data flow to support our core technologies.System Reliability: Ensuring the availability, efficiency, and monitoring of our core AI systems using Kubernetes, Grafana, and AWS.Deployment: Deploying and managing microservices using Docker and Kubernetes, ensuring our core technology is robust and scalable.Codebase Ownership: Gradually take ownership of the codebase, contributing to its architecture, quality, and long-term maintainability.Continuous Learning: Stay up-to-date with the latest technologies and best practices, bringing new ideas to the team to continually improve our platform.Tech StackFrontend:Svelte with TypeScript for high-performance, intuitive UIs.GraphQL for efficient data querying and responsive applications.Backend — API:Node.js for server-side logic and GraphQL APIs powered by Yoga, Pothos and Prisma for scalable architecture.PostgreSQL for secure, efficient database management.Kafka for high-performance, event-driven systems.Backend — Deep Tech:Python for AI and algorithmic development, driving our cutting-edge cybersecurity solutions.Go for network-efficient tasks, optimizing performance and scalability.DevSecOps:AWS infrastructure which successfully passed Foundational Technical Review for AWS Partner Network.SOC-2 Compliance with rigorous code quality and security standards.GitLab CI for streamlined, secure CI/CD pipelinesGrafana for monitoringCode Quality:Modern Standards: All code follows the latest industry standards and best practices.Comprehensive Testing: We maintain high code quality through unit tests, integration tests, end-to-end (E2E) tests, and utilize Codecov for test coverage.Perks💸 Equity: Significant stock options via BSPCE, making you a true stakeholder in our success.❤️‍🩹 Health first: Comprehensive health insurance with Alan🍕 Meal vouchers with a Swile Card💪 Sport subscription to have preferential prices to go to the gym, with Gymlib📚 A place to learn and grow: Unlimited access to books and online courses to help you excel in your role🎁 Open-source: Free time to work on Open-Source projects💻 Tech perks: Get the latest tech gear, including Apple (or not) equipment and ultra-wide screen, to do your best work🌎 Global exposure: Present groundbreaking research at top international conferences, like APIDays (Paris, London, New York), GraphQL Conference (San Francisco), bSides (Berlin, Milan, Oslo, Stockholm…), etc"}, {"source": "welcometothejungle", "job_title": "Backend Engineer", "contract_type": "CDI", "salary": "55K à 65K €", "company": "Escape", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": null, "publication_date": "2025-01-06", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Cybersécurité", "company_size": "23", "creation_date": "2020", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "21", "proportion_male": null}, "skills": {"ProgLanguage": ["python.event-based", "tech:python", "scalable.codebase", "scalable", "scalability.devsecops:aws"], "DataBase": ["postgresql", "architecture.postgresql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws.deployment:", "scalability.devsecops:aws", "aws"], "DevTools": ["standards.gitlab", "docker"], "OS": null, "DBMS": ["postgresql", "architecture.postgresql"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,", "kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker", "kubernetes,", "kubernetes,"], "Collaboration": ["teams"], "Other": ["seamless", "streamlined,", "gymlib📚", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/escape/jobs/backend-engineer_paris_ESCAP_KWpP6Z2?q=bfc932583df57bd893f063f71af02e74&o=b4c2f365-e742-408a-9ac8-c503742209ad", "description": "Descriptif du posteWe are seeking a driven and talented Backend Engineer to join Escape and play a crucial role in advancing our core algorithms and technology. This is a unique opportunity to be part of a fast-growing AI-driven cybersecurity company, progressively take on significant technical responsibilities, and directly contribute to our mission of securing applications at scale. As a member of one of our technical teams you will be responsible for maintaining and evolving our core AI algorithms and technology that form the backbone of our platform, driving the innovation that will shape the future of cybersecurity.ContextLocation: Paris (75002), 2 days remote/weekCompany: Escape – Leading AI Cybersecurity StartupCofounders: CEO (Tristan Kalos) and CTO (Antoine Carossio)Engineering Team: 1 Head of Engineering and 13 Engineers (including 5 Interns), 2 Technical Leads, 1 DesignerYou’ll be working in a close-knit team of 4 outstanding engineers under supervision of a technical leadKey Responsibilities:Core Algorithm Development: Implementing and maintaining key features within our R&D products, with a focus on our AI-driven cybersecurity algorithms, using Golang and Python.Event-Based System: Developing and enhancing our event-based system that ingests data from R&D products into a PostgreSQL database, ensuring seamless data flow to support our core technologies.System Reliability: Ensuring the availability, efficiency, and monitoring of our core AI systems using Kubernetes, Grafana, and AWS.Deployment: Deploying and managing microservices using Docker and Kubernetes, ensuring our core technology is robust and scalable.Codebase Ownership: Gradually take ownership of the codebase, contributing to its architecture, quality, and long-term maintainability.Continuous Learning: Stay up-to-date with the latest technologies and best practices, bringing new ideas to the team to continually improve our platform.Tech StackFrontend:Svelte with TypeScript for high-performance, intuitive UIs.GraphQL for efficient data querying and responsive applications.Backend — API:Node.js for server-side logic and GraphQL APIs powered by Yoga, Pothos and Prisma for scalable architecture.PostgreSQL for secure, efficient database management.Kafka for high-performance, event-driven systems.Backend — Deep Tech:Python for AI and algorithmic development, driving our cutting-edge cybersecurity solutions.Go for network-efficient tasks, optimizing performance and scalability.DevSecOps:AWS infrastructure which successfully passed Foundational Technical Review for AWS Partner Network.SOC-2 Compliance with rigorous code quality and security standards.GitLab CI for streamlined, secure CI/CD pipelinesGrafana for monitoringCode Quality:Modern Standards: All code follows the latest industry standards and best practices.Comprehensive Testing: We maintain high code quality through unit tests, integration tests, end-to-end (E2E) tests, and utilize Codecov for test coverage.Perks💸 Equity: Significant stock options via BSPCE, making you a true stakeholder in our success.❤️‍🩹 Health first: Comprehensive health insurance with Alan🍕 Meal vouchers with a Swile Card💪 Sport subscription to have preferential prices to go to the gym, with Gymlib📚 A place to learn and grow: Unlimited access to books and online courses to help you excel in your role🎁 Open-source: Free time to work on Open-Source projects💻 Tech perks: Get the latest tech gear, including Apple (or not) equipment and ultra-wide screen, to do your best work🌎 Global exposure: Present groundbreaking research at top international conferences, like APIDays (Paris, London, New York), GraphQL Conference (San Francisco), bSides (Berlin, Milan, Oslo, Stockholm…), etc"}, {"source": "welcometothejungle", "job_title": "R&D Software Engineer – Algorithmics & Cybersecurity", "contract_type": "CDI", "salary": "48K à 65K €", "company": "Escape", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-12-11", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Cybersécurité", "company_size": "23", "creation_date": "2020", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "21", "proportion_male": null}, "skills": {"ProgLanguage": ["python.event-based", "tech:python", "scalable.codebase", "scalable", "scalability.devsecops:aws"], "DataBase": ["postgresql", "architecture.postgresql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws.deployment:", "scalability.devsecops:aws", "aws"], "DevTools": ["standards.gitlab", "docker"], "OS": null, "DBMS": ["postgresql", "architecture.postgresql"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,", "kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker", "kubernetes,", "kubernetes,"], "Collaboration": ["teams"], "Other": ["seamless", "streamlined,", "gymlib📚", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/escape/jobs/r-d-software-engineer-ai-cybersecurity_paris?q=bfc932583df57bd893f063f71af02e74&o=ee316f91-5415-401e-8967-bb11e0029f7e", "description": "Descriptif du posteEscape is the pioneering AI-driven cybersecurity startup rapidly expanding across Europe and North America, with recognition from France 2030, Y Combinator, Forbes 30 Under 30… As a deep tech company, innovation is in our DNA, and our team is united by a passion for technology.👉 We are seeking a driven and talented R&D Software Engineer to join Escape and play a crucial role in advancing our core algorithms and technology. This is a unique opportunity to be part of a fast-growing AI-driven cybersecurity company, progressively take on significant technical responsibilities, and directly contribute to our mission of securing applications at scale. As a member of one of our technical teams you will be responsible for maintaining and evolving our core AI algorithms and technology that form the backbone of our platform, driving the innovation that will shape the future of cybersecurity.ContextLocation: Paris (75002), 2 days remote/weekCompany: Escape – Leading AI Cybersecurity StartupCofounders: CEO (Tristan Kalos) and CTO (Antoine Carossio)Engineering Team: 13 Engineers (including 5 Interns), 2 Technical Leads, 1 DesignerYou’ll be working in a close-knit team of 4 outstanding engineers under supervision of a technical leadKey Responsibilities:Core Algorithm Development: Implementing and maintaining key features within our R&D products, with a focus on our AI-driven cybersecurity algorithms, using Golang and Python.Event-Based System: Developing and enhancing our event-based system that ingests data from R&D products into a PostgreSQL database, ensuring seamless data flow to support our core technologies.System Reliability: Ensuring the availability, efficiency, and monitoring of our core AI systems using Kubernetes, Grafana, and AWS.Deployment: Deploying and managing microservices using Docker and Kubernetes, ensuring our core technology is robust and scalable.Codebase Ownership: Gradually take ownership of the codebase, contributing to its architecture, quality, and long-term maintainability.Continuous Learning: Stay up-to-date with the latest technologies and best practices, bringing new ideas to the team to continually improve our platform.Our StackFrontend:Svelte with TypeScript for high-performance, intuitive UIs.GraphQL for efficient data querying and responsive applications.Backend — API:Node.js for server-side logic and GraphQL APIs powered by Yoga, Pothos and Prisma for scalable architecture.PostgreSQL for secure, efficient database management.Kafka for high-performance, event-driven systems.Backend — Deep Tech:Python for AI and algorithmic development, driving our cutting-edge cybersecurity solutions.Go for network-efficient tasks, optimizing performance and scalability.DevSecOps:AWS infrastructure which successfully passed Foundational Technical Review for AWS Partner Network.SOC-2 Compliance with rigorous code quality and security standards.GitLab CI for streamlined, secure CI/CD pipelinesGrafana for monitoringCode Quality:Modern Standards: All code follows the latest industry standards and best practices.Comprehensive Testing: We maintain high code quality through unit tests, integration tests, end-to-end (E2E) tests, and utilize Codecov for test coverage.Perks💸 Equity: Significant stock options via BSPCE, making you a true stakeholder in our success.❤️‍🩹 Health first: Comprehensive health insurance with Alan🍕 Meal vouchers with a Swile Card💪 Sport subscription to have preferential prices to go to the gym, with Gymlib📚 A place to learn and grow: Unlimited access to books and online courses to help you excel in your role🎁 Open-source: Free time to work on Open-Source projects around Pizzas, Bears and Cocas ;)💻 Tech perks: Get the latest tech gear, including Apple (or not) equipment and ultra-wide screen, to do your best work🌎 Global exposure: Present groundbreaking research at top international conferences, like APIDays (Paris, London, New York), GraphQL Conference (San Francisco), bSides (Berlin, Milan, Oslo, Stockholm…), etc"}, {"source": "welcometothejungle", "job_title": "R&D Software Engineer – Algorithmics & Cybersecurity", "contract_type": "CDI", "salary": "48K à 65K €", "company": "Escape", "location": "Paris", "remote": "Télétravail occasionnel", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-12-11", "company_data": {"sector": "Intelligence artificielle / Machine Learning, SaaS / Cloud Services, Cybersécurité", "company_size": "23", "creation_date": "2020", "address": null, "average_age_of_employees": "28", "turnover_in_millions": null, "proportion_female": "21", "proportion_male": null}, "skills": {"ProgLanguage": ["python.event-based", "tech:python", "scalable.codebase", "scalable", "scalability.devsecops:aws"], "DataBase": ["postgresql", "architecture.postgresql"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws.deployment:", "scalability.devsecops:aws", "aws"], "DevTools": ["standards.gitlab", "docker"], "OS": null, "DBMS": ["postgresql", "architecture.postgresql"], "SoftBigDataProcessing": null, "Automation": ["kubernetes,", "kubernetes,"], "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker", "kubernetes,", "kubernetes,"], "Collaboration": ["teams"], "Other": ["seamless", "streamlined,", "gymlib📚", "ci/cd"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/escape/jobs/r-d-software-engineer-ai-cybersecurity_paris?q=bfc932583df57bd893f063f71af02e74&o=ee316f91-5415-401e-8967-bb11e0029f7e", "description": "Descriptif du posteEscape is the pioneering AI-driven cybersecurity startup rapidly expanding across Europe and North America, with recognition from France 2030, Y Combinator, Forbes 30 Under 30… As a deep tech company, innovation is in our DNA, and our team is united by a passion for technology.👉 We are seeking a driven and talented R&D Software Engineer to join Escape and play a crucial role in advancing our core algorithms and technology. This is a unique opportunity to be part of a fast-growing AI-driven cybersecurity company, progressively take on significant technical responsibilities, and directly contribute to our mission of securing applications at scale. As a member of one of our technical teams you will be responsible for maintaining and evolving our core AI algorithms and technology that form the backbone of our platform, driving the innovation that will shape the future of cybersecurity.ContextLocation: Paris (75002), 2 days remote/weekCompany: Escape – Leading AI Cybersecurity StartupCofounders: CEO (Tristan Kalos) and CTO (Antoine Carossio)Engineering Team: 13 Engineers (including 5 Interns), 2 Technical Leads, 1 DesignerYou’ll be working in a close-knit team of 4 outstanding engineers under supervision of a technical leadKey Responsibilities:Core Algorithm Development: Implementing and maintaining key features within our R&D products, with a focus on our AI-driven cybersecurity algorithms, using Golang and Python.Event-Based System: Developing and enhancing our event-based system that ingests data from R&D products into a PostgreSQL database, ensuring seamless data flow to support our core technologies.System Reliability: Ensuring the availability, efficiency, and monitoring of our core AI systems using Kubernetes, Grafana, and AWS.Deployment: Deploying and managing microservices using Docker and Kubernetes, ensuring our core technology is robust and scalable.Codebase Ownership: Gradually take ownership of the codebase, contributing to its architecture, quality, and long-term maintainability.Continuous Learning: Stay up-to-date with the latest technologies and best practices, bringing new ideas to the team to continually improve our platform.Our StackFrontend:Svelte with TypeScript for high-performance, intuitive UIs.GraphQL for efficient data querying and responsive applications.Backend — API:Node.js for server-side logic and GraphQL APIs powered by Yoga, Pothos and Prisma for scalable architecture.PostgreSQL for secure, efficient database management.Kafka for high-performance, event-driven systems.Backend — Deep Tech:Python for AI and algorithmic development, driving our cutting-edge cybersecurity solutions.Go for network-efficient tasks, optimizing performance and scalability.DevSecOps:AWS infrastructure which successfully passed Foundational Technical Review for AWS Partner Network.SOC-2 Compliance with rigorous code quality and security standards.GitLab CI for streamlined, secure CI/CD pipelinesGrafana for monitoringCode Quality:Modern Standards: All code follows the latest industry standards and best practices.Comprehensive Testing: We maintain high code quality through unit tests, integration tests, end-to-end (E2E) tests, and utilize Codecov for test coverage.Perks💸 Equity: Significant stock options via BSPCE, making you a true stakeholder in our success.❤️‍🩹 Health first: Comprehensive health insurance with Alan🍕 Meal vouchers with a Swile Card💪 Sport subscription to have preferential prices to go to the gym, with Gymlib📚 A place to learn and grow: Unlimited access to books and online courses to help you excel in your role🎁 Open-source: Free time to work on Open-Source projects around Pizzas, Bears and Cocas ;)💻 Tech perks: Get the latest tech gear, including Apple (or not) equipment and ultra-wide screen, to do your best work🌎 Global exposure: Present groundbreaking research at top international conferences, like APIDays (Paris, London, New York), GraphQL Conference (San Francisco), bSides (Berlin, Milan, Oslo, Stockholm…), etc"}, {"source": "welcometothejungle", "job_title": "Senior Data Analyst", "contract_type": "CDI", "salary": "63K à 69K €", "company": "Bump", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "Environnement / Développement durable, Mobilité, Energie", "company_size": "90", "creation_date": "2020", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["d’ingestion.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/bump-charge/jobs/senior-data-analyst_paris?q=bfc932583df57bd893f063f71af02e74&o=06faf010-65a3-4c19-9174-cd982d0063ab", "description": "Descriptif du posteChez Bump, on révolutionne la mobilité électrique en déployant des solutions de recharge ultra-performantes. On est la startup qui rend la recharge électrique aussi simple qu’un plein d’essence, mais en bien plus durable !ContexteBump continue de grandir, et on a besoin de toi pour passer au niveau supérieur ! En tant que Senior Data Analyst, tu joueras un rôle clé dans l’analyse des données qui guide nos décisions stratégiques. Tu seras aux côtés de nos équipes Produit, Finance et Opérations, en lien direct avec les performances de nos bornes et les besoins utilisateurs. Tu reporteras directement à Yann, notre CTO, et seras au sein de notre belle équipe Tech !Chez Bump, tu auras l’opportunité de te dépasser dans un rôle où l’analyse de données et la co-création de solutions ne sont plus des mystères pour toi. Ici, tu contribues à construire l’infrastructure data de demain tout en accompagnant nos équipes dans l’exploitation intelligente des données.Un poste où tu construis des dashboards innovants, analyses des données en profondeur, et automatises les pipelines de données pour permettre à Bump d’optimiser chaque décision. Bref, un travail stratégique où tes insights permettent de faire évoluer l’entreprise dans un secteur en pleine croissance.Ton rôle 🎯Analyse de données : Tu fournis des analyses approfondies sur les performances des bornes de recharge, les comportements utilisateurs et l’optimisation des processus internes pour guider notre stratégie.Appels d’offres : Tu participes activement à la bonne exécution de nos appels d’offres en fournissant des analyses détaillées (coût estimé, couverture de trajet, etc.).Co-création des modèles financiers avec l’équipe Finance pour affiner nos prévisions et assurer notre croissance.Dashboards sur mesure : Tu crées et maintiens des dashboards de cohérence de facturation et des analyses pour nos clients directement intégrées dans notre plateforme.Modélisation des données avec dbt : Tu construis et maintiens des modèles de données structurés pour des analyses précises et robustes.Automatisation des pipelines avec Airbyte : Tu assures la qualité et la fiabilité des données en automatisant les flux d’ingestion.Collaboration interne : Tu travailles en étroite collaboration avec les équipes Produit et Opérations pour comprendre leurs besoins en données et concevoir des solutions sur-mesure.Amélioration continue : Tu participes à l’évolution de notre infrastructure de données en travaillant main dans la main avec les équipes tech."}, {"source": "welcometothejungle", "job_title": "Senior Data Analyst", "contract_type": "CDI", "salary": "63K à 69K €", "company": "Bump", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 5", "education_level": "Bac +5 / Master", "publication_date": "2024-12-10", "company_data": {"sector": "Environnement / Développement durable, Mobilité, Energie", "company_size": "90", "creation_date": "2020", "address": null, "average_age_of_employees": "31", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["d’ingestion.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/bump-charge/jobs/senior-data-analyst_paris?q=bfc932583df57bd893f063f71af02e74&o=06faf010-65a3-4c19-9174-cd982d0063ab", "description": "Descriptif du posteChez Bump, on révolutionne la mobilité électrique en déployant des solutions de recharge ultra-performantes. On est la startup qui rend la recharge électrique aussi simple qu’un plein d’essence, mais en bien plus durable !ContexteBump continue de grandir, et on a besoin de toi pour passer au niveau supérieur ! En tant que Senior Data Analyst, tu joueras un rôle clé dans l’analyse des données qui guide nos décisions stratégiques. Tu seras aux côtés de nos équipes Produit, Finance et Opérations, en lien direct avec les performances de nos bornes et les besoins utilisateurs. Tu reporteras directement à Yann, notre CTO, et seras au sein de notre belle équipe Tech !Chez Bump, tu auras l’opportunité de te dépasser dans un rôle où l’analyse de données et la co-création de solutions ne sont plus des mystères pour toi. Ici, tu contribues à construire l’infrastructure data de demain tout en accompagnant nos équipes dans l’exploitation intelligente des données.Un poste où tu construis des dashboards innovants, analyses des données en profondeur, et automatises les pipelines de données pour permettre à Bump d’optimiser chaque décision. Bref, un travail stratégique où tes insights permettent de faire évoluer l’entreprise dans un secteur en pleine croissance.Ton rôle 🎯Analyse de données : Tu fournis des analyses approfondies sur les performances des bornes de recharge, les comportements utilisateurs et l’optimisation des processus internes pour guider notre stratégie.Appels d’offres : Tu participes activement à la bonne exécution de nos appels d’offres en fournissant des analyses détaillées (coût estimé, couverture de trajet, etc.).Co-création des modèles financiers avec l’équipe Finance pour affiner nos prévisions et assurer notre croissance.Dashboards sur mesure : Tu crées et maintiens des dashboards de cohérence de facturation et des analyses pour nos clients directement intégrées dans notre plateforme.Modélisation des données avec dbt : Tu construis et maintiens des modèles de données structurés pour des analyses précises et robustes.Automatisation des pipelines avec Airbyte : Tu assures la qualité et la fiabilité des données en automatisant les flux d’ingestion.Collaboration interne : Tu travailles en étroite collaboration avec les équipes Produit et Opérations pour comprendre leurs besoins en données et concevoir des solutions sur-mesure.Amélioration continue : Tu participes à l’évolution de notre infrastructure de données en travaillant main dans la main avec les équipes tech."}, {"source": "welcometothejungle", "job_title": "Lead Data Scientist (F/H)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Carrefour", "location": "Verteuil-d'Agenais", "remote": "Télétravail fréquent", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-11-18", "company_data": {"sector": "Grande distribution, E-commerce, Grande consommation", "company_size": "100000", "creation_date": "1959", "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": "60", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "azure).data", "(gcp,"], "DevTools": ["digitale,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": ["collaboration", "externes.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/carrefour/jobs/lead-data-scientist-f-h_massy?q=bfc932583df57bd893f063f71af02e74&o=7b79a6e3-9d7a-4eac-a708-996b4fdcca2e", "description": "Descriptif du posteCréateur de l'hypermarché, Carrefour reste fidèle à ses racines tout en se réinventant pour permettre à chacun de mieux manger : plus sain, plus local, plus responsable. Leader mondial de la distribution, nous sommes engagés pour la diversité, la RSE et la transformation digitale, tout en créant un environnement de travail inclusif et stimulant.Nos atouts pour y parvenir ? Un réseau multi format, multi métiers avec des collaborateurs passionnés, qui s'engagent, pour réussir la transition alimentaire pour tous. La Direction Data Groupe, services financiers recherche un(e) :Lead Data Scientist (F/H) Contexte En tant que Lead Data Scientist au sein du département Data Groupe, Services Financiers, vous jouerez un rôle clé dans la conception, le déploiement et la gouvernance de solutions data avancées, orientées vers la création de valeur et l'optimisation des processus métiers. Ce poste englobe l'ensemble du cycle de vie des projets data, y compris la science des données, l'ingénierie, l'architecture, l'analyse, et le dashboarding, pour offrir une vision globale des données et des performances.Vos missions Conception de Modèles Avancés : Développer des modèles de machine learning, notamment pour des cas d'usage tels que la prédiction de risque, la détection de fraude, et les recommandations client.Data Engineering et Architecture : Superviser la construction, l'optimisation et la maintenance des pipelines de données, tout en collaborant avec les équipes d'ingénierie pour garantir une infrastructure de données évolutive et performante sur les environnements cloud (GCP, AWS, Azure).Data Analysis et Dashboarding : Diriger des analyses approfondies pour générer des insights exploitables et superviser la création de dashboards en collaboration avec les équipes métiers pour une meilleure prise de décision.Pilotage de Projets Data : Gérer et superviser des projets de data science de bout en bout, en coordonnant les équipes multidisciplinaires pour garantir la réussite des livrables.Innovation et Veille Technologique : Identifier et proposer des technologies émergentes et des méthodologies innovantes afin d'améliorer les processus et les solutions en place.Encadrement et Mentorat : Former et encadrer une équipe de data scientists, data engineers et data analysts, promouvoir une culture d'excellence technique et encourager le développement continu des compétences.Gouvernance des Données : Contribuer à l'élaboration de la stratégie de gouvernance des données en conformité avec les réglementations internes et externes.Collaboration Interdépartementale : Travailler en étroite collaboration avec d'autres équipes (technique, métier, produit) pour assurer une intégration fluide des solutions et maximiser leur impact.Informations complémentaires Basé à Massy Statut : cadreIntéressement/participationMutuelle/prévoyanceComité d'entreprise et perspectives d'évolution au sein du Groupe"}, {"source": "welcometothejungle", "job_title": "Lead Data Scientist (F/H)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Carrefour", "location": "Verteuil-d'Agenais", "remote": "Télétravail fréquent", "experience": "> 1 an", "education_level": "Bac +5 / Master", "publication_date": "2024-11-18", "company_data": {"sector": "Grande distribution, E-commerce, Grande consommation", "company_size": "100000", "creation_date": "1959", "address": null, "average_age_of_employees": null, "turnover_in_millions": null, "proportion_female": "60", "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "azure).data", "(gcp,"], "DevTools": ["digitale,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud"], "EnSoftSkils": ["collaboration", "externes.collaboration", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/carrefour/jobs/lead-data-scientist-f-h_massy?q=bfc932583df57bd893f063f71af02e74&o=7b79a6e3-9d7a-4eac-a708-996b4fdcca2e", "description": "Descriptif du posteCréateur de l'hypermarché, Carrefour reste fidèle à ses racines tout en se réinventant pour permettre à chacun de mieux manger : plus sain, plus local, plus responsable. Leader mondial de la distribution, nous sommes engagés pour la diversité, la RSE et la transformation digitale, tout en créant un environnement de travail inclusif et stimulant.Nos atouts pour y parvenir ? Un réseau multi format, multi métiers avec des collaborateurs passionnés, qui s'engagent, pour réussir la transition alimentaire pour tous. La Direction Data Groupe, services financiers recherche un(e) :Lead Data Scientist (F/H) Contexte En tant que Lead Data Scientist au sein du département Data Groupe, Services Financiers, vous jouerez un rôle clé dans la conception, le déploiement et la gouvernance de solutions data avancées, orientées vers la création de valeur et l'optimisation des processus métiers. Ce poste englobe l'ensemble du cycle de vie des projets data, y compris la science des données, l'ingénierie, l'architecture, l'analyse, et le dashboarding, pour offrir une vision globale des données et des performances.Vos missions Conception de Modèles Avancés : Développer des modèles de machine learning, notamment pour des cas d'usage tels que la prédiction de risque, la détection de fraude, et les recommandations client.Data Engineering et Architecture : Superviser la construction, l'optimisation et la maintenance des pipelines de données, tout en collaborant avec les équipes d'ingénierie pour garantir une infrastructure de données évolutive et performante sur les environnements cloud (GCP, AWS, Azure).Data Analysis et Dashboarding : Diriger des analyses approfondies pour générer des insights exploitables et superviser la création de dashboards en collaboration avec les équipes métiers pour une meilleure prise de décision.Pilotage de Projets Data : Gérer et superviser des projets de data science de bout en bout, en coordonnant les équipes multidisciplinaires pour garantir la réussite des livrables.Innovation et Veille Technologique : Identifier et proposer des technologies émergentes et des méthodologies innovantes afin d'améliorer les processus et les solutions en place.Encadrement et Mentorat : Former et encadrer une équipe de data scientists, data engineers et data analysts, promouvoir une culture d'excellence technique et encourager le développement continu des compétences.Gouvernance des Données : Contribuer à l'élaboration de la stratégie de gouvernance des données en conformité avec les réglementations internes et externes.Collaboration Interdépartementale : Travailler en étroite collaboration avec d'autres équipes (technique, métier, produit) pour assurer une intégration fluide des solutions et maximiser leur impact.Informations complémentaires Basé à Massy Statut : cadreIntéressement/participationMutuelle/prévoyanceComité d'entreprise et perspectives d'évolution au sein du Groupe"}, {"source": "welcometothejungle", "job_title": "Lead MLOps - Computer Vision automation (AWS) (H/F)", "contract_type": "CDI", "salary": "60K à 90K €", "company": "ALPHAIOTA", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-24", "company_data": {"sector": "SaaS / Cloud Services, Objets connectés, SocialTech / GreenTech", "company_size": "29", "creation_date": "2021", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalabilitésuperviser"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": ["tensorflow,", "pytorchcloud"], "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": ["docker,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["kuberneteslangages"], "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kuberneteslangages"], "Collaboration": null, "Other": ["mlops", "cloud", "pytorchcloud", "cloudfront,"], "EnSoftSkils": ["collaborationmanager", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/vizzia/jobs/lead-mlops-computer-vision-automation-aws-h-f_paris?q=bfc932583df57bd893f063f71af02e74&o=ff3307bb-0af1-457a-b918-b4a11664fabc", "description": "Descriptif du posteEn tant que Lead MLOps spécialisé Computer Vision, vous jouerez un rôle clé dans le développement, la mise en production et l’amélioration continue de nos algorithmes d’intelligence artificielle. Vous serez également en charge du pilotage technique et managérial d’une équipe dédiée à la vision par ordinateur.Responsabilités clésConception et développementConcevoir des algorithmes de computer vision adaptés à nos cas d’usage spécifiques.Mettre en place des pipelines de traitement de données pour entraîner et évaluer les modèles.Mise en place et suivi des processus d’annotation manuelsProduction et scalabilitéSuperviser l’intégration et le déploiement des modèles en production, en assurant leur fiabilité et leur performance.Optimiser l’infrastructure pour répondre aux besoins croissants en termes de charge et d’échelle.Amélioration continueConcevoir des workflows intégrant des feedbacks pour affiner les modèles.Garantir un processus structuré pour la validation et l’évolution des algorithmes.Encadrement et collaborationManager une équipe de collaborateurs divers incluant au minimum 1 Product Manager, 1 sénior, 1 mid et 1 junior.Travailler en étroite collaboration avec les équipes produit et cloud pour garantir l’alignement des priorités.🛠️ Stack et environnement techniqueOrchestration et IaC : CDK ou Terraform (obligatoire), Docker, KubernetesLangages : Python, TensorFlow, PyTorchCloud : AWS (ECR, Batch, Step Functions, RDS, VPC, IAM, Sagemaker, Amplify, Cloudfront, Lambda, S3)Data processing : Pipelines de traitement de données à grande échelle💥 Ce que nous offronsRémunération attractive : 60-90k€ package globalAvantages : tickets restaurant, mutuelle, plan de BSPCEEnvironnement flexible : télétravail partiel, horaires adaptésImpact direct : contribuer à un projet porteur de sens pour l’environnement"}, {"source": "welcometothejungle", "job_title": "Lead MLOps - Computer Vision automation (AWS) (H/F)", "contract_type": "CDI", "salary": "60K à 90K €", "company": "ALPHAIOTA", "location": "Paris", "remote": "Télétravail fréquent", "experience": "> 3", "education_level": "Bac +5 / Master", "publication_date": "2024-12-24", "company_data": {"sector": "SaaS / Cloud Services, Objets connectés, SocialTech / GreenTech", "company_size": "29", "creation_date": "2021", "address": null, "average_age_of_employees": "30", "turnover_in_millions": "5", "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": ["python,", "scalabilitésuperviser"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": ["tensorflow,", "pytorchcloud"], "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws"], "DevTools": ["docker,"], "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": ["kuberneteslangages"], "InfrastructureAsCode": ["terraform"], "NetworkSecurty": null, "Virtualisation": null, "Containers": ["docker,", "kuberneteslangages"], "Collaboration": null, "Other": ["mlops", "cloud", "pytorchcloud", "cloudfront,"], "EnSoftSkils": ["collaborationmanager", "collaboration"]}, "link": "https://www.welcometothejungle.com/fr/companies/vizzia/jobs/lead-mlops-computer-vision-automation-aws-h-f_paris?q=bfc932583df57bd893f063f71af02e74&o=ff3307bb-0af1-457a-b918-b4a11664fabc", "description": "Descriptif du posteEn tant que Lead MLOps spécialisé Computer Vision, vous jouerez un rôle clé dans le développement, la mise en production et l’amélioration continue de nos algorithmes d’intelligence artificielle. Vous serez également en charge du pilotage technique et managérial d’une équipe dédiée à la vision par ordinateur.Responsabilités clésConception et développementConcevoir des algorithmes de computer vision adaptés à nos cas d’usage spécifiques.Mettre en place des pipelines de traitement de données pour entraîner et évaluer les modèles.Mise en place et suivi des processus d’annotation manuelsProduction et scalabilitéSuperviser l’intégration et le déploiement des modèles en production, en assurant leur fiabilité et leur performance.Optimiser l’infrastructure pour répondre aux besoins croissants en termes de charge et d’échelle.Amélioration continueConcevoir des workflows intégrant des feedbacks pour affiner les modèles.Garantir un processus structuré pour la validation et l’évolution des algorithmes.Encadrement et collaborationManager une équipe de collaborateurs divers incluant au minimum 1 Product Manager, 1 sénior, 1 mid et 1 junior.Travailler en étroite collaboration avec les équipes produit et cloud pour garantir l’alignement des priorités.🛠️ Stack et environnement techniqueOrchestration et IaC : CDK ou Terraform (obligatoire), Docker, KubernetesLangages : Python, TensorFlow, PyTorchCloud : AWS (ECR, Batch, Step Functions, RDS, VPC, IAM, Sagemaker, Amplify, Cloudfront, Lambda, S3)Data processing : Pipelines de traitement de données à grande échelle💥 Ce que nous offronsRémunération attractive : 60-90k€ package globalAvantages : tickets restaurant, mutuelle, plan de BSPCEEnvironnement flexible : télétravail partiel, horaires adaptésImpact direct : contribuer à un projet porteur de sens pour l’environnement"}, {"source": "welcometothejungle", "job_title": "Développeur full stack sénior", "contract_type": "CDI", "salary": "60K à 70K €", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-12-16", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilité"], "DataBase": ["mongodb,", "mongodb"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud.soutenir"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/developpeur-full-stack-senior_nice?q=bfc932583df57bd893f063f71af02e74&o=3502ded6-073f-45fb-a7a5-938b8eceffea", "description": "Descriptif du posteLe Poste :Nous recherchons un(e) Ingénieur(e) Full Stack passionné(e) par la résolution de problèmes concrets et motivé(e) à évoluer dans un environnement où vos contributions auront un impact direct. Vous rejoindrez une équipe collaborative composée de 8 développeurs, 2 designers et 4 product owners, et participerez à toutes les étapes de développement, de la conception à la production. Vous travaillerez sur nos technologies principales : AWS, CDK, MongoDB, TypeScript, NestJS, React, React-Native et CubeJS pour la construction d’une couche de données sémantique. Vous opérerez selon un modèle “Vous le construisez, vous le gérez”, en assumant la responsabilité de votre code de bout en bout dans une architecture serverless.Responsabilités clés :Développer et maintenir des applications full stack en utilisant TypeScript, NestJS, React, React-Native et CubeJS pour les couches de données sémantiques.Collaborer avec les product owners, designers et développeurs pour livrer des applications intuitives et évolutives.Travailler avec les services AWS et déployer l’infrastructure à l’aide du Cloud Development Kit (CDK).Gérer et améliorer les services backend, bases de données et API en utilisant MongoDB et des architectures basées sur le cloud.Soutenir la collecte et le traitement des données terrain, en fournissant des analyses précieuses aux acteurs agricoles via notre plateforme d’analyse.Assumer la gestion du cycle de vie des produits que vous développez : déployer, surveiller et maintenir des systèmes performants et sécurisés.Contribuer à l’amélioration de la qualité et de la scalabilité de notre codebase et participer aux revues de code."}, {"source": "welcometothejungle", "job_title": "Développeur full stack sénior", "contract_type": "CDI", "salary": "60K à 70K €", "company": "Doriane", "location": "Nice", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": "Bac +5 / Master", "publication_date": "2024-12-16", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, SocialTech / GreenTech", "company_size": "32", "creation_date": null, "address": null, "average_age_of_employees": "33", "turnover_in_millions": "2.2", "proportion_female": "30", "proportion_male": null}, "skills": {"ProgLanguage": ["scalabilité"], "DataBase": ["mongodb,", "mongodb"], "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": ["aws,", "aws"], "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": ["cloud", "cloud.soutenir"], "EnSoftSkils": null}, "link": "https://www.welcometothejungle.com/fr/companies/doriane/jobs/developpeur-full-stack-senior_nice?q=bfc932583df57bd893f063f71af02e74&o=3502ded6-073f-45fb-a7a5-938b8eceffea", "description": "Descriptif du posteLe Poste :Nous recherchons un(e) Ingénieur(e) Full Stack passionné(e) par la résolution de problèmes concrets et motivé(e) à évoluer dans un environnement où vos contributions auront un impact direct. Vous rejoindrez une équipe collaborative composée de 8 développeurs, 2 designers et 4 product owners, et participerez à toutes les étapes de développement, de la conception à la production. Vous travaillerez sur nos technologies principales : AWS, CDK, MongoDB, TypeScript, NestJS, React, React-Native et CubeJS pour la construction d’une couche de données sémantique. Vous opérerez selon un modèle “Vous le construisez, vous le gérez”, en assumant la responsabilité de votre code de bout en bout dans une architecture serverless.Responsabilités clés :Développer et maintenir des applications full stack en utilisant TypeScript, NestJS, React, React-Native et CubeJS pour les couches de données sémantiques.Collaborer avec les product owners, designers et développeurs pour livrer des applications intuitives et évolutives.Travailler avec les services AWS et déployer l’infrastructure à l’aide du Cloud Development Kit (CDK).Gérer et améliorer les services backend, bases de données et API en utilisant MongoDB et des architectures basées sur le cloud.Soutenir la collecte et le traitement des données terrain, en fournissant des analyses précieuses aux acteurs agricoles via notre plateforme d’analyse.Assumer la gestion du cycle de vie des produits que vous développez : déployer, surveiller et maintenir des systèmes performants et sécurisés.Contribuer à l’amélioration de la qualité et de la scalabilité de notre codebase et participer aux revues de code."}, {"source": "welcometothejungle", "job_title": "Chief Technical Officer", "contract_type": "CDI", "salary": "Non spécifié", "company": "TheraPanacea", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": "> Bac +5 / Doctorat", "publication_date": "2024-12-10", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, Santé", "company_size": "80", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable,", "scalable,", "scalability,", "scalability,"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams"], "Other": ["devops,", "ai/ml", "streamline", "cloud", "cloud-native", "cloud", "cloud-first", "cloud", "(ci/cd),"], "EnSoftSkils": ["leadership", "leadershipdevelop", "leadershipbuild", "collaborationpartner", "organizations.key", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/therapanacea/jobs/chief-technical-officer_paris_THERA_L4MYjVQ?q=bfc932583df57bd893f063f71af02e74&o=45b8214c-c6a5-4f2b-96b8-cac15ee2f1ba", "description": "Descriptif du posteJob SummaryWe are seeking an innovative and results-driven Chief Technology Officer (CTO) to lead the technological strategy and operations specializing in software solutions for treatment implementation and prognosis. As a key member of the executive team, the CTO will spearhead the development of cutting-edge machine learning solutions and a software platform that enhance patient outcomes by enabling personalized treatment plans, precise prognostic assessments and  effective implementation at scale of precision medicine.The ideal candidate will have a strong technical background in machine learning, software development, software engineering and cloud technologies, extensive leadership experience, and the ability to drive innovation in regulated healthcare environments. This role is crucial in positioning the company as a leader in MedTech by delivering scalable, secure, and patient-focused technology solutions that benefit to the patients, physicians . hospitals and healthcare organizations.Key ResponsibilitiesStrategic LeadershipDevelop and execute a technology vision and roadmap focused on a platform for treatment implementation and prognosis.Align technology initiatives with business goals, ensuring innovation drives patient-centric solutions and market competitiveness.Stay ahead of industry trends, guiding the adoption of emerging technologies such as AI/ML and advanced analytics to enhance software capabilities.Product and Technology OversightOversee the design, development, and deployment of scalable, cloud-native software solutions that enable precision treatment workflows and robust prognostic tools.Ensure the security, compliance, and reliability of all software platforms, meeting regulatory requirements such as FDA, HIPAA, and GDPR.Drive software architecture decisions to ensure modularity, scalability, and ease of integration with existing clinical workflows and third-party systems.Team LeadershipBuild and lead a high-performing team of software engineers, cloud architects, and data scientists.Foster a collaborative and innovative culture that emphasizes continuous learning, accountability, and diversity.Mentor teams to adopt agile development practices and cloud-first strategies that accelerate delivery and improve quality.Operational ExcellenceImplement best practices in DevOps, continuous integration/continuous deployment (CI/CD), and software lifecycle management to streamline operations.Establish and monitor KPIs to evaluate the performance, scalability, and usability of software platforms.Drive cost-effective cloud utilization and infrastructure optimization to maximize efficiency.Stakeholder CollaborationPartner with clinical, product management, and regulatory teams to translate complex medical and operational requirements into intuitive, actionable software solutions.Engage with key external stakeholders, including healthcare providers and industry partners, to ensure the relevance and impact of the company’s technology offerings.Act as the primary technical liaison for investors, partners, and customers, articulating the company’s technology vision and progress."}, {"source": "welcometothejungle", "job_title": "Chief Technical Officer", "contract_type": "CDI", "salary": "Non spécifié", "company": "TheraPanacea", "location": "Paris", "remote": "Télétravail fréquent", "experience": null, "education_level": "> Bac +5 / Doctorat", "publication_date": "2024-12-10", "company_data": {"sector": "Logiciels, Intelligence artificielle / Machine Learning, Pharmaceutique / Biotechnologique, Santé", "company_size": "80", "creation_date": "2017", "address": null, "average_age_of_employees": "33", "turnover_in_millions": null, "proportion_female": "40", "proportion_male": null}, "skills": {"ProgLanguage": ["scalable,", "scalable,", "scalability,", "scalability,"], "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": ["teams", "teams"], "Other": ["devops,", "ai/ml", "streamline", "cloud", "cloud-native", "cloud", "cloud-first", "cloud", "(ci/cd),"], "EnSoftSkils": ["leadership", "leadershipdevelop", "leadershipbuild", "collaborationpartner", "organizations.key", "initiatives"]}, "link": "https://www.welcometothejungle.com/fr/companies/therapanacea/jobs/chief-technical-officer_paris_THERA_L4MYjVQ?q=bfc932583df57bd893f063f71af02e74&o=45b8214c-c6a5-4f2b-96b8-cac15ee2f1ba", "description": "Descriptif du posteJob SummaryWe are seeking an innovative and results-driven Chief Technology Officer (CTO) to lead the technological strategy and operations specializing in software solutions for treatment implementation and prognosis. As a key member of the executive team, the CTO will spearhead the development of cutting-edge machine learning solutions and a software platform that enhance patient outcomes by enabling personalized treatment plans, precise prognostic assessments and  effective implementation at scale of precision medicine.The ideal candidate will have a strong technical background in machine learning, software development, software engineering and cloud technologies, extensive leadership experience, and the ability to drive innovation in regulated healthcare environments. This role is crucial in positioning the company as a leader in MedTech by delivering scalable, secure, and patient-focused technology solutions that benefit to the patients, physicians . hospitals and healthcare organizations.Key ResponsibilitiesStrategic LeadershipDevelop and execute a technology vision and roadmap focused on a platform for treatment implementation and prognosis.Align technology initiatives with business goals, ensuring innovation drives patient-centric solutions and market competitiveness.Stay ahead of industry trends, guiding the adoption of emerging technologies such as AI/ML and advanced analytics to enhance software capabilities.Product and Technology OversightOversee the design, development, and deployment of scalable, cloud-native software solutions that enable precision treatment workflows and robust prognostic tools.Ensure the security, compliance, and reliability of all software platforms, meeting regulatory requirements such as FDA, HIPAA, and GDPR.Drive software architecture decisions to ensure modularity, scalability, and ease of integration with existing clinical workflows and third-party systems.Team LeadershipBuild and lead a high-performing team of software engineers, cloud architects, and data scientists.Foster a collaborative and innovative culture that emphasizes continuous learning, accountability, and diversity.Mentor teams to adopt agile development practices and cloud-first strategies that accelerate delivery and improve quality.Operational ExcellenceImplement best practices in DevOps, continuous integration/continuous deployment (CI/CD), and software lifecycle management to streamline operations.Establish and monitor KPIs to evaluate the performance, scalability, and usability of software platforms.Drive cost-effective cloud utilization and infrastructure optimization to maximize efficiency.Stakeholder CollaborationPartner with clinical, product management, and regulatory teams to translate complex medical and operational requirements into intuitive, actionable software solutions.Engage with key external stakeholders, including healthcare providers and industry partners, to ensure the relevance and impact of the company’s technology offerings.Act as the primary technical liaison for investors, partners, and customers, articulating the company’s technology vision and progress."}, {"source": "welcometothejungle", "job_title": "Agile Program Manager  (m/f/w)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Dynatrace", "location": "Linz", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": null, "publication_date": "2024-11-29", "company_data": {"sector": "Logiciels, IT / Digital, SaaS / Cloud Services", "company_size": "4700", "creation_date": "2005", "address": null, "average_age_of_employees": "40", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership", "collaboration", "collaboration", "collaboration", "organization"]}, "link": "https://www.welcometothejungle.com/fr/companies/dynatrace/jobs/agile-program-manager-m-f-w_linz_DYNAT_XqDrqlZ?q=bfc932583df57bd893f063f71af02e74&o=ae1843bb-ff95-4a78-b96e-940d9ae2e14c", "description": "Descriptif du posteJob DescriptionAs Agile Program Manager, you'll orchestrate the collaboration of product management and engineering for a customer-facing solution or the core platform of our product.You will foster the creation, prioritization, and predictable realization of the solution roadmap with particular attention to collaboration and dependencies. You aim to be part of the solution leadership team and ensure you always have up-to-date data to report to higher management and facilitate decision-making. In close collaboration with your team, you will roll out and scale agile methods and principles in parts of the organization and continuously optimize them. You will act as driver for cross functional topics as Project Manager.In your daily tasks you will facilitate solution specific meetings and workshops."}, {"source": "welcometothejungle", "job_title": "Agile Program Manager  (m/f/w)", "contract_type": "CDI", "salary": "Non spécifié", "company": "Dynatrace", "location": "Linz", "remote": "Télétravail fréquent", "experience": "> 2", "education_level": null, "publication_date": "2024-11-29", "company_data": {"sector": "Logiciels, IT / Digital, SaaS / Cloud Services", "company_size": "4700", "creation_date": "2005", "address": null, "average_age_of_employees": "40", "turnover_in_millions": null, "proportion_female": null, "proportion_male": null}, "skills": {"ProgLanguage": null, "DataBase": null, "DataAnalytics": null, "BigData": null, "MachineLearning": null, "DataSerialization": null, "DataVisualisation": null, "Statistics": null, "CloudComputing": null, "DevTools": null, "OS": null, "DBMS": null, "SoftBigDataProcessing": null, "Automation": null, "InfrastructureAsCode": null, "NetworkSecurty": null, "Virtualisation": null, "Containers": null, "Collaboration": null, "Other": null, "EnSoftSkils": ["leadership", "collaboration", "collaboration", "collaboration", "organization"]}, "link": "https://www.welcometothejungle.com/fr/companies/dynatrace/jobs/agile-program-manager-m-f-w_linz_DYNAT_XqDrqlZ?q=bfc932583df57bd893f063f71af02e74&o=ae1843bb-ff95-4a78-b96e-940d9ae2e14c", "description": "Descriptif du posteJob DescriptionAs Agile Program Manager, you'll orchestrate the collaboration of product management and engineering for a customer-facing solution or the core platform of our product.You will foster the creation, prioritization, and predictable realization of the solution roadmap with particular attention to collaboration and dependencies. You aim to be part of the solution leadership team and ensure you always have up-to-date data to report to higher management and facilitate decision-making. In close collaboration with your team, you will roll out and scale agile methods and principles in parts of the organization and continuously optimize them. You will act as driver for cross functional topics as Project Manager.In your daily tasks you will facilitate solution specific meetings and workshops."}]