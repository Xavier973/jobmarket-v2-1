[
    {
        "source": "France Travail",
        "link": "https://candidat.francetravail.fr/offres/recherche/detail/0650155",
        "title": "Machine Learning Engineer F/H - Système, réseaux, données (H/F)",
        "company": "TEKKIT.IO ",
        "location": "92",
        "remote": null,
        "publication_date": "2025-01-13",
        "details": {
            "TypeContract": "CDI",
            "Salary": "Salaire brut : A négocier",
            "Experience": "Débutant accepté",
            "Level": null
        },
        "company_data": {
            "sector": "Programmation informatique",
            "company_size": "Tekkit est le réseau social professionnel spécialisé dans les métiers de la tech. La plateforme se concentre sur les offres d'emploi, stages, alternances et missions freelance, tout en mettant l'accent sur les événements et le réseautage pour les professionnels du secteur. Tekkit propose des opportunités d'évolution en facilitant la rencontre avec des entreprises partenaires et en organisant des événements, comme des soirées de recrutement et de networking.\nAvec Tekkit, les ut...",
            "turnover_in_millions": null
        },
        "description": "Descriptif du poste:\n\nDescription de l'entreprise\nNotre raison d'être chez AXA ? Chaque jour, nous agissons ensemble pour le progrès humain en protégeant ce qui compte. Une mission qui donne le sourire et envie de se lever le matin !\n \nUn des leaders mondiaux de l'assurance dans la protection des biens, des personnes et des actifs, AXA c'est 145 000 collaborateurs et contributeurs qui s'engagent au quotidien pour nos clients, c'est 51 pays dans lesquels nous distribuons nos produits et services et plus de 90 millions de client qui nous font confiance dans le monde. Employeur citoyen et responsable, AXA s'engage au quotidien pour des causes sociétales & environnementales. Nous menons une politique inclusive engagée pour reconnaître et valoriser les différences individuelles. Ces ambitions vous parlent ? Alors venez changer le monde avec nous !\n \nVictime ou témoin, en cas de discrimination, vous pouvez adresser vos signalements et/ou alertes discrimination à : xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n \nMissions\nVotre future équipe\nEn tant que Senior Machine Learning Engineer (F/H), vous intégrerez l'AI Factory qui fait partie intégrante de la DATA OFFICE d'AXA France.\nCette AI Factory a pour but d'implémenter et à industrialiser l'intelligence artificielle au coeur des activités d'AXA France.\nL'AI Factory et ses équipes portent et contribuent au Delivery de bout en bout de l'IA, de l'idéation à la mise en production et au monitoring des cas d'usage.\nVous serez au sein d'une équipe delivery composée de Data Scientists et de ML Engineers pour garantir la livraison de produits IA de haute qualité, innovants et alignés à l'état de l'Art du marché.\nVotre rôle et vos missions\nVotre rôle de Machine Learning Engineer est stratégique car il doit permettre à AXA d'accélérer sa transformation en utilisant la data et l'IA comme un levier stratégique.\nVous jouerez un rôle clé dans l'industrialisation des produits IA, le MLOps, la gouvernance de l'IA, la mise en place d'un socle technologique pour l'innovation et le delivery de projets à forte valeur ajoutée pour les business units d'AXA France.\nVous aurez la charge d'accompagner la squad dans le cadrage des projets et dans la mise en place des bonnes pratiques de qualité logicielle et d'architecture, de contribuer à la mise en production automatisée des modèles de Machine Learning en vous assurant du maintien de leur fonctionnement et d'être garant de l'application des pratiques ML OPS.\nEnfin, vous devrez participer à l'amélioration des pratiques ML OPS, de participer à la veille technologique au sein de communautés de pratiques (CoP) et de communiquer / participer à des Meetups et BBLs autours de sujet techniques.\nEn nous rejoignant, vous pourrez profiter et contribuer aux différents évènements du Web Center pour maintenir et améliorer votre technicité tout en transmettant votre savoir (Meetup, BBL, Dojos, Hackathons, Communautés, Conférences, etc.).\n\nProfil recherché:\n\nProfil recherché\nCe dont vous aurez besoin pour réussir\nDe formation supérieure en informatique, vous justifiez de plusieurs expériences significatives en industrialisation de model IA.\nVous disposez de compétences fortes en software engineering et souhaitez les mettre en application dans un contexte riche et challengeant.\nVous maitrisez les technologies PYTHON, PYSPARK, AZURE ML, GIT, KUBERNETES et les pratiques autour de BDD / TDD, CLEAN CODE, DDD, REST & Architecture logicielle/Patterns.\nNice to have\nVous manifestez un intérêt fort pour l'IA et le Machine Learning. Vous participez à une communauté de développeurs, des évènements de type Meetup/ Conférences, vous actif sur les différents réseaux (ex : GitHub, Linkedin...) .\nVous êtes passionné.e de technique et développez vos propres projets personnels.\n\n\n \nNous sommes persuadés que pour bien prendre soin de nos clients, nous devons commencer par bien prendre soin de nos collaborateurs ! Les avantages que nous proposons à nos salariés sont nombreux.\nNous choisir, c'est bénéficier par exemple :\nD'un package de rémunération complet comprenant un salaire fixe, un complément de rémunération variable, des primes, de la participation et de l'intéressement, la possibilité d'acquérir des actions AXA, ou encore des solutions d'épargne avantageuses ;\nD'un cadre de travail flexible jusqu'à 3 jours de télétravail possible par semaine (selon profil du poste), des tickets restaurant pour les jours télétravaillés ou encore une participation à l'achat d'un écran ou fauteuil ergonomique ;\nD'une politique visant à concilier vie personnelle et vie professionnelle avec 28 jours de congés payés, entre 14 et 16 RTT selon les années, des formules de travail à temps partiel ou encore des jours d'absence rémunérées pour la rentrée scolaire ou un déménagement par exemple ;\nDe la possibilité de s'engager pour une"
    }
, {
    "source": "France Travail",
    "link": "https://candidat.francetravail.fr/offres/recherche/detail/0649438",
    "title": "Machine Learning Engineer /X - Les Clayes F/H - Marketing (H/F)",
    "company": "EVIDEN ",
    "location": "78",
    "remote": null,
    "publication_date": "2025-01-13",
    "details": {
        "TypeContract": "CDI",
        "Salary": "Salaire brut : A négocier",
        "Experience": "Expérience exigée de 5 An(s)",
        "Level": null
    },
    "company_data": {
        "sector": "Tierce maintenance de systèmes et d'applications informatiques",
        "company_size": "Eviden regroupe les activités Digital, Cloud, Big Data et Sécurité d'Atos et sera un leader international d'une transformation numérique fiable, durable et basée sur les données. Acteur clé du numérique de prochaine génération et leader mondial du cloud, du calcul avancé et de la sécurité, Eviden fera bénéficier de son expertise l'ensemble des secteurs d'activités, dans plus de 53 pays. L'orchestration de technologies de pointe sur l'ensemble du continuum numérique, combiné...",
        "turnover_in_millions": null
    },
    "description": "Descriptif du poste:\nContexte :Au sein d'Eviden BDS, la Business Line Advanced Computing est responsable des lignes de produits HPC/AI/Quantum et Business computing.\nL'organisation Portfolio & Strategy est responsable des gammes de produits HPC/AI/Quantum, avec des groupes de chefs de produits matériels et logiciels, d'ingénierie produits et performances et de responsables du cycle de vie des produits.\nPour soutenir notre croissance dans le domaine de l'IA et du LLM, nous recherchons un ingénieur en apprentissage automatique - Model Serving (MLEMS) pour concevoir notre pile matérielle et logicielle AI Serving.\n\n\nMissions : Le/la MLEMS sera responsable de : \n* Participer à la sélection de partenaires logiciels et d'outils open source pour le service IA, avec un accent initial sur le service LLM sur GPU. Puis extension à d'autres domaines d'IA et au matériel de service d'IA (CPU, autres) ; \n* Intégrer de manière optimale des produits internes, des partenaires logiciels ou des outils open source d'inférence IA, et notamment d'inférence LLM sur nos serveurs matériels. Cela peut inclure, sans s'y limiter, l'écosystème de bibliothèques Huggingface, KServe, Triton, DeepSpeed, OpenLLM, RayServe, VLLM, TGI, ainsi que des solutions axées sur les cas d'utilisation (par exemple, résumé de texte, chatbots de connaissances) ; \n* Concevoir et configurer des logiciels d'inférence optimisés + des piles matérielles pour les LLM pour GPU et CPU, en tenant compte des performances, du prix et de la consommation d'énergie en étroite relation avec l'équipe de benchmark. Pour cela vous aurez accès à notre portefeuille matériel comprenant des technologies Nvidia, AMD et Intel et autres ainsi que des technologies internes innovantes (refroidissement, interconnexions, etc). \n* Lire et appliquer les idées discutées dans les documents de recherche dans ce domaine, en sélectionnant et en testant des partenaires logiciels et matériels appropriés en exploitant ces idées dans leur pile. \n\nProfil recherché:\nProfil :Qualifications requises: \n* Anglais courant et volonté d'évoluer dans un contexte international ; \n* Expérience pratique dans le déploiement et la surveillance de l'apprentissage automatique (MLOps) avec preuve de réussite de projets dans l'industrie ou le milieu universitaire à l'aide de frameworks tels que PyTorch ou TensorFlow ; \n* Compréhension des transformateurs, LLM ou autres types de modèles de fondation, notamment les modèles open source comme Llama2, Mixtral ou Zephyr. \nQualifications souhaitable : \n* MS. ou un doctorat. en informatique ou dans un domaine connexe ou une vaste expérience professionnelle pertinente ; \n* Expérience dans le déploiement de LLM avec des techniques telles que le parallélisme de modèles, les mécanismes de mise en cache de l'attention, la quantification, le traitement par lots continu, le décodage spéculatif ou la compression ; \n* Expérience dans les frameworks traitant de l'inférence LLM (par exemple, Triton, DeepSpeed, OpenLLM, RayServe, vLLM, TGI, etc.) ; \n* Intérêt démontré pour le suivi et la gouvernance des LLM ; \n* Compétences en matière d'analyse des performances des systèmes et d'analyse comparative. Le MLEMS relèvera directement du vice-président de l'organisation Portfolio & Solutions et en relation étroite avec les chefs de produits et les parties prenantes R&D. Lieu de travail : France (les Clayes) de préférence ou France."
}]